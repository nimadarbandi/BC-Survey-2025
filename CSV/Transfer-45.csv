Yeojin Jeong- Jeesoo Lee- Young-jin Lee- Jiyun Hwang- Sae Byul Lee- Tae-Kyung Yoo- Myeong-Seong Kim- Jae Il Kim- John L Hopper- Tuong L Nguyen- Jong Won Lee- Joohon Sung,Artificial-Intelligence Powered Identification of High-Risk Breast Cancer Subgroups Using Mammography: A Multicenter Study Integrating Automated Brightest Density Measures with Deep Learning Metrics,Breast Cancer is a significant global health challenge- particularly affecting women with higher mortality compared with other cancer types. Timely detection of such cancer types is crucial- and recent research- employing deep learning techniques- shows promise in earlier detection. The research focuses on the early detection of such tumors using mammogram images with deep-learning models. The paper utilized four public databases where a similar amount of 986 mammograms each for three classes (normal- benign- malignant) are taken for evaluation. Herein- three deep CNN models such as VGG-11- Inception v3- and ResNet50 are employed as base classifiers. The research adopts an ensemble method where the proposed approach makes use of the modified Gompertz function for building a fuzzy ranking of the base classification models and their decision scores are integrated in an adaptive manner for constructing the final prediction of results. The classification results of the proposed fuzzy ensemble approach outperform transfer learning models and other ensemble approaches such as weighted average and Sugeno integral techniques. The proposed ResNet50 ensemble network using the modified Gompertz function-based fuzzy ranking approach provides a superior classification accuracy of 98.986%.
W Wang- Y Li- X Yan- M Xiao- M Gao,Breast cancer image classification method based on deep transfer learning,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ By addressing these areas in future research- we aim to build upon our current findings and make further advancements in utilizing deep learning models for breast cancer detection. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
N. Alabi- M. Guillaud- S. El Hallani- F. Inaba- A. Nichol,A Machine-Learning Model to Predict Axillary Node Positivity from Clinical Characteristics and Large-Scale DNA Organization Features in Breast Cancer Biopsy Specimens,A lot of underdeveloped nations particularly in Africa struggle with cancer-related- deadly diseases. Particularly in women- the incidence of breast cancer is rising daily because of ignorance and delayed diagnosis. Only by correctly identifying and diagnosing cancer in its very early stages of development can be effectively treated. The classification of cancer can be accelerated and automated with the aid of computer-aided diagnosis and medical image analysis techniques. This research provides the use of transfer learning from a Residual Network 18 (ResNet18) and Residual Network 34 (ResNet34) architectures to detect breast cancer. The study examined how breast cancer can be identified in breast mammography pictures using transfer learning from ResNet18 and ResNet34- and developed a demo app for radiologists using the trained models with the best validation accuracy. 1- 200 datasets of breast x-ray mammography images from the National Radiological Society's (NRS) archives were employed in the study. The dataset was categorised as implant cancer negative- implant cancer positive- cancer negative and cancer positive in order to increase the consistency of x-ray mammography images classification and produce better features. For the multi-class classification of the images- the study gave an average accuracy for binary classification of benign or malignant cancer cases of 86.7% validation accuracy for ResNet34 and 92% validation accuracy for ResNet18. A prototype web application showcasing ResNet18 performance has been created. The acquired results show how transfer learning can improve the accuracy of breast cancer detection- providing invaluable assistance to medical professionals- particularly in an African scenario.
Yuan Yao- Yang Zhao- Xu Guo- Xiangli Xu- Baiyang Fu- Hao Cui- Jian Xue- Jiawei Tian- Ke Lu- Lei Zhang,Deep Learning for Distinguishing Mucinous Breast Carcinoma From Fibroadenoma on Ultrasound,"Abstract: Breast cancer poses a significant global health threat to women, underscoring the crucial need for reliable and effective screening approaches. The utilization of computer-aided diagnostic (CAD) systems, leveraging mammograms, enables early detection, diagnosis, and treatment of breast cancer, thereby offering vital support in combating this disease. This study introduces a unique deep-learning model that uses transfer learning to identify and categorize breast cancer automatically. Several recent studies have shown that deep convolutional neural networks (DCNNs) can be used to diagnose breast cancer in mammograms with performances comparable to or even superior to those of human experts. The proposed model extracts features from the Mammographic Image Analysis Society (MIAS) dataset using pre-trained convolutional neural network (CNN) architectures such as ResNet50 and VGG-16. This revolutionary deep-learning model has the potential to improve the efficiency and accuracy of breast cancer detection and categorization."
Muniraj Gupta- Nidhi Verma- Naveen Sharma- Satyendra  Narayan Singh- R. K. Brojen Singh- Saurabh Kumar Sharma,Hybrid Deep Transfer Learning Technique for the Classification of Breast Cancer Tumor Histopathology Images,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ over large volumes of histopathological images. Consequently- this increasing trend in artificial intelligence â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ paper focuses on deep learning for breast cancer histopathological image â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Guyomard- AD Bouhnik- L Tassy- ...,Encoding breast cancer patients' medical pathways from reimbursement data using representation learning: a benchmark for clustering tasks,Neoadjuvant chemotherapy (NAC) is a key element of treatment for locally advanced breast cancer (LABC). Predicting the response to NAC for patients with Locally Advanced Breast Cancer (LABC) before treatment initiation could be beneficial to optimize therapy- ensuring the administration of effective treatments. The objective of the work here was to develop a predictive model to predict tumor response to NAC for LABC using deep learning networks and computed tomography (CT). Several deep learning approaches were investigated including ViT transformer and VGG16- VGG19- ResNet-50- Res-Net-101- Res-Net-152- InceptionV3 and Xception transfer learning networks. These deep learning networks were applied on CT images to assess the response to NAC. Performance was evaluated based on balanced_accuracy- accuracy- sensitivity and specificity classification metrics. A ViT transformer was applied to utilize the attention mechanism in order to increase the weight of important part image which leads to better discrimination between classes. Amongst the 117 LABC patients studied- 82 (70%) had clinical-pathological response and 35 (30%) had no response to NAC. The ViT transformer obtained the best performance range (accuracy = 71 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to accuracy = 77 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- specificity = 86 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 76 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 56 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- and balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%) depending on the split ratio of train-data and test-data. Xception network obtained the second best results (accuracy = 72 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to accuracy = 65 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4- specificity = 81 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 73 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 55 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5%- and balanced_accuracy = 66 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5% to balanced_accuracy = 60 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%). The worst results were obtained using VGG-16 transfer learning network. Deep learning networks in conjunction with CT imaging are able to predict the tumor response to NAC for patients with LABC prior to start. A ViT transformer could obtain the best performance- which demonstrated the importance of attention mechanism.
Lu Gan,Research on Prediction Model of Benign and Malignant Breast Cancer Based on Machine Learning,Breast cancer continues to be a major global health issue- emphasizing the importance of precise and prompt detection to enhance the well-being of patients. In this study- a novel approach is proposed for breast cancer detection using transfer learning with the InceptionV3 model. Our research focuses on analyzing histopathology images to classify breast tissue samples as benign or malignant. Additionally- the effectiveness of alternative models- including ResNet- DenseNet- NasNet- and NasNet Mobile- for the same classification task is explored. To train the models- a comprehensive dataset comprising a diverse range of histopathology images is utilizsed. Transfer learning enabled us to leverage the rich representations learned by InceptionV3- ResNet- DenseNet- NasNet- and NasNet Mobile on large-scale image datasets- which greatly expedited the training process and enhanced overall classification performance. Through extensive evaluations- the superior performance of the InceptionV3 model in accurately distinguishing between benign and malignant breast tissue samples is highlighted. The outcomes of this research present a significant step forward in breast cancer detection- showcasing the potential of transfer learning and the utility of InceptionV3 as a robust classifier for histopathology images. The findings also shed light on the comparative performance of alternative deep learning models- providing valuable insights for future research and clinical applications. Ultimately- this study contributes to the ongoing efforts in improving early detection and diagnosis of breast cancer- paving the way for enhanced patient care and outcomes.
SM Thwin- SJ Malebary- AW Abulfaraj- HS Park,Attention-Based Ensemble Network for Effective Breast Cancer Classification over Benchmarks,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ and classification of breast cancer using transfer learning. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ [19] used the DL-CNN for breast cancer classification from â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ -negative breast cancer based on images of primary breast cancer. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Erin J. Kim- Enoch Chung- Bernard T. Lee- Dhruv Singhal,D134. Application of Machine Learning to Predict Breast Cancer Related-lymphedema Development,Introduction: When considering cancer mortality rates in general- Breast Cancer (BC) is a major contributor among females. Patientsâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ chances of survival increase when BC is detected early and treated with the appropriate treatment at the right time. There is strong evidence that mammography- when used as a screening tool- can detect BC at an early stage. Mammography is a diagnostic tool that uses low-dose X-rays to visualise the breast and evaluate its anatomy. For screening purposes- it is currently the preferred method. The present study employs deep learning models trained using Transfer Learning (TL) techniques. Aim: To automate the process of BC diagnosis in mammograms. The main goal of this approach is to simplify the process of early detection and diagnosis of BC for healthcare practitioners. Materials and Methods: The dataset obtained from the Mammographic Image Analysis Society (MIAS) was categorised into three distinct categories: benign- malignant and normal. The initial MIAS dataset underwent several preprocessing techniques- including noise reduction- breast image contrast enhancement- non breast region deletion and malignant lesion identification- before analysis. An intricately designed fully connected classifier complements pretrained Convolutional Neural Network (CNN) architectures like ResNet50 and VGG16 in the proposed model. Results: The VGG16 model performed admirably- achieving an Area Under the Curve (AUC) of 0.950 and an accuracy rate of 96.00%. In addition- it displayed an outstanding F-score of 97%- along with high sensitivity- specificity and accuracy. These outcomes are significantly better compared to the other methods. Conclusion: The modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s enhanced capabilities for early-stage cancer detection could improve patient outcomes and reduce mortality rates. Furthermore- new tools can ease the workload for radiologists- leading to more standardised and efficient diagnostic procedures.
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
Emmanuel Ahishakiye- Fredrick Kanobe,Breast Cancer Classification Using Breast Ultrasound Images with a Hybrid of Transfer Learning and Bayesian-Optimized Fast Learning Network,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ summary based on transformer language model approaches. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ self-attention mechanism within the transformer architecture â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ the shortcomings of traditional deep learning models- such as â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Muniraj Gupta- Nidhi Verma- Naveen Sharma- Satyendra Narayan Singh- R. K. Brojen Singh- Saurabh Kumar Sharma,Deep Transfer Learning Hybrid Techniques for Precision in Breast Cancer Tumor Histopathology Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ development of artificial intelligence- CAD systems utilizing deep learning technology have â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Compared to CNNs- the self-attention mechanism in Transformers exhibits robust global â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Juan Gutierrez-Cardenas,"Breast Cancer Classification through Transfer Learning with Vision Transformer, PCA, and Machine Learning Models",The objective of our study was to explore the feasibility of integrating artificial intelligence (AI) algorithms for breast cancer detection into a portable- point-of-care ultrasound device (POCUS). This proof-of-concept implementation is to demonstrate the platform for integrating AI algorithms into a POCUS device to achieve a performance benchmark of at least 15 frames/second. Our methodology involved the application of five AI models (FasterRCNN+MobileNetV3- FasterRCNN+ResNet50- RetinaNet+ResNet50- SSD300+VGG16- and SSDLite320+MobileNetV3)- pretrained on public datasets of natural images- fine-tuned using a dataset of gelatin-based breast phantom images with both anechoic and hyperechoic lesions- mimicking real tissue characteristics. We created various gelatin-based ultrasound phantoms containing ten simulated lesions- ranging from 4-20 mm in size. Our experimental setup used the Clarius L15 scanning probe- which was connected via Wi-Fi to both a tablet and a laptop- forming the core of our development platform. The phantom data was divided into training- validation- and held-out testing sets on a per-video basis. We executed 200 timing trials for each finetuned AI model- streaming scanning video from the ultrasound probe in real-time. SSDLite320+MobileNetV3 emerged as a standout- showing a mean frame-to-frame timing of 0.068 seconds (SD=0.005)- which is approximately 14.71 FPS- closely followed by FasterRCNN+MobileNetV3- with a mean timing of 0.123 seconds (SD=0.016)- or about 8.13 FPS. Both models show acceptable performance in lesion localization. Compared to our goal of 15 frames/second- only the SSDLite320+MobileNetV3 architecture performed with sufficient evaluation speed to be used in real-time. Our findings show the necessity of using AI architectures designed for edge devices for real-time use- as well as the potential need for hardware acceleration to encode AI models for use in POCUS.
T Xie- A L Huang- L Y Xiang- H C Xue- Z Z Chen- A L Ma- H L Yan- J P Yuan,[Value of the deep learning automated quantification of tumor-stroma ratio in predicting efficacy and prognosis of neoadjuvant therapy for breast cancer based on residual cancer burden grading],Breast cancer is one of the major causes of deaths in women. However- the early diagnosis is important for screening and control the mortality rate. Thus for the diagnosis of breast cancer at the early stage- a computerâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢aided diagnosis system is highly required. Ultrasound is an important examination technique for breast cancer diagnosis due to its low cost. Recently- many learningâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢based techniques have been introduced to classify breast cancer using breast ultrasound imaging dataset (BUSI) datasets; however- the manual handling is not an easy process and time consuming. The authors propose an EfficientNetâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢integrated ResNet deep network and XAIâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢based framework for accurately classifying breast cancer (malignant and benign). In the initial step- data augmentation is performed to increase the number of training samples. For this purpose- threeâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢pixel flip mathematical equations are introduced: horizontal- vertical- and 90Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšâ€ âˆšÂª. Later- two preâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢trained deep learning models were employed- skipped some layers- and fineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢tuned. Both fineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢tuned models are later trained using a deep transfer learning process and extracted features from the deeper layer. Explainable artificial intelligenceâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢based analysed the performance of trained models. After that- a new feature selection technique is proposed based on the cuckoo search algorithm called cuckoo search controlled standard error mean. This technique selects the best features and fuses using a new parallel zeroâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢padding maximum correlated coefficient features. In the end- the selection algorithm is applied again to the fused feature vector and classified using machine learning algorithms. The experimental process of the proposed framework is conducted on a publicly available BUSI and obtained 98.4% and 98% accuracy in two different experiments. Comparing the proposed framework is also conducted with recent techniques and shows improved accuracy. In addition- the proposed framework was executed less than the original deep learning models.
Lin Yan- Zhiying Liang- Hao Zhang- Gaosong Zhang- Weiwei Zheng- Chunguang Han- Dongsheng Yu- Hanqi Zhang- Xinxin Xie- Chang Liu- Wenxin Zhang- Hui Zheng- Jing Pei- Dinggang Shen- Xuejun Qian,A domain knowledge-based interpretable deep learning system for improving clinical breast ultrasound diagnosis,Abstract: Breast cancer (BC) is one of leading cause of cancer death among women. Early detection of this pathology allows to define- for patients- the appropriate treatment which improve the possibility of survival. Consequently- the earlier it is detected- the better the survival rate will be. In last years- big interest has been made on applying deep learning neural networks to BC analysis- detection and classification. Several interesting results have been found but they still needing more improvement and validation. In this frame is located our work which consists on developing and comparing different deep leaning approaches for earlier detection and classification of BC from mammogram images. Different new deep learning techniques are developed resulting on a considerable improvement in the rate of the classification accuracy with more robust models. Simulations are carried out on two data bases illustrating that the new proposed approaches provide significant evaluation metrics in comparison with several commonly known transfer learning architectures.
Lizhe Wang- Yu Wang- Yueyang Li- Li Zhou- Sihan Liu- Yongyi Cao- Yuzhi Li- Shenting Liu- Jiahui Du- Jin Wang- Ting Zhu,A prospective diagnostic model for breast cancer utilizing machine learning to examine the molecular immune infiltrate in HSPB6,Breast cancer (BC) is the most dominant kind of cancer- which grows continuously and serves as the second highest cause of death for women worldwide. Early BC prediction helps decrease the BC mortality rate and improve treatment plans. Ultrasound is a popular and widely used imaging technique to detect BC at an earlier stage. Segmenting and classifying the tumors from ultrasound images is difficult. This paper proposes an optimal deep learning (DL)-based BC detection system with effective pre-trained transfer learning models-based segmentation and feature learning mechanisms. The proposed system comprises five phases: preprocessing- segmentation- feature learning- selection- and classification. Initially- the ultrasound images are collected from the breast ultrasound images (BUSI) dataset- and the preprocessing operations- such as noise removal using the Wiener filter and contrast enhancement using histogram equalization- are performed on the collected data to improve the dataset quality. Then- the segmentation of cancer-affected regions from the preprocessed data is done using a dilated convolution-based U-shaped network (DCUNet). The features are extracted or learned from the segmented images using spatial and channel attention including densely connected convolutional network-121 (SCADN-121). Afterwards- the system applies an enhanced cuckoo search optimization (ECSO) algorithm to select the features from the extracted feature set optimally. Finally- the ECSO-tuned long short-term memory (ECSO-LSTM) was utilized to classify BC into '3' classes- such as normal- benign- and malignant. The experimental outcomes proved that the proposed system attains 99.86% accuracy for BC classification- which is superior to the existing state-of-the-art methods.
Arpana Parihar- Kritika Gaur- Paromita Sarbadhikary,Advanced 2D Nanomaterials for Phototheranostics of Breast Cancer: A Paradigm Shift,Breast cancer is a worldwide fatal disease that exists mostly among women. The deep learning technique has proven its effectiveness- but the performance of the existing deep learning systems is quite compromising. In this work- a deep transfer learning system is suggested for efficient breast cancer classification from histopathology images. This system is based on a novel multiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢level progressive feature aggregation (MPFA) and a spatial domain learning approach. The combination of a pretrained Resnet101 backbone network with MPFA is implemented to extract more significant features. In addition- a mixedâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢dilated spatial domain learning network (MSLN) is further incorporated to enhance the receptive field and increase discrimination between features. The proposed method achieved superior performance as compared to the existing stateâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ofâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢theâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢art methods- offering 99.24% accuracy- a 98.79% Fâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢1 score- 98.59% precision- and 98.99% recall values over BreaKHis dataset. An ablation study is carried out over the ICIAR2018 dataset to verify the generalizability and effectiveness of the system.
Wei Wang- Lei Liu- Jianxiong Zhu- Youqiang Xing- Songlong Jiao- Ze Wu,AI-Enhanced Visual-Spectral Synergy for Fast and Ultrasensitive Biodetection of Breast Cancer-Related miRNAs.,Breast cancer is a dangerous disease- contributing to a high mortality rate in women. Early detection plays a pivotal role in enhancing survival rates. Breast ultrasound is considered an effective method to help diagnose breast diseases early. Breast ultrasound is inexpensive- easy to perform- non-invasive and painless- so it is often prescribed by doctors in cases where it is necessary to examine the nature of clinically palpable lesions or related symptoms in the breast. In this paper- we introduce a method based on transfer learning and deep feature fusion to classify breast cancer using ultrasound images. The results from our experiments involving 780 breast ultrasound images across three categories (benign- malignant- and normal) indicated that the model using max fusion of deep features outperformed an original CNN in terms of performance- the combination of the maximum value between deep features has a higher performance level with an accuracy of about 1% to 4% compared to the original model. The concatenation fusion of VGG19 and ViT features delivers 1% - 4% times more accuracy than the original model alone
Aslâ€šÃ Ãœâˆšâ‰ Â¬Â¨Â¬Â±nur Albayrak- Kayhan Nuri Cengiz,Assessment of breast cancer awareness among female pharmacy students at a university in Turkey,Breast cancer remains a pressing global health concern- necessitating accurate diagnostics for effective interventions. Deep learning models (AlexNet- ResNet-50- VGG16- GoogLeNet) show remarkable microcalcification identification (>90%). However- distinct architectures and methodologies pose challenges. We propose an ensemble model- merging unique perspectives- enhancing precision- and understanding critical factors for breast cancer intervention. Evaluation favors GoogleNet and ResNet-50- driving their selection for combined functionalities- ensuring improved precision- and dependability in microcalcification detection in clinical settings. This study presents a comprehensive mammogram preprocessing framework using an optimized deep learning ensemble approach. The proposed framework begins with artifact removal using Otsu Segmentation and morphological operation. Subsequent steps include image resizing- adaptive median filtering- and deep convolutional neural network (D-CNN) development via transfer learning with ResNet-50 model. Hyperparameters are optimized- and ensemble optimization (AlexNet- GoogLeNet- VGG16- ResNet-50) are constructed to identify the localized area of microcalcification. Rigorous evaluation protocol validates the efficacy of individual models- culminating in the ensemble model demonstrating superior predictive accuracy. Based on our analysis- the proposed ensemble model exhibited exceptional performance in the classification of microcalcifications. This was evidenced by the model's average confidence score- which indicated a high degree of dependability and certainty in differentiating these critical characteristics. The proposed model demonstrated a noteworthy average confidence level of 0.9305 in the classification of microcalcification- outperforming alternative models and providing substantial insights into the dependability of the model. The average confidence of the ensemble model in classifying normal cases was 0.8859- which strengthened the model's consistent and dependable predictions. In addition- the ensemble models attained remarkably high performances in terms of accuracy- precision- recall- F1-score- and area under the curve (AUC). The proposed model's thorough dataset integration and focus on average confidence ratings within classes improve clinical diagnosis accuracy and effectiveness for breast cancer. This study introduces a novel methodology that takes advantage of an ensemble model and rigorous evaluation standards to substantially improve the accuracy and dependability of breast cancer diagnostics- specifically in the detection of microcalcifications.
Yiqi Sun- Bohan Wan- Xin Liu- Jianguo Dong- Shengjie Yin- Yiqi Wu,Breast cancer and neoplasms of the thyroid gland: a bidirectional two-sample Mendelian randomization study,Small cohorts of certain disease states are common especially in medical imaging. Despite the growing culture of data sharing- information safety often precludes open sharing of these datasets for creating generalizable machine learning models. To overcome this barrier and maintain proper health information protection- foundational models are rapidly evolving to provide deep learning solutions that have been pretrained on the native feature spaces of the data. Although this has been optimized in Large Language Models (LLMs)- there is still a sparsity of foundational models for computer vision tasks. It is in this space that we provide an investigation into pretraining Visual Geometry Group (VGG)-16- Residual Network (ResNet)-50- and Dense Network (DenseNet)-121 on an unrelated dataset of 8500 chest CTs which was subsequently fine-tuned to classify bone mineral density (BMD) in 199 breast cancer patients using the L1 vertebra on CT. These semi-foundational models showed significant improved ternary classification into mild- moderate- and severe demineralization in comparison to ground truth Hounsfield Unit (HU) measurements in trabecular bone with the semi-foundational ResNet50 architecture demonstrating the best relative performance. Specifically- the holdout testing AUC was 0.99 (p-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.05- ANOVA versus no pretraining versus ImageNet transfer learning) and F1-score 0.99 (p-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.05) for the holdout testing set. In this study- the use of a semi-foundational model trained on the native feature space of CT provided improved classification in a completely disparate disease state with different window levels. Future implementation with these models may provide better generalization despite smaller numbers of a disease state to be classified.
S R Sannasi Chakravarthy- N Bharanidharan- V Vinoth Kumar- T R Mahesh- Mohammed S Alqahtani- Suresh Guluwadi,Deep transfer learning with fuzzy ensemble approach for the early detection of breast cancer,The efficacy of immune checkpoint inhibitors is significantly influenced by the tumor immune microenvironment (TIME). RNA sequencing of tumor tissue can offer valuable insights into TIME- but its high cost and long turnaround time seriously restrict its utility in routine clinical examinations. Several recent studies have suggested that ultrahigh-resolution pathology images can infer cellular and molecular characteristics. However- few study pay attention to the quantitative estimation of various tumor infiltration immune cells from pathology images. In this paper- we integrated contrastive learning and weakly supervised learning to infer tumor-associated macrophages and potential immunotherapy benefit from whole slide images (WSIs) of H &E stained pathological sections. We split the high-resolution WSIs into tiles and then apply contrastive learning to extract features of each tile. After aggregating the features at the tile level- we employ weak supervisory signals to fine-tune the encoder for various downstream tasks. Comprehensive experiments on two independent breast cancer cohorts and spatial transcriptomics data demonstrate that the computational pathological features accurately predict the proportion of tumor-infiltrating immune cells- particularly the infiltration level of macrophages- as well as the immune subtypes and potential immunotherapy benefit. These findings demonstrate that our model effectively captures pathological features beyond human vision- establishing a mapping relationship between cellular compositions and histological morphology- thus expanding the clinical applications of digital pathology images.
Hea Lim Choi- Su Min Jeong- Keun Hye Jeon- Bongseong Kim- Wonyoung Jung- Ansuk Jeong- Kyungdo Han- Dong Wook Shin,Depression risk among breast cancer survivors: a nationwide cohort study in South Korea,Photoacoustic tomography (PAT) has emerged as a promising imaging modality for breast cancer detection- offering unique advantages in visualizing tissue composition without ionizing radiation. However- limited-view scenarios in clinical settings present significant challenges for image reconstruction quality and computational efficiency. This paper introduces novel unrolled deep learning networks based on split Bregman total variation (SBTV) and relaxed basis pursuit alternating direction method of multipliers (rBP-ADMM) algorithms to address these challenges. Our approach combines transfer learning from full-view to limited-view scenarios with U-Net denoiser integration- achieving state-of-the-art reconstruction quality (MS-SSIM> 0.95) while reducing reconstruction time by 92% compared to traditional methods. The effectiveness of different sensor configurations is analyzed through restricted isometry property (RIP) analysis and coherence values- demonstrating that semicircular arrays achieve a RIP constant of 0.76 and coherence of 0.77- closely approximating full-view performance (RIP: 0.75- coherence: 0.78). These metrics validate the theoretical foundation for accurate sparse signal recovery in limited-view scenarios. Comprehensive evaluations across semicircular- concave- and convex sensor arrangements show that the proposed U-SBTV network consistently outperforms existing methods- particularly when combined with the U-Net denoiser. This advancement in limited-view PAT reconstruction brings the technology closer to practical clinical application- potentially improving early breast cancer detection capabilities.
Shahad Awadelkarim,Feature Selection using Extra Trees for Breast Cancer Prediction,Breast cancer continues to pose a significant global health challenge- emphasizing the need for advancements in early detection methods. This study explores the application of transfer learning techniques- specifically utilizing EfficientNet- to enhance the accuracy of breast cancer detection through medical imaging. Leveraging a dataset of mammography images from the Digital Database for Screening Mammography (DDSM)- the research implements various data preprocessing methods- including median filtering- contrast enhancement- and artifact removal- to ensure the quality of input data. The EfficientNet model- trained with these preprocessed images- is evaluated against other transfer learning architectures- such as DenseNet and ResNeXt50- using metrics like accuracy- AUC- precision- and F1-score. The results demonstrate that EfficientNet outperforms other models- achieving an accuracy of 95.23%- with a sensitivity of 96.67% and specificity of 93.82%. These findings suggest that transfer learning- particularly with EfficientNet- can significantly improve the predictive accuracy of breast cancer detection- offering a reliable tool for early diagnosis and personalized treatment planning. The study also discusses the potential integration of these models into clinical workflows- addressing challenges such as data privacy- model generalizability- and clinical applicability. Future research will focus on expanding the dataset and exploring the use of other advanced deep learning techniques to further enhance detection accuracy and robustness.
Ko Un Park- Stuart R. Lipsitz- L. Dominici- F. Lynce- Christina A. Minami- F. Nakhlis- Adrienne G. Waks- Laura E. Warren- Nadine Eidman- Jeannie Frazier- Lourdes Hernandez- Carla Leslie- Susan Rafte- Delia Stroud- J. Weissman- T. King- E. Mittendorf,Generative artificial intelligence as a source of breast cancer information for patients: Proceed with caution.,<title>Abstract</title> <p>Breast cancer is one of the most prevalent causes of cancer-related death globally. Preliminary diagnosis of breast cancer increases the patient's chances of survival and healing. In this paper- we propose a hybrid deep transfer learning model integrating xception with support vector classifier (XSV) and xception with random forest (XRF) along with pre-processing technique to classify breast cancer as cancerous (malignant) or non-cancerous (benign) along comparative analysis of prominent machine learning classifiers- such as Random Forest Classifier (RFC)- Logistic Regression (LR)- Support Vector Classifier (SVC)- K-Nearest Neighbors (K-NN)- and Ada-boost. In experiment all the models are implemented on two openly accessible datasets: BreakHis and Breast Histopathology Images Database (BHID) across various metrics such as accuracy- area under the receiver operating curve- precision- recall- f1-score- Matthew's correlation coefficient- classification success index- and kappa at different magnification levels of images. Our proposed model that utilized the fine tuning of xception model in conjunction with RFC and SVC- surpass existing breast cancer classification methodologies. Specifically- the XSV that achieved accuracies of 89.26%- 85.87%- 90.17%- and 88.98%- while the XRF attained accuracies of 87.78%- 84.78%- 88.98%- and 87.61% for BreakHis at 40X- 100X- 200X- and 400X magnifications- respectively. For BHID at 40X magnification- the XSV and XRF models achieved accuracies of 87.35% and 87.29%- respectively. Employing this study will aid our medical practitioners and researchers in choosing an accurate model for tumor classification and our results will help medical professionals to classify the disease with precision.</p>
Yushu Ma- Chien-Hung Shih- Jinxiong Cheng- Hsiao-Chun Chen- Li-Ju Wang- Yanhao Tan- Yu-Chiao Chiu- Yu-Chih Chen,High-Throughput Empirical and Virtual Screening to Discover Novel Inhibitors of Polyploid Giant Cancer Cells in Breast Cancer,Breast cancer (BC) is a type of cancer which progresses and spreads from breast tissues and gradually exceeds the entire body; this kind of cancer originates in both sexes. Prompt recognition of this disorder is most significant in this phase- and it is measured by providing patients with the essential treatment so their efficient lifetime can be protected. Scientists and researchers in numerous studies have initiated techniques to identify tumours in early phases. Still- misperception in classifying skeptical lesions can be due to poor image excellence and dissimilar breast density. BC is a primary health concern- requiring constant initial detection and improvement in analysis. BC analysis has made major progress recently with combining multi-modal image modalities.Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ These studies deliver an overview of the segmentation- classification- or grading of numerous cancer types- including BC- by employing conventional machine learning (ML) models over hand-engineered features. Therefore- this study uses multi-modality medical imaging to propose a Computer Vision with Fusion Joint Transfer Learning for Breast Cancer Diagnosis (CVFBJTL-BCD) technique. The presented CVFBJTL-BCD technique utilizes feature fusion and DL models to effectively detect and identify BC diagnoses. The CVFBJTL-BCD technique primarily employs the Gabor filtering (GF) technique for noise removal. Next- the CVFBJTL-BCD technique uses a fusion-based joint transfer learning (TL) process comprising three models- namely DenseNet201- InceptionV3- and MobileNetV2. The stacked autoencoders (SAE) model is implemented to classify BC diagnosis. Finally- the horse herd optimization algorithm (HHOA) model is utilized to select parameters involved in the SAE method optimally. To demonstrate the improved results of the CVFBJTL-BCD methodology- a comprehensive series of experimentations are performed on two benchmark datasets. The comparative analysis of the CVFBJTL-BCD technique portrayed a superior accuracy value of 98.18% and 99.15% over existing methods under Histopathological and Ultrasound datasets.
Massimiliano Berretta- Daniele Garozzo- Calogero Foti- Mario Roselli- Marco Materazzo- Giulia Vita- Ferdinando Iellamo- Marco Scordari- Giordana Di Mauro- Giovanna Spatari- Alessandro Ottaiano- Annalisa Noce- Marco Pellicciaro- Alessia Bignucolo- Gianluca Vanni- Oreste Claudio Buonomo,Implementing fencing as adapted physical activity in non-metastatic breast cancer patients: design and early rehabilitation strategy of the FENICE study protocol,Background: Breast cancer is one of the most lethal cancers among women. Early detection and proper treatment reduce mortality rates. Histopathological images provide detailed information for diagnosing and staging breast cancer disease. Methods: The BreakHis dataset- which includes histopathological images- is used in this study. Medical images are prone to problems such as different textural backgrounds and overlapping cell structures- unbalanced class distribution- and insufficiently labeled data. In addition to these- the limitations of deep learning models in overfitting and insufficient feature extraction make it extremely difficult to obtain a high-performance model in this dataset. In this study- 20 state-of-the-art models are trained to diagnose eight types of breast cancer using the fine-tuning method. In addition- a comprehensive experimental study was conducted to determine the most successful new model- with 20 different custom models reported. As a result- we propose a novel model called MultiHisNet. Results: The most effective new model- which included a pointwise convolution layer- residual link- channel- and spatial attention module- achieved 94.69% accuracy in multi-class breast cancer classification. An ensemble model was created with the best-performing transfer learning and custom models obtained in the study- and model weights were determined with an Equilibrium Optimizer. The proposed ensemble model achieved 96.71% accuracy in eight-class breast cancer detection. Conclusions: The results show that the proposed model will support pathologists in successfully diagnosing breast cancer.
Christiana Subaar- Fosberg Tweneboah Addai- Eric Clement Kotei Addison- Olivia Christos- Joseph Adom- Martin Owusu-Mensah- Nelson Appiah-Agyei- Shadrack Abbey,Investigating the detection of breast cancer with deep transfer learning using ResNet18 and ResNet34,A novel nomogram incorporating artificial intelligence (AI) and clinical features for enhanced ultrasound prediction of benign and malignant breast masses. This study analyzed 340 breast masses identified through ultrasound in 308 patients. The masses were divided into training (n = 260) and validation (n = 80) groups. The AI-based analysis employed the Samsung Ultrasound AI system (S-detect). Univariate and multivariate analyses were conducted to construct nomograms using logistic regression. The AI-Nomogram was based solely on AI results- while the ClinAI- Nomogram incorporated additional clinical factors. Both nomograms underwent internal validation with 1000 bootstrap resamples and external validation using the independent validation group. Performance was evaluated by analyzing the area under the receiver operating characteristic (ROC) curve (AUC) and calibration curves. The ClinAI-Nomogram- which incorporates patient age- AI-based mass size- and AI-based diagnosis- outperformed an existing AI-Nomogram in differentiating benign from malignant breast masses. The ClinAI-Nomogram surpassed the AI-Nomogram in predicting malignancy with significantly higher AUC scores in both training (0.873- 95% CI: 0.830-0.917 vs. 0.792- 95% CI: 0.748-0.836; p = 0.016) and validation phases (0.847- 95% CI: 0.763-0.932 vs. 0.770- 95% CI: 0.709-0.833; p < 0.001). Calibration curves further revealed excellent agreement between the ClinAI-Nomogram's predicted probabilities and actual observed risks of malignancy. The ClinAI- Nomogram- combining AI alongside clinical data- significantly enhanced the differentiation of benign and malignant breast masses in clinical AI-facilitated ultrasound examinations.
Sang Won Park- Ye-Lin Park- Eun-Gyeong Lee- Heejung Chae- Phillip Park- Dong-Woo Choi- Yeon Ho Choi- Juyeon Hwang- Seohyun Ahn- Keunkyun Kim- Woo Jin Kim- Sun-Young Kong- So-Youn Jung- Hyun-Jin Kim,Mortality Prediction Modeling for Patients with Breast Cancer Based on Explainable Machine Learning,Background/Objectives: Breast cancer is a leading cause of mortality among women in Taiwan and globally. Non-invasive imaging methods- such as mammography and ultrasound- are critical for early detection- yet standalone modalities have limitations in regard to their diagnostic accuracy. This study aims to enhance breast cancer detection through a cross-modality fusion approach combining mammography and ultrasound imaging- using advanced convolutional neural network (CNN) architectures. Materials and Methods: Breast images were sourced from public datasets- including the RSNA- the PAS- and Kaggle- and categorized into malignant and benign groups. Data augmentation techniques were used to address imbalances in the ultrasound dataset. Three models were developed: (1) pre-trained CNNs integrated with machine learning classifiers- (2) transfer learning-based CNNs- and (3) a custom-designed 17-layer CNN for direct classification. The performance of the models was evaluated using metrics such as accuracy and the Kappa score. Results: The custom 17-layer CNN outperformed the other models- achieving an accuracy of 0.964 and a Kappa score of 0.927. The transfer learning model achieved moderate performance (accuracy 0.846- Kappa 0.694)- while the pre-trained CNNs with machine learning classifiers yielded the lowest results (accuracy 0.780- Kappa 0.559). Cross-modality fusion proved effective in leveraging the complementary strengths of mammography and ultrasound imaging. Conclusions: This study demonstrates the potential of cross-modality imaging and tailored CNN architectures to significantly improve diagnostic accuracy and reliability in breast cancer detection. The custom-designed model offers a practical solution for early detection- potentially reducing false positives and false negatives- and improving patient outcomes through timely and accurate diagnosis.
Yini Li- Cao Li- Tao Yang- Lingzhi Chen- Mingquan Huang- Lu Yang- Shuxian Zhou- Huaqing Liu- Jizhu Xia- Shijie Wang,Multiview deep learning networks based on automated breast volume scanner images for identifying breast cancer in BI-RADS 4,Single-vesicle molecular profiling of cancer-associated extracellular vesicles (EVs) is increasingly being recognized as a powerful tool for cancer detection and monitoring. Mask and target dual imaging is a facile method to quantify the fraction of the molecularly targeted population of EVs in biofluids at the single-vesicle level. However- accurate and efficient dual imaging vesicle analysis has been challenging due to the interference of false signals on the mask images and the need to analyze a large number of images in clinical samples. In this work- we report a fully automatic dual imaging analysis method based on machine learning and use it with dual imaging single-vesicle technology (DISVT) to detect breast cancer at different stages. The convolutional neural network Resnet34 was used along with transfer learning to produce a suitable machine learning model that could accurately identify areas of interest in experimental data. A combination of experimental and synthetic data were used to train the model. Using DISVT and our machine learning-assisted image analysis platform- we determined the fractions of EpCAM-positive EVs and CD24-positive EVs over captured plasma EVs with CD81 marker in the blood plasma of pilot HER2-positive breast cancer patients and compared to those from healthy donors. The amount of both EpCAM-positive and CD24-positive EVs was found negligible for both healthy donors and Stage I patients. The amount of EpCAM-positive EVs (also CD81-positive) increased from 18% to 29% as the cancer progressed from Stage II to III. No significant increase was found with further progression to Stage IV. A similar trend was found for the CD24-positive EVs. Statistical analysis showed that both EpCAM and CD24 markers can detect HER2-positive breast cancer at Stages II- III- or IV. They can also differentiate individual cancer stages except those between Stage III and Stage IV. Due to the simplicity- high sensitivity- and high efficiency- the DISVT with the AI-assisted dual imaging analysis can be widely used for both basic research and clinical applications to quantitatively characterize molecularly targeted EV subtypes in biofluids.
Jung In Park- Steven Johnson- Lisiane Pruinelli,Optimizing pain management in breast cancer care: Utilizing 'All of Us' data and deep learning to identify patients at elevated risk for chronic pain,Segmentation is a technique for separating an image into discrete areas in order to separate objects of interest from their surroundings. In image analysis- segmentationâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶âˆšÃœwhich encompasses detection- feature extraction- classification- and treatmentâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶âˆšÃœis crucial. In order to plan treatments- segmentation aids doctors in measuring the amount of tissue in the breast. Categorizing the input data into two groups that are mutually exclusive is the aim of a binary classification problem. In this case- the training data is labeled in a binary format based on the problem being solved. Identifying breast lumps accurately in mammography pictures is essential for the purpose of prenatal testing for breast cancer. The proposed TLA (Transfer Learning Approach) based CNN (Convolution Neural Network) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®TLA based CNN aims to offer binary classification for rapid and precise breast cancer diagnosis (benign and malignant). In order to predict the sub-type of cancer- this exploration as used Deep Learning techniques on the Histogram of Oriented Gradient (HOG) - Feature extraction technique that creates a local histogram of the image to extract features from each place in the image with CNN classifier. This research work employs two well-known pre-trained models- ResNet-50 and VGG16- to extract characteristics from mammography images. The high-level features from the Mammogram dataset are extracted using a transfer learning model based on Visual Geometry Group (VGG) with 16-layer and Residual Neural Network with 50-layers deep model architecture (ResNet-50). The proposed model TLA based CNN has achieved 96.49% and 95.48% accuracy as compared to ResNet50 and VGG16 in the breast cancer classification and segmentation.
Andreas Ekholm- Yinxi Wang- Johan Vallon-Christersson- Constance Boissin- Mattias Rantalainen,Prediction of gene expression-based breast cancer proliferation scores from histopathology whole slide images using deep learning,Breast cancer is a leading cause of death among women- and early detection is crucial for improving survival rates. The manual breast cancer diagnosis utilizes more time and is subjective. Also- the previous CAD models mostly depend on manmade visual details that are complex to generalize across ultrasound images utilizing distinct techniques. Distinct imaging tools have been utilized in previous works such as mammography and MRI. However- these imaging tools are costly and less portable than ultrasound imaging. Also- ultrasound imaging is a non-invasive method commonly used for breast cancer screening. Hence- the paper presents a novel deep learning model- BCDNet- for classifying breast tumors as benign or malignant using ultrasound images. The primary aim of the study is to design an effective breast cancer diagnosis model that can accurately classify tumors in their early stages- thus reducing mortality rates. The model aims to optimize the weight and parameters using the RPAOSM-ESO algorithm to enhance accuracy and minimize false negative rates. The BCDNet model utilizes transfer learning from a pre-trained VGG16 network for feature extraction and employs an AHDNAM classification approach- which includes ASPP- DTCN- 1DCNN- and an attention mechanism. The RPAOSM-ESO algorithm is used to fine-tune the weights and parameters. The RPAOSM-ESO-BCDNet-based breast cancer diagnosis model provided 94.5 accuracy rates. This value is relatively higher than the previous models such as DTCN (88.2)- 1DCNN (89.6)- MobileNet (91.3)- and ASPP-DTC-1DCNN-AM (93.8). Hence- it is guaranteed that the designed RPAOSM-ESO-BCDNet produces relatively accurate solutions for the classification than the previous models. The BCDNet model- with its sophisticated feature extraction and classification techniques optimized by the RPAOSM-ESO algorithm- shows promise in accurately classifying breast tumors using ultrasound images. The study suggests that the model could be a valuable tool in the early detection of breast cancer- potentially saving lives and reducing the burden on healthcare systems.
Morteza Rakhshaninejad- Mohammad Fathian- Reza Shirkoohi- F. Barzinpour- Amir H. Gandomi,Refining breast cancer biomarker discovery and drug targeting through an advanced data-driven approach,Objectives: The research aims to enhance breast cancer detection accuracy and effectiveness using deep transfer learning and pre-trained neural networks. It analyses breast ultrasound images and identifies important characteristics using pre-trained networks. The goal is to create a more efficient and accurate automated system for breast cancer detection. Methods: The study uses breast ultrasound cancer image data from the Kaggle Data Repository to extract informative features- identify cancer-related characteristics- and classify them into benign- malignant- and normal tissue. Pre-trained Deep Neural Networks (DNNs) extract these features and feed them into a 10-fold cross-validation SVM classifier. The SVM is evaluated using various kernel functions to identify the best kernel for separating data points. This methodology aims to achieve accurate classification of breast cancer in ultrasound images. Findings: The study confirms the effectiveness of deep transfer learning for breast cancer detection in ultrasound images- with Inception V3 outperforming VGG-16 and VGG-19 in extracting relevant features. The combination of Inception V3 and the SVM classifier with a polynomial kernel achieved the highest classification accuracy- indicating its ability to model complex relationships. The study demonstrated an AUC of 0.944 and a classification accuracy of 87.44% using the Inception V3 + SVM polynomial. Novelty: This research demonstrates the potential of deep transfer learning and SVM classifiers for accurate breast cancer detection in ultrasound images. It integrates Inception V3- VGG-16- and VGG-19 for breast cancer detection- demonstrating improved classification accuracy. The combination of Inception V3 and SVM (polynomial) achieved a significant AUC (0.944) and classification accuracy (87.44%)- outperforming other models tested. This research underscores the potential of these technologies for accurate breast cancer detection in ultrasound images. Keywords: Breast Cancer- Deep Learning- Feature Extraction- Inception-v3- SVM- Transfer Learning
Xuefeng Fu- Yang Jiao- Yao Feng- Fengwei Lin- Bing Zhang- Qing Mao- Jiahui Wang- Wen Jiang- Yanhua Mou- Han Wang- Shaojie Wang,Scaffold Hopping of Pristimerin Provides Derivatives Containing a Privileged Quinoxaline Substructure as Potent Autophagy Inducers in Breast Cancer Cells,Digital Breast Tomosynthesis (DBT) has revolutionized more traditional breast imaging through its three-dimensional (3D) visualization capability that significantly enhances lesion discernibility- reduces tissue overlap- and improves diagnostic precision as compared to conventional two-dimensional (2D) mammography. In this study- we propose an advanced Computer-Aided Detection (CAD) system that harnesses the power of vision transformers to augment DBT's diagnostic efficiency. This scheme uses a neural network to glean attributes from the 2D slices of DBT followed by post-processing that considers features from neighboring slices to categorize the entire 3D scan. By leveraging a transfer learning technique- we trained and validated our CAD framework on a unique dataset consisting of 3-831 DBT scans and subsequently tested it on 685 scans. Of the architectures tested- the Swin Transformer outperformed the ResNet101 and vanilla Vision Transformer. It achieved an impressive AUC score of 0.934 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 0.026 at a resolution of 384 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 384. Increasing the image resolution from 224 to 384 not only maintained vital image attributes but also led to a marked improvement in performance (p-value = 0.0003). The Mean Teacher algorithm- a semi-supervised method using both labeled and unlabeled DBT slices- showed no significant improvement over the supervised approach. Comprehensive analyses across different lesion types- sizes- and patient ages revealed consistent performance. The integration of attention mechanisms yielded a visual narrative of the model's decision-making process that highlighted the prioritized regions during assessments. These findings should significantly propel the methodologies employed in DBT image analysis by setting a new benchmark for breast cancer diagnostic precision.
Shengnan Hao- Yihan Jia- Jianuo Liu- Zhiwu Wang- Chunling Liu- Zhanlin Ji- Ivan Ganchev,ST-Double-Net: A Two-Stage Breast Tumor Classification Model Based on Swin Transformer and Weakly Supervised Target Localization,"The Deep learning (DL) models for diagnosing breast cancer from mammographic images often operate as""black boxes""- making it difficult for healthcare professionals to trust and understand their decision-making processes. The study presents an integrated framework combining Convolutional Neural Networks (CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an elaborate data preprocessing pipeline and advanced data augmentation techniques to counteract dataset limitations and transfer learning using pre-trained networks such as VGG-16- Inception-V3 and ResNet was employed. A focal point of our study is the evaluation of XAI's effectiveness in interpreting model predictions- highlighted by utilizing the Hausdorff measure to assess the alignment between AI-generated explanations and expert annotations quantitatively. This approach is critical for XAI in promoting trustworthiness and ethical fairness in AI-assisted diagnostics. The findings from our research illustrate the effective collaboration between CNNs and XAI in advancing diagnostic methods for breast cancer- thereby facilitating a more seamless integration of advanced AI technologies within clinical settings. By enhancing the interpretability of AI driven decisions- this work lays the groundwork for improved collaboration between AI systems and medical practitioners- ultimately enriching patient care. Furthermore- the implications of our research extended well beyond the current methodologies. It encourages further research into how to combine multimodal data and improve AI explanations to meet the needs of clinical practice."
Olya Rezaeian- Onur Asan- A. E. Bayrak,The Impact of AI Explanations on Clinicians Trust and Diagnostic Accuracy in Breast Cancer,Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer. Breast tissue histopathological examination is critical in diagnosing and classifying breast cancer. Although existing methods have shown promising results- there is still room for improvement in the classification accuracy and generalization of IDC using histopathology images. We present a novel approach- Supervised Contrastive Vision Transformer (SupCon-ViT)- for improving the classification of invasive ductal carcinoma in terms of accuracy and generalization by leveraging the inherent strengths and advantages of both transfer learning- i.e.- pre-trained vision transformer- and supervised contrastive learning. Our results on a benchmark breast cancer dataset demonstrate that SupCon-ViT achieves state-of-the-art performance in IDC classification- with an F1-score of 0.8188- precision of 0.7692- and specificity of 0.8971- outperforming existing methods. In addition- the proposed model demonstrates resilience in scenarios with minimal labeled data- making it highly efficient in real-world clinical settings where labeled data is limited. Our findings suggest that supervised contrastive learning in conjunction with pre-trained vision transformers appears to be a viable strategy for an accurate classification of IDC- thus paving the way for a more efficient and reliable diagnosis of breast cancer through histopathological image analysis.
Eleonore Baum- Daniela Bernhardsgrâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Â´tter- Ramona Engst- Carola Maurer- Jessica Ebneter- Adrienne Zenklusen- Barbara Wartlsteiner- Lotti Barandun- Andrea Neher- Antje Koller- Andrea Kobleder,The meaning of trust along the treatment pathway of women with breast cancer: a mixed-methods study among cancer survivors,Objective Early diagnosis of breast cancer can lead to effective treatment- possibly increase long-term survival rates- and improve quality of life. The objective of this study is to present an automated analysis and classification system for breast cancer using clinical markers such as tumor shape- orientation- margin- and surrounding tissue. The novelty and uniqueness of the study lie in the approach of considering medical features based on the diagnosis of radiologists. Methods Using clinical markers- a graph is generated where each feature is represented by a node- and the connection between them is represented by an edge which is derived through Pearson's correlation method. A graph convolutional network (GCN) model is proposed to classify breast tumors into benign and malignant- using the graph data. Several statistical tests are performed to assess the importance of the proposed features. The performance of the proposed GCN model is improved by experimenting with different layer configurations and hyper-parameter settings. Results Results show that the proposed model has a 98.73% test accuracy. The performance of the model is compared with a graph attention network- a one-dimensional convolutional neural network- and five transfer learning models- ten machine learning models- and three ensemble learning models. The performance of the model was further assessed with three supplementary breast cancer ultrasound image datasets- where the accuracies are 91.03%- 94.37%- and 89.62% for Dataset A- Dataset B- and Dataset C (combining Dataset A and Dataset B) respectively. Overfitting issues are assessed through k-fold cross-validation. Conclusion Several variants are utilized to present a more rigorous and fair evaluation of our work- especially the importance of extracting clinically relevant features. Moreover- a GCN model using graph data can be a promising solution for an automated feature-based breast image classification system.
Pritpal Singh- Rakesh Kumar- Meenu Gupta- Ahmed J. Obaid,Transfer Learning based Breast Cancer Classification using Histopathology Images,BACKGROUND The aim of this study is an improved understanding of drug distribution in brain metastases. Rather than single point snapshots- we analyzed the time course and route of drug/probe elimination (clearance)- focusing on the Intramural Periarterial Drainage (IPAD) pathway. METHODS Mice with JIMT1-BR HER2+ experimental brain metastases were injected with biocytin-TMR and either trastuzumab or human IgG. Drugs/probes circulated for 5 min-48h- followed by perfusion. Brain sections were stained for human IgG- vascular basement membrane proteins laminin or collagen IV- and periarterial â€šÃ¢Ã âˆšâ‰ Â¬Â¨Â¬Â±-SMA. A machine learning algorithm was developed to identify metastases- metastatic microenvironment- and uninvolved brain in confocally scanned brain sections. Drug/probe intensity over time and total imaged drug exposure (iAUC) were calculated for 27-249 lesions and co-immunofluorescence with IPAD- vascular matrix analyzed in 11-668 metastases. RESULTS In metastases- peak trastuzumab levels were 5-fold higher than human IgG but 4-fold less than biocytin-TMR. The elimination phase constituted 85-93% of total iAUC for all drugs/probes tested. For trastuzumab- total iAUC during uptake was similar to the small molecule drug probe biocytin-TMR- but slower trastuzumab elimination resulted in a 1.7-fold higher total iAUC. During elimination trastuzumab and IgG were preferentially enriched in the â€šÃ¢Ã âˆšâ‰ Â¬Â¨Â¬Â±-SMA+ periarterial vascular matrix- consistent with the IPAD clearance route; biocytin-TMR showed heterogeneous elimination pathways. CONCLUSIONS Drug/probe elimination is an important component of drug development for brain metastases. We identified a prolonged elimination pathway for systemically administered antibodies through the periarterial vascular matrix that may contribute to the sustained presence and efficacy of large antibody therapeutics.
A. Tien- M. Sadar,Treatments Targeting the Androgen Receptor and Its Splice Variants in Breast Cancer,Cytological evaluation through microscopic image analysis of fine needle aspiration cytology (FNAC) is pivotal in the initial screening of breast cancer. The sensitivity of FNAC as a screening tool relies on both image quality and the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s expertise. To enhance diagnostic accuracy and alleviate the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s workload- a computer-aided diagnosis (CAD) system was developed. A comparative study was conducted- assessing twelve candidate pre-trained models. Utilizing a locally gathered FNAC image dataset- three superior models-MobileNet-V2- DenseNet-121- and Inception-V3-were selected based on their training- validation- and testing accuracies. Further- these models underwent evaluation in four transfer learning scenarios to enhance testing accuracy. While the outcomes were promising- they left room for improvement- motivating us to create a novel deep convolutional neural network (CNN). The newly proposed model exhibited robust performance with testing accuracy at 85%. Our research concludes that the most lightweight- high-accuracy model is the one we propose. Weâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ve integrated it into our user-friendly Android App- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Breast Cancer Detection System-â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Å“Ã„ in TensorFlow Lite format- with cloud database support- showcasing its effectiveness. Implementing an artificial intelligent (AI)-based diagnosis system with a user-friendly interface holds the potential to enhance early breast cancer detection using FNAC.
Alexander S Millar- John Arnn- Sam Himes- Julio C. Facelli,Uncertainty in Breast Cancer Risk Prediction: A Conformal Prediction Study of Race Stratification,Breast cancer (BC) is one of the most fatal forms of cancer- making it a significant contributor to mortality rates worldwide. Early detection and timely treatment of breast cancer are crucial in reducing its mortality rate. To ensure a healthy lifestyle- it is essential to develop systems that can accurately diagnose breast cancer. Recent advances in modern computing and information technologies have enabled significant progress in the early detection and prediction of diseases within healthcare systems. This study proposes a method for precise and automatic breast cancer prediction using deep-modified transfer learning-based Convolutional Neural Networks (CNNs). The CNN architectures employed include ResNet50- MobileNetV2- DenseNet121- and Xception- which serve as feature extractors to capture the most relevant features of breast Ultrasound images (BUSI). These extracted features are then accurately classified as benign or malignant using various high-performance classifiers- including Support Vector Machine (SVM)- K-Nearest Neighbors (KNN)- XGBoost- and Softmax. The experimental results demonstrate that the proposed deep modified DenseNet121 network with the Softmax classifier outperformed other models and existing techniques. This latter achieved remarkable performance metrics- including an accuracy of 95.34%- a precision of 90.90%- and an F1 score of 93.02%. These results highlight the effectiveness of our approach in enhancing the accuracy of breast cancer prediction. The superior performance of the proposed method provides significant improvements in decision-making speed and reduces the time- effort- and laboratory resources required for healthcare services. Consequently- this method has the potential to significantly enhance early diagnosis and enable more tailored treatment plans- ultimately contributing to better patient outcomes and reducing the overall mortality rates associated with breast cancer.
Ali Hendi- Jalal Abu Halimah- Naif Majrashi- Sarah Daghriri- Mohammed Alhafaf- Mohammed Alshaikh- Mohammed Akkam- Saleha Haroobi- Rahaf Othathi- Reem Harbi- Abdulrahman Zalah- Elham Maghrabi- Alanoud Masmali- Mohammed Mojiri,Understanding Breast Cancer Awareness- Perceptions- and Screening Practices Among the Population of Jazan- Saudi Arabia: A Cross-Sectional Study,A comprehensive evaluation of the relationship between the densities of various cell types in the breast cancer tumor microenvironment and patient prognosis is currently lacking. Additionally- the absence of a large patch-level whole slide imaging (WSI) dataset of breast cancer with annotated cell types hinders the ability of artificial intelligence to evaluate cell density in breast cancer WSI. We first employed Lasso-Cox regression to build a breast cancer prognosis assessment model based on cell density in a population study. Pathology experts manually annotated a dataset containing over 70-000 patches and used transfer learning based on ResNet152 to develop an artificial intelligence model for identifying different cell types in these patches. The results showed that significant prognostic differences were observed among breast cancer patients stratified by cell density score (P = 0.0018)- with the cell density score identified as an independent prognostic factor for breast cancer patients (P < 0.05). In the validation cohort- the predictive performance for overall survival (OS) was satisfactory- with area under the curve (AUC) values of 0.893 (OS) at 1-year- 0.823 (OS) at 3-year- and 0.861 (OS) at 5-year intervals. We trained a robust model based on ResNet152- achieving over 99% classification accuracy for different cell types in patches. These achievements offer new public resources and tools for personalized treatment and prognosis assessment.
Shiping Li- Yihao Lin- Guangyu Liu- Zhimin Shao- Yinlong Yang,Unveiling the potential of breast MRI: a game changer for BI-RADS 4A microcalcifications.,Breast cancer can progress silently in its early stages and frequently without noticeable symptoms. However- it poses a serious risk to women. It is imperative to recognize this potential health concern to mitigate it early. In the last few years- Convolutional Neural Networks (CNNs) have advanced significantly in their ability to classify images of breast cancer. Their capacity to automatically extract discriminant features from images has enhanced the performances and accuracy of image classification tasks. They outperform state-of-the-art techniques in this area. Furthermore- complicated models that were first learned for certain tasks can be easily adapted to complete new tasks by using transfer-learning approaches. However- deep learning-based categorization techniques could experience overfitting issues- particularly in cases where the dataset is small. The primary goal of this work is to investigate the performances of certain deep learning models to classify breast cancer images and to study the effects of data augmentation techniques- such as image rotation or displacement when utilizing a transfer learning approach. Using certain image datasets- the ResNet18- Resnet50- and VGG16 models demonstrated accuracy improvements- according to our experimental results.
GHB Andrade- T Nishiyama- T Fujimaki- S Yada- ...,Assessing domain adaptation in adverse drug event extraction on real-world breast cancer records,Objectives This study explored the familiarity- perceptions and confidence of Australian radiology clinicians involved in reading screening mammograms- regarding artificial intelligence (AI) applications in breast cancer detection. Methods Sixty-five radiologists- breast physicians and radiology trainees participated in an online survey that consisted of 23 multiple choice questions asking about their experience and familiarity with AI products. Furthermore- the survey asked about their confidence in using AI outputs and their preference for AI modes applied in a breast screening context. Participants' responses to questions were compared using Pearson's â€šÃ¢Ã âˆšÂ¨â€šÃ Ã¶Â¬âˆž 2 test. Bonferroni-adjusted significance tests were used for pairwise comparisons. Results Fifty-five percent of respondents had experience with AI in their workplaces- with automatic density measurement powered by machine learning being the most familiar AI product (69.4%). The top AI outputs with the highest ranks of perceived confidence were 'Displaying suspicious areas on mammograms with the percentage of cancer possibility' (67.8%) and 'Automatic mammogram classification (normal- benign- cancer- uncertain)' (64.6%). Radiology and breast physicians preferred using AI as second-reader mode (75.4% saying 'somewhat happy' to 'extremely happy') over triage (47.7%)- pre-screening and first-reader modes (both with 26.2%) (P â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.001). Conclusion The majority of screen readers expressed increased confidence in utilising AI for highlighting suspicious areas on mammograms and for automatically classifying mammograms. They considered AI as an optimal second-reader mode being the most ideal use in a screening program. The findings provide valuable insights into the familiarities and expectations of radiologists and breast clinicians for the AI products that can enhance the effectiveness of the breast cancer screening programs- benefitting both healthcare professionals and patients alike.
Usman Haider- Muhammad Hanif- Ahmer Rashid- Khursheed Aurangzeb- A. Khalil- Musaed A. Alhussein,Discriminative Dictionary Learning Using Penalized Rank-1 Approximation for Breast Cancer Classification With Imbalanced Dataset,Analysis of histopathological images (HIs) is crucial for detecting breast cancer (BR). However- because they vary- it is still very difficult to extract well-designed elements. Deep learning (DL) is a recent development that is used to extract high-level features. However- DL techniques continue to confront several difficult problems- such as the need for sufficient training data for DL models- which reduces the classification findings. In this study- an ensemble deep transfer convolutional neural network is presented to address this problem. The pre-trained models (ResNet50 and MobileNet) are employed to extract high-level features by freezing the front layer parameters while fine-tuning the last layers. In the proposed ensemble framework- KNN- SVM- logistic regression and neural networks are used as base classifiers. The majority vote and product approaches are used to integrate the predictions of each separate classifier. In the benchmark BreaKHis dataset- the suggested ensemble model is compared to some current approaches. It demonstrates that while the ensemble model obtains a considerable accuracy of 97.72% for the multiclass classification test- it achieves an accuracy of 99.2% for the binary task. The suggested ensemble modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s effectiveness in extracting useful features for BR images is demonstrated by comparison with existing cutting-edge models.
Massimiliano Berretta- Daniele Garozzo- Calogero Foti- Mario Roselli- Marco Materazzo- Giulia Vita- Ferdinando Iellamo- Marco Scordari- Giordana Di Mauro- Giovanna Spatari- Alessandro Ottaiano- Annalisa Noce- Marco Pellicciaro- Alessia Bignucolo- Gianluca Vanni- Oreste Claudio Buonomo,Implementing fencing as adapted physical activity in non-metastatic breast cancer patients: design and early rehabilitation strategy of the FENICE study protocol,Background: Breast cancer is one of the most lethal cancers among women. Early detection and proper treatment reduce mortality rates. Histopathological images provide detailed information for diagnosing and staging breast cancer disease. Methods: The BreakHis dataset- which includes histopathological images- is used in this study. Medical images are prone to problems such as different textural backgrounds and overlapping cell structures- unbalanced class distribution- and insufficiently labeled data. In addition to these- the limitations of deep learning models in overfitting and insufficient feature extraction make it extremely difficult to obtain a high-performance model in this dataset. In this study- 20 state-of-the-art models are trained to diagnose eight types of breast cancer using the fine-tuning method. In addition- a comprehensive experimental study was conducted to determine the most successful new model- with 20 different custom models reported. As a result- we propose a novel model called MultiHisNet. Results: The most effective new model- which included a pointwise convolution layer- residual link- channel- and spatial attention module- achieved 94.69% accuracy in multi-class breast cancer classification. An ensemble model was created with the best-performing transfer learning and custom models obtained in the study- and model weights were determined with an Equilibrium Optimizer. The proposed ensemble model achieved 96.71% accuracy in eight-class breast cancer detection. Conclusions: The results show that the proposed model will support pathologists in successfully diagnosing breast cancer.
Ayman Alsabry- Malek Algabri,Iterative Tuning of Tree-Ensemble-Based Models' parameters Using Bayesian Optimization for Breast Cancer Prediction,Breast cancer- a widespread malignancy predominantly affecting women aged 40 and above- presents a significant global health challenge with high mortality rates. The scarcity of medical data underscores the need for collaborative efforts among hospitals to enhance automated breast cancer detection. This research employs decentralized Federated Learning (FL) to facilitate cooperative learning across an interconnected smart hospital network- addressing data privacy- regulatory compliance- voluminous medical image data- and the necessity for distributed machine learning. Our innovative approach integrates Ant Colony Optimization (ACO) for hyperparameter fine-tuning and Neural Architecture Search (NAS) in a collaborative framework for smart hospitals linked with decentralized edge intelligent networks. This optimization strategy significantly improves the performance of our breast cancer detection system. Through a comprehensive experimental study (including diverse datasets)- we classify Normal vs. Mass and Benign vs. Malignant regions in mammograms within a decentralized- federated collaborative learning environment. Empirical results consistently highlight the superiority of models trained using our method over individual hospital client-level training. Our method yielded significant improvements across evaluation measures: for Normal vs. Mass- achieving 92.6% sensitivity- 93.0% specificity- and 93.0% accuracy; for Benign vs. Malignant- achieving 89.6% sensitivity- 91.6% specificity- and 89.7% accuracy. Moreover- it has obtained a 6% and 5% increase in accuracy for Normal vs. Mass and Benign vs. Malignant cases- respectively- compared to the PSO-based HPO method. This evidence underscores the potential of collaborative approaches- emphasizing decentralized FL as a robust paradigm in medical research. The incorporation of ACO optimization reinforces the effectiveness of the proposed computer-aided diagnosis (CAD) system- marking a noteworthy advancement in the ongoing fight against breast cancer.
Boya Manasa Sai- Yirivinti Hayagreeva Dinakar- Hitesh Kumar- Rupshee Jain- Sharyu Kesharwani- Siddharth S Kesharwani- Shyam Lal Mudavath- Ajmeer Ramkishan- Vikas Jain,Therapeutic delivery of siRNA for the management of breast cancer and triple-negative breast cancer,Breast cancer is the most prevalent cancer among women globally- making early and accurate detection essential for effective treatment and improved survival rates. This paper presents a method designed to detect and localize breast cancer using deep learning- specifically convolutional neural networks. The approach classifies histological images of breast tissue as either tumor-positive or tumor-negative. We utilize several deep learning models- including a custom-built CNN- EfficientNet- ResNet50- VGG-16- VGG-19- and MobileNet. Fine-tuning was also applied to VGG-16- VGG-19- and MobileNet to enhance performance. Additionally- we introduce a novel deep learning model called MR_Net- aimed at providing a more accurate network for breast cancer detection and localization- potentially assisting clinicians in making informed decisions. This model could also accelerate the diagnostic process- enabling early detection of the disease. Furthermore- we propose a method for explainable predictions by generating heatmaps that highlight the regions within tissue images that the model focuses on when predicting a label- revealing the detection of benign- atypical- and malignant tumors. We evaluate both the quantitative and qualitative performance of MR_Net and the other models- also presenting explainable results that allow visualization of the tissue areas identified by the model as relevant to the presence of breast cancer.
Ko Un Park- Stuart R. Lipsitz- L. Dominici- F. Lynce- Christina A. Minami- F. Nakhlis- Adrienne G. Waks- Laura E. Warren- Nadine Eidman- Jeannie Frazier- Lourdes Hernandez- Carla Leslie- Susan Rafte- Delia Stroud- J. Weissman- T. King- E. Mittendorf,Generative artificial intelligence as a source of breast cancer information for patients: Proceed with caution.,<title>Abstract</title> <p>Breast cancer is one of the most prevalent causes of cancer-related death globally. Preliminary diagnosis of breast cancer increases the patient's chances of survival and healing. In this paper- we propose a hybrid deep transfer learning model integrating xception with support vector classifier (XSV) and xception with random forest (XRF) along with pre-processing technique to classify breast cancer as cancerous (malignant) or non-cancerous (benign) along comparative analysis of prominent machine learning classifiers- such as Random Forest Classifier (RFC)- Logistic Regression (LR)- Support Vector Classifier (SVC)- K-Nearest Neighbors (K-NN)- and Ada-boost. In experiment all the models are implemented on two openly accessible datasets: BreakHis and Breast Histopathology Images Database (BHID) across various metrics such as accuracy- area under the receiver operating curve- precision- recall- f1-score- Matthew's correlation coefficient- classification success index- and kappa at different magnification levels of images. Our proposed model that utilized the fine tuning of xception model in conjunction with RFC and SVC- surpass existing breast cancer classification methodologies. Specifically- the XSV that achieved accuracies of 89.26%- 85.87%- 90.17%- and 88.98%- while the XRF attained accuracies of 87.78%- 84.78%- 88.98%- and 87.61% for BreakHis at 40X- 100X- 200X- and 400X magnifications- respectively. For BHID at 40X magnification- the XSV and XRF models achieved accuracies of 87.35% and 87.29%- respectively. Employing this study will aid our medical practitioners and researchers in choosing an accurate model for tumor classification and our results will help medical professionals to classify the disease with precision.</p>
