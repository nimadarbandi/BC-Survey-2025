2016,Breast cancer histopathological image classification using Convolutional Neural Networks,"The performance of most conventional classification systems relies on appropriate data representation and much of the efforts are dedicated to feature engineering, a difficult and time-consuming process that uses prior expert domain knowledge of the data to create useful features. On the other hand, deep learning can extract and organize the discriminative information from the data, not requiring the design of feature extractors by a domain expert. Convolutional Neural Networks (CNNs) are a particular type of deep, feedforward network that have gained attention from research community and industry, achieving empirical successes in tasks such as speech recognition, signal processing, object recognition, natural language processing and transfer learning. In this paper, we conduct some preliminary experiments using the deep learning approach to classify breast cancer histopathological images from BreaKHis, a publicly dataset available at http://web.inf.ufpr.br/vri/breast-cancer-database. We propose a method based on the extraction of image patches for training the CNN and the combination of these patches for final classification. This method aims to allow using the high-resolution histopathological images from BreaKHis as input to existing CNN, avoiding adaptations of the model that can lead to a more complex and computationally costly architecture. The CNN performance is better when compared to previously reported results obtained by other machine learning models trained with hand-crafted textural descriptors. Finally, we also investigate the combination of different CNNs using simple fusion rules, achieving some improvement in recognition rates."
2018,A deep learning method for classifying mammographic breast density categories,"PURPOSE Mammographic breast density is an established risk marker for breast cancer and is visually assessed by radiologists in routine mammogram image reading, using four qualitative Breast Imaging and Reporting Data System (BI-RADS) breast density categories. It is particularly difficult for radiologists to consistently distinguish the two most common and most variably assigned BI-RADS categories, i.e., ""scattered density"" and ""heterogeneously dense"". The aim of this work was to investigate a deep learning-based breast density classifier to consistently distinguish these two categories, aiming at providing a potential computerized tool to assist radiologists in assigning a BI-RADS category in current clinical workflow. METHODS In this study, we constructed a convolutional neural network (CNN)-based model coupled with a large (i.e., 22,000 images) digital mammogram imaging dataset to evaluate the classification performance between the two aforementioned breast density categories. All images were collected from a cohort of 1,427 women who underwent standard digital mammography screening from 2005 to 2016 at our institution. The truths of the density categories were based on standard clinical assessment made by board-certified breast imaging radiologists. Effects of direct training from scratch solely using digital mammogram images and transfer learning of a pretrained model on a large nonmedical imaging dataset were evaluated for the specific task of breast density classification. In order to measure the classification performance, the CNN classifier was also tested on a refined version of the mammogram image dataset by removing some potentially inaccurately labeled images. Receiver operating characteristic (ROC) curves and the area under the curve (AUC) were used to measure the accuracy of the classifier. RESULTS The AUC was 0.9421 when the CNN-model was trained from scratch on our own mammogram images, and the accuracy increased gradually along with an increased size of training samples. Using the pretrained model followed by a fine-tuning process with as few as 500 mammogram images led to an AUC of 0.9265. After removing the potentially inaccurately labeled images, AUC was increased to 0.9882 and 0.9857 for without and with the pretrained model, respectively, both significantly higher (P < 0.001) than when using the full imaging dataset. CONCLUSIONS Our study demonstrated high classification accuracies between two difficult to distinguish breast density categories that are routinely assessed by radiologists. We anticipate that our approach will help enhance current clinical assessment of breast density and better support consistent density notification to patients in breast cancer screening."
2021,Novel Transfer Learning Approach for Medical Imaging with Limited Labeled Data,"Deep learning requires a large amount of data to perform well. However, the field of medical image analysis suffers from a lack of sufficient data for training deep learning models. Moreover, medical images require manual labeling, usually provided by human annotators coming from various backgrounds. More importantly, the annotation process is time-consuming, expensive, and prone to errors. Transfer learning was introduced to reduce the need for the annotation process by transferring the deep learning models with knowledge from a previous task and then by fine-tuning them on a relatively small dataset of the current task. Most of the methods of medical image classification employ transfer learning from pretrained models, e.g., ImageNet, which has been proven to be ineffective. This is due to the mismatch in learned features between the natural image, e.g., ImageNet, and medical images. Additionally, it results in the utilization of deeply elaborated models. In this paper, we propose a novel transfer learning approach to overcome the previous drawbacks by means of training the deep learning model on large unlabeled medical image datasets and by next transferring the knowledge to train the deep learning model on the small amount of labeled medical images. Additionally, we propose a new deep convolutional neural network (DCNN) model that combines recent advancements in the field. We conducted several experiments on two challenging medical imaging scenarios dealing with skin and breast cancer classification tasks. According to the reported results, it has been empirically proven that the proposed approach can significantly improve the performance of both classification scenarios. In terms of skin cancer, the proposed model achieved an F1-score value of 89.09% when trained from scratch and 98.53% with the proposed approach. Secondly, it achieved an accuracy value of 85.29% and 97.51%, respectively, when trained from scratch and using the proposed approach in the case of the breast cancer scenario. Finally, we concluded that our method can possibly be applied to many medical imaging problems in which a substantial amount of unlabeled image data is available and the labeled image data is limited. Moreover, it can be utilized to improve the performance of medical imaging tasks in the same domain. To do so, we used the pretrained skin cancer model to train on feet skin to classify them into two classes—either normal or abnormal (diabetic foot ulcer (DFU)). It achieved an F1-score value of 86.0% when trained from scratch, 96.25% using transfer learning, and 99.25% using double-transfer learning."
2022,Breast Cancer Classification from Ultrasound Images Using Probability-Based Optimal Deep Learning Feature Fusion,"After lung cancer, breast cancer is the second leading cause of death in women. If breast cancer is detected early, mortality rates in women can be reduced. Because manual breast cancer diagnosis takes a long time, an automated system is required for early cancer detection. This paper proposes a new framework for breast cancer classification from ultrasound images that employs deep learning and the fusion of the best selected features. The proposed framework is divided into five major steps: (i) data augmentation is performed to increase the size of the original dataset for better learning of Convolutional Neural Network (CNN) models; (ii) a pre-trained DarkNet-53 model is considered and the output layer is modified based on the augmented dataset classes; (iii) the modified model is trained using transfer learning and features are extracted from the global average pooling layer; (iv) the best features are selected using two improved optimization algorithms known as reformed differential evaluation (RDE) and reformed gray wolf (RGW); and (v) the best selected features are fused using a new probability-based serial approach and classified using machine learning algorithms. The experiment was conducted on an augmented Breast Ultrasound Images (BUSI) dataset, and the best accuracy was 99.1%. When compared with recent techniques, the proposed framework outperforms them."
2021,Deep-Learning-Empowered Breast Cancer Auxiliary Diagnosis for 5GB Remote E-Health,"Breast cancer, the most common cancer in women, is receiving increasing attention. The lack of high-quality medical resources, especially highly skilled doctors, in remote areas makes the diagnosis of breast cancer inefficient and causes great harm to women. The emergence of remote e-health has improved the situation to a certain extent, but its capabilities are still hampered by technical limitations, which manifest in two main aspects. First, due to network bandwidth limitations, it is difficult to guarantee the real-time transmission of breast cancer pathology images between remote areas and cities. Second, the highly skilled breast cancer doctors at large city hospitals are not guaranteed to be available for online diagnosis at all times. To overcome these limitations, this article proposes a deep-learning-empowered breast cancer auxiliary diagnosis scheme for remote e-health supported by 5G technology and beyond (5GB remote e-health). In this scheme, breast pathology images are first received from major hospitals via 5G, and a deep learning model based on the Inception-v3 network is subjected to transfer learning to obtain a diagnostic model. This diagnostic model is then employed on edge servers for auxiliary diagnosis at remote area hospitals. A theoretical analysis and experimental results show that this solution not only overcomes the two problems mentioned above but also improves the diagnostic accuracy for breast cancer in remote areas to 98.19 percent."
2020,Deep Learning Assisted Efficient AdaBoost Algorithm for Breast Cancer Detection and Early Diagnosis,"Breast cancer is one of the most dangerous diseases and the second largest cause of female cancer death. Breast cancer starts when malignant, cancerous lumps start to grow from the breast cells. Self-tests and Periodic clinical checks help to early diagnosis and thereby improve the survival chances significantly. The breast cancer classification is a medical method that provides researchers and scientists with a great challenge. Neural networks have recently become a popular tool in cancer data classification. In this paper, Deep Learning assisted Efficient Adaboost Algorithm (DLA-EABA) for breast cancer detection has been mathematically proposed with advanced computational techniques. In addition to traditional computer vision approaches, tumor classification methods using transfers are being actively developed through the use of deep convolutional neural networks (CNNs). This study starts with examining the CNN-based transfer learning to characterize breast masses for different diagnostic, predictive tasks or prognostic or in several imaging modalities, such as Magnetic Resonance Imaging (MRI), Ultrasound (US), digital breast tomosynthesis and mammography. The deep learning framework contains several convolutional layers, LSTM, Max-pooling layers. The classification and error estimation that has been included in a fully connected layer and a softmax layer. This paper focuses on combining these machine learning approaches with the methods of selecting features and extracting them through evaluating their output using classification and segmentation techniques to find the most appropriate approach. The experimental results show that the high accuracy level of 97.2%, Sensitivity 98.3%, and Specificity 96.5% has been compared to other existing systems."
2020,Optimizing the Performance of Breast Cancer Classification by Employing the Same Domain Transfer Learning from Hybrid Deep Convolutional Neural Network Model,"Breast cancer is a significant factor in female mortality. An early cancer diagnosis leads to a reduction in the breast cancer death rate. With the help of a computer-aided diagnosis system, the efficiency increased, and the cost was reduced for the cancer diagnosis. Traditional breast cancer classification techniques are based on handcrafted features techniques, and their performance relies upon the chosen features. They also are very sensitive to different sizes and complex shapes. However, histopathological breast cancer images are very complex in shape. Currently, deep learning models have become an alternative solution for diagnosis, and have overcome the drawbacks of classical classification techniques. Although deep learning has performed well in various tasks of computer vision and pattern recognition, it still has some challenges. One of the main challenges is the lack of training data. To address this challenge and optimize the performance, we have utilized a transfer learning technique which is where the deep learning models train on a task, and then fine-tune the models for another task. We have employed transfer learning in two ways: Training our proposed model first on the same domain dataset, then on the target dataset, and training our model on a different domain dataset, then on the target dataset. We have empirically proven that the same domain transfer learning optimized the performance. Our hybrid model of parallel convolutional layers and residual links is utilized to classify hematoxylin–eosin-stained breast biopsy images into four classes: invasive carcinoma, in-situ carcinoma, benign tumor and normal tissue. To reduce the effect of overfitting, we have augmented the images with different image processing techniques. The proposed model achieved state-of-the-art performance, and it outperformed the latest methods by achieving a patch-wise classification accuracy of 90.5%, and an image-wise classification accuracy of 97.4% on the validation set. Moreover, we have achieved an image-wise classification accuracy of 96.1% on the test set of the microscopy ICIAR-2018 dataset."
2021,Transfer Learning in Breast Cancer Diagnoses via Ultrasound Imaging,"Simple Summary Transfer learning plays a major role in medical image analyses; however, obtaining adequate training image datasets for machine learning algorithms can be challenging. Although many studies have attempted to employ transfer learning in medical image analyses, thus far, only a few review articles regarding the application of transfer learning to medical image analyses have been published. Moreover, reviews on the application of transfer learning in ultrasound breast imaging are rare. This work reviews previous studies that focused on detecting breast cancer from ultrasound images by using transfer learning, in order to summarize existing methods and identify their advantages and shortcomings. Additionally, this review presents potential future research directions for applying transfer learning in ultrasound imaging for the purposes of breast cancer detection and diagnoses. This review is expected to be significantly helpful in guiding researchers to identify potential improved methods and areas that can be improved through further research on transfer learning-based ultrasound breast imaging. Abstract Transfer learning is a machine learning approach that reuses a learning method developed for a task as the starting point for a model on a target task. The goal of transfer learning is to improve performance of target learners by transferring the knowledge contained in other (but related) source domains. As a result, the need for large numbers of target-domain data is lowered for constructing target learners. Due to this immense property, transfer learning techniques are frequently used in ultrasound breast cancer image analyses. In this review, we focus on transfer learning methods applied on ultrasound breast image classification and detection from the perspective of transfer learning approaches, pre-processing, pre-training models, and convolutional neural network (CNN) models. Finally, comparison of different works is carried out, and challenges—as well as outlooks—are discussed."
2017,Deep learning model based breast cancer histopathological image classification,"The automatic and precision classification for breast cancer histopathological image has a great significance in clinical application. However, the existing analysis approaches are difficult to addressing the breast cancer classification problem because the feature subtle differences of inter-class histopathological image and the classification accuracy still hard to meet the clinical application. Recent advancements in data-driven sharing processing and multi-level hierarchical feature learning have made available considerable chance to dope out a solution to this problem. To address the challenging problem, we propose a novel breast cancer histopathological image classification method based on deep convolutional neural networks, named as BiCNN model, to address the two-class breast cancer classification on the pathological image. This deep learning model considers class and sub-class labels of breast cancer as prior knowledge, which can restrain the distance of features of different breast cancer pathological images. In addition, an advanced data augmented method is proposed to fit tolerance whole slide image recognition, which can full reserve image edge feature of cancerization region. The transfer learning and fine-tuning method are adopted as an optimal training strategy to improve breast cancer histopathological image classification accuracy. The experiment results show that the proposed method leads to a higher classification accuracy (up to 97%) and displays good robustness and generalization, which provides efficient tools for breast cancer clinical diagnosis."
2019,A Technical Review of Convolutional Neural Network-Based Mammographic Breast Cancer Diagnosis,"This study reviews the technique of convolutional neural network (CNN) applied in a specific field of mammographic breast cancer diagnosis (MBCD). It aims to provide several clues on how to use CNN for related tasks. MBCD is a long-standing problem, and massive computer-aided diagnosis models have been proposed. The models of CNN-based MBCD can be broadly categorized into three groups. One is to design shallow or to modify existing models to decrease the time cost as well as the number of instances for training; another is to make the best use of a pretrained CNN by transfer learning and fine-tuning; the third is to take advantage of CNN models for feature extraction, and the differentiation of malignant lesions from benign ones is fulfilled by using machine learning classifiers. This study enrolls peer-reviewed journal publications and presents technical details and pros and cons of each model. Furthermore, the findings, challenges and limitations are summarized and some clues on the future work are also given. Conclusively, CNN-based MBCD is at its early stage, and there is still a long way ahead in achieving the ultimate goal of using deep learning tools to facilitate clinical practice. This review benefits scientific researchers, industrial engineers, and those who are devoted to intelligent cancer diagnosis."
2022,Ensemble Deep-Learning-Enabled Clinical Decision Support System for Breast Cancer Diagnosis and Classification on Ultrasound Images,"Simple Summary In the literature, there exist plenty of research works focused on the detection and classification of breast cancer. However, only a few works have focused on the classification of breast cancer using ultrasound scan images. Although deep transfer learning models are useful in breast cancer classification, owing to their outstanding performance in a number of applications, image pre-processing and segmentation techniques are essential. In this context, the current study developed a new Ensemble Deep-Learning-Enabled Clinical Decision Support System for the diagnosis and classification of breast cancer using ultrasound images. In the study, an optimal multi-level thresholding-based image segmentation technique was designed to identify the tumor-affected regions. The study also developed an ensemble of three deep learning models for feature extraction and an optimal machine learning classifier for breast cancer detection. The study offers a means of assisting radiologists and healthcare professionals in the breast cancer classification process. Abstract Clinical Decision Support Systems (CDSS) provide an efficient way to diagnose the presence of diseases such as breast cancer using ultrasound images (USIs). Globally, breast cancer is one of the major causes of increased mortality rates among women. Computer-Aided Diagnosis (CAD) models are widely employed in the detection and classification of tumors in USIs. The CAD systems are designed in such a way that they provide recommendations to help radiologists in diagnosing breast tumors and, furthermore, in disease prognosis. The accuracy of the classification process is decided by the quality of images and the radiologist’s experience. The design of Deep Learning (DL) models is found to be effective in the classification of breast cancer. In the current study, an Ensemble Deep-Learning-Enabled Clinical Decision Support System for Breast Cancer Diagnosis and Classification (EDLCDS-BCDC) technique was developed using USIs. The proposed EDLCDS-BCDC technique was intended to identify the existence of breast cancer using USIs. In this technique, USIs initially undergo pre-processing through two stages, namely wiener filtering and contrast enhancement. Furthermore, Chaotic Krill Herd Algorithm (CKHA) is applied with Kapur’s entropy (KE) for the image segmentation process. In addition, an ensemble of three deep learning models, VGG-16, VGG-19, and SqueezeNet, is used for feature extraction. Finally, Cat Swarm Optimization (CSO) with the Multilayer Perceptron (MLP) model is utilized to classify the images based on whether breast cancer exists or not. A wide range of simulations were carried out on benchmark databases and the extensive results highlight the better outcomes of the proposed EDLCDS-BCDC technique over recent methods."
2019,Deep Learning Approaches for Data Augmentation and Classification of Breast Masses using Ultrasound Images,"Breast classification and detection using ultrasound imaging is considered a significant step in computer-aided diagno-sis systems. Over the previous decades, researchers have proved the opportunities to automate the initial tumor classification and detection. The shortage of popular datasets of ultrasound images of breast cancer prevents researchers from obtaining a good performance of the classification algorithms. Traditional augmentation approaches are firmly limited, especially in tasks where the images follow strict standards, as in the case of medical datasets. Therefore besides the traditional augmentation, we use a new methodology for data augmentation using Generative Adversarial Network (GAN). We achieved higher accuracies by integrating traditional with GAN-based augmentation. This paper uses two breast ultrasound image datasets obtained from two various ultrasound systems. The first dataset is our dataset which was collected from Baheya Hospital for Early Detection and Treatment of Women’s Cancer, Cairo (Egypt), we name it (BUSI) referring to Breast Ultrasound Images (BUSI) dataset. It contains 780 images (133 normal, 437 benign and 210 malignant). While the Dataset (B) is obtained from related work and it has 163 images (110 benign and 53 malignant). To overcome the shortage of public datasets in this field, BUSI dataset will be publicly available for researchers. Moreover, in this paper, deep learning approaches are proposed to be used for breast ultrasound classification. We examine two different methods: a Convolutional Neural Network (CNN) approach and a Transfer Learning (TL) approach and we compare their performance with and without augmentation. The results confirm an overall enhancement using augmentation methods with deep learning classification methods (especially transfer learning) when evaluated on the two datasets."
2017,A method for classifying medical images using transfer learning: A pilot study on histopathology of breast cancer,"The advance of deep learning has made huge changes in computer vision and produced various off-the-shelf trained models. Particularly, Convolutional Neural Network (CNN) has been widely used to build image classification model which allow researchers transfer the pre-trained learning model for other classifications. We propose a transfer learning method to detect breast cancer using histopathology images based on Google's Inception v3 model which were initially trained for the classification of non-medical images. The pilot study shows the feasibility of transfer learning in the detection of breast cancer with AUC of 0.93."
2018,Evolutionary pruning of transfer learned deep convolutional neural network for breast cancer diagnosis in digital breast tomosynthesis,"Deep learning models are highly parameterized, resulting in difficulty in inference and transfer learning for image recognition tasks. In this work, we propose a layered pathway evolution method to compress a deep convolutional neural network (DCNN) for classification of masses in digital breast tomosynthesis (DBT). The objective is to prune the number of tunable parameters while preserving the classification accuracy. In the first stage transfer learning, 19 632 augmented regions-of-interest (ROIs) from 2454 mass lesions on mammograms were used to train a pre-trained DCNN on ImageNet. In the second stage transfer learning, the DCNN was used as a feature extractor followed by feature selection and random forest classification. The pathway evolution was performed using genetic algorithm in an iterative approach with tournament selection driven by count-preserving crossover and mutation. The second stage was trained with 9120 DBT ROIs from 228 mass lesions using leave-one-case-out cross-validation. The DCNN was reduced by 87% in the number of neurons, 34% in the number of parameters, and 95% in the number of multiply-and-add operations required in the convolutional layers. The test AUC on 89 mass lesions from 94 independent DBT cases before and after pruning were 0.88 and 0.90, respectively, and the difference was not statistically significant (p  >  0.05). The proposed DCNN compression approach can reduce the number of required operations by 95% while maintaining the classification performance. The approach can be extended to other deep neural networks and imaging tasks where transfer learning is appropriate."
2019,Semi-Supervised Histology Classification using Deep Multiple Instance Learning and Contrastive Predictive Coding,"Convolutional neural networks can be trained to perform histology slide classification using weak annotations with multiple instance learning (MIL). However, given the paucity of labeled histology data, direct application of MIL can easily suffer from overfitting and the network is unable to learn rich feature representations due to the weak supervisory signal. We propose to overcome such limitations with a two-stage semi-supervised approach that combines the power of data-efficient self-supervised feature learning via contrastive predictive coding (CPC) and the interpretability and flexibility of regularized attention-based MIL. We apply our two-stage CPC + MIL semi-supervised pipeline to the binary classification of breast cancer histology images. Across five random splits, we report state-of-the-art performance with a mean validation accuracy of 95% and an area under the ROC curve of 0.968. We further evaluate the quality of features learned via CPC relative to simple transfer learning and show that strong classification performance using CPC features can be efficiently leveraged under the MIL framework even with the feature encoder frozen."
2022,A Novel Multistage Transfer Learning for Ultrasound Breast Cancer Image Classification,"Breast cancer diagnosis is one of the many areas that has taken advantage of artificial intelligence to achieve better performance, despite the fact that the availability of a large medical image dataset remains a challenge. Transfer learning (TL) is a phenomenon that enables deep learning algorithms to overcome the issue of shortage of training data in constructing an efficient model by transferring knowledge from a given source task to a target task. However, in most cases, ImageNet (natural images) pre-trained models that do not include medical images, are utilized for transfer learning to medical images. Considering the utilization of microscopic cancer cell line images that can be acquired in large amount, we argue that learning from both natural and medical datasets improves performance in ultrasound breast cancer image classification. The proposed multistage transfer learning (MSTL) algorithm was implemented using three pre-trained models: EfficientNetB2, InceptionV3, and ResNet50 with three optimizers: Adam, Adagrad, and stochastic gradient de-scent (SGD). Dataset sizes of 20,400 cancer cell images, 200 ultrasound images from Mendeley and 400 ultrasound images from the MT-Small-Dataset were used. ResNet50-Adagrad-based MSTL achieved a test accuracy of 99 ± 0.612% on the Mendeley dataset and 98.7 ± 1.1% on the MT-Small-Dataset, averaging over 5-fold cross validation. A p-value of 0.01191 was achieved when comparing MSTL against ImageNet based TL for the Mendeley dataset. The result is a significant improvement in the performance of artificial intelligence methods for ultrasound breast cancer classification compared to state-of-the-art methods and could remarkably improve the early diagnosis of breast cancer in young women."
2021,Deep CNN Model based on VGG16 for Breast Cancer Classification,"Deep learning (DL) technologies are becoming a buzzword these days, especially for breast histopathology image tasks, such as diagnosing, due to the high performance obtained in image classification. Among deep learning types, Convolutional Neural Networks (CNN) are the most common types of DL models utilized for medical image diagnosis and analysis. However, CNN suffers from high computation cost to be implemented and may require to adapt huge number of parameters. Thus, and in order to address this issue; several pre-trained models have been established with the predefined network architecture. In this study, a transfer learning model based on Visual Geometry Group with 16-layer deep model architecture (VGG16) is utilized to extract high-level features from the BreaKHis benchmark histopathological images dataset. Then, multiple machine learning models (classifiers) are used to handle different Breast Cancer (BC) histopathological image classification tasks mainly: binary and multiclass with eight-class classifications. The experimental results on the public BreakHis benchmark dataset demonstrate that the proposed models are better than the previous works on the same dataset. Besides, the results show that the proposed models are able to outperform recent classical machine learning algorithms."
2019,Breast Cancer Diagnosis with Transfer Learning and Global Pooling,"Breast cancer is one of the most common causes of cancer-related death in women worldwide. Early and accurate diagnosis of breast cancer may significantly increase the survival rate of patients. In this study, we aim to develop a fully automatic, deep learning-based, method using descriptor features extracted by Deep Convolutional Neural Network (DCNN) models and pooling operation for the classification of hematoxylin and eosin stain (H#E) histological breast cancer images provided as a part of the International Conference on Image Analysis and Recognition (ICIAR) 2018 Grand Challenge on BreAst Cancer Histology (BACH) Images. Different data augmentation methods are applied to optimize the DCNN performance. We also investigated the efficacy of different stain normalization methods as a pre-processing step. The proposed network architecture using a pre-trained Xception model yields 92.50% average classification accuracy."
2017,Deep learning in breast cancer risk assessment: evaluation of convolutional neural networks on a clinical dataset of full-field digital mammograms,"Abstract. To evaluate deep learning in the assessment of breast cancer risk in which convolutional neural networks (CNNs) with transfer learning are used to extract parenchymal characteristics directly from full-field digital mammographic (FFDM) images instead of using computerized radiographic texture analysis (RTA), 456 clinical FFDM cases were included: a “high-risk” BRCA1/2 gene-mutation carriers dataset (53 cases), a “high-risk” unilateral cancer patients dataset (75 cases), and a “low-risk dataset” (328 cases). Deep learning was compared to the use of features from RTA, as well as to a combination of both in the task of distinguishing between high- and low-risk subjects. Similar classification performances were obtained using CNN [area under the curve (AUC)=0.83; standard error (SE)=0.03] and RTA (AUC=0.82; SE=0.03) in distinguishing BRCA1/2 carriers and low-risk women. However, in distinguishing unilateral cancer patients and low-risk women, performance was significantly greater with CNN (AUC=0.82; SE=0.03) compared to RTA (AUC=0.73; SE=0.03). Fusion classifiers performed significantly better than the RTA-alone classifiers with AUC values of 0.86 and 0.84 in differentiating BRCA1/2 carriers from low-risk women and unilateral cancer patients from low-risk women, respectively. In conclusion, deep learning extracted parenchymal characteristics from FFDMs performed as well as, or better than, conventional texture analysis in the task of distinguishing between cancer risk populations."
2016,MO-DE-207B-06: Computer-Aided Diagnosis of Breast Ultrasound Images Using Transfer Learning From Deep Convolutional Neural Networks.,"PURPOSE To assess the performance of using transferred features from pre-trained deep convolutional networks (CNNs) in the task of classifying cancer in breast ultrasound images, and to compare this method of transfer learning with previous methods involving human-designed features. METHODS A breast ultrasound dataset consisting of 1125 cases and 2393 regions of interest (ROIs) was used. Each ROI was labeled as cystic, benign, or malignant. Features were extracted from each ROI using pre-trained CNNs and used to train support vector machine (SVM) classifiers in the tasks of distinguishing non-malignant (benign+cystic) vs malignant lesions and benign vs malignant lesions. For a baseline comparison, classifiers were also trained on prior analytically-extracted tumor features. Five-fold cross-validation (by case) was conducted with the area under the receiver operating characteristic curve (AUC) as the performance metric. RESULTS Classifiers trained on CNN-extracted features were comparable to classifiers trained on human-designed features. In the non-malignant vs malignant task, both the SVM trained on CNN-extracted features and the SVM trained on human-designed features obtained an AUC of 0.90. In the task of determining benign vs malignant, the SVM trained on CNN-extracted features obtained an AUC of 0.88, compared to the AUC of 0.85 obtained by the SVM trained on human-designed features. CONCLUSION We obtained strong results using transfer learning to characterize ultrasound breast cancer images. This method allows us to directly classify a small dataset of lesions in a computationally inexpensive fashion without any manual input. Modern deep learning methods in computer vision are contingent on large datasets and vast computational resources, which are often inaccessible for clinical applications. Consequently, we believe transfer learning methods will be important for computer-aided diagnosis schemes in order to utilize advancements in deep learning and computer vision without the associated costs. This work was partially funded by NIH grant U01 CA195564 and the University of Chicago Metcalf program. M.L.G. is a stockholder in R2/Hologic, co-founder and equity holder in Quantitative Insights, and receives royalties from Hologic, GE Medical Systems, MEDIAN Technologies, Riverain Medical, Mitsubishi, and Toshiba. K.D. received royalties from Hologic."
2019,Breast Cancer Classification in Ultrasound Images using Transfer Learning,"Computer-aided detection of malignant breast tumors in ultrasound images has been receiving growing attention. In this paper, we propose a deep learning methodology to tackle this problem. The training data, which contains several hundred images of benign and malignant cases, was used to train a deep convolutional neural network (CNN). Three training approaches are proposed: a baseline approach where the CNN architecture is trained from scratch, a transfer-learning approach where the pre-trained VGG16 CNN architecture is further trained with the ultrasound images, and a fine-tuned learning approach where the deep learning parameters are fine-tuned to overcome overfitting. The experimental results demonstrate that the fine-tuned model had the best performance (0.97 accuracy, 0.98 AUC), with pre-training on US images. Creating pre-trained models using medical imaging data would certainly improve deep learning outcomes in biomedical applications."
2021,Multi- class classification of breast cancer abnormalities using Deep Convolutional Neural Network (CNN),"The real cause of breast cancer is very challenging to determine and therefore early detection of the disease is necessary for reducing the death rate due to risks of breast cancer. Early detection of cancer boosts increasing the survival chance up to 8%. Primarily, breast images emanating from mammograms, X-Rays or MRI are analyzed by radiologists to detect abnormalities. However, even experienced radiologists face problems in identifying features like micro-calcifications, lumps and masses, leading to high false positive and high false negative. Recent advancement in image processing and deep learning create some hopes in devising more enhanced applications that can be used for the early detection of breast cancer. In this work, we have developed a Deep Convolutional Neural Network (CNN) to segment and classify the various types of breast abnormalities, such as calcifications, masses, asymmetry and carcinomas, unlike existing research work, which mainly classified the cancer into benign and malignant, leading to improved disease management. Firstly, a transfer learning was carried out on our dataset using the pre-trained model ResNet50. Along similar lines, we have developed an enhanced deep learning model, in which learning rate is considered as one of the most important attributes while training the neural network. The learning rate is set adaptively in our proposed model based on changes in error curves during the learning process involved. The proposed deep learning model has achieved a performance of 88% in the classification of these four types of breast cancer abnormalities such as, masses, calcifications, carcinomas and asymmetry mammograms."
2022,Histopathologic Oral Cancer Prediction Using Oral Squamous Cell Carcinoma Biopsy Empowered with Transfer Learning,"Oral cancer is a dangerous and extensive cancer with a high death ratio. Oral cancer is the most usual cancer in the world, with more than 300,335 deaths every year. The cancerous tumor appears in the neck, oral glands, face, and mouth. To overcome this dangerous cancer, there are many ways to detect like a biopsy, in which small chunks of tissues are taken from the mouth and tested under a secure and hygienic microscope. However, microscope results of tissues to detect oral cancer are not up to the mark, a microscope cannot easily identify the cancerous cells and normal cells. Detection of cancerous cells using microscopic biopsy images helps in allaying and predicting the issues and gives better results if biologically approaches apply accurately for the prediction of cancerous cells, but during the physical examinations microscopic biopsy images for cancer detection there are major chances for human error and mistake. So, with the development of technology deep learning algorithms plays a major role in medical image diagnosing. Deep learning algorithms are efficiently developed to predict breast cancer, oral cancer, lung cancer, or any other type of medical image. In this study, the proposed model of transfer learning model using AlexNet in the convolutional neural network to extract rank features from oral squamous cell carcinoma (OSCC) biopsy images to train the model. Simulation results have shown that the proposed model achieved higher classification accuracy 97.66% and 90.06% of training and testing, respectively."
2021,Conventional Machine Learning versus Deep Learning for Magnification Dependent Histopathological Breast Cancer Image Classification: A Comparative Study with Visual Explanation,"Breast cancer is a serious threat to women. Many machine learning-based computer-aided diagnosis (CAD) methods have been proposed for the early diagnosis of breast cancer based on histopathological images. Even though many such classification methods achieved high accuracy, many of them lack the explanation of the classification process. In this paper, we compare the performance of conventional machine learning (CML) against deep learning (DL)-based methods. We also provide a visual interpretation for the task of classifying breast cancer in histopathological images. For CML-based methods, we extract a set of handcrafted features using three feature extractors and fuse them to get image representation that would act as an input to train five classical classifiers. For DL-based methods, we adopt the transfer learning approach to the well-known VGG-19 deep learning architecture, where its pre-trained version on the large scale ImageNet, is block-wise fine-tuned on histopathological images. The evaluation of the proposed methods is carried out on the publicly available BreaKHis dataset for the magnification dependent classification of benign and malignant breast cancer and their eight sub-classes, and a further validation on KIMIA Path960, a magnification-free histopathological dataset with 20 image classes, is also performed. After providing the classification results of CML and DL methods, and to better explain the difference in the classification performance, we visualize the learned features. For the DL-based method, we intuitively visualize the areas of interest of the best fine-tuned deep neural networks using attention maps to explain the decision-making process and improve the clinical interpretability of the proposed models. The visual explanation can inherently improve the pathologist’s trust in automated DL methods as a credible and trustworthy support tool for breast cancer diagnosis. The achieved results show that DL methods outperform CML approaches where we reached an accuracy between 94.05% and 98.13% for the binary classification and between 76.77% and 88.95% for the eight-class classification, while for DL approaches, the accuracies range from 85.65% to 89.32% for the binary classification and from 63.55% to 69.69% for the eight-class classification."
2016,High-Content Analysis of Breast Cancer Using Single-Cell Deep Transfer Learning,"High-content analysis has revolutionized cancer drug discovery by identifying substances that alter the phenotype of a cell, which prevents tumor growth and metastasis. The high-resolution biofluorescence images from assays allow precise quantitative measures enabling the distinction of small molecules of a host cell from a tumor. In this work, we are particularly interested in the application of deep neural networks (DNNs), a cutting-edge machine learning method, to the classification of compounds in chemical mechanisms of action (MOAs). Compound classification has been performed using image-based profiling methods sometimes combined with feature reduction methods such as principal component analysis or factor analysis. In this article, we map the input features of each cell to a particular MOA class without using any treatment-level profiles or feature reduction methods. To the best of our knowledge, this is the first application of DNN in this domain, leveraging single-cell information. Furthermore, we use deep transfer learning (DTL) to alleviate the intensive and computational demanding effort of searching the huge parameter’s space of a DNN. Results show that using this approach, we obtain a 30% speedup and a 2% accuracy improvement."
2021,Review of Breast Cancer Pathologigcal Image Processing,"Breast cancer is one of the most common malignancies. Pathological image processing of breast has become an important means for early diagnosis of breast cancer. Using medical image processing to assist doctors to detect potential breast cancer as early as possible has always been a hot topic in the field of medical image diagnosis. In this paper, a breast cancer recognition method based on image processing is systematically expounded from four aspects: breast cancer detection, image segmentation, image registration, and image fusion. The achievements and application scope of supervised learning, unsupervised learning, deep learning, CNN, and so on in breast cancer examination are expounded. The prospect of unsupervised learning and transfer learning for breast cancer diagnosis is prospected. Finally, the privacy protection of breast cancer patients is put forward."
2019,Transfer Learning in Breast Mammogram Abnormalities Classification With Mobilenet and Nasnet,"Breast cancer has an important incidence in women mortality worldwide. Currently, mammography is considered the gold standard for breast abnormalities screening examinations since it aids in the early detection and diagnosis of the illness. However, both identification of mass lesions and its malignancy classification is a challenging problem for artificial intelligence. Research has turned to the use of deep learning models in mammography which can enhance the performance of Computer Aided Diagnosis Systems (CADx). In this paper, we present our preliminary results on the use of transfer learning for malignancy classification of breast abnormality. We experiment with models that, according to our literature review, have not yet been explored thoroughly such as NasNet and MobileNet. Their performance is compared with InceptionV3 and Resnet50. The best results were obtained with Resnet50 and MobileNet with 78.4% and 74.3%, respectively. Also, some image pre-processing steps are studied in order to increase classification accuracy."
2020,Breast Cancer Classification Using Deep Learning Approaches and Histopathology Image: A Comparison Study,"Convolutional Neural Network (CNN) models are a type of deep learning architecture introduced to achieve the correct classification of breast cancer. This paper has a two-fold purpose. The first aim is to investigate the various deep learning models in classifying breast cancer histopathology images. This study identified the most accurate models in terms of the binary, four, and eight classifications of breast cancer histopathology image databases. The different accuracy scores obtained for the deep learning models on the same database showed that other factors such as pre-processing, data augmentation, and transfer learning methods can impact the ability of the models to achieve higher accuracy. The second purpose of our manuscript is to investigate the latest models that have no or limited examination done in previous studies. The models like ResNeXt, Dual Path Net, SENet, and NASNet had been identified with the most cutting-edge results for the ImageNet database. These models were examined for the binary, and eight classifications on BreakHis, a breast cancer histopathology image database. Furthermore, the BACH database was used to investigate these models for four classifications. Then, these models were compared with the previous studies to find and propose the most state-of-the-art models for each classification. Since the Inception-ResNet-V2 architecture achieved the best results for binary and eight classifications, we have examined this model in our study as well to provide a better comparison result. In short, this paper provides an extensive evaluation and discussion about the experimental settings for each study that had been conducted on the breast cancer histopathology images."
2020,Deep Learning Applied for Histological Diagnosis of Breast Cancer,"Deep learning, as one of the currently most popular computer science research trends, improves neural networks, which has more and deeper layers allowing higher abstraction levels and more accurate data analysis. Although deep convolutional neural networks, as a deep learning algorithm, has recently achieved promising results in data analysis, the requirement for a large amount of data prevents its use in medical data analysis since it is challenging to obtain data from the medical field. Breast cancer is a common cancer in women. To diagnose this kind of cancer, breast cell shapes in histopathology images should be examined by senior pathologists. The number of pathologists per population in the world is not enough, especially in Africa, and human mistake may occur in diagnosis procedure. After the evaluation of deep learning methods and algorithms in breast histological data processing, we tried to improve the current systems’ accuracy. As a result, this study proposes two effective deep transfer learning-based models, which rely on pre-trained DCNN using a large collection of ImageNet dataset images that improve current state-of-the-art systems in both binary and multiclass classification. We transfer pre-trained weights of the ResNet50 and DesneNet121 on the Imagenet as initial weights and fine-tune these models with a deep classifier with data augmentation to detect various malignant and benign samples tissues in the two categories of binary classification and multiclass classification. The proposed models have been examined with optimized hyperparameters in magnification-dependent and magnification-independent classification modes. In the multiclass classification, the proposed system achieved up to 98% accuracy. As for binary classification, the proposed system provides up to 100% accuracy. The results outperform previous studies accuracies in all defined performance metrics in breast cancer CAD systems from histological images."
2022,Automated Breast Cancer Detection Models Based on Transfer Learning,"Breast cancer is among the leading causes of mortality for females across the planet. It is essential for the well-being of women to develop early detection and diagnosis techniques. In mammography, focus has contributed to the use of deep learning (DL) models, which have been utilized by radiologists to enhance the needed processes to overcome the shortcomings of human observers. The transfer learning method is being used to distinguish malignant and benign breast cancer by fine-tuning multiple pre-trained models. In this study, we introduce a framework focused on the principle of transfer learning. In addition, a mixture of augmentation strategies were used to prevent overfitting and produce stable outcomes by increasing the number of mammographic images; including several rotation combinations, scaling, and shifting. On the Mammographic Image Analysis Society (MIAS) dataset, the proposed system was evaluated and achieved an accuracy of 89.5% using (residual network-50) ResNet50, and achieved an accuracy of 70% using the Nasnet-Mobile network. The proposed system demonstrated that pre-trained classification networks are significantly more effective and efficient, making them more acceptable for medical imaging, particularly for small training datasets."
2019,Photoacoustic Image Classification and Segmentation of Breast Cancer: A Feasibility Study,"Nowadays, breast cancer has increasingly threatened the health of human, especially females. However, breast cancer is still hard to detect in the early stage, and the diagnostic procedure can be time-consuming with abundant expertise needed. In this paper, we explored the deep learning algorithms in emerging photoacoustic tomography for breast cancer diagnostics. Specifically, we used a pre-processing algorithm to enhance the quality and uniformity of input breast cancer images and a transfer learning method to achieve better classification performance. Besides, by comparing the area under the curve, sensitivity, and specificity of support vector machine with AlexNet and GoogLeNet, it can be concluded that the combination of deep learning and photoacoustic imaging has the potential to achieve important impact on clinical diagnostics. Finally, according to the breast imaging reporting and data-system levels, we divided breast cancer images into six grades and designed a segmentation software for identifying the six grades of breast cancer. Then, we tested based on MAMMOGRAPHYC IMAGES DATABASE FROM LAPIMO EESC/USP (Laboratory of Analysis and Processing of Medical and Dental Images) to verify the accuracy of our segmentation method, which showed a satisfactory result."
2023,Vision-Transformer-Based Transfer Learning for Mammogram Classification,"Breast mass identification is a crucial procedure during mammogram-based early breast cancer diagnosis. However, it is difficult to determine whether a breast lump is benign or cancerous at early stages. Convolutional neural networks (CNNs) have been used to solve this problem and have provided useful advancements. However, CNNs focus only on a certain portion of the mammogram while ignoring the remaining and present computational complexity because of multiple convolutions. Recently, vision transformers have been developed as a technique to overcome such limitations of CNNs, ensuring better or comparable performance in natural image classification. However, the utility of this technique has not been thoroughly investigated in the medical image domain. In this study, we developed a transfer learning technique based on vision transformers to classify breast mass mammograms. The area under the receiver operating curve of the new model was estimated as 1 ± 0, thus outperforming the CNN-based transfer-learning models and vision transformer models trained from scratch. The technique can, hence, be applied in a clinical setting, to improve the early diagnosis of breast cancer."
2023,BC2NetRF: Breast Cancer Classification from Mammogram Images Using Enhanced Deep Learning Features and Equilibrium-Jaya Controlled Regula Falsi-Based Features Selection,"One of the most frequent cancers in women is breast cancer, and in the year 2022, approximately 287,850 new cases have been diagnosed. From them, 43,250 women died from this cancer. An early diagnosis of this cancer can help to overcome the mortality rate. However, the manual diagnosis of this cancer using mammogram images is not an easy process and always requires an expert person. Several AI-based techniques have been suggested in the literature. However, still, they are facing several challenges, such as similarities between cancer and non-cancer regions, irrelevant feature extraction, and weak training models. In this work, we proposed a new automated computerized framework for breast cancer classification. The proposed framework improves the contrast using a novel enhancement technique called haze-reduced local-global. The enhanced images are later employed for the dataset augmentation. This step aimed at increasing the diversity of the dataset and improving the training capability of the selected deep learning model. After that, a pre-trained model named EfficientNet-b0 was employed and fine-tuned to add a few new layers. The fine-tuned model was trained separately on original and enhanced images using deep transfer learning concepts with static hyperparameters’ initialization. Deep features were extracted from the average pooling layer in the next step and fused using a new serial-based approach. The fused features were later optimized using a feature selection algorithm known as Equilibrium-Jaya controlled Regula Falsi. The Regula Falsi was employed as a termination function in this algorithm. The selected features were finally classified using several machine learning classifiers. The experimental process was conducted on two publicly available datasets—CBIS-DDSM and INbreast. For these datasets, the achieved average accuracy is 95.4% and 99.7%. A comparison with state-of-the-art (SOTA) technology shows that the obtained proposed framework improved the accuracy. Moreover, the confidence interval-based analysis shows consistent results of the proposed framework."
2022,Breast lesions classifications of mammographic images using a deep convolutional neural network-based approach,"Breast cancer is one of the worst illnesses, with a higher fatality rate among women globally. Breast cancer detection needs accurate mammography interpretation and analysis, which is challenging for radiologists owing to the intricate anatomy of the breast and low image quality. Advances in deep learning-based models have significantly improved breast lesions’ detection, localization, risk assessment, and categorization. This study proposes a novel deep learning-based convolutional neural network (ConvNet) that significantly reduces human error in diagnosing breast malignancy tissues. Our methodology is most effective in eliciting task-specific features, as feature learning is coupled with classification tasks to achieve higher performance in automatically classifying the suspicious regions in mammograms as benign and malignant. To evaluate the model’s validity, 322 raw mammogram images from Mammographic Image Analysis Society (MIAS) and 580 from Private datasets were obtained to extract in-depth features, the intensity of information, and the high likelihood of malignancy. Both datasets are magnificently improved through preprocessing, synthetic data augmentation, and transfer learning techniques to attain the distinctive combination of breast tumors. The experimental findings indicate that the proposed approach achieved remarkable training accuracy of 0.98, test accuracy of 0.97, high sensitivity of 0.99, and an AUC of 0.99 in classifying breast masses on mammograms. The developed model achieved promising performance that helps the clinician in the speedy computation of mammography, breast masses diagnosis, treatment planning, and follow-up of disease progression. Moreover, it has the immense potential over retrospective approaches in consistency feature extraction and precise lesions classification."
2022,Application of Transfer Learning and Ensemble Learning in Image-level Classification for Breast Histopathology,"Background: Breast cancer has the highest prevalence in women globally. The classification and diagnosis of breast cancer and its histopathological images have always been a hot spot of clinical concern. In Computer-Aided Diagnosis (CAD), traditional classification models mostly use a single network to extract features, which has significant limitations. On the other hand, many networks are trained and optimized on patient-level datasets, ignoring the application of lower-level data labels. Method: This paper proposes a deep ensemble model based on image-level labels for the binary classification of benign and malignant lesions of breast histopathological images. First, the BreaKHis dataset is randomly divided into a training, validation and test set. Then, data augmentation techniques are used to balance the number of benign and malignant samples. Thirdly, considering the performance of transfer learning and the complementarity between each network, VGG16, Xception, ResNet50, DenseNet201 are selected as the base classifiers. Result: In the ensemble network model with accuracy as the weight, the image-level binary classification achieves an accuracy of $98.90\%$. In order to verify the capabilities of our method, the latest Transformer and Multilayer Perception (MLP) models have been experimentally compared on the same dataset. Our model wins with a $5\%-20\%$ advantage, emphasizing the ensemble model's far-reaching significance in classification tasks. Conclusion: This research focuses on improving the model's classification performance with an ensemble algorithm. Transfer learning plays an essential role in small datasets, improving training speed and accuracy. Our model has outperformed many existing approaches in accuracy, providing a method for the field of auxiliary medical diagnosis."
2020,Deep Learning in Selected Cancers’ Image Analysis—A Survey,"Deep learning algorithms have become the first choice as an approach to medical image analysis, face recognition, and emotion recognition. In this survey, several deep-learning-based approaches applied to breast cancer, cervical cancer, brain tumor, colon and lung cancers are studied and reviewed. Deep learning has been applied in almost all of the imaging modalities used for cervical and breast cancers and MRIs for the brain tumor. The result of the review process indicated that deep learning methods have achieved state-of-the-art in tumor detection, segmentation, feature extraction and classification. As presented in this paper, the deep learning approaches were used in three different modes that include training from scratch, transfer learning through freezing some layers of the deep learning network and modifying the architecture to reduce the number of parameters existing in the network. Moreover, the application of deep learning to imaging devices for the detection of various cancer cases has been studied by researchers affiliated to academic and medical institutes in economically developed countries; while, the study has not had much attention in Africa despite the dramatic soar of cancer risks in the continent."
2022,Breast Cancer Detection and Classification Empowered With Transfer Learning,"Cancer is a major public health issue in the modern world. Breast cancer is a type of cancer that starts in the breast and spreads to other parts of the body. One of the most common types of cancer that kill women is breast cancer. When cells become uncontrollably large, cancer develops. There are various types of breast cancer. The proposed model discussed benign and malignant breast cancer. In computer-aided diagnosis systems, the identification and classification of breast cancer using histopathology and ultrasound images are critical steps. Investigators have demonstrated the ability to automate the initial level identification and classification of the tumor throughout the last few decades. Breast cancer can be detected early, allowing patients to obtain proper therapy and thereby increase their chances of survival. Deep learning (DL), machine learning (ML), and transfer learning (TL) techniques are used to solve many medical issues. There are several scientific studies in the previous literature on the categorization and identification of cancer tumors using various types of models but with some limitations. However, research is hampered by the lack of a dataset. The proposed methodology is created to help with the automatic identification and diagnosis of breast cancer. Our main contribution is that the proposed model used the transfer learning technique on three datasets, A, B, C, and A2, A2 is the dataset A with two classes. In this study, ultrasound images and histopathology images are used. The model used in this work is a customized CNN-AlexNet, which was trained according to the requirements of the datasets. This is also one of the contributions of this work. The results have shown that the proposed system empowered with transfer learning achieved the highest accuracy than the existing models on datasets A, B, C, and A2."
2022,Breast Cancer Detection in Mammography Images Using Deep Convolutional Neural Networks and Fuzzy Ensemble Modeling Techniques,"Breast cancer has evolved as the most lethal illness impacting women all over the globe. Breast cancer may be detected early, which reduces mortality and increases the chances of a full recovery. Researchers all around the world are working on breast cancer screening tools based on medical imaging. Deep learning approaches have piqued the attention of many in the medical imaging field due to their rapid growth. In this research, mammography pictures were utilized to detect breast cancer. We have used four mammography imaging datasets with a similar number of 1145 normal, benign, and malignant pictures using various deep CNN (Inception V4, ResNet-164, VGG-11, and DenseNet121) models as base classifiers. The proposed technique employs an ensemble approach in which the Gompertz function is used to build fuzzy rankings of the base classification techniques, and the decision scores of the base models are adaptively combined to construct final predictions. The proposed fuzzy ensemble techniques outperform each individual transfer learning methodology as well as multiple advanced ensemble strategies (Weighted Average, Sugeno Integral) with reference to prediction and accuracy. The suggested Inception V4 ensemble model with fuzzy rank based Gompertz function has a 99.32% accuracy rate. We believe that the suggested approach will be of tremendous value to healthcare practitioners in identifying breast cancer patients early on, perhaps leading to an immediate diagnosis."
2023,A Transfer Learning-Based Deep Learning Model for Automated Breast Cancer Identification in Mammograms,"Abstract: Breast cancer is a severe health issue that affects women all over the world, underscoring the need for reliable and effective screening techniques. The early detection, diagnosis, and treatment of breast cancer are made possible by computer-aided diagnostic (CAD) systems that rely on mammograms. This study introduces a unique deep-learning model that uses transfer learning to identify and categorize breast cancer automatically. Deep convolutional neural networks have been shown in several recent studies to diagnose breast cancer in mammograms with performance comparable to or even outperforming that of human experts. In order to extract features from the dataset from the Mammographic Image Analysis Society (MIAS), the proposed model uses pre-trained convolutional neural network (CNN) architectures like ResNet50 and Visual Geometry Group networks (VGG)-16. This novel deep-learning model holds significant potential for enhancing the efficiency and accuracy of breast cancer detection and classification."
2023,Automatic BI-RADS Classification of Breast Magnetic Resonance Medical Records Using Transformer-Based Models for Brazilian Portuguese,"This chapter aims to present a classification model for categorizing textual clinical records of breast magnetic resonance imaging, based on lexical, syntactic and semantic analysis of clinical reports according to the Breast Imaging-Reporting and Data System (BI-RADS) classification, using Deep Learning and Natural Language Processing (NLP). The model was developed from transfer learning based on the pre-trained BERTimbau model, BERT model (Bidirectional Encoder Representations from Transformers) trained in Brazilian Portuguese. The dataset is composed of medical reports in Brazilian Portuguese classified into six categories: Inconclusive; Normal or Negative; Certainly Benign Findings; Probably Benign Findings; Suspicious Findings; High Risk of Cancer; Previously Known Malignant Injury. The following models were implemented and compared: Random Forest, SVM, Naïve Bayes, BERTimbau with and without finetuning. The BERTimbau model presented better results, with better performance after finetuning."
2023,"Classification of Breast Masses Using Ultrasound Images by Approaching GAN, Transfer Learning and Deep Learning Techniques","Breast cancer is a common cause of death among women worldwide. Ultrasonic imaging is a valuable diagnostic tool in breast cancer detection. However, the accuracy of computer-aided diagnosis systems for breast cancer classification is limited due to the lack of well-annotated datasets. This study proposes a deep learning-based framework for breast mass classification using ultrasound images, which incorporates a novel data augmentation technique, Generative Adversarial Network (GAN), and Transfer Learning (TL). Automating early tumor identification and classification in breast cancer diagnosis can save lives by improving the accuracy of diagnoses and reducing the need for invasive procedures. However, the limited availability of well-annotated datasets for ultrasound images of breast cancer has hampered the development of accurate computer-aided diagnosis systems. The accuracy of breast mass classification using ultrasound images is limited due to the lack of well-annotated datasets. Conventional data augmentation techniques have limitations in applications with strict guidelines, such as medical datasets. Therefore, there is a need to develop a novel data augmentation technique to improve the accuracy of breast mass classification using ultrasound images. The proposed framework can be extended to other medical imaging applications, where the availability of well-annotated datasets is limited. The GAN-based data augmentation technique and TL-based feature extraction can be used to improve the accuracy of classification models in other medical imaging applications. Additionally, the proposed framework can be used to develop accurate computer-aided diagnosis systems for breast cancer detection in clinical settings. The proposed framework incorporates a deep learning-based approach for breast mass classification using ultrasound images. The framework includes a GAN-based data augmentation technique and TL for feature extraction. The dataset used for training and testing the model is the Breast Ultrasound Images (BUSI) dataset, which includes 1311 images with normal and abnormal breast masses. The proposed framework achieved an accuracy of 99.6% for breast mass classification using ultrasound images, which outperformed existing methods. The GAN-based data augmentation technique and TL-based feature extraction improved the accuracy of the classification model. The results suggest that deep learning algorithms can be effectively applied for breast ultrasound categorization. The proposed framework presents a novel approach for breast mass classification using ultrasound images, which incorporates a GAN-based data augmentation technique and TL-based feature extraction. The results demonstrate that the proposed framework outperforms existing methods and achieves high accuracy in breast mass classification using ultrasound images. This framework can be useful for developing accurate computer-aided diagnosis systems for breast cancer detection."
2020,Multi-View Attention-based Late Fusion (MVALF) CADx system for breast cancer using deep learning,"Breast cancer is a leading cause of death among women. Early detection can significantly reduce the mortality rate among women and improve their prognosis. Mammography is the first line procedure for early diagnosis. In the early era, conventional Computer-Aided Diagnosis (CADx) systems for breast lesion diagnosis were based on just single view information. The last decade evidence the use of two views mammogram: Medio-Lateral Oblique (MLO) and Cranio-Caudal (CC) view for the CADx systems. Most recent studies show the effectiveness of four views of mammogram to train CADx system with feature fusion strategy for classification task. In this paper, we proposed an end-to-end Multi-View Attention-based Late Fusion (MVALF) CADx system that fused the obtained predictions of four view models, which is trained for each view separately. These separate models have different predictive ability for each class. The appropriate fusion of multi-view models can achieve better diagnosis performance. So, it is necessary to assign the proper weights to the multi-view classification models. To resolve this issue, attention-based weighting mechanism is adopted to assign the proper weights to trained models for fusion strategy. The proposed methodology is used for the classification of mammogram into normal, mass, calcification, malignant masses and benign masses. The publicly available datasets CBIS-DDSM and mini-MIAS are used for the experimentation. The results show that our proposed system achieved 0.996 AUC for normal vs. abnormal, 0.922 for mass vs. calcification and 0.896 for malignant vs. benign masses. Superior results are seen for the classification of malignant vs benign masses with our proposed approach, which is higher than the results using single view, two views and four views early fusion-based systems. The overall results of each level show the potential of multi-view late fusion with transfer learning in the diagnosis of breast cancer."
2022,Breast Tumor Classification in Digital Tomosynthesis Based on Deep Learning Radiomics,"Breast cancer is the most frequently diagnosed cancer in women globally. Early and accurate detection and classification of breast tumors are critical in improving treatment strategies and increasing the patient survival rate. Digital breast tomosynthesis (DBT) is an advanced form of mammography that aids better in the early detection and diagnosis of breast disease. This paper proposes a breast tumor classification method based on analyzing and evaluating the performance of various of the most innovative deep learning classification models in cooperation with a support vector machine (SVM) classifier for a DBT dataset. Specifically, we study the ability to use transfer learning from non-medical images to classify tumors in unseen DBT medical images. In addition, we utilize the fine-tuning technique to improve classification accuracy."
2023,Breast cancer diagnosis through knowledge distillation of Swin transformer-based teacher–student models,"Abstract: Breast cancer is a significant global health concern, emphasizing the crucial need for a timely and accurate diagnosis to enhance survival rates. Traditional diagnostic methods rely on pathologists analyzing whole-slide images (WSIs) to identify and diagnose malignancies. However, this task is complex, demanding specialized expertise and imposing a substantial workload on pathologists. Additionally, existing deep learning models, commonly employed for classifying histopathology images, often need enhancements to ensure their suitability for real-time deployment on WSI, especially when trained for small regions of interest (ROIs). This article introduces two Swin transformer-based architectures: the teacher model, characterized by its moderate size, and the lightweight student model. Both models are trained using a publicly available dataset of breast cancer histopathology images, focusing on ROIs with varying magnification factors. Transfer learning is applied to train the teacher model, and knowledge distillation (KD) transfers its capabilities to the student model. To enhance validation accuracy and minimize the total loss in KD, we employ the state–action–reward–state–action (SARSA) reinforcement learning algorithm. The algorithm dynamically computes temperature and a weighting factor throughout the KD process to achieve high accuracy within a considerably shorter training timeframe. Additionally, the student model is deployed to analyze malignancies in WSI. Despite the student model being only one-third the size and flops of the teacher model, it achieves an impressive accuracy of 98.71%, slightly below the teacher’s accuracy of 98.91%. Experimental results demonstrate that the student model can process WSIs at a throughput of 1.67 samples s"
2023,Breast Cancer Using Deep Learning and Histopathology Images,"Abstract: Breast cancer is among one of the most common cancers in the world. Early detection in this area can be crucial and help the patients to start the medication. One way to detect the breast cancer is using histopathology images. In recent years deep learning methods are among the methods that have shown high accuracy in detection cancerous tumors in images. In this work different deep learning methods such as Xception, MobileVNet, VGG16 and VGG19 have been used and the results are compared. Two popular datasets in breast cancer have been used. Transfer learning is used for pre-training the structures. In addition, different preprocessing methods is introduced and used to increase the number of images in the dataset."
2023,Breast Cancer Detection Using Image Processing and Machine Learning,"Different breast cancer detection systems have been developed to help clinicians analyze screening mammograms. Breast cancer has been increasing gradually so scientists work to develop new methods to reduce the risks of this life-threatening disease. Convolutional Neural Networks (CNNs) have shown much promise In the field of medical imaging because of recent developments in deep learning. However, CNN’s based methods have been restricted due to the small size of the few public breast cancer datasets. This research has developed a new framework and introduced it to detect breast cancer. This framework utilizes Convolutional Neural Networks (CNNs) and image processing to achieve its goal because CNNs have been an important success in image recognition, reaching human performance. An efficient and fast CNN pre-trained object detector called RetinaNet has been used in this research. RetinaNet is an uncomplicated one-stage object detector. A two-stage transfer learning has been used with the selected detector to improve the performance. RetinaNet model is initially trained with a general-purpose dataset called COCO dataset. The transfer learning is then used to apply the RetinaNet model to another dataset of mammograms called the CBIS-DDSM dataset. Finally, the second transfer learning is used to test the RetinaNet model onto a small dataset of mammograms called the INbreast dataset. The results of the proposed two-stage transfer learning (RetinaNet → CBIS-DDSM → INbreast) are better than the other state-of-the-art methods on the public INbreast dataset. Furthermore, the True Positive Rate (TPR) is 0.99 ± 0.02 at 1.67 False Positives per Image (FPPI), which is better than the one-stage transfer learning with a TPR of 0.94 ± 0.02 at 1.67 FPPI."
2023,"Breast Cancer Mass Classification Using Machine Learning, Binary-Coded Genetic Algorithms and an Ensemble of Deep Transfer Learning","Abstract: The diagnosis of breast cancer (BC) as early as possible is crucial for increasing the survival rate. Mammography enables finding the breast tissue changes years before they could develop into cancer symptoms. In this study, machine learning methods for BC mass pathology classification have been investigated using the radiologists’ mass annotations on the screen-film mammograms of the Breast Cancer Digital Repository (BCDR). The performances of precomputed features in the BCDR and discrete wavelet transform followed by Radon transform have been investigated by using four sequential feature selections and three genetic algorithms. Feature fusion from craniocaudal and mediolateral oblique views was shown to increase the performance of the classifier. Mass classification has been implemented by deep transfer learning (DTL) using the weights of ResNet50, NASNetLarge and Xception networks. An ensemble of DTL (EDTL) was shown to have higher classification performance than the DTL models. The proposed EDTL has area under the receiver operating curve (AUC) scores of 0.8843 and 0.9089 for mass classification on the region of interest (ROI) and ROI union datasets, respectively. The proposed EDTL has the highest BC mass classification AUC score on the BCDR to date and may be useful for other datasets."
2020,Classification of Breast Cancer from Digital Mammography Using Deep Learning,"Breast cancer is the most frequent in females. Mammography has proven to be the most effective method for the early detection of this type of cancer. Mammographic images are sometimes difficult to understand, due to the nature of the anomalies, the low contrast image and the composition of the mammary tissues, as well as various technological factors such as spatial resolution of the image or noise. Computer-aided diagnostic systems have been developed to increase the accuracy of mammographic examinations and be used by physicians as a second opinion in obtaining the final diagnosis, and thus reduce human errors. Convolutional neural networks are a current trend in computer vision tasks, due to the great performance they have achieved. The present investigation was based on this type of networks to classify into three classes, normal, benign and malignant tumour. Due to the fact that the miniMIAS database used has a low number of images, the transfer learning technique was applied to the Inception v3 pre-trained network. Two convolutional neural network architectures were implemented, obtaining in the architecture with three classes, 86.05% accuracy. On the other hand, in the architecture with two neural networks in series, an accuracy of 88.2% was reached."
2023,Deep Learning in Automating Breast Cancer Diagnosis from Microscopy Images,"Context: Breast cancer is one of the most common cancers in women. With early diagnosis, some breast cancers are highly curable. However, the concordance rate of breast cancer diagnosis from histology slides by pathologists is unacceptably low. Classifying normal versus tumor breast tissues from microscopy images of breast histology is an ideal case to use for deep learning and could help to more reproducibly diagnose breast cancer. Since data preprocessing and hyperparameter configurations have impacts on breast cancer classification accuracies of deep learning models, training a deep learning classifier with appropriate data preprocessing approaches and optimized hyperparameter configurations could improve breast cancer classification accuracy. Methods and Material: Using 12 combinations of deep learning model architectures (i.e., including 5 non-specialized and 7 digital pathology-specialized model architectures), image data preprocessing, and hyperparameter configurations, the validation accuracy of tumor versus normal classification were calculated using the Results: The DenseNet201, a non-specialized model architecture, with transfer learning approach achieved 98.61% validation accuracy compared to only 64.00% for the digital pathology-specialized model architecture. Conclusions: The combination of image data preprocessing approaches and hyperparameter configurations have a profound impact on the performance of deep neural networks for image classification. To identify a well-performing deep neural network to classify tumor versus normal breast histology, researchers should not only focus on developing new models specifically for digital pathology, since hyperparameter tuning for existing deep neural networks in the computer vision field could also achieve a high (often better) prediction accuracy."
2022,Skin Cancer Detection Using Deep Learning and Artificial Intelligence: Incorporated model of deep features fusion,"Among the most frequent forms of cancer, skin cancer accounts for hundreds of thousands of fatalities annually throughout the globe. It shows up as excessive cell proliferation on the skin. The likelihood of a successful recovery is greatly enhanced by an early diagnosis. More than that, it might reduce the need for or the frequency of chemical, radiological, or surgical treatments. As a result, savings on healthcare expenses will be possible. Dermoscopy, which examines the size, form, and color features of skin lesions, is the first step in the process of detecting skin cancer and is followed by sample and lab testing to confirm any suspicious lesions. Deep learning AI has allowed for significant progress in image-based diagnostics in recent years. Deep neural networks known as convolutional neural networks (CNNs or ConvNets) are essentially an extended form of multi-layer perceptrons. In visual imaging challenges, CNNs have shown the best accuracy. The purpose of this research is to create a CNN model for the early identification of skin cancer. The backend of the CNN classification model will be built using Keras and Tensorflow in Python. Different network topologies, such as Convolutional layers, Dropout layers, Pooling layers, and Dense layers, are explored and tried out throughout the model's development and validation phases. Transfer Learning methods will also be included in the model to facilitate early convergence. The dataset gathered from the ISIC challenge archives will be used to both tests and train the model."
2020,A New Deep Learning Model Selection Method for Colorectal Cancer Classification,"<p>Deep learning is one of the most commonly used techniques in computer-aided diagnosis systems. Their exploitation for histopathological image analysis is important because of the complex morphology of whole slide images. However, the main limitation of these methods is the restricted number of available medical images, which can lead to an overfitting problem. Many studies have suggested the use of static ensemble learning methods to address this issue. This article aims to propose a new dynamic ensemble deep learning method. First, it generates a set of models based on the transfer learning strategy from deep neural networks. Then, the relevant subset of models is selected by the particle swarm optimization algorithm and combined by voting or averaging methods. The proposed approach was tested on a histopathological dataset for colorectal cancer classification, based on seven types of CNNs. The method has achieved accurate results (94.52%) by the Resnet121 model and the voting strategy, which provides important insights into the efficiency of dynamic ensembling in deep learning.</p>"
2022,Deep-learning and transfer learning identify new breast cancer survival subtypes from single-cell imaging data,"STATEMENT OF TRANSLATIONAL RELEVANCE: Our findings from a breast cancer population cohort demonstrate the clinical utility of using the single-cell level imaging mass cytometry (IMC) data as a new type of patient prognosis prediction marker. Not only did the prognosis prediction achieve high accuracy with a Concordance index score greater than 0.8, it also enabled the discovery of seven survival subtypes that are more distinguishable than the molecular subtypes. These new subtypes present distinct profiles of epithelial, immune, fibroblast cells, and their interactions. Most importantly, this study identified and validated atypical subpopulations of TNBC patients with moderate prognosis (GATA3 over-expression) and Luminal A patients with poor prognosis (KRT6 and ACTA2 over-expression and CDH1 under-expression), using multiple large breast cancer cohorts."
2022,Machine Learning and Deep Learning Algorithms for Skin Cancer Classification from Dermoscopic Images,"We carry out a critical assessment of machine learning and deep learning models for the classification of skin tumors. Machine learning (ML) algorithms tested in this work include logistic regression, linear discriminant analysis, k-nearest neighbors classifier, decision tree classifier and Gaussian naive Bayes, while deep learning (DL) models employed are either based on a custom Convolutional Neural Network model, or leverage transfer learning via the use of pre-trained models (VGG16, Xception and ResNet50). We find that DL models, with accuracies up to 0.88, all outperform ML models. ML models exhibit accuracies below 0.72, which can be increased to up to 0.75 with ensemble learning. To further assess the performance of DL models, we test them on a larger and more imbalanced dataset. Metrics, such as the F-score and accuracy, indicate that, after fine-tuning, pre-trained models perform extremely well for skin tumor classification. This is most notably the case for VGG16, which exhibits an F-score of 0.88 and an accuracy of 0.88 on the smaller database, and metrics of 0.70 and 0.88, respectively, on the larger database."
2022,Hybrid Model for Breast Cancer Diagnosis on Mammograms Using Transfer Learning,"Abstract: Breast cancer is one of the most common types of cancer among women all over the world, which leads to the death of many women every year due to misdiagnosis and late treatment. Therefore, in this research, a new deep learning model was developed based on Python and using the mini-MIAS dataset. Initially image contrast optimization operations and segmentation were performed to enhance image and extract the region of interest (breast region) in order to improve the performance of the model and increase the accuracy of diagnosis and then extract the features using the transfer learning technique and based on a set of pre-trained networks. A comparison was made between a set of pre-trained convolutional network architectures (VGG16, ResNet50, MobileNetV2, InceptionV3) where the VGG16 network gave the best performance in the phase of extracting features and then building the final hybrid model by merging the VGG16 network with the random forest classifier. Our model achieved 94.25% average accuracy and the Area under curve (AUC) is 98% for all three classes, in addition to reducing the time required to build the system."
2022,Detection of Breast Cancer Images Based on Transfer and Deep Learning Models,"Abstract: Using a technology known as deep learning, which involves classifying photos based on the data they contain, it is possible to detect images, such as tumors and other signs. Because of the scarcity of pathologists and the growing number of patients with breast cancer, the manual numeration of biopsy echantillons must be mechanized (CS). To rectify the histopathological images of malignant tissue, preliminary study is required, which can be done utilizing BreaKHis' free database of data. An approach based on isolated image fragments is proposed, with the final categorization determined by an interconnected network of neurons (CNN) and a final combination of these pieces. Because of its unique architecture, capacity to recognize speech, identify objects, and analyze signals, as well as the popularity of neural language processing, the CNN is attracting increasing interest from industry and researchers. The employment of transfer learning methods is a problem with tiny collections of medical data. To improve the classification of defamatory and obscene photos, this article recommends integrating the impacts of many resolutions. In order to better depict the entering image's texture, many essential phases in CNN development are also used. Maintain a safe distance from the model's customization. Traditional CNN development may become more complex and expensive as a result. The simulation results achieved by running CNN in MATLAB outperform other artificial intelligence (AI) models recently published that used hand-crafted texture descriptors. With this in mind, we looked at all of CNN's possible combinations and discovered a technique to boost the execution rate by a little amount."
2021,Deep Multi-View Breast Cancer Detection: A Multi-View Concatenated Infrared Thermal Images Based Breast Cancer Detection System Using Deep Transfer Learning,"This paper simply presents a fully automated breast cancer detection system as “Deep Multi-view Breast cancer Detection” based on deep transfer learning. The deep transfer learning model i.e., Visual Geometry Group 16 (VGG 16) is used in this approach for the correct classification of Breast thermal images into either normal or abnormal. This VGG 16 model is trained with the help of Static as well as Dynamic breast thermal images dataset consisting of multi-view, single view breast thermal images. These Multi-view breast thermal images are generated in this approach by concatenating the conventional left, frontal and right view breast thermal images taken from the Database for Mastology Research with Infrared image for the first time in order to generate a more informative and complete thermal temperature map of breast for enhancing the accuracy of the overall system. For the sake of genuine comparison, three other popular deep transfer learning models like Residual Network 50 (ResNet50V2), InceptionV3 network and Visual Geometry Group 19 (VGG 19) are also trained with the same augmented dataset consisting of multi-view as well as single view breast thermal images. The VGG 16 based Deep Multi-view Breast cancer Detect system delivers the best training, validation as well as testing accuracies as compared to their other deep transfer learning models. The VGG 16 achieves an encouraging testing accuracy of 99% on the Dynamic breast thermal images testing dataset utilizing the multi-view breast thermal images as input. Whereas the testing accuracies of 95%, 94% and 89% are achieved by the VGG 19, ResNet50V2, InceptionV3 models respectively over the Dynamic breast thermal images testing dataset utilizing the same multi-view breast thermal images as input."
2023,Assessing VTE Risk in Cancer Patients Using Deep Learning Synthetic Data Generation and Domain Adaptation Techniques,"This article focuses on the use of deep learning synthetic data generation methods to assess the risk of future treatments and medication for preventing venous thromboembolism (VTE) in cancer patients, based on a small dataset of genetic and clinical variables. The study employs CopulaGANs to generate synthetic tabular data, which is then used to train a Deep Learning-based classifier using domain adaptation techniques. The trained model is fine-tuned using real data and performs better than current state-of-the-art medical scores in assessing VTE risk. Additionally, the resulting Precision-Recall curve offers flexibility in selecting different and better operational points for VTE risk assessment."
2018,A deep learning method for classifying mammographic breast density categories,"PURPOSE Mammographic breast density is an established risk marker for breast cancer and is visually assessed by radiologists in routine mammogram image reading, using four qualitative Breast Imaging and Reporting Data System (BI-RADS) breast density categories. It is particularly difficult for radiologists to consistently distinguish the two most common and most variably assigned BI-RADS categories, i.e., ""scattered density"" and ""heterogeneously dense"". The aim of this work was to investigate a deep learning-based breast density classifier to consistently distinguish these two categories, aiming at providing a potential computerized tool to assist radiologists in assigning a BI-RADS category in current clinical workflow. METHODS In this study, we constructed a convolutional neural network (CNN)-based model coupled with a large (i.e., 22,000 images) digital mammogram imaging dataset to evaluate the classification performance between the two aforementioned breast density categories. All images were collected from a cohort of 1,427 women who underwent standard digital mammography screening from 2005 to 2016 at our institution. The truths of the density categories were based on standard clinical assessment made by board-certified breast imaging radiologists. Effects of direct training from scratch solely using digital mammogram images and transfer learning of a pretrained model on a large nonmedical imaging dataset were evaluated for the specific task of breast density classification. In order to measure the classification performance, the CNN classifier was also tested on a refined version of the mammogram image dataset by removing some potentially inaccurately labeled images. Receiver operating characteristic (ROC) curves and the area under the curve (AUC) were used to measure the accuracy of the classifier. RESULTS The AUC was 0.9421 when the CNN-model was trained from scratch on our own mammogram images, and the accuracy increased gradually along with an increased size of training samples. Using the pretrained model followed by a fine-tuning process with as few as 500 mammogram images led to an AUC of 0.9265. After removing the potentially inaccurately labeled images, AUC was increased to 0.9882 and 0.9857 for without and with the pretrained model, respectively, both significantly higher (P < 0.001) than when using the full imaging dataset. CONCLUSIONS Our study demonstrated high classification accuracies between two difficult to distinguish breast density categories that are routinely assessed by radiologists. We anticipate that our approach will help enhance current clinical assessment of breast density and better support consistent density notification to patients in breast cancer screening."
2021,Novel Transfer Learning Approach for Medical Imaging with Limited Labeled Data,"Deep learning requires a large amount of data to perform well. However, the field of medical image analysis suffers from a lack of sufficient data for training deep learning models. Moreover, medical images require manual labeling, usually provided by human annotators coming from various backgrounds. More importantly, the annotation process is time-consuming, expensive, and prone to errors. Transfer learning was introduced to reduce the need for the annotation process by transferring the deep learning models with knowledge from a previous task and then by fine-tuning them on a relatively small dataset of the current task. Most of the methods of medical image classification employ transfer learning from pretrained models, e.g., ImageNet, which has been proven to be ineffective. This is due to the mismatch in learned features between the natural image, e.g., ImageNet, and medical images. Additionally, it results in the utilization of deeply elaborated models. In this paper, we propose a novel transfer learning approach to overcome the previous drawbacks by means of training the deep learning model on large unlabeled medical image datasets and by next transferring the knowledge to train the deep learning model on the small amount of labeled medical images. Additionally, we propose a new deep convolutional neural network (DCNN) model that combines recent advancements in the field. We conducted several experiments on two challenging medical imaging scenarios dealing with skin and breast cancer classification tasks. According to the reported results, it has been empirically proven that the proposed approach can significantly improve the performance of both classification scenarios. In terms of skin cancer, the proposed model achieved an F1-score value of 89.09% when trained from scratch and 98.53% with the proposed approach. Secondly, it achieved an accuracy value of 85.29% and 97.51%, respectively, when trained from scratch and using the proposed approach in the case of the breast cancer scenario. Finally, we concluded that our method can possibly be applied to many medical imaging problems in which a substantial amount of unlabeled image data is available and the labeled image data is limited. Moreover, it can be utilized to improve the performance of medical imaging tasks in the same domain. To do so, we used the pretrained skin cancer model to train on feet skin to classify them into two classes—either normal or abnormal (diabetic foot ulcer (DFU)). It achieved an F1-score value of 86.0% when trained from scratch, 96.25% using transfer learning, and 99.25% using double-transfer learning."
2019,Deep Learning for Breast Cancer Diagnosis from Mammograms—A Comparative Study,"Deep convolutional neural networks (CNNs) are investigated in the context of computer-aided diagnosis (CADx) of breast cancer. State-of-the-art CNNs are trained and evaluated on two mammographic datasets, consisting of ROIs depicting benign or malignant mass lesions. The performance evaluation of each examined network is addressed in two training scenarios: the first involves initializing the network with pre-trained weights, while for the second the networks are initialized in a random fashion. Extensive experimental results show the superior performance achieved in the case of fine-tuning a pretrained network compared to training from scratch."
2017,Deep learning model based breast cancer histopathological image classification,"The automatic and precision classification for breast cancer histopathological image has a great significance in clinical application. However, the existing analysis approaches are difficult to addressing the breast cancer classification problem because the feature subtle differences of inter-class histopathological image and the classification accuracy still hard to meet the clinical application. Recent advancements in data-driven sharing processing and multi-level hierarchical feature learning have made available considerable chance to dope out a solution to this problem. To address the challenging problem, we propose a novel breast cancer histopathological image classification method based on deep convolutional neural networks, named as BiCNN model, to address the two-class breast cancer classification on the pathological image. This deep learning model considers class and sub-class labels of breast cancer as prior knowledge, which can restrain the distance of features of different breast cancer pathological images. In addition, an advanced data augmented method is proposed to fit tolerance whole slide image recognition, which can full reserve image edge feature of cancerization region. The transfer learning and fine-tuning method are adopted as an optimal training strategy to improve breast cancer histopathological image classification accuracy. The experiment results show that the proposed method leads to a higher classification accuracy (up to 97%) and displays good robustness and generalization, which provides efficient tools for breast cancer clinical diagnosis."
2021,Breast Cancer Classification From Histopathological Images Using Patch-Based Deep Learning Modeling,"Accurate detection and classification of breast cancer is a critical task in medical imaging due to the complexity of breast tissues. Due to automatic feature extraction ability, deep learning methods have been successfully applied in different areas, especially in the field of medical imaging. In this study, a novel patch-based deep learning method called Pa-DBN-BC is proposed to detect and classify breast cancer on histopathology images using the Deep Belief Network (DBN). Features are extracted through an unsupervised pre-training and supervised fine-tuning phase. The network automatically extracts features from image patches. Logistic regression is used to classify the patches from histopathology images. The features extracted from the patches are fed to the model as input and the model presents the result as a probability matrix as either a positive sample (cancer) or a negative sample (background). The proposed model is trained and tested on the whole slide histopathology image dataset having images from four different data cohorts and achieved an accuracy of 86%. Consequently, the proposed method is better than the traditional ones, as it automatically learns the best possible features and experimental results show that the model outperformed the previously proposed deep learning methods."
2019,A Technical Review of Convolutional Neural Network-Based Mammographic Breast Cancer Diagnosis,"This study reviews the technique of convolutional neural network (CNN) applied in a specific field of mammographic breast cancer diagnosis (MBCD). It aims to provide several clues on how to use CNN for related tasks. MBCD is a long-standing problem, and massive computer-aided diagnosis models have been proposed. The models of CNN-based MBCD can be broadly categorized into three groups. One is to design shallow or to modify existing models to decrease the time cost as well as the number of instances for training; another is to make the best use of a pretrained CNN by transfer learning and fine-tuning; the third is to take advantage of CNN models for feature extraction, and the differentiation of malignant lesions from benign ones is fulfilled by using machine learning classifiers. This study enrolls peer-reviewed journal publications and presents technical details and pros and cons of each model. Furthermore, the findings, challenges and limitations are summarized and some clues on the future work are also given. Conclusively, CNN-based MBCD is at its early stage, and there is still a long way ahead in achieving the ultimate goal of using deep learning tools to facilitate clinical practice. This review benefits scientific researchers, industrial engineers, and those who are devoted to intelligent cancer diagnosis."
2019,Classification of Histopathological Biopsy Images Using Ensemble of Deep Learning Networks,"Breast cancer is one of the leading causes of death across the world in women. Early diagnosis of this type of cancer is critical for treatment and patient care. Computer-aided detection (CAD) systems using convolutional neural networks (CNN) could assist in the classification of abnormalities. In this study, we proposed an ensemble deep learning-based approach for automatic binary classification of breast histology images. The proposed ensemble model adapts three pre-trained CNNs, namely VGG19, MobileNet, and DenseNet. The ensemble model is used for the feature representation and extraction steps. The extracted features are then fed into a multi-layer perceptron classifier to carry out the classification task. Various pre-processing and CNN tuning techniques such as stain-normalization, data augmentation, hyperparameter tuning, and fine-tuning are used to train the model. The proposed method is validated on four publicly available benchmark datasets, i.e., ICIAR, BreakHis, PatchCamelyon, and Bioimaging. The proposed multi-model ensemble method obtains better predictions than single classifiers and machine learning algorithms with accuracies of 98.13%, 95.00%, 94.64% and 83.10% for BreakHis, ICIAR, PatchCamelyon and Bioimaging datasets, respectively."
2022,Automated Breast Cancer Detection Models Based on Transfer Learning,"Breast cancer is among the leading causes of mortality for females across the planet. It is essential for the well-being of women to develop early detection and diagnosis techniques. In mammography, focus has contributed to the use of deep learning (DL) models, which have been utilized by radiologists to enhance the needed processes to overcome the shortcomings of human observers. The transfer learning method is being used to distinguish malignant and benign breast cancer by fine-tuning multiple pre-trained models. In this study, we introduce a framework focused on the principle of transfer learning. In addition, a mixture of augmentation strategies were used to prevent overfitting and produce stable outcomes by increasing the number of mammographic images; including several rotation combinations, scaling, and shifting. On the Mammographic Image Analysis Society (MIAS) dataset, the proposed system was evaluated and achieved an accuracy of 89.5% using (residual network-50) ResNet50, and achieved an accuracy of 70% using the Nasnet-Mobile network. The proposed system demonstrated that pre-trained classification networks are significantly more effective and efficient, making them more acceptable for medical imaging, particularly for small training datasets."
2022,Breast Tumor Classification in Digital Tomosynthesis Based on Deep Learning Radiomics,"Breast cancer is the most frequently diagnosed cancer in women globally. Early and accurate detection and classification of breast tumors are critical in improving treatment strategies and increasing the patient survival rate. Digital breast tomosynthesis (DBT) is an advanced form of mammography that aids better in the early detection and diagnosis of breast disease. This paper proposes a breast tumor classification method based on analyzing and evaluating the performance of various of the most innovative deep learning classification models in cooperation with a support vector machine (SVM) classifier for a DBT dataset. Specifically, we study the ability to use transfer learning from non-medical images to classify tumors in unseen DBT medical images. In addition, we utilize the fine-tuning technique to improve classification accuracy."
2022,Machine Learning and Deep Learning Algorithms for Skin Cancer Classification from Dermoscopic Images,"We carry out a critical assessment of machine learning and deep learning models for the classification of skin tumors. Machine learning (ML) algorithms tested in this work include logistic regression, linear discriminant analysis, k-nearest neighbors classifier, decision tree classifier and Gaussian naive Bayes, while deep learning (DL) models employed are either based on a custom Convolutional Neural Network model, or leverage transfer learning via the use of pre-trained models (VGG16, Xception and ResNet50). We find that DL models, with accuracies up to 0.88, all outperform ML models. ML models exhibit accuracies below 0.72, which can be increased to up to 0.75 with ensemble learning. To further assess the performance of DL models, we test them on a larger and more imbalanced dataset. Metrics, such as the F-score and accuracy, indicate that, after fine-tuning, pre-trained models perform extremely well for skin tumor classification. This is most notably the case for VGG16, which exhibits an F-score of 0.88 and an accuracy of 0.88 on the smaller database, and metrics of 0.70 and 0.88, respectively, on the larger database."
2022,The Efforts of Deep Learning Approaches for Breast Cancer Detection Based on X-Ray Images,"In this chapter, deep learning-based approaches, namely deep feature extraction, fine-tuning of pre-trained convolutional neural networks (CNN), and end-to-end training of a developed CNN model, are used to classify the malignant and normal breast X-ray images. For deep feature extraction, pre-trained deep CNN models such as ResNet18, ResNet50, ResNet101, VGG16, and VGG19 are used. For classification of the deep features, the support vector machines (SVM) classifier is used with various kernel functions namely linear, quadratic, cubic, and Gaussian, respectively. The aforementioned pre-trained deep CNN models are also used in fine-tuning procedure. A new CNN model is also proposed in end-to-end training fashion. The classification accuracy is used as performance measurements. The experimental works show that the deep learning has potential in detection of the breast cancer from the X-ray images. The deep features that are extracted from the ResNet50 model and SVM classifier with linear kernel function produced 94.7% accuracy score which the highest among all obtained."
2021,Pre-Trained Convolutional Neural Networks for Breast Cancer Detection Using Ultrasound Images,"Volunteer computing based data processing is a new trend in healthcare applications. Researchers are now leveraging volunteer computing power to train deep learning networks consisting of billions of parameters. Breast cancer is the second most common cause of death in women among cancers. The early detection of cancer may diminish the death risk of patients. Since the diagnosis of breast cancer manually takes lengthy time and there is a scarcity of detection systems, development of an automatic diagnosis system is needed for early detection of cancer. Machine learning models are now widely used for cancer detection and prediction research for improving the successive therapy of patients. Considering this need, this study implements pre-trained convolutional neural network based models for detecting breast cancer using ultrasound images. In particular, we tuned the pre-trained models for extracting key features from ultrasound images and included a classifier on the top layer. We measured accuracy of seven popular state-of-the-art pre-trained models using different optimizers and hyper-parameters through fivefold cross validation. Moreover, we consider Grad-CAM and occlusion mapping techniques to examine how well the models extract key features from the ultrasound images to detect cancers. We observe that after fine tuning, DenseNet201 and ResNet50 show 100% accuracy with Adam and RMSprop optimizers. VGG16 shows 100% accuracy using the Stochastic Gradient Descent optimizer. We also develop a custom convolutional neural network model with a smaller number of layers compared to large layers in the pre-trained models. The model also shows 100% accuracy using the Adam optimizer in classifying healthy and breast cancer patients. It is our belief that the model will assist healthcare experts with improved and faster patient screening and pave a way to further breast cancer research."
2021,Chatbot for Health Care and Oncology Applications Using Artificial Intelligence and Machine Learning: Systematic Review,"Background: Chatbot is a timely topic applied in various fields, including medicine and health care, for human-like knowledge transfer and communication. Machine learning, a subset of artificial intelligence, has been proven particularly applicable in health care, with the ability for complex dialog management and conversational flexibility. Objective: This review article aims to report on the recent advances and current trends in chatbot technology in medicine. A brief historical overview, along with the developmental progress and design characteristics, is first introduced. The focus will be on cancer therapy, with in-depth discussions and examples of diagnosis, treatment, monitoring, patient support, workflow efficiency, and health promotion. In addition, this paper will explore the limitations and areas of concern, highlighting ethical, moral, security, technical, and regulatory standards and evaluation issues to explain the hesitancy in implementation. Methods: A search of the literature published in the past 20 years was conducted using the IEEE Xplore, PubMed, Web of Science, Scopus, and OVID databases. The screening of chatbots was guided by the open-access Botlist directory for health care components and further divided according to the following criteria: diagnosis, treatment, monitoring, support, workflow, and health promotion. Results: Even after addressing these issues and establishing the safety or efficacy of chatbots, human elements in health care will not be replaceable. Therefore, chatbots have the potential to be integrated into clinical practice by working alongside health practitioners to reduce costs, refine workflow efficiencies, and improve patient outcomes. Other applications in pandemic support, global health, and education are yet to be fully explored. Conclusions: Further research and interdisciplinary collaboration could advance this technology to dramatically improve the quality of care for patients, rebalance the workload for clinicians, and revolutionize the practice of medicine."
