2016,Breast cancer histopathological image classification using Convolutional Neural Networks,"The performance of most conventional classification systems relies on appropriate data representation and much of the efforts are dedicated to feature engineering, a difficult and time-consuming process that uses prior expert domain knowledge of the data to create useful features. On the other hand, deep learning can extract and organize the discriminative information from the data, not requiring the design of feature extractors by a domain expert. Convolutional Neural Networks (CNNs) are a particular type of deep, feedforward network that have gained attention from research community and industry, achieving empirical successes in tasks such as speech recognition, signal processing, object recognition, natural language processing and transfer learning. In this paper, we conduct some preliminary experiments using the deep learning approach to classify breast cancer histopathological images from BreaKHis, a publicly dataset available at http://web.inf.ufpr.br/vri/breast-cancer-database. We propose a method based on the extraction of image patches for training the CNN and the combination of these patches for final classification. This method aims to allow using the high-resolution histopathological images from BreaKHis as input to existing CNN, avoiding adaptations of the model that can lead to a more complex and computationally costly architecture. The CNN performance is better when compared to previously reported results obtained by other machine learning models trained with hand-crafted textural descriptors. Finally, we also investigate the combination of different CNNs using simple fusion rules, achieving some improvement in recognition rates."
2018,A deep learning method for classifying mammographic breast density categories,"PURPOSE Mammographic breast density is an established risk marker for breast cancer and is visually assessed by radiologists in routine mammogram image reading, using four qualitative Breast Imaging and Reporting Data System (BI-RADS) breast density categories. It is particularly difficult for radiologists to consistently distinguish the two most common and most variably assigned BI-RADS categories, i.e., ""scattered density"" and ""heterogeneously dense"". The aim of this work was to investigate a deep learning-based breast density classifier to consistently distinguish these two categories, aiming at providing a potential computerized tool to assist radiologists in assigning a BI-RADS category in current clinical workflow. METHODS In this study, we constructed a convolutional neural network (CNN)-based model coupled with a large (i.e., 22,000 images) digital mammogram imaging dataset to evaluate the classification performance between the two aforementioned breast density categories. All images were collected from a cohort of 1,427 women who underwent standard digital mammography screening from 2005 to 2016 at our institution. The truths of the density categories were based on standard clinical assessment made by board-certified breast imaging radiologists. Effects of direct training from scratch solely using digital mammogram images and transfer learning of a pretrained model on a large nonmedical imaging dataset were evaluated for the specific task of breast density classification. In order to measure the classification performance, the CNN classifier was also tested on a refined version of the mammogram image dataset by removing some potentially inaccurately labeled images. Receiver operating characteristic (ROC) curves and the area under the curve (AUC) were used to measure the accuracy of the classifier. RESULTS The AUC was 0.9421 when the CNN-model was trained from scratch on our own mammogram images, and the accuracy increased gradually along with an increased size of training samples. Using the pretrained model followed by a fine-tuning process with as few as 500 mammogram images led to an AUC of 0.9265. After removing the potentially inaccurately labeled images, AUC was increased to 0.9882 and 0.9857 for without and with the pretrained model, respectively, both significantly higher (P < 0.001) than when using the full imaging dataset. CONCLUSIONS Our study demonstrated high classification accuracies between two difficult to distinguish breast density categories that are routinely assessed by radiologists. We anticipate that our approach will help enhance current clinical assessment of breast density and better support consistent density notification to patients in breast cancer screening."
2021,Novel Transfer Learning Approach for Medical Imaging with Limited Labeled Data,"Deep learning requires a large amount of data to perform well. However, the field of medical image analysis suffers from a lack of sufficient data for training deep learning models. Moreover, medical images require manual labeling, usually provided by human annotators coming from various backgrounds. More importantly, the annotation process is time-consuming, expensive, and prone to errors. Transfer learning was introduced to reduce the need for the annotation process by transferring the deep learning models with knowledge from a previous task and then by fine-tuning them on a relatively small dataset of the current task. Most of the methods of medical image classification employ transfer learning from pretrained models, e.g., ImageNet, which has been proven to be ineffective. This is due to the mismatch in learned features between the natural image, e.g., ImageNet, and medical images. Additionally, it results in the utilization of deeply elaborated models. In this paper, we propose a novel transfer learning approach to overcome the previous drawbacks by means of training the deep learning model on large unlabeled medical image datasets and by next transferring the knowledge to train the deep learning model on the small amount of labeled medical images. Additionally, we propose a new deep convolutional neural network (DCNN) model that combines recent advancements in the field. We conducted several experiments on two challenging medical imaging scenarios dealing with skin and breast cancer classification tasks. According to the reported results, it has been empirically proven that the proposed approach can significantly improve the performance of both classification scenarios. In terms of skin cancer, the proposed model achieved an F1-score value of 89.09% when trained from scratch and 98.53% with the proposed approach. Secondly, it achieved an accuracy value of 85.29% and 97.51%, respectively, when trained from scratch and using the proposed approach in the case of the breast cancer scenario. Finally, we concluded that our method can possibly be applied to many medical imaging problems in which a substantial amount of unlabeled image data is available and the labeled image data is limited. Moreover, it can be utilized to improve the performance of medical imaging tasks in the same domain. To do so, we used the pretrained skin cancer model to train on feet skin to classify them into two classes—either normal or abnormal (diabetic foot ulcer (DFU)). It achieved an F1-score value of 86.0% when trained from scratch, 96.25% using transfer learning, and 99.25% using double-transfer learning."
2022,Breast Cancer Classification from Ultrasound Images Using Probability-Based Optimal Deep Learning Feature Fusion,"After lung cancer, breast cancer is the second leading cause of death in women. If breast cancer is detected early, mortality rates in women can be reduced. Because manual breast cancer diagnosis takes a long time, an automated system is required for early cancer detection. This paper proposes a new framework for breast cancer classification from ultrasound images that employs deep learning and the fusion of the best selected features. The proposed framework is divided into five major steps: (i) data augmentation is performed to increase the size of the original dataset for better learning of Convolutional Neural Network (CNN) models; (ii) a pre-trained DarkNet-53 model is considered and the output layer is modified based on the augmented dataset classes; (iii) the modified model is trained using transfer learning and features are extracted from the global average pooling layer; (iv) the best features are selected using two improved optimization algorithms known as reformed differential evaluation (RDE) and reformed gray wolf (RGW); and (v) the best selected features are fused using a new probability-based serial approach and classified using machine learning algorithms. The experiment was conducted on an augmented Breast Ultrasound Images (BUSI) dataset, and the best accuracy was 99.1%. When compared with recent techniques, the proposed framework outperforms them."
2021,Deep-Learning-Empowered Breast Cancer Auxiliary Diagnosis for 5GB Remote E-Health,"Breast cancer, the most common cancer in women, is receiving increasing attention. The lack of high-quality medical resources, especially highly skilled doctors, in remote areas makes the diagnosis of breast cancer inefficient and causes great harm to women. The emergence of remote e-health has improved the situation to a certain extent, but its capabilities are still hampered by technical limitations, which manifest in two main aspects. First, due to network bandwidth limitations, it is difficult to guarantee the real-time transmission of breast cancer pathology images between remote areas and cities. Second, the highly skilled breast cancer doctors at large city hospitals are not guaranteed to be available for online diagnosis at all times. To overcome these limitations, this article proposes a deep-learning-empowered breast cancer auxiliary diagnosis scheme for remote e-health supported by 5G technology and beyond (5GB remote e-health). In this scheme, breast pathology images are first received from major hospitals via 5G, and a deep learning model based on the Inception-v3 network is subjected to transfer learning to obtain a diagnostic model. This diagnostic model is then employed on edge servers for auxiliary diagnosis at remote area hospitals. A theoretical analysis and experimental results show that this solution not only overcomes the two problems mentioned above but also improves the diagnostic accuracy for breast cancer in remote areas to 98.19 percent."
2020,Deep Learning Assisted Efficient AdaBoost Algorithm for Breast Cancer Detection and Early Diagnosis,"Breast cancer is one of the most dangerous diseases and the second largest cause of female cancer death. Breast cancer starts when malignant, cancerous lumps start to grow from the breast cells. Self-tests and Periodic clinical checks help to early diagnosis and thereby improve the survival chances significantly. The breast cancer classification is a medical method that provides researchers and scientists with a great challenge. Neural networks have recently become a popular tool in cancer data classification. In this paper, Deep Learning assisted Efficient Adaboost Algorithm (DLA-EABA) for breast cancer detection has been mathematically proposed with advanced computational techniques. In addition to traditional computer vision approaches, tumor classification methods using transfers are being actively developed through the use of deep convolutional neural networks (CNNs). This study starts with examining the CNN-based transfer learning to characterize breast masses for different diagnostic, predictive tasks or prognostic or in several imaging modalities, such as Magnetic Resonance Imaging (MRI), Ultrasound (US), digital breast tomosynthesis and mammography. The deep learning framework contains several convolutional layers, LSTM, Max-pooling layers. The classification and error estimation that has been included in a fully connected layer and a softmax layer. This paper focuses on combining these machine learning approaches with the methods of selecting features and extracting them through evaluating their output using classification and segmentation techniques to find the most appropriate approach. The experimental results show that the high accuracy level of 97.2%, Sensitivity 98.3%, and Specificity 96.5% has been compared to other existing systems."
2020,Optimizing the Performance of Breast Cancer Classification by Employing the Same Domain Transfer Learning from Hybrid Deep Convolutional Neural Network Model,"Breast cancer is a significant factor in female mortality. An early cancer diagnosis leads to a reduction in the breast cancer death rate. With the help of a computer-aided diagnosis system, the efficiency increased, and the cost was reduced for the cancer diagnosis. Traditional breast cancer classification techniques are based on handcrafted features techniques, and their performance relies upon the chosen features. They also are very sensitive to different sizes and complex shapes. However, histopathological breast cancer images are very complex in shape. Currently, deep learning models have become an alternative solution for diagnosis, and have overcome the drawbacks of classical classification techniques. Although deep learning has performed well in various tasks of computer vision and pattern recognition, it still has some challenges. One of the main challenges is the lack of training data. To address this challenge and optimize the performance, we have utilized a transfer learning technique which is where the deep learning models train on a task, and then fine-tune the models for another task. We have employed transfer learning in two ways: Training our proposed model first on the same domain dataset, then on the target dataset, and training our model on a different domain dataset, then on the target dataset. We have empirically proven that the same domain transfer learning optimized the performance. Our hybrid model of parallel convolutional layers and residual links is utilized to classify hematoxylin–eosin-stained breast biopsy images into four classes: invasive carcinoma, in-situ carcinoma, benign tumor and normal tissue. To reduce the effect of overfitting, we have augmented the images with different image processing techniques. The proposed model achieved state-of-the-art performance, and it outperformed the latest methods by achieving a patch-wise classification accuracy of 90.5%, and an image-wise classification accuracy of 97.4% on the validation set. Moreover, we have achieved an image-wise classification accuracy of 96.1% on the test set of the microscopy ICIAR-2018 dataset."
2021,Transfer Learning in Breast Cancer Diagnoses via Ultrasound Imaging,"Simple Summary Transfer learning plays a major role in medical image analyses; however, obtaining adequate training image datasets for machine learning algorithms can be challenging. Although many studies have attempted to employ transfer learning in medical image analyses, thus far, only a few review articles regarding the application of transfer learning to medical image analyses have been published. Moreover, reviews on the application of transfer learning in ultrasound breast imaging are rare. This work reviews previous studies that focused on detecting breast cancer from ultrasound images by using transfer learning, in order to summarize existing methods and identify their advantages and shortcomings. Additionally, this review presents potential future research directions for applying transfer learning in ultrasound imaging for the purposes of breast cancer detection and diagnoses. This review is expected to be significantly helpful in guiding researchers to identify potential improved methods and areas that can be improved through further research on transfer learning-based ultrasound breast imaging. Abstract Transfer learning is a machine learning approach that reuses a learning method developed for a task as the starting point for a model on a target task. The goal of transfer learning is to improve performance of target learners by transferring the knowledge contained in other (but related) source domains. As a result, the need for large numbers of target-domain data is lowered for constructing target learners. Due to this immense property, transfer learning techniques are frequently used in ultrasound breast cancer image analyses. In this review, we focus on transfer learning methods applied on ultrasound breast image classification and detection from the perspective of transfer learning approaches, pre-processing, pre-training models, and convolutional neural network (CNN) models. Finally, comparison of different works is carried out, and challenges—as well as outlooks—are discussed."
2017,Deep learning model based breast cancer histopathological image classification,"The automatic and precision classification for breast cancer histopathological image has a great significance in clinical application. However, the existing analysis approaches are difficult to addressing the breast cancer classification problem because the feature subtle differences of inter-class histopathological image and the classification accuracy still hard to meet the clinical application. Recent advancements in data-driven sharing processing and multi-level hierarchical feature learning have made available considerable chance to dope out a solution to this problem. To address the challenging problem, we propose a novel breast cancer histopathological image classification method based on deep convolutional neural networks, named as BiCNN model, to address the two-class breast cancer classification on the pathological image. This deep learning model considers class and sub-class labels of breast cancer as prior knowledge, which can restrain the distance of features of different breast cancer pathological images. In addition, an advanced data augmented method is proposed to fit tolerance whole slide image recognition, which can full reserve image edge feature of cancerization region. The transfer learning and fine-tuning method are adopted as an optimal training strategy to improve breast cancer histopathological image classification accuracy. The experiment results show that the proposed method leads to a higher classification accuracy (up to 97%) and displays good robustness and generalization, which provides efficient tools for breast cancer clinical diagnosis."
2019,A Technical Review of Convolutional Neural Network-Based Mammographic Breast Cancer Diagnosis,"This study reviews the technique of convolutional neural network (CNN) applied in a specific field of mammographic breast cancer diagnosis (MBCD). It aims to provide several clues on how to use CNN for related tasks. MBCD is a long-standing problem, and massive computer-aided diagnosis models have been proposed. The models of CNN-based MBCD can be broadly categorized into three groups. One is to design shallow or to modify existing models to decrease the time cost as well as the number of instances for training; another is to make the best use of a pretrained CNN by transfer learning and fine-tuning; the third is to take advantage of CNN models for feature extraction, and the differentiation of malignant lesions from benign ones is fulfilled by using machine learning classifiers. This study enrolls peer-reviewed journal publications and presents technical details and pros and cons of each model. Furthermore, the findings, challenges and limitations are summarized and some clues on the future work are also given. Conclusively, CNN-based MBCD is at its early stage, and there is still a long way ahead in achieving the ultimate goal of using deep learning tools to facilitate clinical practice. This review benefits scientific researchers, industrial engineers, and those who are devoted to intelligent cancer diagnosis."
2022,Ensemble Deep-Learning-Enabled Clinical Decision Support System for Breast Cancer Diagnosis and Classification on Ultrasound Images,"Simple Summary In the literature, there exist plenty of research works focused on the detection and classification of breast cancer. However, only a few works have focused on the classification of breast cancer using ultrasound scan images. Although deep transfer learning models are useful in breast cancer classification, owing to their outstanding performance in a number of applications, image pre-processing and segmentation techniques are essential. In this context, the current study developed a new Ensemble Deep-Learning-Enabled Clinical Decision Support System for the diagnosis and classification of breast cancer using ultrasound images. In the study, an optimal multi-level thresholding-based image segmentation technique was designed to identify the tumor-affected regions. The study also developed an ensemble of three deep learning models for feature extraction and an optimal machine learning classifier for breast cancer detection. The study offers a means of assisting radiologists and healthcare professionals in the breast cancer classification process. Abstract Clinical Decision Support Systems (CDSS) provide an efficient way to diagnose the presence of diseases such as breast cancer using ultrasound images (USIs). Globally, breast cancer is one of the major causes of increased mortality rates among women. Computer-Aided Diagnosis (CAD) models are widely employed in the detection and classification of tumors in USIs. The CAD systems are designed in such a way that they provide recommendations to help radiologists in diagnosing breast tumors and, furthermore, in disease prognosis. The accuracy of the classification process is decided by the quality of images and the radiologist’s experience. The design of Deep Learning (DL) models is found to be effective in the classification of breast cancer. In the current study, an Ensemble Deep-Learning-Enabled Clinical Decision Support System for Breast Cancer Diagnosis and Classification (EDLCDS-BCDC) technique was developed using USIs. The proposed EDLCDS-BCDC technique was intended to identify the existence of breast cancer using USIs. In this technique, USIs initially undergo pre-processing through two stages, namely wiener filtering and contrast enhancement. Furthermore, Chaotic Krill Herd Algorithm (CKHA) is applied with Kapur’s entropy (KE) for the image segmentation process. In addition, an ensemble of three deep learning models, VGG-16, VGG-19, and SqueezeNet, is used for feature extraction. Finally, Cat Swarm Optimization (CSO) with the Multilayer Perceptron (MLP) model is utilized to classify the images based on whether breast cancer exists or not. A wide range of simulations were carried out on benchmark databases and the extensive results highlight the better outcomes of the proposed EDLCDS-BCDC technique over recent methods."
2019,Deep Learning Approaches for Data Augmentation and Classification of Breast Masses using Ultrasound Images,"Breast classification and detection using ultrasound imaging is considered a significant step in computer-aided diagno-sis systems. Over the previous decades, researchers have proved the opportunities to automate the initial tumor classification and detection. The shortage of popular datasets of ultrasound images of breast cancer prevents researchers from obtaining a good performance of the classification algorithms. Traditional augmentation approaches are firmly limited, especially in tasks where the images follow strict standards, as in the case of medical datasets. Therefore besides the traditional augmentation, we use a new methodology for data augmentation using Generative Adversarial Network (GAN). We achieved higher accuracies by integrating traditional with GAN-based augmentation. This paper uses two breast ultrasound image datasets obtained from two various ultrasound systems. The first dataset is our dataset which was collected from Baheya Hospital for Early Detection and Treatment of Women’s Cancer, Cairo (Egypt), we name it (BUSI) referring to Breast Ultrasound Images (BUSI) dataset. It contains 780 images (133 normal, 437 benign and 210 malignant). While the Dataset (B) is obtained from related work and it has 163 images (110 benign and 53 malignant). To overcome the shortage of public datasets in this field, BUSI dataset will be publicly available for researchers. Moreover, in this paper, deep learning approaches are proposed to be used for breast ultrasound classification. We examine two different methods: a Convolutional Neural Network (CNN) approach and a Transfer Learning (TL) approach and we compare their performance with and without augmentation. The results confirm an overall enhancement using augmentation methods with deep learning classification methods (especially transfer learning) when evaluated on the two datasets."
2017,A method for classifying medical images using transfer learning: A pilot study on histopathology of breast cancer,"The advance of deep learning has made huge changes in computer vision and produced various off-the-shelf trained models. Particularly, Convolutional Neural Network (CNN) has been widely used to build image classification model which allow researchers transfer the pre-trained learning model for other classifications. We propose a transfer learning method to detect breast cancer using histopathology images based on Google's Inception v3 model which were initially trained for the classification of non-medical images. The pilot study shows the feasibility of transfer learning in the detection of breast cancer with AUC of 0.93."
2018,Evolutionary pruning of transfer learned deep convolutional neural network for breast cancer diagnosis in digital breast tomosynthesis,"Deep learning models are highly parameterized, resulting in difficulty in inference and transfer learning for image recognition tasks. In this work, we propose a layered pathway evolution method to compress a deep convolutional neural network (DCNN) for classification of masses in digital breast tomosynthesis (DBT). The objective is to prune the number of tunable parameters while preserving the classification accuracy. In the first stage transfer learning, 19 632 augmented regions-of-interest (ROIs) from 2454 mass lesions on mammograms were used to train a pre-trained DCNN on ImageNet. In the second stage transfer learning, the DCNN was used as a feature extractor followed by feature selection and random forest classification. The pathway evolution was performed using genetic algorithm in an iterative approach with tournament selection driven by count-preserving crossover and mutation. The second stage was trained with 9120 DBT ROIs from 228 mass lesions using leave-one-case-out cross-validation. The DCNN was reduced by 87% in the number of neurons, 34% in the number of parameters, and 95% in the number of multiply-and-add operations required in the convolutional layers. The test AUC on 89 mass lesions from 94 independent DBT cases before and after pruning were 0.88 and 0.90, respectively, and the difference was not statistically significant (p  >  0.05). The proposed DCNN compression approach can reduce the number of required operations by 95% while maintaining the classification performance. The approach can be extended to other deep neural networks and imaging tasks where transfer learning is appropriate."
2019,Semi-Supervised Histology Classification using Deep Multiple Instance Learning and Contrastive Predictive Coding,"Convolutional neural networks can be trained to perform histology slide classification using weak annotations with multiple instance learning (MIL). However, given the paucity of labeled histology data, direct application of MIL can easily suffer from overfitting and the network is unable to learn rich feature representations due to the weak supervisory signal. We propose to overcome such limitations with a two-stage semi-supervised approach that combines the power of data-efficient self-supervised feature learning via contrastive predictive coding (CPC) and the interpretability and flexibility of regularized attention-based MIL. We apply our two-stage CPC + MIL semi-supervised pipeline to the binary classification of breast cancer histology images. Across five random splits, we report state-of-the-art performance with a mean validation accuracy of 95% and an area under the ROC curve of 0.968. We further evaluate the quality of features learned via CPC relative to simple transfer learning and show that strong classification performance using CPC features can be efficiently leveraged under the MIL framework even with the feature encoder frozen."
2022,A Novel Multistage Transfer Learning for Ultrasound Breast Cancer Image Classification,"Breast cancer diagnosis is one of the many areas that has taken advantage of artificial intelligence to achieve better performance, despite the fact that the availability of a large medical image dataset remains a challenge. Transfer learning (TL) is a phenomenon that enables deep learning algorithms to overcome the issue of shortage of training data in constructing an efficient model by transferring knowledge from a given source task to a target task. However, in most cases, ImageNet (natural images) pre-trained models that do not include medical images, are utilized for transfer learning to medical images. Considering the utilization of microscopic cancer cell line images that can be acquired in large amount, we argue that learning from both natural and medical datasets improves performance in ultrasound breast cancer image classification. The proposed multistage transfer learning (MSTL) algorithm was implemented using three pre-trained models: EfficientNetB2, InceptionV3, and ResNet50 with three optimizers: Adam, Adagrad, and stochastic gradient de-scent (SGD). Dataset sizes of 20,400 cancer cell images, 200 ultrasound images from Mendeley and 400 ultrasound images from the MT-Small-Dataset were used. ResNet50-Adagrad-based MSTL achieved a test accuracy of 99 ± 0.612% on the Mendeley dataset and 98.7 ± 1.1% on the MT-Small-Dataset, averaging over 5-fold cross validation. A p-value of 0.01191 was achieved when comparing MSTL against ImageNet based TL for the Mendeley dataset. The result is a significant improvement in the performance of artificial intelligence methods for ultrasound breast cancer classification compared to state-of-the-art methods and could remarkably improve the early diagnosis of breast cancer in young women."
2021,Deep CNN Model based on VGG16 for Breast Cancer Classification,"Deep learning (DL) technologies are becoming a buzzword these days, especially for breast histopathology image tasks, such as diagnosing, due to the high performance obtained in image classification. Among deep learning types, Convolutional Neural Networks (CNN) are the most common types of DL models utilized for medical image diagnosis and analysis. However, CNN suffers from high computation cost to be implemented and may require to adapt huge number of parameters. Thus, and in order to address this issue; several pre-trained models have been established with the predefined network architecture. In this study, a transfer learning model based on Visual Geometry Group with 16-layer deep model architecture (VGG16) is utilized to extract high-level features from the BreaKHis benchmark histopathological images dataset. Then, multiple machine learning models (classifiers) are used to handle different Breast Cancer (BC) histopathological image classification tasks mainly: binary and multiclass with eight-class classifications. The experimental results on the public BreakHis benchmark dataset demonstrate that the proposed models are better than the previous works on the same dataset. Besides, the results show that the proposed models are able to outperform recent classical machine learning algorithms."
2019,Breast Cancer Diagnosis with Transfer Learning and Global Pooling,"Breast cancer is one of the most common causes of cancer-related death in women worldwide. Early and accurate diagnosis of breast cancer may significantly increase the survival rate of patients. In this study, we aim to develop a fully automatic, deep learning-based, method using descriptor features extracted by Deep Convolutional Neural Network (DCNN) models and pooling operation for the classification of hematoxylin and eosin stain (H#E) histological breast cancer images provided as a part of the International Conference on Image Analysis and Recognition (ICIAR) 2018 Grand Challenge on BreAst Cancer Histology (BACH) Images. Different data augmentation methods are applied to optimize the DCNN performance. We also investigated the efficacy of different stain normalization methods as a pre-processing step. The proposed network architecture using a pre-trained Xception model yields 92.50% average classification accuracy."
2017,Deep learning in breast cancer risk assessment: evaluation of convolutional neural networks on a clinical dataset of full-field digital mammograms,"Abstract. To evaluate deep learning in the assessment of breast cancer risk in which convolutional neural networks (CNNs) with transfer learning are used to extract parenchymal characteristics directly from full-field digital mammographic (FFDM) images instead of using computerized radiographic texture analysis (RTA), 456 clinical FFDM cases were included: a “high-risk” BRCA1/2 gene-mutation carriers dataset (53 cases), a “high-risk” unilateral cancer patients dataset (75 cases), and a “low-risk dataset” (328 cases). Deep learning was compared to the use of features from RTA, as well as to a combination of both in the task of distinguishing between high- and low-risk subjects. Similar classification performances were obtained using CNN [area under the curve (AUC)=0.83; standard error (SE)=0.03] and RTA (AUC=0.82; SE=0.03) in distinguishing BRCA1/2 carriers and low-risk women. However, in distinguishing unilateral cancer patients and low-risk women, performance was significantly greater with CNN (AUC=0.82; SE=0.03) compared to RTA (AUC=0.73; SE=0.03). Fusion classifiers performed significantly better than the RTA-alone classifiers with AUC values of 0.86 and 0.84 in differentiating BRCA1/2 carriers from low-risk women and unilateral cancer patients from low-risk women, respectively. In conclusion, deep learning extracted parenchymal characteristics from FFDMs performed as well as, or better than, conventional texture analysis in the task of distinguishing between cancer risk populations."
2016,MO-DE-207B-06: Computer-Aided Diagnosis of Breast Ultrasound Images Using Transfer Learning From Deep Convolutional Neural Networks.,"PURPOSE To assess the performance of using transferred features from pre-trained deep convolutional networks (CNNs) in the task of classifying cancer in breast ultrasound images, and to compare this method of transfer learning with previous methods involving human-designed features. METHODS A breast ultrasound dataset consisting of 1125 cases and 2393 regions of interest (ROIs) was used. Each ROI was labeled as cystic, benign, or malignant. Features were extracted from each ROI using pre-trained CNNs and used to train support vector machine (SVM) classifiers in the tasks of distinguishing non-malignant (benign+cystic) vs malignant lesions and benign vs malignant lesions. For a baseline comparison, classifiers were also trained on prior analytically-extracted tumor features. Five-fold cross-validation (by case) was conducted with the area under the receiver operating characteristic curve (AUC) as the performance metric. RESULTS Classifiers trained on CNN-extracted features were comparable to classifiers trained on human-designed features. In the non-malignant vs malignant task, both the SVM trained on CNN-extracted features and the SVM trained on human-designed features obtained an AUC of 0.90. In the task of determining benign vs malignant, the SVM trained on CNN-extracted features obtained an AUC of 0.88, compared to the AUC of 0.85 obtained by the SVM trained on human-designed features. CONCLUSION We obtained strong results using transfer learning to characterize ultrasound breast cancer images. This method allows us to directly classify a small dataset of lesions in a computationally inexpensive fashion without any manual input. Modern deep learning methods in computer vision are contingent on large datasets and vast computational resources, which are often inaccessible for clinical applications. Consequently, we believe transfer learning methods will be important for computer-aided diagnosis schemes in order to utilize advancements in deep learning and computer vision without the associated costs. This work was partially funded by NIH grant U01 CA195564 and the University of Chicago Metcalf program. M.L.G. is a stockholder in R2/Hologic, co-founder and equity holder in Quantitative Insights, and receives royalties from Hologic, GE Medical Systems, MEDIAN Technologies, Riverain Medical, Mitsubishi, and Toshiba. K.D. received royalties from Hologic."
2019,Breast Cancer Classification in Ultrasound Images using Transfer Learning,"Computer-aided detection of malignant breast tumors in ultrasound images has been receiving growing attention. In this paper, we propose a deep learning methodology to tackle this problem. The training data, which contains several hundred images of benign and malignant cases, was used to train a deep convolutional neural network (CNN). Three training approaches are proposed: a baseline approach where the CNN architecture is trained from scratch, a transfer-learning approach where the pre-trained VGG16 CNN architecture is further trained with the ultrasound images, and a fine-tuned learning approach where the deep learning parameters are fine-tuned to overcome overfitting. The experimental results demonstrate that the fine-tuned model had the best performance (0.97 accuracy, 0.98 AUC), with pre-training on US images. Creating pre-trained models using medical imaging data would certainly improve deep learning outcomes in biomedical applications."
2021,Multi- class classification of breast cancer abnormalities using Deep Convolutional Neural Network (CNN),"The real cause of breast cancer is very challenging to determine and therefore early detection of the disease is necessary for reducing the death rate due to risks of breast cancer. Early detection of cancer boosts increasing the survival chance up to 8%. Primarily, breast images emanating from mammograms, X-Rays or MRI are analyzed by radiologists to detect abnormalities. However, even experienced radiologists face problems in identifying features like micro-calcifications, lumps and masses, leading to high false positive and high false negative. Recent advancement in image processing and deep learning create some hopes in devising more enhanced applications that can be used for the early detection of breast cancer. In this work, we have developed a Deep Convolutional Neural Network (CNN) to segment and classify the various types of breast abnormalities, such as calcifications, masses, asymmetry and carcinomas, unlike existing research work, which mainly classified the cancer into benign and malignant, leading to improved disease management. Firstly, a transfer learning was carried out on our dataset using the pre-trained model ResNet50. Along similar lines, we have developed an enhanced deep learning model, in which learning rate is considered as one of the most important attributes while training the neural network. The learning rate is set adaptively in our proposed model based on changes in error curves during the learning process involved. The proposed deep learning model has achieved a performance of 88% in the classification of these four types of breast cancer abnormalities such as, masses, calcifications, carcinomas and asymmetry mammograms."
2022,Histopathologic Oral Cancer Prediction Using Oral Squamous Cell Carcinoma Biopsy Empowered with Transfer Learning,"Oral cancer is a dangerous and extensive cancer with a high death ratio. Oral cancer is the most usual cancer in the world, with more than 300,335 deaths every year. The cancerous tumor appears in the neck, oral glands, face, and mouth. To overcome this dangerous cancer, there are many ways to detect like a biopsy, in which small chunks of tissues are taken from the mouth and tested under a secure and hygienic microscope. However, microscope results of tissues to detect oral cancer are not up to the mark, a microscope cannot easily identify the cancerous cells and normal cells. Detection of cancerous cells using microscopic biopsy images helps in allaying and predicting the issues and gives better results if biologically approaches apply accurately for the prediction of cancerous cells, but during the physical examinations microscopic biopsy images for cancer detection there are major chances for human error and mistake. So, with the development of technology deep learning algorithms plays a major role in medical image diagnosing. Deep learning algorithms are efficiently developed to predict breast cancer, oral cancer, lung cancer, or any other type of medical image. In this study, the proposed model of transfer learning model using AlexNet in the convolutional neural network to extract rank features from oral squamous cell carcinoma (OSCC) biopsy images to train the model. Simulation results have shown that the proposed model achieved higher classification accuracy 97.66% and 90.06% of training and testing, respectively."
2021,Conventional Machine Learning versus Deep Learning for Magnification Dependent Histopathological Breast Cancer Image Classification: A Comparative Study with Visual Explanation,"Breast cancer is a serious threat to women. Many machine learning-based computer-aided diagnosis (CAD) methods have been proposed for the early diagnosis of breast cancer based on histopathological images. Even though many such classification methods achieved high accuracy, many of them lack the explanation of the classification process. In this paper, we compare the performance of conventional machine learning (CML) against deep learning (DL)-based methods. We also provide a visual interpretation for the task of classifying breast cancer in histopathological images. For CML-based methods, we extract a set of handcrafted features using three feature extractors and fuse them to get image representation that would act as an input to train five classical classifiers. For DL-based methods, we adopt the transfer learning approach to the well-known VGG-19 deep learning architecture, where its pre-trained version on the large scale ImageNet, is block-wise fine-tuned on histopathological images. The evaluation of the proposed methods is carried out on the publicly available BreaKHis dataset for the magnification dependent classification of benign and malignant breast cancer and their eight sub-classes, and a further validation on KIMIA Path960, a magnification-free histopathological dataset with 20 image classes, is also performed. After providing the classification results of CML and DL methods, and to better explain the difference in the classification performance, we visualize the learned features. For the DL-based method, we intuitively visualize the areas of interest of the best fine-tuned deep neural networks using attention maps to explain the decision-making process and improve the clinical interpretability of the proposed models. The visual explanation can inherently improve the pathologist’s trust in automated DL methods as a credible and trustworthy support tool for breast cancer diagnosis. The achieved results show that DL methods outperform CML approaches where we reached an accuracy between 94.05% and 98.13% for the binary classification and between 76.77% and 88.95% for the eight-class classification, while for DL approaches, the accuracies range from 85.65% to 89.32% for the binary classification and from 63.55% to 69.69% for the eight-class classification."
2016,High-Content Analysis of Breast Cancer Using Single-Cell Deep Transfer Learning,"High-content analysis has revolutionized cancer drug discovery by identifying substances that alter the phenotype of a cell, which prevents tumor growth and metastasis. The high-resolution biofluorescence images from assays allow precise quantitative measures enabling the distinction of small molecules of a host cell from a tumor. In this work, we are particularly interested in the application of deep neural networks (DNNs), a cutting-edge machine learning method, to the classification of compounds in chemical mechanisms of action (MOAs). Compound classification has been performed using image-based profiling methods sometimes combined with feature reduction methods such as principal component analysis or factor analysis. In this article, we map the input features of each cell to a particular MOA class without using any treatment-level profiles or feature reduction methods. To the best of our knowledge, this is the first application of DNN in this domain, leveraging single-cell information. Furthermore, we use deep transfer learning (DTL) to alleviate the intensive and computational demanding effort of searching the huge parameter’s space of a DNN. Results show that using this approach, we obtain a 30% speedup and a 2% accuracy improvement."
2021,Review of Breast Cancer Pathologigcal Image Processing,"Breast cancer is one of the most common malignancies. Pathological image processing of breast has become an important means for early diagnosis of breast cancer. Using medical image processing to assist doctors to detect potential breast cancer as early as possible has always been a hot topic in the field of medical image diagnosis. In this paper, a breast cancer recognition method based on image processing is systematically expounded from four aspects: breast cancer detection, image segmentation, image registration, and image fusion. The achievements and application scope of supervised learning, unsupervised learning, deep learning, CNN, and so on in breast cancer examination are expounded. The prospect of unsupervised learning and transfer learning for breast cancer diagnosis is prospected. Finally, the privacy protection of breast cancer patients is put forward."
2019,Transfer Learning in Breast Mammogram Abnormalities Classification With Mobilenet and Nasnet,"Breast cancer has an important incidence in women mortality worldwide. Currently, mammography is considered the gold standard for breast abnormalities screening examinations since it aids in the early detection and diagnosis of the illness. However, both identification of mass lesions and its malignancy classification is a challenging problem for artificial intelligence. Research has turned to the use of deep learning models in mammography which can enhance the performance of Computer Aided Diagnosis Systems (CADx). In this paper, we present our preliminary results on the use of transfer learning for malignancy classification of breast abnormality. We experiment with models that, according to our literature review, have not yet been explored thoroughly such as NasNet and MobileNet. Their performance is compared with InceptionV3 and Resnet50. The best results were obtained with Resnet50 and MobileNet with 78.4% and 74.3%, respectively. Also, some image pre-processing steps are studied in order to increase classification accuracy."
2020,Breast Cancer Classification Using Deep Learning Approaches and Histopathology Image: A Comparison Study,"Convolutional Neural Network (CNN) models are a type of deep learning architecture introduced to achieve the correct classification of breast cancer. This paper has a two-fold purpose. The first aim is to investigate the various deep learning models in classifying breast cancer histopathology images. This study identified the most accurate models in terms of the binary, four, and eight classifications of breast cancer histopathology image databases. The different accuracy scores obtained for the deep learning models on the same database showed that other factors such as pre-processing, data augmentation, and transfer learning methods can impact the ability of the models to achieve higher accuracy. The second purpose of our manuscript is to investigate the latest models that have no or limited examination done in previous studies. The models like ResNeXt, Dual Path Net, SENet, and NASNet had been identified with the most cutting-edge results for the ImageNet database. These models were examined for the binary, and eight classifications on BreakHis, a breast cancer histopathology image database. Furthermore, the BACH database was used to investigate these models for four classifications. Then, these models were compared with the previous studies to find and propose the most state-of-the-art models for each classification. Since the Inception-ResNet-V2 architecture achieved the best results for binary and eight classifications, we have examined this model in our study as well to provide a better comparison result. In short, this paper provides an extensive evaluation and discussion about the experimental settings for each study that had been conducted on the breast cancer histopathology images."
2020,Deep Learning Applied for Histological Diagnosis of Breast Cancer,"Deep learning, as one of the currently most popular computer science research trends, improves neural networks, which has more and deeper layers allowing higher abstraction levels and more accurate data analysis. Although deep convolutional neural networks, as a deep learning algorithm, has recently achieved promising results in data analysis, the requirement for a large amount of data prevents its use in medical data analysis since it is challenging to obtain data from the medical field. Breast cancer is a common cancer in women. To diagnose this kind of cancer, breast cell shapes in histopathology images should be examined by senior pathologists. The number of pathologists per population in the world is not enough, especially in Africa, and human mistake may occur in diagnosis procedure. After the evaluation of deep learning methods and algorithms in breast histological data processing, we tried to improve the current systems’ accuracy. As a result, this study proposes two effective deep transfer learning-based models, which rely on pre-trained DCNN using a large collection of ImageNet dataset images that improve current state-of-the-art systems in both binary and multiclass classification. We transfer pre-trained weights of the ResNet50 and DesneNet121 on the Imagenet as initial weights and fine-tune these models with a deep classifier with data augmentation to detect various malignant and benign samples tissues in the two categories of binary classification and multiclass classification. The proposed models have been examined with optimized hyperparameters in magnification-dependent and magnification-independent classification modes. In the multiclass classification, the proposed system achieved up to 98% accuracy. As for binary classification, the proposed system provides up to 100% accuracy. The results outperform previous studies accuracies in all defined performance metrics in breast cancer CAD systems from histological images."
2022,Automated Breast Cancer Detection Models Based on Transfer Learning,"Breast cancer is among the leading causes of mortality for females across the planet. It is essential for the well-being of women to develop early detection and diagnosis techniques. In mammography, focus has contributed to the use of deep learning (DL) models, which have been utilized by radiologists to enhance the needed processes to overcome the shortcomings of human observers. The transfer learning method is being used to distinguish malignant and benign breast cancer by fine-tuning multiple pre-trained models. In this study, we introduce a framework focused on the principle of transfer learning. In addition, a mixture of augmentation strategies were used to prevent overfitting and produce stable outcomes by increasing the number of mammographic images; including several rotation combinations, scaling, and shifting. On the Mammographic Image Analysis Society (MIAS) dataset, the proposed system was evaluated and achieved an accuracy of 89.5% using (residual network-50) ResNet50, and achieved an accuracy of 70% using the Nasnet-Mobile network. The proposed system demonstrated that pre-trained classification networks are significantly more effective and efficient, making them more acceptable for medical imaging, particularly for small training datasets."
2019,Photoacoustic Image Classification and Segmentation of Breast Cancer: A Feasibility Study,"Nowadays, breast cancer has increasingly threatened the health of human, especially females. However, breast cancer is still hard to detect in the early stage, and the diagnostic procedure can be time-consuming with abundant expertise needed. In this paper, we explored the deep learning algorithms in emerging photoacoustic tomography for breast cancer diagnostics. Specifically, we used a pre-processing algorithm to enhance the quality and uniformity of input breast cancer images and a transfer learning method to achieve better classification performance. Besides, by comparing the area under the curve, sensitivity, and specificity of support vector machine with AlexNet and GoogLeNet, it can be concluded that the combination of deep learning and photoacoustic imaging has the potential to achieve important impact on clinical diagnostics. Finally, according to the breast imaging reporting and data-system levels, we divided breast cancer images into six grades and designed a segmentation software for identifying the six grades of breast cancer. Then, we tested based on MAMMOGRAPHYC IMAGES DATABASE FROM LAPIMO EESC/USP (Laboratory of Analysis and Processing of Medical and Dental Images) to verify the accuracy of our segmentation method, which showed a satisfactory result."
2023,Vision-Transformer-Based Transfer Learning for Mammogram Classification,"Breast mass identification is a crucial procedure during mammogram-based early breast cancer diagnosis. However, it is difficult to determine whether a breast lump is benign or cancerous at early stages. Convolutional neural networks (CNNs) have been used to solve this problem and have provided useful advancements. However, CNNs focus only on a certain portion of the mammogram while ignoring the remaining and present computational complexity because of multiple convolutions. Recently, vision transformers have been developed as a technique to overcome such limitations of CNNs, ensuring better or comparable performance in natural image classification. However, the utility of this technique has not been thoroughly investigated in the medical image domain. In this study, we developed a transfer learning technique based on vision transformers to classify breast mass mammograms. The area under the receiver operating curve of the new model was estimated as 1 ± 0, thus outperforming the CNN-based transfer-learning models and vision transformer models trained from scratch. The technique can, hence, be applied in a clinical setting, to improve the early diagnosis of breast cancer."
2023,BC2NetRF: Breast Cancer Classification from Mammogram Images Using Enhanced Deep Learning Features and Equilibrium-Jaya Controlled Regula Falsi-Based Features Selection,"One of the most frequent cancers in women is breast cancer, and in the year 2022, approximately 287,850 new cases have been diagnosed. From them, 43,250 women died from this cancer. An early diagnosis of this cancer can help to overcome the mortality rate. However, the manual diagnosis of this cancer using mammogram images is not an easy process and always requires an expert person. Several AI-based techniques have been suggested in the literature. However, still, they are facing several challenges, such as similarities between cancer and non-cancer regions, irrelevant feature extraction, and weak training models. In this work, we proposed a new automated computerized framework for breast cancer classification. The proposed framework improves the contrast using a novel enhancement technique called haze-reduced local-global. The enhanced images are later employed for the dataset augmentation. This step aimed at increasing the diversity of the dataset and improving the training capability of the selected deep learning model. After that, a pre-trained model named EfficientNet-b0 was employed and fine-tuned to add a few new layers. The fine-tuned model was trained separately on original and enhanced images using deep transfer learning concepts with static hyperparameters’ initialization. Deep features were extracted from the average pooling layer in the next step and fused using a new serial-based approach. The fused features were later optimized using a feature selection algorithm known as Equilibrium-Jaya controlled Regula Falsi. The Regula Falsi was employed as a termination function in this algorithm. The selected features were finally classified using several machine learning classifiers. The experimental process was conducted on two publicly available datasets—CBIS-DDSM and INbreast. For these datasets, the achieved average accuracy is 95.4% and 99.7%. A comparison with state-of-the-art (SOTA) technology shows that the obtained proposed framework improved the accuracy. Moreover, the confidence interval-based analysis shows consistent results of the proposed framework."
2022,Breast lesions classifications of mammographic images using a deep convolutional neural network-based approach,"Breast cancer is one of the worst illnesses, with a higher fatality rate among women globally. Breast cancer detection needs accurate mammography interpretation and analysis, which is challenging for radiologists owing to the intricate anatomy of the breast and low image quality. Advances in deep learning-based models have significantly improved breast lesions’ detection, localization, risk assessment, and categorization. This study proposes a novel deep learning-based convolutional neural network (ConvNet) that significantly reduces human error in diagnosing breast malignancy tissues. Our methodology is most effective in eliciting task-specific features, as feature learning is coupled with classification tasks to achieve higher performance in automatically classifying the suspicious regions in mammograms as benign and malignant. To evaluate the model’s validity, 322 raw mammogram images from Mammographic Image Analysis Society (MIAS) and 580 from Private datasets were obtained to extract in-depth features, the intensity of information, and the high likelihood of malignancy. Both datasets are magnificently improved through preprocessing, synthetic data augmentation, and transfer learning techniques to attain the distinctive combination of breast tumors. The experimental findings indicate that the proposed approach achieved remarkable training accuracy of 0.98, test accuracy of 0.97, high sensitivity of 0.99, and an AUC of 0.99 in classifying breast masses on mammograms. The developed model achieved promising performance that helps the clinician in the speedy computation of mammography, breast masses diagnosis, treatment planning, and follow-up of disease progression. Moreover, it has the immense potential over retrospective approaches in consistency feature extraction and precise lesions classification."
2022,Application of Transfer Learning and Ensemble Learning in Image-level Classification for Breast Histopathology,"Background: Breast cancer has the highest prevalence in women globally. The classification and diagnosis of breast cancer and its histopathological images have always been a hot spot of clinical concern. In Computer-Aided Diagnosis (CAD), traditional classification models mostly use a single network to extract features, which has significant limitations. On the other hand, many networks are trained and optimized on patient-level datasets, ignoring the application of lower-level data labels. Method: This paper proposes a deep ensemble model based on image-level labels for the binary classification of benign and malignant lesions of breast histopathological images. First, the BreaKHis dataset is randomly divided into a training, validation and test set. Then, data augmentation techniques are used to balance the number of benign and malignant samples. Thirdly, considering the performance of transfer learning and the complementarity between each network, VGG16, Xception, ResNet50, DenseNet201 are selected as the base classifiers. Result: In the ensemble network model with accuracy as the weight, the image-level binary classification achieves an accuracy of $98.90\%$. In order to verify the capabilities of our method, the latest Transformer and Multilayer Perception (MLP) models have been experimentally compared on the same dataset. Our model wins with a $5\%-20\%$ advantage, emphasizing the ensemble model's far-reaching significance in classification tasks. Conclusion: This research focuses on improving the model's classification performance with an ensemble algorithm. Transfer learning plays an essential role in small datasets, improving training speed and accuracy. Our model has outperformed many existing approaches in accuracy, providing a method for the field of auxiliary medical diagnosis."
2020,Deep Learning in Selected Cancers’ Image Analysis—A Survey,"Deep learning algorithms have become the first choice as an approach to medical image analysis, face recognition, and emotion recognition. In this survey, several deep-learning-based approaches applied to breast cancer, cervical cancer, brain tumor, colon and lung cancers are studied and reviewed. Deep learning has been applied in almost all of the imaging modalities used for cervical and breast cancers and MRIs for the brain tumor. The result of the review process indicated that deep learning methods have achieved state-of-the-art in tumor detection, segmentation, feature extraction and classification. As presented in this paper, the deep learning approaches were used in three different modes that include training from scratch, transfer learning through freezing some layers of the deep learning network and modifying the architecture to reduce the number of parameters existing in the network. Moreover, the application of deep learning to imaging devices for the detection of various cancer cases has been studied by researchers affiliated to academic and medical institutes in economically developed countries; while, the study has not had much attention in Africa despite the dramatic soar of cancer risks in the continent."
2022,Breast Cancer Detection and Classification Empowered With Transfer Learning,"Cancer is a major public health issue in the modern world. Breast cancer is a type of cancer that starts in the breast and spreads to other parts of the body. One of the most common types of cancer that kill women is breast cancer. When cells become uncontrollably large, cancer develops. There are various types of breast cancer. The proposed model discussed benign and malignant breast cancer. In computer-aided diagnosis systems, the identification and classification of breast cancer using histopathology and ultrasound images are critical steps. Investigators have demonstrated the ability to automate the initial level identification and classification of the tumor throughout the last few decades. Breast cancer can be detected early, allowing patients to obtain proper therapy and thereby increase their chances of survival. Deep learning (DL), machine learning (ML), and transfer learning (TL) techniques are used to solve many medical issues. There are several scientific studies in the previous literature on the categorization and identification of cancer tumors using various types of models but with some limitations. However, research is hampered by the lack of a dataset. The proposed methodology is created to help with the automatic identification and diagnosis of breast cancer. Our main contribution is that the proposed model used the transfer learning technique on three datasets, A, B, C, and A2, A2 is the dataset A with two classes. In this study, ultrasound images and histopathology images are used. The model used in this work is a customized CNN-AlexNet, which was trained according to the requirements of the datasets. This is also one of the contributions of this work. The results have shown that the proposed system empowered with transfer learning achieved the highest accuracy than the existing models on datasets A, B, C, and A2."
2022,Breast Cancer Detection in Mammography Images Using Deep Convolutional Neural Networks and Fuzzy Ensemble Modeling Techniques,"Breast cancer has evolved as the most lethal illness impacting women all over the globe. Breast cancer may be detected early, which reduces mortality and increases the chances of a full recovery. Researchers all around the world are working on breast cancer screening tools based on medical imaging. Deep learning approaches have piqued the attention of many in the medical imaging field due to their rapid growth. In this research, mammography pictures were utilized to detect breast cancer. We have used four mammography imaging datasets with a similar number of 1145 normal, benign, and malignant pictures using various deep CNN (Inception V4, ResNet-164, VGG-11, and DenseNet121) models as base classifiers. The proposed technique employs an ensemble approach in which the Gompertz function is used to build fuzzy rankings of the base classification techniques, and the decision scores of the base models are adaptively combined to construct final predictions. The proposed fuzzy ensemble techniques outperform each individual transfer learning methodology as well as multiple advanced ensemble strategies (Weighted Average, Sugeno Integral) with reference to prediction and accuracy. The suggested Inception V4 ensemble model with fuzzy rank based Gompertz function has a 99.32% accuracy rate. We believe that the suggested approach will be of tremendous value to healthcare practitioners in identifying breast cancer patients early on, perhaps leading to an immediate diagnosis."
2023,A Transfer Learning-Based Deep Learning Model for Automated Breast Cancer Identification in Mammograms,"Abstract: Breast cancer is a severe health issue that affects women all over the world, underscoring the need for reliable and effective screening techniques. The early detection, diagnosis, and treatment of breast cancer are made possible by computer-aided diagnostic (CAD) systems that rely on mammograms. This study introduces a unique deep-learning model that uses transfer learning to identify and categorize breast cancer automatically. Deep convolutional neural networks have been shown in several recent studies to diagnose breast cancer in mammograms with performance comparable to or even outperforming that of human experts. In order to extract features from the dataset from the Mammographic Image Analysis Society (MIAS), the proposed model uses pre-trained convolutional neural network (CNN) architectures like ResNet50 and Visual Geometry Group networks (VGG)-16. This novel deep-learning model holds significant potential for enhancing the efficiency and accuracy of breast cancer detection and classification."
2023,Automatic BI-RADS Classification of Breast Magnetic Resonance Medical Records Using Transformer-Based Models for Brazilian Portuguese,"This chapter aims to present a classification model for categorizing textual clinical records of breast magnetic resonance imaging, based on lexical, syntactic and semantic analysis of clinical reports according to the Breast Imaging-Reporting and Data System (BI-RADS) classification, using Deep Learning and Natural Language Processing (NLP). The model was developed from transfer learning based on the pre-trained BERTimbau model, BERT model (Bidirectional Encoder Representations from Transformers) trained in Brazilian Portuguese. The dataset is composed of medical reports in Brazilian Portuguese classified into six categories: Inconclusive; Normal or Negative; Certainly Benign Findings; Probably Benign Findings; Suspicious Findings; High Risk of Cancer; Previously Known Malignant Injury. The following models were implemented and compared: Random Forest, SVM, Naïve Bayes, BERTimbau with and without finetuning. The BERTimbau model presented better results, with better performance after finetuning."
2023,"Classification of Breast Masses Using Ultrasound Images by Approaching GAN, Transfer Learning and Deep Learning Techniques","Breast cancer is a common cause of death among women worldwide. Ultrasonic imaging is a valuable diagnostic tool in breast cancer detection. However, the accuracy of computer-aided diagnosis systems for breast cancer classification is limited due to the lack of well-annotated datasets. This study proposes a deep learning-based framework for breast mass classification using ultrasound images, which incorporates a novel data augmentation technique, Generative Adversarial Network (GAN), and Transfer Learning (TL). Automating early tumor identification and classification in breast cancer diagnosis can save lives by improving the accuracy of diagnoses and reducing the need for invasive procedures. However, the limited availability of well-annotated datasets for ultrasound images of breast cancer has hampered the development of accurate computer-aided diagnosis systems. The accuracy of breast mass classification using ultrasound images is limited due to the lack of well-annotated datasets. Conventional data augmentation techniques have limitations in applications with strict guidelines, such as medical datasets. Therefore, there is a need to develop a novel data augmentation technique to improve the accuracy of breast mass classification using ultrasound images. The proposed framework can be extended to other medical imaging applications, where the availability of well-annotated datasets is limited. The GAN-based data augmentation technique and TL-based feature extraction can be used to improve the accuracy of classification models in other medical imaging applications. Additionally, the proposed framework can be used to develop accurate computer-aided diagnosis systems for breast cancer detection in clinical settings. The proposed framework incorporates a deep learning-based approach for breast mass classification using ultrasound images. The framework includes a GAN-based data augmentation technique and TL for feature extraction. The dataset used for training and testing the model is the Breast Ultrasound Images (BUSI) dataset, which includes 1311 images with normal and abnormal breast masses. The proposed framework achieved an accuracy of 99.6% for breast mass classification using ultrasound images, which outperformed existing methods. The GAN-based data augmentation technique and TL-based feature extraction improved the accuracy of the classification model. The results suggest that deep learning algorithms can be effectively applied for breast ultrasound categorization. The proposed framework presents a novel approach for breast mass classification using ultrasound images, which incorporates a GAN-based data augmentation technique and TL-based feature extraction. The results demonstrate that the proposed framework outperforms existing methods and achieves high accuracy in breast mass classification using ultrasound images. This framework can be useful for developing accurate computer-aided diagnosis systems for breast cancer detection."
2020,Multi-View Attention-based Late Fusion (MVALF) CADx system for breast cancer using deep learning,"Breast cancer is a leading cause of death among women. Early detection can significantly reduce the mortality rate among women and improve their prognosis. Mammography is the first line procedure for early diagnosis. In the early era, conventional Computer-Aided Diagnosis (CADx) systems for breast lesion diagnosis were based on just single view information. The last decade evidence the use of two views mammogram: Medio-Lateral Oblique (MLO) and Cranio-Caudal (CC) view for the CADx systems. Most recent studies show the effectiveness of four views of mammogram to train CADx system with feature fusion strategy for classification task. In this paper, we proposed an end-to-end Multi-View Attention-based Late Fusion (MVALF) CADx system that fused the obtained predictions of four view models, which is trained for each view separately. These separate models have different predictive ability for each class. The appropriate fusion of multi-view models can achieve better diagnosis performance. So, it is necessary to assign the proper weights to the multi-view classification models. To resolve this issue, attention-based weighting mechanism is adopted to assign the proper weights to trained models for fusion strategy. The proposed methodology is used for the classification of mammogram into normal, mass, calcification, malignant masses and benign masses. The publicly available datasets CBIS-DDSM and mini-MIAS are used for the experimentation. The results show that our proposed system achieved 0.996 AUC for normal vs. abnormal, 0.922 for mass vs. calcification and 0.896 for malignant vs. benign masses. Superior results are seen for the classification of malignant vs benign masses with our proposed approach, which is higher than the results using single view, two views and four views early fusion-based systems. The overall results of each level show the potential of multi-view late fusion with transfer learning in the diagnosis of breast cancer."
2022,Breast Tumor Classification in Digital Tomosynthesis Based on Deep Learning Radiomics,"Breast cancer is the most frequently diagnosed cancer in women globally. Early and accurate detection and classification of breast tumors are critical in improving treatment strategies and increasing the patient survival rate. Digital breast tomosynthesis (DBT) is an advanced form of mammography that aids better in the early detection and diagnosis of breast disease. This paper proposes a breast tumor classification method based on analyzing and evaluating the performance of various of the most innovative deep learning classification models in cooperation with a support vector machine (SVM) classifier for a DBT dataset. Specifically, we study the ability to use transfer learning from non-medical images to classify tumors in unseen DBT medical images. In addition, we utilize the fine-tuning technique to improve classification accuracy."
2023,Breast cancer diagnosis through knowledge distillation of Swin transformer-based teacher–student models,"Abstract: Breast cancer is a significant global health concern, emphasizing the crucial need for a timely and accurate diagnosis to enhance survival rates. Traditional diagnostic methods rely on pathologists analyzing whole-slide images (WSIs) to identify and diagnose malignancies. However, this task is complex, demanding specialized expertise and imposing a substantial workload on pathologists. Additionally, existing deep learning models, commonly employed for classifying histopathology images, often need enhancements to ensure their suitability for real-time deployment on WSI, especially when trained for small regions of interest (ROIs). This article introduces two Swin transformer-based architectures: the teacher model, characterized by its moderate size, and the lightweight student model. Both models are trained using a publicly available dataset of breast cancer histopathology images, focusing on ROIs with varying magnification factors. Transfer learning is applied to train the teacher model, and knowledge distillation (KD) transfers its capabilities to the student model. To enhance validation accuracy and minimize the total loss in KD, we employ the state–action–reward–state–action (SARSA) reinforcement learning algorithm. The algorithm dynamically computes temperature and a weighting factor throughout the KD process to achieve high accuracy within a considerably shorter training timeframe. Additionally, the student model is deployed to analyze malignancies in WSI. Despite the student model being only one-third the size and flops of the teacher model, it achieves an impressive accuracy of 98.71%, slightly below the teacher’s accuracy of 98.91%. Experimental results demonstrate that the student model can process WSIs at a throughput of 1.67 samples s"
2023,Breast Cancer Using Deep Learning and Histopathology Images,"Abstract: Breast cancer is among one of the most common cancers in the world. Early detection in this area can be crucial and help the patients to start the medication. One way to detect the breast cancer is using histopathology images. In recent years deep learning methods are among the methods that have shown high accuracy in detection cancerous tumors in images. In this work different deep learning methods such as Xception, MobileVNet, VGG16 and VGG19 have been used and the results are compared. Two popular datasets in breast cancer have been used. Transfer learning is used for pre-training the structures. In addition, different preprocessing methods is introduced and used to increase the number of images in the dataset."
2023,Breast Cancer Detection Using Image Processing and Machine Learning,"Different breast cancer detection systems have been developed to help clinicians analyze screening mammograms. Breast cancer has been increasing gradually so scientists work to develop new methods to reduce the risks of this life-threatening disease. Convolutional Neural Networks (CNNs) have shown much promise In the field of medical imaging because of recent developments in deep learning. However, CNN’s based methods have been restricted due to the small size of the few public breast cancer datasets. This research has developed a new framework and introduced it to detect breast cancer. This framework utilizes Convolutional Neural Networks (CNNs) and image processing to achieve its goal because CNNs have been an important success in image recognition, reaching human performance. An efficient and fast CNN pre-trained object detector called RetinaNet has been used in this research. RetinaNet is an uncomplicated one-stage object detector. A two-stage transfer learning has been used with the selected detector to improve the performance. RetinaNet model is initially trained with a general-purpose dataset called COCO dataset. The transfer learning is then used to apply the RetinaNet model to another dataset of mammograms called the CBIS-DDSM dataset. Finally, the second transfer learning is used to test the RetinaNet model onto a small dataset of mammograms called the INbreast dataset. The results of the proposed two-stage transfer learning (RetinaNet → CBIS-DDSM → INbreast) are better than the other state-of-the-art methods on the public INbreast dataset. Furthermore, the True Positive Rate (TPR) is 0.99 ± 0.02 at 1.67 False Positives per Image (FPPI), which is better than the one-stage transfer learning with a TPR of 0.94 ± 0.02 at 1.67 FPPI."
2023,"Breast Cancer Mass Classification Using Machine Learning, Binary-Coded Genetic Algorithms and an Ensemble of Deep Transfer Learning","Abstract: The diagnosis of breast cancer (BC) as early as possible is crucial for increasing the survival rate. Mammography enables finding the breast tissue changes years before they could develop into cancer symptoms. In this study, machine learning methods for BC mass pathology classification have been investigated using the radiologists’ mass annotations on the screen-film mammograms of the Breast Cancer Digital Repository (BCDR). The performances of precomputed features in the BCDR and discrete wavelet transform followed by Radon transform have been investigated by using four sequential feature selections and three genetic algorithms. Feature fusion from craniocaudal and mediolateral oblique views was shown to increase the performance of the classifier. Mass classification has been implemented by deep transfer learning (DTL) using the weights of ResNet50, NASNetLarge and Xception networks. An ensemble of DTL (EDTL) was shown to have higher classification performance than the DTL models. The proposed EDTL has area under the receiver operating curve (AUC) scores of 0.8843 and 0.9089 for mass classification on the region of interest (ROI) and ROI union datasets, respectively. The proposed EDTL has the highest BC mass classification AUC score on the BCDR to date and may be useful for other datasets."
2020,Classification of Breast Cancer from Digital Mammography Using Deep Learning,"Breast cancer is the most frequent in females. Mammography has proven to be the most effective method for the early detection of this type of cancer. Mammographic images are sometimes difficult to understand, due to the nature of the anomalies, the low contrast image and the composition of the mammary tissues, as well as various technological factors such as spatial resolution of the image or noise. Computer-aided diagnostic systems have been developed to increase the accuracy of mammographic examinations and be used by physicians as a second opinion in obtaining the final diagnosis, and thus reduce human errors. Convolutional neural networks are a current trend in computer vision tasks, due to the great performance they have achieved. The present investigation was based on this type of networks to classify into three classes, normal, benign and malignant tumour. Due to the fact that the miniMIAS database used has a low number of images, the transfer learning technique was applied to the Inception v3 pre-trained network. Two convolutional neural network architectures were implemented, obtaining in the architecture with three classes, 86.05% accuracy. On the other hand, in the architecture with two neural networks in series, an accuracy of 88.2% was reached."
2023,Deep Learning in Automating Breast Cancer Diagnosis from Microscopy Images,"Context: Breast cancer is one of the most common cancers in women. With early diagnosis, some breast cancers are highly curable. However, the concordance rate of breast cancer diagnosis from histology slides by pathologists is unacceptably low. Classifying normal versus tumor breast tissues from microscopy images of breast histology is an ideal case to use for deep learning and could help to more reproducibly diagnose breast cancer. Since data preprocessing and hyperparameter configurations have impacts on breast cancer classification accuracies of deep learning models, training a deep learning classifier with appropriate data preprocessing approaches and optimized hyperparameter configurations could improve breast cancer classification accuracy. Methods and Material: Using 12 combinations of deep learning model architectures (i.e., including 5 non-specialized and 7 digital pathology-specialized model architectures), image data preprocessing, and hyperparameter configurations, the validation accuracy of tumor versus normal classification were calculated using the Results: The DenseNet201, a non-specialized model architecture, with transfer learning approach achieved 98.61% validation accuracy compared to only 64.00% for the digital pathology-specialized model architecture. Conclusions: The combination of image data preprocessing approaches and hyperparameter configurations have a profound impact on the performance of deep neural networks for image classification. To identify a well-performing deep neural network to classify tumor versus normal breast histology, researchers should not only focus on developing new models specifically for digital pathology, since hyperparameter tuning for existing deep neural networks in the computer vision field could also achieve a high (often better) prediction accuracy."
2022,Skin Cancer Detection Using Deep Learning and Artificial Intelligence: Incorporated model of deep features fusion,"Among the most frequent forms of cancer, skin cancer accounts for hundreds of thousands of fatalities annually throughout the globe. It shows up as excessive cell proliferation on the skin. The likelihood of a successful recovery is greatly enhanced by an early diagnosis. More than that, it might reduce the need for or the frequency of chemical, radiological, or surgical treatments. As a result, savings on healthcare expenses will be possible. Dermoscopy, which examines the size, form, and color features of skin lesions, is the first step in the process of detecting skin cancer and is followed by sample and lab testing to confirm any suspicious lesions. Deep learning AI has allowed for significant progress in image-based diagnostics in recent years. Deep neural networks known as convolutional neural networks (CNNs or ConvNets) are essentially an extended form of multi-layer perceptrons. In visual imaging challenges, CNNs have shown the best accuracy. The purpose of this research is to create a CNN model for the early identification of skin cancer. The backend of the CNN classification model will be built using Keras and Tensorflow in Python. Different network topologies, such as Convolutional layers, Dropout layers, Pooling layers, and Dense layers, are explored and tried out throughout the model's development and validation phases. Transfer Learning methods will also be included in the model to facilitate early convergence. The dataset gathered from the ISIC challenge archives will be used to both tests and train the model."
2020,A New Deep Learning Model Selection Method for Colorectal Cancer Classification,"<p>Deep learning is one of the most commonly used techniques in computer-aided diagnosis systems. Their exploitation for histopathological image analysis is important because of the complex morphology of whole slide images. However, the main limitation of these methods is the restricted number of available medical images, which can lead to an overfitting problem. Many studies have suggested the use of static ensemble learning methods to address this issue. This article aims to propose a new dynamic ensemble deep learning method. First, it generates a set of models based on the transfer learning strategy from deep neural networks. Then, the relevant subset of models is selected by the particle swarm optimization algorithm and combined by voting or averaging methods. The proposed approach was tested on a histopathological dataset for colorectal cancer classification, based on seven types of CNNs. The method has achieved accurate results (94.52%) by the Resnet121 model and the voting strategy, which provides important insights into the efficiency of dynamic ensembling in deep learning.</p>"
2022,Deep-learning and transfer learning identify new breast cancer survival subtypes from single-cell imaging data,"STATEMENT OF TRANSLATIONAL RELEVANCE: Our findings from a breast cancer population cohort demonstrate the clinical utility of using the single-cell level imaging mass cytometry (IMC) data as a new type of patient prognosis prediction marker. Not only did the prognosis prediction achieve high accuracy with a Concordance index score greater than 0.8, it also enabled the discovery of seven survival subtypes that are more distinguishable than the molecular subtypes. These new subtypes present distinct profiles of epithelial, immune, fibroblast cells, and their interactions. Most importantly, this study identified and validated atypical subpopulations of TNBC patients with moderate prognosis (GATA3 over-expression) and Luminal A patients with poor prognosis (KRT6 and ACTA2 over-expression and CDH1 under-expression), using multiple large breast cancer cohorts."
2022,Machine Learning and Deep Learning Algorithms for Skin Cancer Classification from Dermoscopic Images,"We carry out a critical assessment of machine learning and deep learning models for the classification of skin tumors. Machine learning (ML) algorithms tested in this work include logistic regression, linear discriminant analysis, k-nearest neighbors classifier, decision tree classifier and Gaussian naive Bayes, while deep learning (DL) models employed are either based on a custom Convolutional Neural Network model, or leverage transfer learning via the use of pre-trained models (VGG16, Xception and ResNet50). We find that DL models, with accuracies up to 0.88, all outperform ML models. ML models exhibit accuracies below 0.72, which can be increased to up to 0.75 with ensemble learning. To further assess the performance of DL models, we test them on a larger and more imbalanced dataset. Metrics, such as the F-score and accuracy, indicate that, after fine-tuning, pre-trained models perform extremely well for skin tumor classification. This is most notably the case for VGG16, which exhibits an F-score of 0.88 and an accuracy of 0.88 on the smaller database, and metrics of 0.70 and 0.88, respectively, on the larger database."
2022,Hybrid Model for Breast Cancer Diagnosis on Mammograms Using Transfer Learning,"Abstract: Breast cancer is one of the most common types of cancer among women all over the world, which leads to the death of many women every year due to misdiagnosis and late treatment. Therefore, in this research, a new deep learning model was developed based on Python and using the mini-MIAS dataset. Initially image contrast optimization operations and segmentation were performed to enhance image and extract the region of interest (breast region) in order to improve the performance of the model and increase the accuracy of diagnosis and then extract the features using the transfer learning technique and based on a set of pre-trained networks. A comparison was made between a set of pre-trained convolutional network architectures (VGG16, ResNet50, MobileNetV2, InceptionV3) where the VGG16 network gave the best performance in the phase of extracting features and then building the final hybrid model by merging the VGG16 network with the random forest classifier. Our model achieved 94.25% average accuracy and the Area under curve (AUC) is 98% for all three classes, in addition to reducing the time required to build the system."
2022,Detection of Breast Cancer Images Based on Transfer and Deep Learning Models,"Abstract: Using a technology known as deep learning, which involves classifying photos based on the data they contain, it is possible to detect images, such as tumors and other signs. Because of the scarcity of pathologists and the growing number of patients with breast cancer, the manual numeration of biopsy echantillons must be mechanized (CS). To rectify the histopathological images of malignant tissue, preliminary study is required, which can be done utilizing BreaKHis' free database of data. An approach based on isolated image fragments is proposed, with the final categorization determined by an interconnected network of neurons (CNN) and a final combination of these pieces. Because of its unique architecture, capacity to recognize speech, identify objects, and analyze signals, as well as the popularity of neural language processing, the CNN is attracting increasing interest from industry and researchers. The employment of transfer learning methods is a problem with tiny collections of medical data. To improve the classification of defamatory and obscene photos, this article recommends integrating the impacts of many resolutions. In order to better depict the entering image's texture, many essential phases in CNN development are also used. Maintain a safe distance from the model's customization. Traditional CNN development may become more complex and expensive as a result. The simulation results achieved by running CNN in MATLAB outperform other artificial intelligence (AI) models recently published that used hand-crafted texture descriptors. With this in mind, we looked at all of CNN's possible combinations and discovered a technique to boost the execution rate by a little amount."
2021,Deep Multi-View Breast Cancer Detection: A Multi-View Concatenated Infrared Thermal Images Based Breast Cancer Detection System Using Deep Transfer Learning,"This paper simply presents a fully automated breast cancer detection system as “Deep Multi-view Breast cancer Detection” based on deep transfer learning. The deep transfer learning model i.e., Visual Geometry Group 16 (VGG 16) is used in this approach for the correct classification of Breast thermal images into either normal or abnormal. This VGG 16 model is trained with the help of Static as well as Dynamic breast thermal images dataset consisting of multi-view, single view breast thermal images. These Multi-view breast thermal images are generated in this approach by concatenating the conventional left, frontal and right view breast thermal images taken from the Database for Mastology Research with Infrared image for the first time in order to generate a more informative and complete thermal temperature map of breast for enhancing the accuracy of the overall system. For the sake of genuine comparison, three other popular deep transfer learning models like Residual Network 50 (ResNet50V2), InceptionV3 network and Visual Geometry Group 19 (VGG 19) are also trained with the same augmented dataset consisting of multi-view as well as single view breast thermal images. The VGG 16 based Deep Multi-view Breast cancer Detect system delivers the best training, validation as well as testing accuracies as compared to their other deep transfer learning models. The VGG 16 achieves an encouraging testing accuracy of 99% on the Dynamic breast thermal images testing dataset utilizing the multi-view breast thermal images as input. Whereas the testing accuracies of 95%, 94% and 89% are achieved by the VGG 19, ResNet50V2, InceptionV3 models respectively over the Dynamic breast thermal images testing dataset utilizing the same multi-view breast thermal images as input."
2023,Assessing VTE Risk in Cancer Patients Using Deep Learning Synthetic Data Generation and Domain Adaptation Techniques,"This article focuses on the use of deep learning synthetic data generation methods to assess the risk of future treatments and medication for preventing venous thromboembolism (VTE) in cancer patients, based on a small dataset of genetic and clinical variables. The study employs CopulaGANs to generate synthetic tabular data, which is then used to train a Deep Learning-based classifier using domain adaptation techniques. The trained model is fine-tuned using real data and performs better than current state-of-the-art medical scores in assessing VTE risk. Additionally, the resulting Precision-Recall curve offers flexibility in selecting different and better operational points for VTE risk assessment."
2018,A deep learning method for classifying mammographic breast density categories,"PURPOSE Mammographic breast density is an established risk marker for breast cancer and is visually assessed by radiologists in routine mammogram image reading, using four qualitative Breast Imaging and Reporting Data System (BI-RADS) breast density categories. It is particularly difficult for radiologists to consistently distinguish the two most common and most variably assigned BI-RADS categories, i.e., ""scattered density"" and ""heterogeneously dense"". The aim of this work was to investigate a deep learning-based breast density classifier to consistently distinguish these two categories, aiming at providing a potential computerized tool to assist radiologists in assigning a BI-RADS category in current clinical workflow. METHODS In this study, we constructed a convolutional neural network (CNN)-based model coupled with a large (i.e., 22,000 images) digital mammogram imaging dataset to evaluate the classification performance between the two aforementioned breast density categories. All images were collected from a cohort of 1,427 women who underwent standard digital mammography screening from 2005 to 2016 at our institution. The truths of the density categories were based on standard clinical assessment made by board-certified breast imaging radiologists. Effects of direct training from scratch solely using digital mammogram images and transfer learning of a pretrained model on a large nonmedical imaging dataset were evaluated for the specific task of breast density classification. In order to measure the classification performance, the CNN classifier was also tested on a refined version of the mammogram image dataset by removing some potentially inaccurately labeled images. Receiver operating characteristic (ROC) curves and the area under the curve (AUC) were used to measure the accuracy of the classifier. RESULTS The AUC was 0.9421 when the CNN-model was trained from scratch on our own mammogram images, and the accuracy increased gradually along with an increased size of training samples. Using the pretrained model followed by a fine-tuning process with as few as 500 mammogram images led to an AUC of 0.9265. After removing the potentially inaccurately labeled images, AUC was increased to 0.9882 and 0.9857 for without and with the pretrained model, respectively, both significantly higher (P < 0.001) than when using the full imaging dataset. CONCLUSIONS Our study demonstrated high classification accuracies between two difficult to distinguish breast density categories that are routinely assessed by radiologists. We anticipate that our approach will help enhance current clinical assessment of breast density and better support consistent density notification to patients in breast cancer screening."
2021,Novel Transfer Learning Approach for Medical Imaging with Limited Labeled Data,"Deep learning requires a large amount of data to perform well. However, the field of medical image analysis suffers from a lack of sufficient data for training deep learning models. Moreover, medical images require manual labeling, usually provided by human annotators coming from various backgrounds. More importantly, the annotation process is time-consuming, expensive, and prone to errors. Transfer learning was introduced to reduce the need for the annotation process by transferring the deep learning models with knowledge from a previous task and then by fine-tuning them on a relatively small dataset of the current task. Most of the methods of medical image classification employ transfer learning from pretrained models, e.g., ImageNet, which has been proven to be ineffective. This is due to the mismatch in learned features between the natural image, e.g., ImageNet, and medical images. Additionally, it results in the utilization of deeply elaborated models. In this paper, we propose a novel transfer learning approach to overcome the previous drawbacks by means of training the deep learning model on large unlabeled medical image datasets and by next transferring the knowledge to train the deep learning model on the small amount of labeled medical images. Additionally, we propose a new deep convolutional neural network (DCNN) model that combines recent advancements in the field. We conducted several experiments on two challenging medical imaging scenarios dealing with skin and breast cancer classification tasks. According to the reported results, it has been empirically proven that the proposed approach can significantly improve the performance of both classification scenarios. In terms of skin cancer, the proposed model achieved an F1-score value of 89.09% when trained from scratch and 98.53% with the proposed approach. Secondly, it achieved an accuracy value of 85.29% and 97.51%, respectively, when trained from scratch and using the proposed approach in the case of the breast cancer scenario. Finally, we concluded that our method can possibly be applied to many medical imaging problems in which a substantial amount of unlabeled image data is available and the labeled image data is limited. Moreover, it can be utilized to improve the performance of medical imaging tasks in the same domain. To do so, we used the pretrained skin cancer model to train on feet skin to classify them into two classes—either normal or abnormal (diabetic foot ulcer (DFU)). It achieved an F1-score value of 86.0% when trained from scratch, 96.25% using transfer learning, and 99.25% using double-transfer learning."
2019,Deep Learning for Breast Cancer Diagnosis from Mammograms—A Comparative Study,"Deep convolutional neural networks (CNNs) are investigated in the context of computer-aided diagnosis (CADx) of breast cancer. State-of-the-art CNNs are trained and evaluated on two mammographic datasets, consisting of ROIs depicting benign or malignant mass lesions. The performance evaluation of each examined network is addressed in two training scenarios: the first involves initializing the network with pre-trained weights, while for the second the networks are initialized in a random fashion. Extensive experimental results show the superior performance achieved in the case of fine-tuning a pretrained network compared to training from scratch."
2017,Deep learning model based breast cancer histopathological image classification,"The automatic and precision classification for breast cancer histopathological image has a great significance in clinical application. However, the existing analysis approaches are difficult to addressing the breast cancer classification problem because the feature subtle differences of inter-class histopathological image and the classification accuracy still hard to meet the clinical application. Recent advancements in data-driven sharing processing and multi-level hierarchical feature learning have made available considerable chance to dope out a solution to this problem. To address the challenging problem, we propose a novel breast cancer histopathological image classification method based on deep convolutional neural networks, named as BiCNN model, to address the two-class breast cancer classification on the pathological image. This deep learning model considers class and sub-class labels of breast cancer as prior knowledge, which can restrain the distance of features of different breast cancer pathological images. In addition, an advanced data augmented method is proposed to fit tolerance whole slide image recognition, which can full reserve image edge feature of cancerization region. The transfer learning and fine-tuning method are adopted as an optimal training strategy to improve breast cancer histopathological image classification accuracy. The experiment results show that the proposed method leads to a higher classification accuracy (up to 97%) and displays good robustness and generalization, which provides efficient tools for breast cancer clinical diagnosis."
2021,Breast Cancer Classification From Histopathological Images Using Patch-Based Deep Learning Modeling,"Accurate detection and classification of breast cancer is a critical task in medical imaging due to the complexity of breast tissues. Due to automatic feature extraction ability, deep learning methods have been successfully applied in different areas, especially in the field of medical imaging. In this study, a novel patch-based deep learning method called Pa-DBN-BC is proposed to detect and classify breast cancer on histopathology images using the Deep Belief Network (DBN). Features are extracted through an unsupervised pre-training and supervised fine-tuning phase. The network automatically extracts features from image patches. Logistic regression is used to classify the patches from histopathology images. The features extracted from the patches are fed to the model as input and the model presents the result as a probability matrix as either a positive sample (cancer) or a negative sample (background). The proposed model is trained and tested on the whole slide histopathology image dataset having images from four different data cohorts and achieved an accuracy of 86%. Consequently, the proposed method is better than the traditional ones, as it automatically learns the best possible features and experimental results show that the model outperformed the previously proposed deep learning methods."
2019,A Technical Review of Convolutional Neural Network-Based Mammographic Breast Cancer Diagnosis,"This study reviews the technique of convolutional neural network (CNN) applied in a specific field of mammographic breast cancer diagnosis (MBCD). It aims to provide several clues on how to use CNN for related tasks. MBCD is a long-standing problem, and massive computer-aided diagnosis models have been proposed. The models of CNN-based MBCD can be broadly categorized into three groups. One is to design shallow or to modify existing models to decrease the time cost as well as the number of instances for training; another is to make the best use of a pretrained CNN by transfer learning and fine-tuning; the third is to take advantage of CNN models for feature extraction, and the differentiation of malignant lesions from benign ones is fulfilled by using machine learning classifiers. This study enrolls peer-reviewed journal publications and presents technical details and pros and cons of each model. Furthermore, the findings, challenges and limitations are summarized and some clues on the future work are also given. Conclusively, CNN-based MBCD is at its early stage, and there is still a long way ahead in achieving the ultimate goal of using deep learning tools to facilitate clinical practice. This review benefits scientific researchers, industrial engineers, and those who are devoted to intelligent cancer diagnosis."
2019,Classification of Histopathological Biopsy Images Using Ensemble of Deep Learning Networks,"Breast cancer is one of the leading causes of death across the world in women. Early diagnosis of this type of cancer is critical for treatment and patient care. Computer-aided detection (CAD) systems using convolutional neural networks (CNN) could assist in the classification of abnormalities. In this study, we proposed an ensemble deep learning-based approach for automatic binary classification of breast histology images. The proposed ensemble model adapts three pre-trained CNNs, namely VGG19, MobileNet, and DenseNet. The ensemble model is used for the feature representation and extraction steps. The extracted features are then fed into a multi-layer perceptron classifier to carry out the classification task. Various pre-processing and CNN tuning techniques such as stain-normalization, data augmentation, hyperparameter tuning, and fine-tuning are used to train the model. The proposed method is validated on four publicly available benchmark datasets, i.e., ICIAR, BreakHis, PatchCamelyon, and Bioimaging. The proposed multi-model ensemble method obtains better predictions than single classifiers and machine learning algorithms with accuracies of 98.13%, 95.00%, 94.64% and 83.10% for BreakHis, ICIAR, PatchCamelyon and Bioimaging datasets, respectively."
2022,Automated Breast Cancer Detection Models Based on Transfer Learning,"Breast cancer is among the leading causes of mortality for females across the planet. It is essential for the well-being of women to develop early detection and diagnosis techniques. In mammography, focus has contributed to the use of deep learning (DL) models, which have been utilized by radiologists to enhance the needed processes to overcome the shortcomings of human observers. The transfer learning method is being used to distinguish malignant and benign breast cancer by fine-tuning multiple pre-trained models. In this study, we introduce a framework focused on the principle of transfer learning. In addition, a mixture of augmentation strategies were used to prevent overfitting and produce stable outcomes by increasing the number of mammographic images; including several rotation combinations, scaling, and shifting. On the Mammographic Image Analysis Society (MIAS) dataset, the proposed system was evaluated and achieved an accuracy of 89.5% using (residual network-50) ResNet50, and achieved an accuracy of 70% using the Nasnet-Mobile network. The proposed system demonstrated that pre-trained classification networks are significantly more effective and efficient, making them more acceptable for medical imaging, particularly for small training datasets."
2022,Breast Tumor Classification in Digital Tomosynthesis Based on Deep Learning Radiomics,"Breast cancer is the most frequently diagnosed cancer in women globally. Early and accurate detection and classification of breast tumors are critical in improving treatment strategies and increasing the patient survival rate. Digital breast tomosynthesis (DBT) is an advanced form of mammography that aids better in the early detection and diagnosis of breast disease. This paper proposes a breast tumor classification method based on analyzing and evaluating the performance of various of the most innovative deep learning classification models in cooperation with a support vector machine (SVM) classifier for a DBT dataset. Specifically, we study the ability to use transfer learning from non-medical images to classify tumors in unseen DBT medical images. In addition, we utilize the fine-tuning technique to improve classification accuracy."
2022,Machine Learning and Deep Learning Algorithms for Skin Cancer Classification from Dermoscopic Images,"We carry out a critical assessment of machine learning and deep learning models for the classification of skin tumors. Machine learning (ML) algorithms tested in this work include logistic regression, linear discriminant analysis, k-nearest neighbors classifier, decision tree classifier and Gaussian naive Bayes, while deep learning (DL) models employed are either based on a custom Convolutional Neural Network model, or leverage transfer learning via the use of pre-trained models (VGG16, Xception and ResNet50). We find that DL models, with accuracies up to 0.88, all outperform ML models. ML models exhibit accuracies below 0.72, which can be increased to up to 0.75 with ensemble learning. To further assess the performance of DL models, we test them on a larger and more imbalanced dataset. Metrics, such as the F-score and accuracy, indicate that, after fine-tuning, pre-trained models perform extremely well for skin tumor classification. This is most notably the case for VGG16, which exhibits an F-score of 0.88 and an accuracy of 0.88 on the smaller database, and metrics of 0.70 and 0.88, respectively, on the larger database."
2022,The Efforts of Deep Learning Approaches for Breast Cancer Detection Based on X-Ray Images,"In this chapter, deep learning-based approaches, namely deep feature extraction, fine-tuning of pre-trained convolutional neural networks (CNN), and end-to-end training of a developed CNN model, are used to classify the malignant and normal breast X-ray images. For deep feature extraction, pre-trained deep CNN models such as ResNet18, ResNet50, ResNet101, VGG16, and VGG19 are used. For classification of the deep features, the support vector machines (SVM) classifier is used with various kernel functions namely linear, quadratic, cubic, and Gaussian, respectively. The aforementioned pre-trained deep CNN models are also used in fine-tuning procedure. A new CNN model is also proposed in end-to-end training fashion. The classification accuracy is used as performance measurements. The experimental works show that the deep learning has potential in detection of the breast cancer from the X-ray images. The deep features that are extracted from the ResNet50 model and SVM classifier with linear kernel function produced 94.7% accuracy score which the highest among all obtained."
2021,Pre-Trained Convolutional Neural Networks for Breast Cancer Detection Using Ultrasound Images,"Volunteer computing based data processing is a new trend in healthcare applications. Researchers are now leveraging volunteer computing power to train deep learning networks consisting of billions of parameters. Breast cancer is the second most common cause of death in women among cancers. The early detection of cancer may diminish the death risk of patients. Since the diagnosis of breast cancer manually takes lengthy time and there is a scarcity of detection systems, development of an automatic diagnosis system is needed for early detection of cancer. Machine learning models are now widely used for cancer detection and prediction research for improving the successive therapy of patients. Considering this need, this study implements pre-trained convolutional neural network based models for detecting breast cancer using ultrasound images. In particular, we tuned the pre-trained models for extracting key features from ultrasound images and included a classifier on the top layer. We measured accuracy of seven popular state-of-the-art pre-trained models using different optimizers and hyper-parameters through fivefold cross validation. Moreover, we consider Grad-CAM and occlusion mapping techniques to examine how well the models extract key features from the ultrasound images to detect cancers. We observe that after fine tuning, DenseNet201 and ResNet50 show 100% accuracy with Adam and RMSprop optimizers. VGG16 shows 100% accuracy using the Stochastic Gradient Descent optimizer. We also develop a custom convolutional neural network model with a smaller number of layers compared to large layers in the pre-trained models. The model also shows 100% accuracy using the Adam optimizer in classifying healthy and breast cancer patients. It is our belief that the model will assist healthcare experts with improved and faster patient screening and pave a way to further breast cancer research."
2021,Chatbot for Health Care and Oncology Applications Using Artificial Intelligence and Machine Learning: Systematic Review,"Background: Chatbot is a timely topic applied in various fields, including medicine and health care, for human-like knowledge transfer and communication. Machine learning, a subset of artificial intelligence, has been proven particularly applicable in health care, with the ability for complex dialog management and conversational flexibility. Objective: This review article aims to report on the recent advances and current trends in chatbot technology in medicine. A brief historical overview, along with the developmental progress and design characteristics, is first introduced. The focus will be on cancer therapy, with in-depth discussions and examples of diagnosis, treatment, monitoring, patient support, workflow efficiency, and health promotion. In addition, this paper will explore the limitations and areas of concern, highlighting ethical, moral, security, technical, and regulatory standards and evaluation issues to explain the hesitancy in implementation. Methods: A search of the literature published in the past 20 years was conducted using the IEEE Xplore, PubMed, Web of Science, Scopus, and OVID databases. The screening of chatbots was guided by the open-access Botlist directory for health care components and further divided according to the following criteria: diagnosis, treatment, monitoring, support, workflow, and health promotion. Results: Even after addressing these issues and establishing the safety or efficacy of chatbots, human elements in health care will not be replaceable. Therefore, chatbots have the potential to be integrated into clinical practice by working alongside health practitioners to reduce costs, refine workflow efficiencies, and improve patient outcomes. Other applications in pandemic support, global health, and education are yet to be fully explored. Conclusions: Further research and interdisciplinary collaboration could advance this technology to dramatically improve the quality of care for patients, rebalance the workload for clinicians, and revolutionize the practice of medicine."
2016,Breast cancer histopathological image classification using Convolutional Neural Networks,"The performance of most conventional classification systems relies on appropriate data representation and much of the efforts are dedicated to feature engineering, a difficult and time-consuming process that uses prior expert domain knowledge of the data to create useful features. On the other hand, deep learning can extract and organize the discriminative information from the data, not requiring the design of feature extractors by a domain expert. Convolutional Neural Networks (CNNs) are a particular type of deep, feedforward network that have gained attention from research community and industry, achieving empirical successes in tasks such as speech recognition, signal processing, object recognition, natural language processing and transfer learning. In this paper, we conduct some preliminary experiments using the deep learning approach to classify breast cancer histopathological images from BreaKHis, a publicly dataset available at http://web.inf.ufpr.br/vri/breast-cancer-database. We propose a method based on the extraction of image patches for training the CNN and the combination of these patches for final classification. This method aims to allow using the high-resolution histopathological images from BreaKHis as input to existing CNN, avoiding adaptations of the model that can lead to a more complex and computationally costly architecture. The CNN performance is better when compared to previously reported results obtained by other machine learning models trained with hand-crafted textural descriptors. Finally, we also investigate the combination of different CNNs using simple fusion rules, achieving some improvement in recognition rates."
2016,AggNet: Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images,"The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions. 1) Can deep CNN be trained with data collected from crowdsourcing? 2) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)? 3) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration."
2019,"Cancer-Related Cognitive Impairment: An update on state of the art, detection, and management strategies in cancer survivors.","BACKGROUND Advances in diagnostic and therapeutic strategies in oncology have significantly increased the chance of survival of cancer patients, even those with metastatic disease. However, cancer-related cognitive impairment (CRCI) is frequently reported in patients treated for non-central nervous system cancers, particularly during and after chemotherapy. DESIGN This review provides an update of the state of the art based on PubMed searches between 2012 and March 2019 on ""cognition"", ""cancer"", ""antineoplastic agents"" or ""chemotherapy"". It includes the most recent clinical, imaging and pre-clinical data and reports management strategies of CRCI. RESULTS Evidence obtained primarily from studies on breast cancer patients highlight memory, processing speed, attention, and executive functions as the most cognitive domains impaired post-chemotherapy. Recent investigations established that other cancer treatments, such as hormone therapies and targeted therapies, can also induce cognitive deficits. Knowledge regarding predisposing factors, biological markers or brain functions associated with CRCI has improved. Factors such as age and genetic polymorphisms of apolipoprotein E, catechol-O-methyltransferase and BDNF may predispose individuals to a higher risk of cognitive impairment. Poor performance on neuropsychological tests were associated with volume reduction in grey matter, less connectivity and activation after chemotherapy. In animals, hippocampus-based memory and executive functions, mediated by the frontal lobes, were shown to be particularly susceptible to the effects of chemotherapy. It involves altered neurogenesis, mitochondrial dysfunction or brain cytokine response. An important next step is to identify strategies for managing cognitive difficulties, with primary studies to assess cognitive training and physical exercise regimens. CONCLUSIONS CRCI is not limited to chemotherapy. A multidisciplinary approach has improved our knowledge of the complex mechanisms involved. Nowadays, studies evaluating cognitive rehabilitation programs are encouraged to help patients cope with cognitive difficulties and improve quality of life during and after cancer."
2018,Staingan: Stain Style Transfer for Digital Histological Images,"Digitized Histological diagnosis is in increasing demand. However, color variations due to various factors are imposing obstacles to the diagnosis process. The problem of stain color variations is a well-defined problem with many proposed solutions. Most of these solutions are highly dependent on a reference template slide. We propose a deep-learning solution inspired by CycleGANs that is trained end-to-end, eliminating the need for an expert to pick a representative reference slide. Our approach showed superior results quantitatively and qualitatively against the state of the art methods (10% improvement visually using SSIM). We further validated our method on a clinical use-case, namely Breast Cancer tumor classification, showing a 12% increase in AUC. The code is made publicly available 1.1https://github.com/xtarx/StainGAN"
2018,A deep learning method for classifying mammographic breast density categories,"PURPOSE Mammographic breast density is an established risk marker for breast cancer and is visually assessed by radiologists in routine mammogram image reading, using four qualitative Breast Imaging and Reporting Data System (BI-RADS) breast density categories. It is particularly difficult for radiologists to consistently distinguish the two most common and most variably assigned BI-RADS categories, i.e., ""scattered density"" and ""heterogeneously dense"". The aim of this work was to investigate a deep learning-based breast density classifier to consistently distinguish these two categories, aiming at providing a potential computerized tool to assist radiologists in assigning a BI-RADS category in current clinical workflow. METHODS In this study, we constructed a convolutional neural network (CNN)-based model coupled with a large (i.e., 22,000 images) digital mammogram imaging dataset to evaluate the classification performance between the two aforementioned breast density categories. All images were collected from a cohort of 1,427 women who underwent standard digital mammography screening from 2005 to 2016 at our institution. The truths of the density categories were based on standard clinical assessment made by board-certified breast imaging radiologists. Effects of direct training from scratch solely using digital mammogram images and transfer learning of a pretrained model on a large nonmedical imaging dataset were evaluated for the specific task of breast density classification. In order to measure the classification performance, the CNN classifier was also tested on a refined version of the mammogram image dataset by removing some potentially inaccurately labeled images. Receiver operating characteristic (ROC) curves and the area under the curve (AUC) were used to measure the accuracy of the classifier. RESULTS The AUC was 0.9421 when the CNN-model was trained from scratch on our own mammogram images, and the accuracy increased gradually along with an increased size of training samples. Using the pretrained model followed by a fine-tuning process with as few as 500 mammogram images led to an AUC of 0.9265. After removing the potentially inaccurately labeled images, AUC was increased to 0.9882 and 0.9857 for without and with the pretrained model, respectively, both significantly higher (P < 0.001) than when using the full imaging dataset. CONCLUSIONS Our study demonstrated high classification accuracies between two difficult to distinguish breast density categories that are routinely assessed by radiologists. We anticipate that our approach will help enhance current clinical assessment of breast density and better support consistent density notification to patients in breast cancer screening."
2021,A Novel Deep-Learning Model for Automatic Detection and Classification of Breast Cancer Using the Transfer-Learning Technique,"Breast cancer (BC) is one of the primary causes of cancer death among women. Early detection of BC allows patients to receive appropriate treatment, thus increasing the possibility of survival. In this work, a new deep-learning (DL) model based on the transfer-learning (TL) technique is developed to efficiently assist in the automatic detection and diagnosis of the BC suspected area based on two techniques namely 80–20 and cross-validation. DL architectures are modeled to be problem-specific. TL uses the knowledge gained during solving one problem in another relevant problem. In the proposed model, the features are extracted from the mammographic image analysis- society (MIAS) dataset using a pre-trained convolutional neural network (CNN) architecture such as Inception V3, ResNet50, Visual Geometry Group networks (VGG)-19, VGG-16, and Inception-V2 ResNet. Six evaluation metrics for evaluating the performance of the proposed model in terms of accuracy, sensitivity, specificity, precision, F-score, and area under the ROC curve (AUC) has been chosen. Experimental results show that the TL of the VGG16 model is powerful for BC diagnosis by classifying the mammogram breast images with overall accuracy, sensitivity, specificity, precision, F-score, and AUC of 98.96%, 97.83%, 99.13%, 97.35%, 97.66%, and 0.995, respectively for 80–20 method and 98.87%, 97.27%, 98.2%, 98.84%, 98.04%, and 0.993 for 10-fold cross-validation method."
2021,Novel Transfer Learning Approach for Medical Imaging with Limited Labeled Data,"Deep learning requires a large amount of data to perform well. However, the field of medical image analysis suffers from a lack of sufficient data for training deep learning models. Moreover, medical images require manual labeling, usually provided by human annotators coming from various backgrounds. More importantly, the annotation process is time-consuming, expensive, and prone to errors. Transfer learning was introduced to reduce the need for the annotation process by transferring the deep learning models with knowledge from a previous task and then by fine-tuning them on a relatively small dataset of the current task. Most of the methods of medical image classification employ transfer learning from pretrained models, e.g., ImageNet, which has been proven to be ineffective. This is due to the mismatch in learned features between the natural image, e.g., ImageNet, and medical images. Additionally, it results in the utilization of deeply elaborated models. In this paper, we propose a novel transfer learning approach to overcome the previous drawbacks by means of training the deep learning model on large unlabeled medical image datasets and by next transferring the knowledge to train the deep learning model on the small amount of labeled medical images. Additionally, we propose a new deep convolutional neural network (DCNN) model that combines recent advancements in the field. We conducted several experiments on two challenging medical imaging scenarios dealing with skin and breast cancer classification tasks. According to the reported results, it has been empirically proven that the proposed approach can significantly improve the performance of both classification scenarios. In terms of skin cancer, the proposed model achieved an F1-score value of 89.09% when trained from scratch and 98.53% with the proposed approach. Secondly, it achieved an accuracy value of 85.29% and 97.51%, respectively, when trained from scratch and using the proposed approach in the case of the breast cancer scenario. Finally, we concluded that our method can possibly be applied to many medical imaging problems in which a substantial amount of unlabeled image data is available and the labeled image data is limited. Moreover, it can be utilized to improve the performance of medical imaging tasks in the same domain. To do so, we used the pretrained skin cancer model to train on feet skin to classify them into two classes—either normal or abnormal (diabetic foot ulcer (DFU)). It achieved an F1-score value of 86.0% when trained from scratch, 96.25% using transfer learning, and 99.25% using double-transfer learning."
2015,"Exosomes in development, metastasis and drug resistance of breast cancer","Transport through the cell membrane can be divided into active, passive and vesicular types (exosomes). Exosomes are nano‐sized vesicles released by a variety of cells. Emerging evidence shows that exosomes play a critical role in cancers. Exosomes mediate communication between stroma and cancer cells through the transfer of nucleic acid and proteins. It is demonstrated that the contents and the quantity of exosomes will change after occurrence of cancers. Over the last decade, growing attention has been paid to the role of exosomes in the development of breast cancer, the most life‐threatening cancer in women. Breast cancer could induce salivary glands to secret specific exosomes, which could be used as biomarkers in the diagnosis of early breast cancer. Exosome‐delivered nucleic acid and proteins partly facilitate the tumorigenesis, metastasis and resistance of breast cancer. Exosomes could also transmit anti‐cancer drugs outside breast cancer cells, therefore leading to drug resistance. However, exosomes are effective tools for transportation of anti‐cancer drugs with lower immunogenicity and toxicity. This is a promising way to establish a drug delivery system."
2022,Breast Cancer Classification from Ultrasound Images Using Probability-Based Optimal Deep Learning Feature Fusion,"After lung cancer, breast cancer is the second leading cause of death in women. If breast cancer is detected early, mortality rates in women can be reduced. Because manual breast cancer diagnosis takes a long time, an automated system is required for early cancer detection. This paper proposes a new framework for breast cancer classification from ultrasound images that employs deep learning and the fusion of the best selected features. The proposed framework is divided into five major steps: (i) data augmentation is performed to increase the size of the original dataset for better learning of Convolutional Neural Network (CNN) models; (ii) a pre-trained DarkNet-53 model is considered and the output layer is modified based on the augmented dataset classes; (iii) the modified model is trained using transfer learning and features are extracted from the global average pooling layer; (iv) the best features are selected using two improved optimization algorithms known as reformed differential evaluation (RDE) and reformed gray wolf (RGW); and (v) the best selected features are fused using a new probability-based serial approach and classified using machine learning algorithms. The experiment was conducted on an augmented Breast Ultrasound Images (BUSI) dataset, and the best accuracy was 99.1%. When compared with recent techniques, the proposed framework outperforms them."
2021,Deep-Learning-Empowered Breast Cancer Auxiliary Diagnosis for 5GB Remote E-Health,"Breast cancer, the most common cancer in women, is receiving increasing attention. The lack of high-quality medical resources, especially highly skilled doctors, in remote areas makes the diagnosis of breast cancer inefficient and causes great harm to women. The emergence of remote e-health has improved the situation to a certain extent, but its capabilities are still hampered by technical limitations, which manifest in two main aspects. First, due to network bandwidth limitations, it is difficult to guarantee the real-time transmission of breast cancer pathology images between remote areas and cities. Second, the highly skilled breast cancer doctors at large city hospitals are not guaranteed to be available for online diagnosis at all times. To overcome these limitations, this article proposes a deep-learning-empowered breast cancer auxiliary diagnosis scheme for remote e-health supported by 5G technology and beyond (5GB remote e-health). In this scheme, breast pathology images are first received from major hospitals via 5G, and a deep learning model based on the Inception-v3 network is subjected to transfer learning to obtain a diagnostic model. This diagnostic model is then employed on edge servers for auxiliary diagnosis at remote area hospitals. A theoretical analysis and experimental results show that this solution not only overcomes the two problems mentioned above but also improves the diagnostic accuracy for breast cancer in remote areas to 98.19 percent."
2014,Essential role for TrpC5-containing extracellular vesicles in breast cancer with chemotherapeutic resistance,"Significance A critical challenge for chemotherapy is development of chemoresistance, but underlying molecular mechanisms remain unclear. In this study, we found that drug-resistant adriamycin-resistant human breast cancer cells possessed numerous transient receptor potential channel 5 (TrpC5) -containing extracellular vesicles (EVs) on the cell surface. Suppressing TrpC5 expression diminished the formation of EVs. Incubation of drug-sensitive recipient cells with EVs endowed recipients with drug-resistant properties. In both human samples and a mouse model of breast cancer, the expression of TrpC5 proteins was high in the tumor, and the levels of TrpC5-positive EVs were high in the circulation. These data suggest a critical role of TrpC5-containing EVs in the transfer of drug resistance. In the future, monitoring TrpC5-containing EVs in the circulation could potentially be used to predict the clinical outcome of chemotherapy. A critical challenge for chemotherapy is the development of chemoresistance in breast cancer. However, the underlying mechanisms and validated predictors remain unclear. Extracellular vesicles (EVs) have gained attention as potential means for cancer cells to share intracellular contents. In adriamycin-resistant human breast cancer cells (MCF-7/ADM), we analyzed the role of transient receptor potential channel 5 (TrpC5) in EV formation and transfer as well as the diagnostic implications. Up-regulated TrpC5, accumulated in EVs, is responsible for EV formation and trapping of adriamycin (ADM) in EVs. EV-mediated intercellular transfer of TrpC5 allowed recipient cells to acquire TrpC5, consequently stimulating multidrug efflux transporter P-glycoprotein production through a Ca2+- and activated T-cells isoform c3-mediated mechanism and thus, conferring chemoresistance on nonresistant cells. TrpC5-containing circulating EVs were detected in nude mice bearing MCF-7/ADM tumor xenografts, and the level was lower after TrpC5–siRNA treatment. In breast cancer patients who underwent chemotherapy, TrpC5 expression in the tumor was significantly higher in patients with progressive or stable disease than in patients with a partial or complete response. TrpC5-containing circulating EVs were found in peripheral blood from patients who underwent chemotherapy but not patients without chemotherapy. Taken together, we found that TrpC5-containing circulating EVs may transfer chemoresistance property to nonchemoresistant recipient cells. It may be worthwhile to further explore the potential of using TrpC5-containing EVs as a diagnostic biomarker for chemoresistant breast cancer."
2020,Deep Learning Assisted Efficient AdaBoost Algorithm for Breast Cancer Detection and Early Diagnosis,"Breast cancer is one of the most dangerous diseases and the second largest cause of female cancer death. Breast cancer starts when malignant, cancerous lumps start to grow from the breast cells. Self-tests and Periodic clinical checks help to early diagnosis and thereby improve the survival chances significantly. The breast cancer classification is a medical method that provides researchers and scientists with a great challenge. Neural networks have recently become a popular tool in cancer data classification. In this paper, Deep Learning assisted Efficient Adaboost Algorithm (DLA-EABA) for breast cancer detection has been mathematically proposed with advanced computational techniques. In addition to traditional computer vision approaches, tumor classification methods using transfers are being actively developed through the use of deep convolutional neural networks (CNNs). This study starts with examining the CNN-based transfer learning to characterize breast masses for different diagnostic, predictive tasks or prognostic or in several imaging modalities, such as Magnetic Resonance Imaging (MRI), Ultrasound (US), digital breast tomosynthesis and mammography. The deep learning framework contains several convolutional layers, LSTM, Max-pooling layers. The classification and error estimation that has been included in a fully connected layer and a softmax layer. This paper focuses on combining these machine learning approaches with the methods of selecting features and extracting them through evaluating their output using classification and segmentation techniques to find the most appropriate approach. The experimental results show that the high accuracy level of 97.2%, Sensitivity 98.3%, and Specificity 96.5% has been compared to other existing systems."
2016,The Emerging Roles of Long Noncoding RNA ROR (lincRNA-ROR) and its Possible Mechanisms in Human Cancers,"To date, there is only up to 2% of protein-coding genes that are stably transcribed, whereas the vast majority are non-coding RNAs (ncRNAs). These ncRNAs, also known as non-messenger RNAs (nmRNAs) or functional RNAs (fRNAs), include transfer RNAs, ribosomal RNAs, microRNAs and long non-coding RNAs (lncRNAs). With the advance of high-resolution microarrays and massively parallel sequencing technology, lncRNAs have gained extended attentions nowadays and are found to play important roles in tumorigenesis and progression of human cancers. Long intergenic non-protein coding RNA, regulator of reprogramming (linc-ROR), was first discovered in induced pluripotent stem cells (iPSCs), where it was controlled by the key pluripotency factors Oct4, Sox2 and Nanog. Linc-ROR has been shown to be dysregulated in many types of cancers, including breast cancer (BC), pancreatic cancer (PC), hepatocellular cancer (HCC), endometrial cancer (EC), and nasopharyngeal carcinoma (NPC). Also, linc-ROR functions as regulatory molecule in a large amount of biological processes. However, the underlying mechanisms of its contribution to carcinogenesis remain to be elucidated. In this review, we will emphasize on the characteristics of linc-ROR and their roles in different types of human cancers."
2019,Artificial Intelligence (AI) for the early detection of breast cancer: a scoping review to assess AI’s potential in breast screening practice,"ABSTRACT Introduction: Various factors are driving interest in the application of artificial intelligence (AI) for breast cancer (BC) detection, but it is unclear whether the evidence warrants large-scale use in population-based screening. Areas covered: We performed a scoping review, a structured evidence synthesis describing a broad research field, to summarize knowledge on AI evaluated for BC detection and to assess AI’s readiness for adoption in BC screening. Studies were predominantly small retrospective studies based on highly selected image datasets that contained a high proportion of cancers (median BC proportion in datasets 26.5%), and used heterogeneous techniques to develop AI models; the range of estimated AUC (area under ROC curve) for AI models was 69.2–97.8% (median AUC 88.2%). We identified various methodologic limitations including use of non-representative imaging data for model training, limited validation in external datasets, potential bias in training data, and few comparative data for AI versus radiologists’ interpretation of mammography screening. Expert opinion: Although contemporary AI models have reported generally good accuracy for BC detection, methodological concerns, and evidence gaps exist that limit translation into clinical BC screening settings. These should be addressed in parallel to advancing AI techniques to render AI transferable to large-scale population-based screening."
2020,Optimizing the Performance of Breast Cancer Classification by Employing the Same Domain Transfer Learning from Hybrid Deep Convolutional Neural Network Model,"Breast cancer is a significant factor in female mortality. An early cancer diagnosis leads to a reduction in the breast cancer death rate. With the help of a computer-aided diagnosis system, the efficiency increased, and the cost was reduced for the cancer diagnosis. Traditional breast cancer classification techniques are based on handcrafted features techniques, and their performance relies upon the chosen features. They also are very sensitive to different sizes and complex shapes. However, histopathological breast cancer images are very complex in shape. Currently, deep learning models have become an alternative solution for diagnosis, and have overcome the drawbacks of classical classification techniques. Although deep learning has performed well in various tasks of computer vision and pattern recognition, it still has some challenges. One of the main challenges is the lack of training data. To address this challenge and optimize the performance, we have utilized a transfer learning technique which is where the deep learning models train on a task, and then fine-tune the models for another task. We have employed transfer learning in two ways: Training our proposed model first on the same domain dataset, then on the target dataset, and training our model on a different domain dataset, then on the target dataset. We have empirically proven that the same domain transfer learning optimized the performance. Our hybrid model of parallel convolutional layers and residual links is utilized to classify hematoxylin–eosin-stained breast biopsy images into four classes: invasive carcinoma, in-situ carcinoma, benign tumor and normal tissue. To reduce the effect of overfitting, we have augmented the images with different image processing techniques. The proposed model achieved state-of-the-art performance, and it outperformed the latest methods by achieving a patch-wise classification accuracy of 90.5%, and an image-wise classification accuracy of 97.4% on the validation set. Moreover, we have achieved an image-wise classification accuracy of 96.1% on the test set of the microscopy ICIAR-2018 dataset."
2020,Characterization of Triple-Negative Breast Cancer MDA-MB-231 Cell Spheroid Model,"Background The tumor three-dimensional (3D) spheroid model in vitro is effective on detecting malignant cells and tumorigenesis, and assessing drug resistance. Compared with two-dimensional (2D) monolayer culture, breast cancer (BC) spheroids more accurately reﬂect the complex microenvironment in vivo, which have been extensively reported in BC research. MDA-MB-231 cells, the triple-negative breast cancer (TNBC) cell line, display representative epithelial to mesenchymal transition (EMT) associated with BC metastasis. However, the characterization of MDA-MB-231 spheroids has been largely unknown at present, which requires further attention. Materials and Methods Microwell array was conducted for the formation of MDA-MB-231 spheroids. In addition, H&E staining, immunohistochemistry (IHC), CellTiter-Glo® 3D cell viability assay, and flow cytometry were performed to investigate the structure and growth characteristics. Besides, Transwell and scratch healing assays were carried out to detect the migratory capacities compared with 2D culture. Western blotting and confocal fluorescence were selected to detect the expression of EMT-associated proteins. Additionally, the half maximal inhibitory concentration (IC50) values of antitumor compounds Carboplatin and Doxorubicin were measured to assess drug resistance. Results The MDA-MB-231 spheroids were viable, which maintained a compact structure with zonation features for up to 9 days. Moreover, those spheroids had a slower growth rate than those cultured as a monolayer and differential zones of proliferation. The migratory capacities were significantly enhanced by transferring the spheroids to 2D adherent culture. Compared with 2D culture, the levels of EMT-associated proteins were significantly up-regulated in spheroids. Furthermore, toxicity assessment showed that spheroids exhibited an increased resistance to the antitumor compounds. Conclusion This study develops the simple spheroids and demonstrates their structure, growth and proliferation characteristics. According to our results, the spheroids are associated with superior EMT and high resistance to toxicological response compared with the standard 2D monocultures."
2021,Transfer Learning in Breast Cancer Diagnoses via Ultrasound Imaging,"Simple Summary Transfer learning plays a major role in medical image analyses; however, obtaining adequate training image datasets for machine learning algorithms can be challenging. Although many studies have attempted to employ transfer learning in medical image analyses, thus far, only a few review articles regarding the application of transfer learning to medical image analyses have been published. Moreover, reviews on the application of transfer learning in ultrasound breast imaging are rare. This work reviews previous studies that focused on detecting breast cancer from ultrasound images by using transfer learning, in order to summarize existing methods and identify their advantages and shortcomings. Additionally, this review presents potential future research directions for applying transfer learning in ultrasound imaging for the purposes of breast cancer detection and diagnoses. This review is expected to be significantly helpful in guiding researchers to identify potential improved methods and areas that can be improved through further research on transfer learning-based ultrasound breast imaging. Abstract Transfer learning is a machine learning approach that reuses a learning method developed for a task as the starting point for a model on a target task. The goal of transfer learning is to improve performance of target learners by transferring the knowledge contained in other (but related) source domains. As a result, the need for large numbers of target-domain data is lowered for constructing target learners. Due to this immense property, transfer learning techniques are frequently used in ultrasound breast cancer image analyses. In this review, we focus on transfer learning methods applied on ultrasound breast image classification and detection from the perspective of transfer learning approaches, pre-processing, pre-training models, and convolutional neural network (CNN) models. Finally, comparison of different works is carried out, and challenges—as well as outlooks—are discussed."
2017,Deep learning model based breast cancer histopathological image classification,"The automatic and precision classification for breast cancer histopathological image has a great significance in clinical application. However, the existing analysis approaches are difficult to addressing the breast cancer classification problem because the feature subtle differences of inter-class histopathological image and the classification accuracy still hard to meet the clinical application. Recent advancements in data-driven sharing processing and multi-level hierarchical feature learning have made available considerable chance to dope out a solution to this problem. To address the challenging problem, we propose a novel breast cancer histopathological image classification method based on deep convolutional neural networks, named as BiCNN model, to address the two-class breast cancer classification on the pathological image. This deep learning model considers class and sub-class labels of breast cancer as prior knowledge, which can restrain the distance of features of different breast cancer pathological images. In addition, an advanced data augmented method is proposed to fit tolerance whole slide image recognition, which can full reserve image edge feature of cancerization region. The transfer learning and fine-tuning method are adopted as an optimal training strategy to improve breast cancer histopathological image classification accuracy. The experiment results show that the proposed method leads to a higher classification accuracy (up to 97%) and displays good robustness and generalization, which provides efficient tools for breast cancer clinical diagnosis."
2019,A Technical Review of Convolutional Neural Network-Based Mammographic Breast Cancer Diagnosis,"This study reviews the technique of convolutional neural network (CNN) applied in a specific field of mammographic breast cancer diagnosis (MBCD). It aims to provide several clues on how to use CNN for related tasks. MBCD is a long-standing problem, and massive computer-aided diagnosis models have been proposed. The models of CNN-based MBCD can be broadly categorized into three groups. One is to design shallow or to modify existing models to decrease the time cost as well as the number of instances for training; another is to make the best use of a pretrained CNN by transfer learning and fine-tuning; the third is to take advantage of CNN models for feature extraction, and the differentiation of malignant lesions from benign ones is fulfilled by using machine learning classifiers. This study enrolls peer-reviewed journal publications and presents technical details and pros and cons of each model. Furthermore, the findings, challenges and limitations are summarized and some clues on the future work are also given. Conclusively, CNN-based MBCD is at its early stage, and there is still a long way ahead in achieving the ultimate goal of using deep learning tools to facilitate clinical practice. This review benefits scientific researchers, industrial engineers, and those who are devoted to intelligent cancer diagnosis."
2022,Ensemble Deep-Learning-Enabled Clinical Decision Support System for Breast Cancer Diagnosis and Classification on Ultrasound Images,"Simple Summary In the literature, there exist plenty of research works focused on the detection and classification of breast cancer. However, only a few works have focused on the classification of breast cancer using ultrasound scan images. Although deep transfer learning models are useful in breast cancer classification, owing to their outstanding performance in a number of applications, image pre-processing and segmentation techniques are essential. In this context, the current study developed a new Ensemble Deep-Learning-Enabled Clinical Decision Support System for the diagnosis and classification of breast cancer using ultrasound images. In the study, an optimal multi-level thresholding-based image segmentation technique was designed to identify the tumor-affected regions. The study also developed an ensemble of three deep learning models for feature extraction and an optimal machine learning classifier for breast cancer detection. The study offers a means of assisting radiologists and healthcare professionals in the breast cancer classification process. Abstract Clinical Decision Support Systems (CDSS) provide an efficient way to diagnose the presence of diseases such as breast cancer using ultrasound images (USIs). Globally, breast cancer is one of the major causes of increased mortality rates among women. Computer-Aided Diagnosis (CAD) models are widely employed in the detection and classification of tumors in USIs. The CAD systems are designed in such a way that they provide recommendations to help radiologists in diagnosing breast tumors and, furthermore, in disease prognosis. The accuracy of the classification process is decided by the quality of images and the radiologist’s experience. The design of Deep Learning (DL) models is found to be effective in the classification of breast cancer. In the current study, an Ensemble Deep-Learning-Enabled Clinical Decision Support System for Breast Cancer Diagnosis and Classification (EDLCDS-BCDC) technique was developed using USIs. The proposed EDLCDS-BCDC technique was intended to identify the existence of breast cancer using USIs. In this technique, USIs initially undergo pre-processing through two stages, namely wiener filtering and contrast enhancement. Furthermore, Chaotic Krill Herd Algorithm (CKHA) is applied with Kapur’s entropy (KE) for the image segmentation process. In addition, an ensemble of three deep learning models, VGG-16, VGG-19, and SqueezeNet, is used for feature extraction. Finally, Cat Swarm Optimization (CSO) with the Multilayer Perceptron (MLP) model is utilized to classify the images based on whether breast cancer exists or not. A wide range of simulations were carried out on benchmark databases and the extensive results highlight the better outcomes of the proposed EDLCDS-BCDC technique over recent methods."
2019,Deep Learning Approaches for Data Augmentation and Classification of Breast Masses using Ultrasound Images,"Breast classification and detection using ultrasound imaging is considered a significant step in computer-aided diagno-sis systems. Over the previous decades, researchers have proved the opportunities to automate the initial tumor classification and detection. The shortage of popular datasets of ultrasound images of breast cancer prevents researchers from obtaining a good performance of the classification algorithms. Traditional augmentation approaches are firmly limited, especially in tasks where the images follow strict standards, as in the case of medical datasets. Therefore besides the traditional augmentation, we use a new methodology for data augmentation using Generative Adversarial Network (GAN). We achieved higher accuracies by integrating traditional with GAN-based augmentation. This paper uses two breast ultrasound image datasets obtained from two various ultrasound systems. The first dataset is our dataset which was collected from Baheya Hospital for Early Detection and Treatment of Women’s Cancer, Cairo (Egypt), we name it (BUSI) referring to Breast Ultrasound Images (BUSI) dataset. It contains 780 images (133 normal, 437 benign and 210 malignant). While the Dataset (B) is obtained from related work and it has 163 images (110 benign and 53 malignant). To overcome the shortage of public datasets in this field, BUSI dataset will be publicly available for researchers. Moreover, in this paper, deep learning approaches are proposed to be used for breast ultrasound classification. We examine two different methods: a Convolutional Neural Network (CNN) approach and a Transfer Learning (TL) approach and we compare their performance with and without augmentation. The results confirm an overall enhancement using augmentation methods with deep learning classification methods (especially transfer learning) when evaluated on the two datasets."
2017,A method for classifying medical images using transfer learning: A pilot study on histopathology of breast cancer,"The advance of deep learning has made huge changes in computer vision and produced various off-the-shelf trained models. Particularly, Convolutional Neural Network (CNN) has been widely used to build image classification model which allow researchers transfer the pre-trained learning model for other classifications. We propose a transfer learning method to detect breast cancer using histopathology images based on Google's Inception v3 model which were initially trained for the classification of non-medical images. The pilot study shows the feasibility of transfer learning in the detection of breast cancer with AUC of 0.93."
2014,Enhanced charge transfer by gold nanoparticle at DNA modified electrode and its application to label-free DNA detection.,"Rational utilization of nanomaterials to construct electrochemical nucleic acid sensors has attracted large attention in recent years. In this work, we systematically interrogate the interaction between gold nanoparticles (GNPs) and single-strand DNA (ssDNA) immobilized on an electrode surface and then take advantage of the ultrahigh charge-transfer efficiency of GNPs to develop a novel DNA sensing method. Specifically, ssDNA modified gold electrode can adsorb GNPs because of the interaction between gold and nitrogen-containing bases; thus, the negative electrochemical species [Fe(CN)6](3-/4-) may transfer electrons to electrode through adsorbed GNPs. In the presence of target DNA, the formed double-strand DNA (dsDNA) cannot capture GNPs onto the electrode surface and the dsDNA may result in a large charge-transfer resistance owing to the negatively charged phosphate backbones of DNA. So a simple but sensitive method for the detection of target DNA can be developed by using GNPs without any requirement of modification. Experimental results demonstrate that the electrochemical method we have proposed in this work can detect as low as 1 pM breast cancer gene BRCA1 in a 10 μL sample volume without any signal amplification process or the involvement of other synthesized complex, which may provide an alternative for cancer DNA detection. This method may also be generalized for detecting a spectrum of targets using functional DNA (aptamer, metal-specific oligonucleotide, or DNAzyme) in the future."
2018,Evolutionary pruning of transfer learned deep convolutional neural network for breast cancer diagnosis in digital breast tomosynthesis,"Deep learning models are highly parameterized, resulting in difficulty in inference and transfer learning for image recognition tasks. In this work, we propose a layered pathway evolution method to compress a deep convolutional neural network (DCNN) for classification of masses in digital breast tomosynthesis (DBT). The objective is to prune the number of tunable parameters while preserving the classification accuracy. In the first stage transfer learning, 19 632 augmented regions-of-interest (ROIs) from 2454 mass lesions on mammograms were used to train a pre-trained DCNN on ImageNet. In the second stage transfer learning, the DCNN was used as a feature extractor followed by feature selection and random forest classification. The pathway evolution was performed using genetic algorithm in an iterative approach with tournament selection driven by count-preserving crossover and mutation. The second stage was trained with 9120 DBT ROIs from 228 mass lesions using leave-one-case-out cross-validation. The DCNN was reduced by 87% in the number of neurons, 34% in the number of parameters, and 95% in the number of multiply-and-add operations required in the convolutional layers. The test AUC on 89 mass lesions from 94 independent DBT cases before and after pruning were 0.88 and 0.90, respectively, and the difference was not statistically significant (p  >  0.05). The proposed DCNN compression approach can reduce the number of required operations by 95% while maintaining the classification performance. The approach can be extended to other deep neural networks and imaging tasks where transfer learning is appropriate."
2019,Semi-Supervised Histology Classification using Deep Multiple Instance Learning and Contrastive Predictive Coding,"Convolutional neural networks can be trained to perform histology slide classification using weak annotations with multiple instance learning (MIL). However, given the paucity of labeled histology data, direct application of MIL can easily suffer from overfitting and the network is unable to learn rich feature representations due to the weak supervisory signal. We propose to overcome such limitations with a two-stage semi-supervised approach that combines the power of data-efficient self-supervised feature learning via contrastive predictive coding (CPC) and the interpretability and flexibility of regularized attention-based MIL. We apply our two-stage CPC + MIL semi-supervised pipeline to the binary classification of breast cancer histology images. Across five random splits, we report state-of-the-art performance with a mean validation accuracy of 95% and an area under the ROC curve of 0.968. We further evaluate the quality of features learned via CPC relative to simple transfer learning and show that strong classification performance using CPC features can be efficiently leveraged under the MIL framework even with the feature encoder frozen."
2016,AggNet : Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images,"The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions. 1) Can deep CNN be trained with data collected from crowdsourcing? 2) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)? 3) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration."
2022,TTCNN: A Breast Cancer Detection and Classification towards Computer-Aided Diagnosis Using Digital Mammography in Early Stages,"Breast cancer is a major research area in the medical image analysis field; it is a dangerous disease and a major cause of death among women. Early and accurate diagnosis of breast cancer based on digital mammograms can enhance disease detection accuracy. Medical imagery must be detected, segmented, and classified for computer-aided diagnosis (CAD) systems to help the radiologists for accurate diagnosis of breast lesions. Therefore, an accurate breast cancer detection and classification approach is proposed for screening of mammograms. In this paper, we present a deep learning system that can identify breast cancer in mammogram screening images using an “end-to-end” training strategy that efficiently uses mammography images for computer-aided breast cancer recognition in the early stages. First, the proposed approach implements the modified contrast enhancement method in order to refine the detail of edges from the source mammogram images. Next, the transferable texture convolutional neural network (TTCNN) is presented to enhance the performance of classification and the energy layer is integrated in this work to extract the texture features from the convolutional layer. The proposed approach consists of only three layers of convolution and one energy layer, rather than the pooling layer. In the third stage, we analyzed the performance of TTCNN based on deep features of convolutional neural network models (InceptionResNet-V2, Inception-V3, VGG-16, VGG-19, GoogLeNet, ResNet-18, ResNet-50, and ResNet-101). The deep features are extracted by determining the best layers which enhance the classification accuracy. In the fourth stage, by using the convolutional sparse image decomposition approach, all the extracted feature vectors are fused and, finally, the best features are selected by using the entropy controlled firefly method. The proposed approach employed on DDSM, INbreast, and MIAS datasets and attained the average accuracy of 97.49%. Our proposed transferable texture CNN-based method for classifying screening mammograms has outperformed prior methods. These findings demonstrate that automatic deep learning algorithms can be easily trained to achieve high accuracy in diverse mammography images, and can offer great potential to improve clinical tools to minimize false positive and false negative screening mammography results."
2022,A Novel Multistage Transfer Learning for Ultrasound Breast Cancer Image Classification,"Breast cancer diagnosis is one of the many areas that has taken advantage of artificial intelligence to achieve better performance, despite the fact that the availability of a large medical image dataset remains a challenge. Transfer learning (TL) is a phenomenon that enables deep learning algorithms to overcome the issue of shortage of training data in constructing an efficient model by transferring knowledge from a given source task to a target task. However, in most cases, ImageNet (natural images) pre-trained models that do not include medical images, are utilized for transfer learning to medical images. Considering the utilization of microscopic cancer cell line images that can be acquired in large amount, we argue that learning from both natural and medical datasets improves performance in ultrasound breast cancer image classification. The proposed multistage transfer learning (MSTL) algorithm was implemented using three pre-trained models: EfficientNetB2, InceptionV3, and ResNet50 with three optimizers: Adam, Adagrad, and stochastic gradient de-scent (SGD). Dataset sizes of 20,400 cancer cell images, 200 ultrasound images from Mendeley and 400 ultrasound images from the MT-Small-Dataset were used. ResNet50-Adagrad-based MSTL achieved a test accuracy of 99 ± 0.612% on the Mendeley dataset and 98.7 ± 1.1% on the MT-Small-Dataset, averaging over 5-fold cross validation. A p-value of 0.01191 was achieved when comparing MSTL against ImageNet based TL for the Mendeley dataset. The result is a significant improvement in the performance of artificial intelligence methods for ultrasound breast cancer classification compared to state-of-the-art methods and could remarkably improve the early diagnosis of breast cancer in young women."
2021,Deep CNN Model based on VGG16 for Breast Cancer Classification,"Deep learning (DL) technologies are becoming a buzzword these days, especially for breast histopathology image tasks, such as diagnosing, due to the high performance obtained in image classification. Among deep learning types, Convolutional Neural Networks (CNN) are the most common types of DL models utilized for medical image diagnosis and analysis. However, CNN suffers from high computation cost to be implemented and may require to adapt huge number of parameters. Thus, and in order to address this issue; several pre-trained models have been established with the predefined network architecture. In this study, a transfer learning model based on Visual Geometry Group with 16-layer deep model architecture (VGG16) is utilized to extract high-level features from the BreaKHis benchmark histopathological images dataset. Then, multiple machine learning models (classifiers) are used to handle different Breast Cancer (BC) histopathological image classification tasks mainly: binary and multiclass with eight-class classifications. The experimental results on the public BreakHis benchmark dataset demonstrate that the proposed models are better than the previous works on the same dataset. Besides, the results show that the proposed models are able to outperform recent classical machine learning algorithms."
2019,Breast Cancer Diagnosis with Transfer Learning and Global Pooling,"Breast cancer is one of the most common causes of cancer-related death in women worldwide. Early and accurate diagnosis of breast cancer may significantly increase the survival rate of patients. In this study, we aim to develop a fully automatic, deep learning-based, method using descriptor features extracted by Deep Convolutional Neural Network (DCNN) models and pooling operation for the classification of hematoxylin and eosin stain (H#E) histological breast cancer images provided as a part of the International Conference on Image Analysis and Recognition (ICIAR) 2018 Grand Challenge on BreAst Cancer Histology (BACH) Images. Different data augmentation methods are applied to optimize the DCNN performance. We also investigated the efficacy of different stain normalization methods as a pre-processing step. The proposed network architecture using a pre-trained Xception model yields 92.50% average classification accuracy."
2017,Deep learning in breast cancer risk assessment: evaluation of convolutional neural networks on a clinical dataset of full-field digital mammograms,"Abstract. To evaluate deep learning in the assessment of breast cancer risk in which convolutional neural networks (CNNs) with transfer learning are used to extract parenchymal characteristics directly from full-field digital mammographic (FFDM) images instead of using computerized radiographic texture analysis (RTA), 456 clinical FFDM cases were included: a “high-risk” BRCA1/2 gene-mutation carriers dataset (53 cases), a “high-risk” unilateral cancer patients dataset (75 cases), and a “low-risk dataset” (328 cases). Deep learning was compared to the use of features from RTA, as well as to a combination of both in the task of distinguishing between high- and low-risk subjects. Similar classification performances were obtained using CNN [area under the curve (AUC)=0.83; standard error (SE)=0.03] and RTA (AUC=0.82; SE=0.03) in distinguishing BRCA1/2 carriers and low-risk women. However, in distinguishing unilateral cancer patients and low-risk women, performance was significantly greater with CNN (AUC=0.82; SE=0.03) compared to RTA (AUC=0.73; SE=0.03). Fusion classifiers performed significantly better than the RTA-alone classifiers with AUC values of 0.86 and 0.84 in differentiating BRCA1/2 carriers from low-risk women and unilateral cancer patients from low-risk women, respectively. In conclusion, deep learning extracted parenchymal characteristics from FFDMs performed as well as, or better than, conventional texture analysis in the task of distinguishing between cancer risk populations."
2016,MO-DE-207B-06: Computer-Aided Diagnosis of Breast Ultrasound Images Using Transfer Learning From Deep Convolutional Neural Networks.,"PURPOSE To assess the performance of using transferred features from pre-trained deep convolutional networks (CNNs) in the task of classifying cancer in breast ultrasound images, and to compare this method of transfer learning with previous methods involving human-designed features. METHODS A breast ultrasound dataset consisting of 1125 cases and 2393 regions of interest (ROIs) was used. Each ROI was labeled as cystic, benign, or malignant. Features were extracted from each ROI using pre-trained CNNs and used to train support vector machine (SVM) classifiers in the tasks of distinguishing non-malignant (benign+cystic) vs malignant lesions and benign vs malignant lesions. For a baseline comparison, classifiers were also trained on prior analytically-extracted tumor features. Five-fold cross-validation (by case) was conducted with the area under the receiver operating characteristic curve (AUC) as the performance metric. RESULTS Classifiers trained on CNN-extracted features were comparable to classifiers trained on human-designed features. In the non-malignant vs malignant task, both the SVM trained on CNN-extracted features and the SVM trained on human-designed features obtained an AUC of 0.90. In the task of determining benign vs malignant, the SVM trained on CNN-extracted features obtained an AUC of 0.88, compared to the AUC of 0.85 obtained by the SVM trained on human-designed features. CONCLUSION We obtained strong results using transfer learning to characterize ultrasound breast cancer images. This method allows us to directly classify a small dataset of lesions in a computationally inexpensive fashion without any manual input. Modern deep learning methods in computer vision are contingent on large datasets and vast computational resources, which are often inaccessible for clinical applications. Consequently, we believe transfer learning methods will be important for computer-aided diagnosis schemes in order to utilize advancements in deep learning and computer vision without the associated costs. This work was partially funded by NIH grant U01 CA195564 and the University of Chicago Metcalf program. M.L.G. is a stockholder in R2/Hologic, co-founder and equity holder in Quantitative Insights, and receives royalties from Hologic, GE Medical Systems, MEDIAN Technologies, Riverain Medical, Mitsubishi, and Toshiba. K.D. received royalties from Hologic."
2019,Breast Cancer Classification in Ultrasound Images using Transfer Learning,"Computer-aided detection of malignant breast tumors in ultrasound images has been receiving growing attention. In this paper, we propose a deep learning methodology to tackle this problem. The training data, which contains several hundred images of benign and malignant cases, was used to train a deep convolutional neural network (CNN). Three training approaches are proposed: a baseline approach where the CNN architecture is trained from scratch, a transfer-learning approach where the pre-trained VGG16 CNN architecture is further trained with the ultrasound images, and a fine-tuned learning approach where the deep learning parameters are fine-tuned to overcome overfitting. The experimental results demonstrate that the fine-tuned model had the best performance (0.97 accuracy, 0.98 AUC), with pre-training on US images. Creating pre-trained models using medical imaging data would certainly improve deep learning outcomes in biomedical applications."
2021,Multi- class classification of breast cancer abnormalities using Deep Convolutional Neural Network (CNN),"The real cause of breast cancer is very challenging to determine and therefore early detection of the disease is necessary for reducing the death rate due to risks of breast cancer. Early detection of cancer boosts increasing the survival chance up to 8%. Primarily, breast images emanating from mammograms, X-Rays or MRI are analyzed by radiologists to detect abnormalities. However, even experienced radiologists face problems in identifying features like micro-calcifications, lumps and masses, leading to high false positive and high false negative. Recent advancement in image processing and deep learning create some hopes in devising more enhanced applications that can be used for the early detection of breast cancer. In this work, we have developed a Deep Convolutional Neural Network (CNN) to segment and classify the various types of breast abnormalities, such as calcifications, masses, asymmetry and carcinomas, unlike existing research work, which mainly classified the cancer into benign and malignant, leading to improved disease management. Firstly, a transfer learning was carried out on our dataset using the pre-trained model ResNet50. Along similar lines, we have developed an enhanced deep learning model, in which learning rate is considered as one of the most important attributes while training the neural network. The learning rate is set adaptively in our proposed model based on changes in error curves during the learning process involved. The proposed deep learning model has achieved a performance of 88% in the classification of these four types of breast cancer abnormalities such as, masses, calcifications, carcinomas and asymmetry mammograms."
2022,Histopathologic Oral Cancer Prediction Using Oral Squamous Cell Carcinoma Biopsy Empowered with Transfer Learning,"Oral cancer is a dangerous and extensive cancer with a high death ratio. Oral cancer is the most usual cancer in the world, with more than 300,335 deaths every year. The cancerous tumor appears in the neck, oral glands, face, and mouth. To overcome this dangerous cancer, there are many ways to detect like a biopsy, in which small chunks of tissues are taken from the mouth and tested under a secure and hygienic microscope. However, microscope results of tissues to detect oral cancer are not up to the mark, a microscope cannot easily identify the cancerous cells and normal cells. Detection of cancerous cells using microscopic biopsy images helps in allaying and predicting the issues and gives better results if biologically approaches apply accurately for the prediction of cancerous cells, but during the physical examinations microscopic biopsy images for cancer detection there are major chances for human error and mistake. So, with the development of technology deep learning algorithms plays a major role in medical image diagnosing. Deep learning algorithms are efficiently developed to predict breast cancer, oral cancer, lung cancer, or any other type of medical image. In this study, the proposed model of transfer learning model using AlexNet in the convolutional neural network to extract rank features from oral squamous cell carcinoma (OSCC) biopsy images to train the model. Simulation results have shown that the proposed model achieved higher classification accuracy 97.66% and 90.06% of training and testing, respectively."
2021,Conventional Machine Learning versus Deep Learning for Magnification Dependent Histopathological Breast Cancer Image Classification: A Comparative Study with Visual Explanation,"Breast cancer is a serious threat to women. Many machine learning-based computer-aided diagnosis (CAD) methods have been proposed for the early diagnosis of breast cancer based on histopathological images. Even though many such classification methods achieved high accuracy, many of them lack the explanation of the classification process. In this paper, we compare the performance of conventional machine learning (CML) against deep learning (DL)-based methods. We also provide a visual interpretation for the task of classifying breast cancer in histopathological images. For CML-based methods, we extract a set of handcrafted features using three feature extractors and fuse them to get image representation that would act as an input to train five classical classifiers. For DL-based methods, we adopt the transfer learning approach to the well-known VGG-19 deep learning architecture, where its pre-trained version on the large scale ImageNet, is block-wise fine-tuned on histopathological images. The evaluation of the proposed methods is carried out on the publicly available BreaKHis dataset for the magnification dependent classification of benign and malignant breast cancer and their eight sub-classes, and a further validation on KIMIA Path960, a magnification-free histopathological dataset with 20 image classes, is also performed. After providing the classification results of CML and DL methods, and to better explain the difference in the classification performance, we visualize the learned features. For the DL-based method, we intuitively visualize the areas of interest of the best fine-tuned deep neural networks using attention maps to explain the decision-making process and improve the clinical interpretability of the proposed models. The visual explanation can inherently improve the pathologist’s trust in automated DL methods as a credible and trustworthy support tool for breast cancer diagnosis. The achieved results show that DL methods outperform CML approaches where we reached an accuracy between 94.05% and 98.13% for the binary classification and between 76.77% and 88.95% for the eight-class classification, while for DL approaches, the accuracies range from 85.65% to 89.32% for the binary classification and from 63.55% to 69.69% for the eight-class classification."
2016,High-Content Analysis of Breast Cancer Using Single-Cell Deep Transfer Learning,"High-content analysis has revolutionized cancer drug discovery by identifying substances that alter the phenotype of a cell, which prevents tumor growth and metastasis. The high-resolution biofluorescence images from assays allow precise quantitative measures enabling the distinction of small molecules of a host cell from a tumor. In this work, we are particularly interested in the application of deep neural networks (DNNs), a cutting-edge machine learning method, to the classification of compounds in chemical mechanisms of action (MOAs). Compound classification has been performed using image-based profiling methods sometimes combined with feature reduction methods such as principal component analysis or factor analysis. In this article, we map the input features of each cell to a particular MOA class without using any treatment-level profiles or feature reduction methods. To the best of our knowledge, this is the first application of DNN in this domain, leveraging single-cell information. Furthermore, we use deep transfer learning (DTL) to alleviate the intensive and computational demanding effort of searching the huge parameter’s space of a DNN. Results show that using this approach, we obtain a 30% speedup and a 2% accuracy improvement."
2021,Review of Breast Cancer Pathologigcal Image Processing,"Breast cancer is one of the most common malignancies. Pathological image processing of breast has become an important means for early diagnosis of breast cancer. Using medical image processing to assist doctors to detect potential breast cancer as early as possible has always been a hot topic in the field of medical image diagnosis. In this paper, a breast cancer recognition method based on image processing is systematically expounded from four aspects: breast cancer detection, image segmentation, image registration, and image fusion. The achievements and application scope of supervised learning, unsupervised learning, deep learning, CNN, and so on in breast cancer examination are expounded. The prospect of unsupervised learning and transfer learning for breast cancer diagnosis is prospected. Finally, the privacy protection of breast cancer patients is put forward."
2019,Transfer Learning in Breast Mammogram Abnormalities Classification With Mobilenet and Nasnet,"Breast cancer has an important incidence in women mortality worldwide. Currently, mammography is considered the gold standard for breast abnormalities screening examinations since it aids in the early detection and diagnosis of the illness. However, both identification of mass lesions and its malignancy classification is a challenging problem for artificial intelligence. Research has turned to the use of deep learning models in mammography which can enhance the performance of Computer Aided Diagnosis Systems (CADx). In this paper, we present our preliminary results on the use of transfer learning for malignancy classification of breast abnormality. We experiment with models that, according to our literature review, have not yet been explored thoroughly such as NasNet and MobileNet. Their performance is compared with InceptionV3 and Resnet50. The best results were obtained with Resnet50 and MobileNet with 78.4% and 74.3%, respectively. Also, some image pre-processing steps are studied in order to increase classification accuracy."
2020,Breast Cancer Classification Using Deep Learning Approaches and Histopathology Image: A Comparison Study,"Convolutional Neural Network (CNN) models are a type of deep learning architecture introduced to achieve the correct classification of breast cancer. This paper has a two-fold purpose. The first aim is to investigate the various deep learning models in classifying breast cancer histopathology images. This study identified the most accurate models in terms of the binary, four, and eight classifications of breast cancer histopathology image databases. The different accuracy scores obtained for the deep learning models on the same database showed that other factors such as pre-processing, data augmentation, and transfer learning methods can impact the ability of the models to achieve higher accuracy. The second purpose of our manuscript is to investigate the latest models that have no or limited examination done in previous studies. The models like ResNeXt, Dual Path Net, SENet, and NASNet had been identified with the most cutting-edge results for the ImageNet database. These models were examined for the binary, and eight classifications on BreakHis, a breast cancer histopathology image database. Furthermore, the BACH database was used to investigate these models for four classifications. Then, these models were compared with the previous studies to find and propose the most state-of-the-art models for each classification. Since the Inception-ResNet-V2 architecture achieved the best results for binary and eight classifications, we have examined this model in our study as well to provide a better comparison result. In short, this paper provides an extensive evaluation and discussion about the experimental settings for each study that had been conducted on the breast cancer histopathology images."
2016,Synergistic Chemo-Photothermal Therapy of Breast Cancer by Mesenchymal Stem Cell-Encapsulated Yolk-Shell GNR@HPMO-PTX Nanospheres.,"Mesenchymal stem cells (MSCs) have attracted increasing attention as vehicles for cancer treatment. Herein, MSC-based synergistic oncotherapy strategy is presented for the first time. To achieve this goal, yolk-shell structured gold nanorod embedded hollow periodic mesoporous organosilica nanospheres (GNR@HPMOs) with high paclitaxel (PTX) loading capability and excellent photothermal transfer ability upon near-infrared (NIR) light irradiation are first prepared. Cytotoxicity and migration assays show that the viability and tumor-homing capability of MSCs are well-retained after internalization of high content of PTX loaded GNR@HPMOs (denoted as GNR@HPMOs-PTX). In vitro experiments show the GNR@HPMOs-PTX loaded MSCs (GNR@HPMOs-PTX@MSCs) possess synergistic chemo-photothermal killing effects for breast cancer cells. Also, photoacoustic imaging shows that the MSCs can improve dispersion and distribution in tumor tissue for GNR@HPMOs-PTX after intratumoral injection. In vivo experiments in breast cancer model of nude mice further demonstrate that the GNR@HPMOs-PTX@MSCs significantly inhibit tumor growth, suggesting their great potential for synergistic therapy of cancer."
2020,Deep Learning Applied for Histological Diagnosis of Breast Cancer,"Deep learning, as one of the currently most popular computer science research trends, improves neural networks, which has more and deeper layers allowing higher abstraction levels and more accurate data analysis. Although deep convolutional neural networks, as a deep learning algorithm, has recently achieved promising results in data analysis, the requirement for a large amount of data prevents its use in medical data analysis since it is challenging to obtain data from the medical field. Breast cancer is a common cancer in women. To diagnose this kind of cancer, breast cell shapes in histopathology images should be examined by senior pathologists. The number of pathologists per population in the world is not enough, especially in Africa, and human mistake may occur in diagnosis procedure. After the evaluation of deep learning methods and algorithms in breast histological data processing, we tried to improve the current systems’ accuracy. As a result, this study proposes two effective deep transfer learning-based models, which rely on pre-trained DCNN using a large collection of ImageNet dataset images that improve current state-of-the-art systems in both binary and multiclass classification. We transfer pre-trained weights of the ResNet50 and DesneNet121 on the Imagenet as initial weights and fine-tune these models with a deep classifier with data augmentation to detect various malignant and benign samples tissues in the two categories of binary classification and multiclass classification. The proposed models have been examined with optimized hyperparameters in magnification-dependent and magnification-independent classification modes. In the multiclass classification, the proposed system achieved up to 98% accuracy. As for binary classification, the proposed system provides up to 100% accuracy. The results outperform previous studies accuracies in all defined performance metrics in breast cancer CAD systems from histological images."
2022,Automated Breast Cancer Detection Models Based on Transfer Learning,"Breast cancer is among the leading causes of mortality for females across the planet. It is essential for the well-being of women to develop early detection and diagnosis techniques. In mammography, focus has contributed to the use of deep learning (DL) models, which have been utilized by radiologists to enhance the needed processes to overcome the shortcomings of human observers. The transfer learning method is being used to distinguish malignant and benign breast cancer by fine-tuning multiple pre-trained models. In this study, we introduce a framework focused on the principle of transfer learning. In addition, a mixture of augmentation strategies were used to prevent overfitting and produce stable outcomes by increasing the number of mammographic images; including several rotation combinations, scaling, and shifting. On the Mammographic Image Analysis Society (MIAS) dataset, the proposed system was evaluated and achieved an accuracy of 89.5% using (residual network-50) ResNet50, and achieved an accuracy of 70% using the Nasnet-Mobile network. The proposed system demonstrated that pre-trained classification networks are significantly more effective and efficient, making them more acceptable for medical imaging, particularly for small training datasets."
2019,Photoacoustic Image Classification and Segmentation of Breast Cancer: A Feasibility Study,"Nowadays, breast cancer has increasingly threatened the health of human, especially females. However, breast cancer is still hard to detect in the early stage, and the diagnostic procedure can be time-consuming with abundant expertise needed. In this paper, we explored the deep learning algorithms in emerging photoacoustic tomography for breast cancer diagnostics. Specifically, we used a pre-processing algorithm to enhance the quality and uniformity of input breast cancer images and a transfer learning method to achieve better classification performance. Besides, by comparing the area under the curve, sensitivity, and specificity of support vector machine with AlexNet and GoogLeNet, it can be concluded that the combination of deep learning and photoacoustic imaging has the potential to achieve important impact on clinical diagnostics. Finally, according to the breast imaging reporting and data-system levels, we divided breast cancer images into six grades and designed a segmentation software for identifying the six grades of breast cancer. Then, we tested based on MAMMOGRAPHYC IMAGES DATABASE FROM LAPIMO EESC/USP (Laboratory of Analysis and Processing of Medical and Dental Images) to verify the accuracy of our segmentation method, which showed a satisfactory result."
2023,Vision-Transformer-Based Transfer Learning for Mammogram Classification,"Breast mass identification is a crucial procedure during mammogram-based early breast cancer diagnosis. However, it is difficult to determine whether a breast lump is benign or cancerous at early stages. Convolutional neural networks (CNNs) have been used to solve this problem and have provided useful advancements. However, CNNs focus only on a certain portion of the mammogram while ignoring the remaining and present computational complexity because of multiple convolutions. Recently, vision transformers have been developed as a technique to overcome such limitations of CNNs, ensuring better or comparable performance in natural image classification. However, the utility of this technique has not been thoroughly investigated in the medical image domain. In this study, we developed a transfer learning technique based on vision transformers to classify breast mass mammograms. The area under the receiver operating curve of the new model was estimated as 1 ± 0, thus outperforming the CNN-based transfer-learning models and vision transformer models trained from scratch. The technique can, hence, be applied in a clinical setting, to improve the early diagnosis of breast cancer."
2023,BC2NetRF: Breast Cancer Classification from Mammogram Images Using Enhanced Deep Learning Features and Equilibrium-Jaya Controlled Regula Falsi-Based Features Selection,"One of the most frequent cancers in women is breast cancer, and in the year 2022, approximately 287,850 new cases have been diagnosed. From them, 43,250 women died from this cancer. An early diagnosis of this cancer can help to overcome the mortality rate. However, the manual diagnosis of this cancer using mammogram images is not an easy process and always requires an expert person. Several AI-based techniques have been suggested in the literature. However, still, they are facing several challenges, such as similarities between cancer and non-cancer regions, irrelevant feature extraction, and weak training models. In this work, we proposed a new automated computerized framework for breast cancer classification. The proposed framework improves the contrast using a novel enhancement technique called haze-reduced local-global. The enhanced images are later employed for the dataset augmentation. This step aimed at increasing the diversity of the dataset and improving the training capability of the selected deep learning model. After that, a pre-trained model named EfficientNet-b0 was employed and fine-tuned to add a few new layers. The fine-tuned model was trained separately on original and enhanced images using deep transfer learning concepts with static hyperparameters’ initialization. Deep features were extracted from the average pooling layer in the next step and fused using a new serial-based approach. The fused features were later optimized using a feature selection algorithm known as Equilibrium-Jaya controlled Regula Falsi. The Regula Falsi was employed as a termination function in this algorithm. The selected features were finally classified using several machine learning classifiers. The experimental process was conducted on two publicly available datasets—CBIS-DDSM and INbreast. For these datasets, the achieved average accuracy is 95.4% and 99.7%. A comparison with state-of-the-art (SOTA) technology shows that the obtained proposed framework improved the accuracy. Moreover, the confidence interval-based analysis shows consistent results of the proposed framework."
2022,Breast lesions classifications of mammographic images using a deep convolutional neural network-based approach,"Breast cancer is one of the worst illnesses, with a higher fatality rate among women globally. Breast cancer detection needs accurate mammography interpretation and analysis, which is challenging for radiologists owing to the intricate anatomy of the breast and low image quality. Advances in deep learning-based models have significantly improved breast lesions’ detection, localization, risk assessment, and categorization. This study proposes a novel deep learning-based convolutional neural network (ConvNet) that significantly reduces human error in diagnosing breast malignancy tissues. Our methodology is most effective in eliciting task-specific features, as feature learning is coupled with classification tasks to achieve higher performance in automatically classifying the suspicious regions in mammograms as benign and malignant. To evaluate the model’s validity, 322 raw mammogram images from Mammographic Image Analysis Society (MIAS) and 580 from Private datasets were obtained to extract in-depth features, the intensity of information, and the high likelihood of malignancy. Both datasets are magnificently improved through preprocessing, synthetic data augmentation, and transfer learning techniques to attain the distinctive combination of breast tumors. The experimental findings indicate that the proposed approach achieved remarkable training accuracy of 0.98, test accuracy of 0.97, high sensitivity of 0.99, and an AUC of 0.99 in classifying breast masses on mammograms. The developed model achieved promising performance that helps the clinician in the speedy computation of mammography, breast masses diagnosis, treatment planning, and follow-up of disease progression. Moreover, it has the immense potential over retrospective approaches in consistency feature extraction and precise lesions classification."
2022,Application of Transfer Learning and Ensemble Learning in Image-level Classification for Breast Histopathology,"Background: Breast cancer has the highest prevalence in women globally. The classification and diagnosis of breast cancer and its histopathological images have always been a hot spot of clinical concern. In Computer-Aided Diagnosis (CAD), traditional classification models mostly use a single network to extract features, which has significant limitations. On the other hand, many networks are trained and optimized on patient-level datasets, ignoring the application of lower-level data labels. Method: This paper proposes a deep ensemble model based on image-level labels for the binary classification of benign and malignant lesions of breast histopathological images. First, the BreaKHis dataset is randomly divided into a training, validation and test set. Then, data augmentation techniques are used to balance the number of benign and malignant samples. Thirdly, considering the performance of transfer learning and the complementarity between each network, VGG16, Xception, ResNet50, DenseNet201 are selected as the base classifiers. Result: In the ensemble network model with accuracy as the weight, the image-level binary classification achieves an accuracy of $98.90\%$. In order to verify the capabilities of our method, the latest Transformer and Multilayer Perception (MLP) models have been experimentally compared on the same dataset. Our model wins with a $5\%-20\%$ advantage, emphasizing the ensemble model's far-reaching significance in classification tasks. Conclusion: This research focuses on improving the model's classification performance with an ensemble algorithm. Transfer learning plays an essential role in small datasets, improving training speed and accuracy. Our model has outperformed many existing approaches in accuracy, providing a method for the field of auxiliary medical diagnosis."
2020,Deep Learning in Selected Cancers’ Image Analysis—A Survey,"Deep learning algorithms have become the first choice as an approach to medical image analysis, face recognition, and emotion recognition. In this survey, several deep-learning-based approaches applied to breast cancer, cervical cancer, brain tumor, colon and lung cancers are studied and reviewed. Deep learning has been applied in almost all of the imaging modalities used for cervical and breast cancers and MRIs for the brain tumor. The result of the review process indicated that deep learning methods have achieved state-of-the-art in tumor detection, segmentation, feature extraction and classification. As presented in this paper, the deep learning approaches were used in three different modes that include training from scratch, transfer learning through freezing some layers of the deep learning network and modifying the architecture to reduce the number of parameters existing in the network. Moreover, the application of deep learning to imaging devices for the detection of various cancer cases has been studied by researchers affiliated to academic and medical institutes in economically developed countries; while, the study has not had much attention in Africa despite the dramatic soar of cancer risks in the continent."
2022,Breast Cancer Detection and Classification Empowered With Transfer Learning,"Cancer is a major public health issue in the modern world. Breast cancer is a type of cancer that starts in the breast and spreads to other parts of the body. One of the most common types of cancer that kill women is breast cancer. When cells become uncontrollably large, cancer develops. There are various types of breast cancer. The proposed model discussed benign and malignant breast cancer. In computer-aided diagnosis systems, the identification and classification of breast cancer using histopathology and ultrasound images are critical steps. Investigators have demonstrated the ability to automate the initial level identification and classification of the tumor throughout the last few decades. Breast cancer can be detected early, allowing patients to obtain proper therapy and thereby increase their chances of survival. Deep learning (DL), machine learning (ML), and transfer learning (TL) techniques are used to solve many medical issues. There are several scientific studies in the previous literature on the categorization and identification of cancer tumors using various types of models but with some limitations. However, research is hampered by the lack of a dataset. The proposed methodology is created to help with the automatic identification and diagnosis of breast cancer. Our main contribution is that the proposed model used the transfer learning technique on three datasets, A, B, C, and A2, A2 is the dataset A with two classes. In this study, ultrasound images and histopathology images are used. The model used in this work is a customized CNN-AlexNet, which was trained according to the requirements of the datasets. This is also one of the contributions of this work. The results have shown that the proposed system empowered with transfer learning achieved the highest accuracy than the existing models on datasets A, B, C, and A2."
2022,Breast Cancer Detection in Mammography Images Using Deep Convolutional Neural Networks and Fuzzy Ensemble Modeling Techniques,"Breast cancer has evolved as the most lethal illness impacting women all over the globe. Breast cancer may be detected early, which reduces mortality and increases the chances of a full recovery. Researchers all around the world are working on breast cancer screening tools based on medical imaging. Deep learning approaches have piqued the attention of many in the medical imaging field due to their rapid growth. In this research, mammography pictures were utilized to detect breast cancer. We have used four mammography imaging datasets with a similar number of 1145 normal, benign, and malignant pictures using various deep CNN (Inception V4, ResNet-164, VGG-11, and DenseNet121) models as base classifiers. The proposed technique employs an ensemble approach in which the Gompertz function is used to build fuzzy rankings of the base classification techniques, and the decision scores of the base models are adaptively combined to construct final predictions. The proposed fuzzy ensemble techniques outperform each individual transfer learning methodology as well as multiple advanced ensemble strategies (Weighted Average, Sugeno Integral) with reference to prediction and accuracy. The suggested Inception V4 ensemble model with fuzzy rank based Gompertz function has a 99.32% accuracy rate. We believe that the suggested approach will be of tremendous value to healthcare practitioners in identifying breast cancer patients early on, perhaps leading to an immediate diagnosis."
2023,A Transfer Learning-Based Deep Learning Model for Automated Breast Cancer Identification in Mammograms,"Abstract: Breast cancer is a severe health issue that affects women all over the world, underscoring the need for reliable and effective screening techniques. The early detection, diagnosis, and treatment of breast cancer are made possible by computer-aided diagnostic (CAD) systems that rely on mammograms. This study introduces a unique deep-learning model that uses transfer learning to identify and categorize breast cancer automatically. Deep convolutional neural networks have been shown in several recent studies to diagnose breast cancer in mammograms with performance comparable to or even outperforming that of human experts. In order to extract features from the dataset from the Mammographic Image Analysis Society (MIAS), the proposed model uses pre-trained convolutional neural network (CNN) architectures like ResNet50 and Visual Geometry Group networks (VGG)-16. This novel deep-learning model holds significant potential for enhancing the efficiency and accuracy of breast cancer detection and classification."
2023,Automatic BI-RADS Classification of Breast Magnetic Resonance Medical Records Using Transformer-Based Models for Brazilian Portuguese,"This chapter aims to present a classification model for categorizing textual clinical records of breast magnetic resonance imaging, based on lexical, syntactic and semantic analysis of clinical reports according to the Breast Imaging-Reporting and Data System (BI-RADS) classification, using Deep Learning and Natural Language Processing (NLP). The model was developed from transfer learning based on the pre-trained BERTimbau model, BERT model (Bidirectional Encoder Representations from Transformers) trained in Brazilian Portuguese. The dataset is composed of medical reports in Brazilian Portuguese classified into six categories: Inconclusive; Normal or Negative; Certainly Benign Findings; Probably Benign Findings; Suspicious Findings; High Risk of Cancer; Previously Known Malignant Injury. The following models were implemented and compared: Random Forest, SVM, Naïve Bayes, BERTimbau with and without finetuning. The BERTimbau model presented better results, with better performance after finetuning."
2023,"Classification of Breast Masses Using Ultrasound Images by Approaching GAN, Transfer Learning and Deep Learning Techniques","Breast cancer is a common cause of death among women worldwide. Ultrasonic imaging is a valuable diagnostic tool in breast cancer detection. However, the accuracy of computer-aided diagnosis systems for breast cancer classification is limited due to the lack of well-annotated datasets. This study proposes a deep learning-based framework for breast mass classification using ultrasound images, which incorporates a novel data augmentation technique, Generative Adversarial Network (GAN), and Transfer Learning (TL). Automating early tumor identification and classification in breast cancer diagnosis can save lives by improving the accuracy of diagnoses and reducing the need for invasive procedures. However, the limited availability of well-annotated datasets for ultrasound images of breast cancer has hampered the development of accurate computer-aided diagnosis systems. The accuracy of breast mass classification using ultrasound images is limited due to the lack of well-annotated datasets. Conventional data augmentation techniques have limitations in applications with strict guidelines, such as medical datasets. Therefore, there is a need to develop a novel data augmentation technique to improve the accuracy of breast mass classification using ultrasound images. The proposed framework can be extended to other medical imaging applications, where the availability of well-annotated datasets is limited. The GAN-based data augmentation technique and TL-based feature extraction can be used to improve the accuracy of classification models in other medical imaging applications. Additionally, the proposed framework can be used to develop accurate computer-aided diagnosis systems for breast cancer detection in clinical settings. The proposed framework incorporates a deep learning-based approach for breast mass classification using ultrasound images. The framework includes a GAN-based data augmentation technique and TL for feature extraction. The dataset used for training and testing the model is the Breast Ultrasound Images (BUSI) dataset, which includes 1311 images with normal and abnormal breast masses. The proposed framework achieved an accuracy of 99.6% for breast mass classification using ultrasound images, which outperformed existing methods. The GAN-based data augmentation technique and TL-based feature extraction improved the accuracy of the classification model. The results suggest that deep learning algorithms can be effectively applied for breast ultrasound categorization. The proposed framework presents a novel approach for breast mass classification using ultrasound images, which incorporates a GAN-based data augmentation technique and TL-based feature extraction. The results demonstrate that the proposed framework outperforms existing methods and achieves high accuracy in breast mass classification using ultrasound images. This framework can be useful for developing accurate computer-aided diagnosis systems for breast cancer detection."
2020,Multi-View Attention-based Late Fusion (MVALF) CADx system for breast cancer using deep learning,"Breast cancer is a leading cause of death among women. Early detection can significantly reduce the mortality rate among women and improve their prognosis. Mammography is the first line procedure for early diagnosis. In the early era, conventional Computer-Aided Diagnosis (CADx) systems for breast lesion diagnosis were based on just single view information. The last decade evidence the use of two views mammogram: Medio-Lateral Oblique (MLO) and Cranio-Caudal (CC) view for the CADx systems. Most recent studies show the effectiveness of four views of mammogram to train CADx system with feature fusion strategy for classification task. In this paper, we proposed an end-to-end Multi-View Attention-based Late Fusion (MVALF) CADx system that fused the obtained predictions of four view models, which is trained for each view separately. These separate models have different predictive ability for each class. The appropriate fusion of multi-view models can achieve better diagnosis performance. So, it is necessary to assign the proper weights to the multi-view classification models. To resolve this issue, attention-based weighting mechanism is adopted to assign the proper weights to trained models for fusion strategy. The proposed methodology is used for the classification of mammogram into normal, mass, calcification, malignant masses and benign masses. The publicly available datasets CBIS-DDSM and mini-MIAS are used for the experimentation. The results show that our proposed system achieved 0.996 AUC for normal vs. abnormal, 0.922 for mass vs. calcification and 0.896 for malignant vs. benign masses. Superior results are seen for the classification of malignant vs benign masses with our proposed approach, which is higher than the results using single view, two views and four views early fusion-based systems. The overall results of each level show the potential of multi-view late fusion with transfer learning in the diagnosis of breast cancer."
2022,Breast Tumor Classification in Digital Tomosynthesis Based on Deep Learning Radiomics,"Breast cancer is the most frequently diagnosed cancer in women globally. Early and accurate detection and classification of breast tumors are critical in improving treatment strategies and increasing the patient survival rate. Digital breast tomosynthesis (DBT) is an advanced form of mammography that aids better in the early detection and diagnosis of breast disease. This paper proposes a breast tumor classification method based on analyzing and evaluating the performance of various of the most innovative deep learning classification models in cooperation with a support vector machine (SVM) classifier for a DBT dataset. Specifically, we study the ability to use transfer learning from non-medical images to classify tumors in unseen DBT medical images. In addition, we utilize the fine-tuning technique to improve classification accuracy."
2023,Breast cancer diagnosis through knowledge distillation of Swin transformer-based teacher–student models,"Abstract: Breast cancer is a significant global health concern, emphasizing the crucial need for a timely and accurate diagnosis to enhance survival rates. Traditional diagnostic methods rely on pathologists analyzing whole-slide images (WSIs) to identify and diagnose malignancies. However, this task is complex, demanding specialized expertise and imposing a substantial workload on pathologists. Additionally, existing deep learning models, commonly employed for classifying histopathology images, often need enhancements to ensure their suitability for real-time deployment on WSI, especially when trained for small regions of interest (ROIs). This article introduces two Swin transformer-based architectures: the teacher model, characterized by its moderate size, and the lightweight student model. Both models are trained using a publicly available dataset of breast cancer histopathology images, focusing on ROIs with varying magnification factors. Transfer learning is applied to train the teacher model, and knowledge distillation (KD) transfers its capabilities to the student model. To enhance validation accuracy and minimize the total loss in KD, we employ the state–action–reward–state–action (SARSA) reinforcement learning algorithm. The algorithm dynamically computes temperature and a weighting factor throughout the KD process to achieve high accuracy within a considerably shorter training timeframe. Additionally, the student model is deployed to analyze malignancies in WSI. Despite the student model being only one-third the size and flops of the teacher model, it achieves an impressive accuracy of 98.71%, slightly below the teacher’s accuracy of 98.91%. Experimental results demonstrate that the student model can process WSIs at a throughput of 1.67 samples s"
2023,Breast Cancer Using Deep Learning and Histopathology Images,"Abstract: Breast cancer is among one of the most common cancers in the world. Early detection in this area can be crucial and help the patients to start the medication. One way to detect the breast cancer is using histopathology images. In recent years deep learning methods are among the methods that have shown high accuracy in detection cancerous tumors in images. In this work different deep learning methods such as Xception, MobileVNet, VGG16 and VGG19 have been used and the results are compared. Two popular datasets in breast cancer have been used. Transfer learning is used for pre-training the structures. In addition, different preprocessing methods is introduced and used to increase the number of images in the dataset."
2023,Breast Cancer Detection Using Image Processing and Machine Learning,"Different breast cancer detection systems have been developed to help clinicians analyze screening mammograms. Breast cancer has been increasing gradually so scientists work to develop new methods to reduce the risks of this life-threatening disease. Convolutional Neural Networks (CNNs) have shown much promise In the field of medical imaging because of recent developments in deep learning. However, CNN’s based methods have been restricted due to the small size of the few public breast cancer datasets. This research has developed a new framework and introduced it to detect breast cancer. This framework utilizes Convolutional Neural Networks (CNNs) and image processing to achieve its goal because CNNs have been an important success in image recognition, reaching human performance. An efficient and fast CNN pre-trained object detector called RetinaNet has been used in this research. RetinaNet is an uncomplicated one-stage object detector. A two-stage transfer learning has been used with the selected detector to improve the performance. RetinaNet model is initially trained with a general-purpose dataset called COCO dataset. The transfer learning is then used to apply the RetinaNet model to another dataset of mammograms called the CBIS-DDSM dataset. Finally, the second transfer learning is used to test the RetinaNet model onto a small dataset of mammograms called the INbreast dataset. The results of the proposed two-stage transfer learning (RetinaNet → CBIS-DDSM → INbreast) are better than the other state-of-the-art methods on the public INbreast dataset. Furthermore, the True Positive Rate (TPR) is 0.99 ± 0.02 at 1.67 False Positives per Image (FPPI), which is better than the one-stage transfer learning with a TPR of 0.94 ± 0.02 at 1.67 FPPI."
2021,Chatbot for Health Care and Oncology Applications Using Artificial Intelligence and Machine Learning: Systematic Review,"Background: Chatbot is a timely topic applied in various fields, including medicine and health care, for human-like knowledge transfer and communication. Machine learning, a subset of artificial intelligence, has been proven particularly applicable in health care, with the ability for complex dialog management and conversational flexibility. Objective: This review article aims to report on the recent advances and current trends in chatbot technology in medicine. A brief historical overview, along with the developmental progress and design characteristics, is first introduced. The focus will be on cancer therapy, with in-depth discussions and examples of diagnosis, treatment, monitoring, patient support, workflow efficiency, and health promotion. In addition, this paper will explore the limitations and areas of concern, highlighting ethical, moral, security, technical, and regulatory standards and evaluation issues to explain the hesitancy in implementation. Methods: A search of the literature published in the past 20 years was conducted using the IEEE Xplore, PubMed, Web of Science, Scopus, and OVID databases. The screening of chatbots was guided by the open-access Botlist directory for health care components and further divided according to the following criteria: diagnosis, treatment, monitoring, support, workflow, and health promotion. Results: Even after addressing these issues and establishing the safety or efficacy of chatbots, human elements in health care will not be replaceable. Therefore, chatbots have the potential to be integrated into clinical practice by working alongside health practitioners to reduce costs, refine workflow efficiencies, and improve patient outcomes. Other applications in pandemic support, global health, and education are yet to be fully explored. Conclusions: Further research and interdisciplinary collaboration could advance this technology to dramatically improve the quality of care for patients, rebalance the workload for clinicians, and revolutionize the practice of medicine."
2023,"Breast Cancer Mass Classification Using Machine Learning, Binary-Coded Genetic Algorithms and an Ensemble of Deep Transfer Learning","Abstract: The diagnosis of breast cancer (BC) as early as possible is crucial for increasing the survival rate. Mammography enables finding the breast tissue changes years before they could develop into cancer symptoms. In this study, machine learning methods for BC mass pathology classification have been investigated using the radiologists’ mass annotations on the screen-film mammograms of the Breast Cancer Digital Repository (BCDR). The performances of precomputed features in the BCDR and discrete wavelet transform followed by Radon transform have been investigated by using four sequential feature selections and three genetic algorithms. Feature fusion from craniocaudal and mediolateral oblique views was shown to increase the performance of the classifier. Mass classification has been implemented by deep transfer learning (DTL) using the weights of ResNet50, NASNetLarge and Xception networks. An ensemble of DTL (EDTL) was shown to have higher classification performance than the DTL models. The proposed EDTL has area under the receiver operating curve (AUC) scores of 0.8843 and 0.9089 for mass classification on the region of interest (ROI) and ROI union datasets, respectively. The proposed EDTL has the highest BC mass classification AUC score on the BCDR to date and may be useful for other datasets."
2022,A New Hybrid Breast Cancer Diagnosis Model Using Deep Learning Model and ReliefF,"Breast cancer is a dangerous type of cancer usually found in women and is a significant research topic in medical science. In patients who are diagnosed and not treated early, cancer spreads to other organs, making treatment difficult. In breast cancer diagnosis, the accuracy of the pathological diagnosis is of great importance to shorten the decision-making process, minimize unnoticed cancer cells and obtain a faster diagnosis. However, the similarity of images in histopathological breast cancer image analysis is a sensitive and difficult process that requires high competence for field experts. In recent years, researchers have been seeking solutions to this process using machine learning and deep learning methods, which have contributed to significant developments in medical diagnosis and image analysis. In this study, a hybrid DCNN + ReliefF is proposed for the classification of breast cancer histopathological images, utilizing the activation properties of pre-trained deep convolutional neural network (DCNN) models, and the dimension-reduction-based ReliefF feature selective algorithm. The model is based on a fine-tuned transfer-learning technique for fully connected layers. In addition, the models were compared to the k-nearest neighbor (kNN), naive Bayes (NB), and support vector machine (SVM) machine learning approaches. The performance of each feature extractor and classifier combination was analyzed using the sensitivity, precision, F1-Score, and ROC curves. The proposed hybrid model was trained separately at different magnifications using the BreakHis dataset. The results show that the model is an efficient classification model with up to 97.8% (AUC) accuracy."
2020,Classification of Breast Cancer from Digital Mammography Using Deep Learning,"Breast cancer is the most frequent in females. Mammography has proven to be the most effective method for the early detection of this type of cancer. Mammographic images are sometimes difficult to understand, due to the nature of the anomalies, the low contrast image and the composition of the mammary tissues, as well as various technological factors such as spatial resolution of the image or noise. Computer-aided diagnostic systems have been developed to increase the accuracy of mammographic examinations and be used by physicians as a second opinion in obtaining the final diagnosis, and thus reduce human errors. Convolutional neural networks are a current trend in computer vision tasks, due to the great performance they have achieved. The present investigation was based on this type of networks to classify into three classes, normal, benign and malignant tumour. Due to the fact that the miniMIAS database used has a low number of images, the transfer learning technique was applied to the Inception v3 pre-trained network. Two convolutional neural network architectures were implemented, obtaining in the architecture with three classes, 86.05% accuracy. On the other hand, in the architecture with two neural networks in series, an accuracy of 88.2% was reached."
2023,Deep Learning in Automating Breast Cancer Diagnosis from Microscopy Images,"Context: Breast cancer is one of the most common cancers in women. With early diagnosis, some breast cancers are highly curable. However, the concordance rate of breast cancer diagnosis from histology slides by pathologists is unacceptably low. Classifying normal versus tumor breast tissues from microscopy images of breast histology is an ideal case to use for deep learning and could help to more reproducibly diagnose breast cancer. Since data preprocessing and hyperparameter configurations have impacts on breast cancer classification accuracies of deep learning models, training a deep learning classifier with appropriate data preprocessing approaches and optimized hyperparameter configurations could improve breast cancer classification accuracy. Methods and Material: Using 12 combinations of deep learning model architectures (i.e., including 5 non-specialized and 7 digital pathology-specialized model architectures), image data preprocessing, and hyperparameter configurations, the validation accuracy of tumor versus normal classification were calculated using the Results: The DenseNet201, a non-specialized model architecture, with transfer learning approach achieved 98.61% validation accuracy compared to only 64.00% for the digital pathology-specialized model architecture. Conclusions: The combination of image data preprocessing approaches and hyperparameter configurations have a profound impact on the performance of deep neural networks for image classification. To identify a well-performing deep neural network to classify tumor versus normal breast histology, researchers should not only focus on developing new models specifically for digital pathology, since hyperparameter tuning for existing deep neural networks in the computer vision field could also achieve a high (often better) prediction accuracy."
2022,Skin Cancer Detection Using Deep Learning and Artificial Intelligence: Incorporated model of deep features fusion,"Among the most frequent forms of cancer, skin cancer accounts for hundreds of thousands of fatalities annually throughout the globe. It shows up as excessive cell proliferation on the skin. The likelihood of a successful recovery is greatly enhanced by an early diagnosis. More than that, it might reduce the need for or the frequency of chemical, radiological, or surgical treatments. As a result, savings on healthcare expenses will be possible. Dermoscopy, which examines the size, form, and color features of skin lesions, is the first step in the process of detecting skin cancer and is followed by sample and lab testing to confirm any suspicious lesions. Deep learning AI has allowed for significant progress in image-based diagnostics in recent years. Deep neural networks known as convolutional neural networks (CNNs or ConvNets) are essentially an extended form of multi-layer perceptrons. In visual imaging challenges, CNNs have shown the best accuracy. The purpose of this research is to create a CNN model for the early identification of skin cancer. The backend of the CNN classification model will be built using Keras and Tensorflow in Python. Different network topologies, such as Convolutional layers, Dropout layers, Pooling layers, and Dense layers, are explored and tried out throughout the model's development and validation phases. Transfer Learning methods will also be included in the model to facilitate early convergence. The dataset gathered from the ISIC challenge archives will be used to both tests and train the model."
2020,A New Deep Learning Model Selection Method for Colorectal Cancer Classification,"<p>Deep learning is one of the most commonly used techniques in computer-aided diagnosis systems. Their exploitation for histopathological image analysis is important because of the complex morphology of whole slide images. However, the main limitation of these methods is the restricted number of available medical images, which can lead to an overfitting problem. Many studies have suggested the use of static ensemble learning methods to address this issue. This article aims to propose a new dynamic ensemble deep learning method. First, it generates a set of models based on the transfer learning strategy from deep neural networks. Then, the relevant subset of models is selected by the particle swarm optimization algorithm and combined by voting or averaging methods. The proposed approach was tested on a histopathological dataset for colorectal cancer classification, based on seven types of CNNs. The method has achieved accurate results (94.52%) by the Resnet121 model and the voting strategy, which provides important insights into the efficiency of dynamic ensembling in deep learning.</p>"
2022,Deep-learning and transfer learning identify new breast cancer survival subtypes from single-cell imaging data,"STATEMENT OF TRANSLATIONAL RELEVANCE: Our findings from a breast cancer population cohort demonstrate the clinical utility of using the single-cell level imaging mass cytometry (IMC) data as a new type of patient prognosis prediction marker. Not only did the prognosis prediction achieve high accuracy with a Concordance index score greater than 0.8, it also enabled the discovery of seven survival subtypes that are more distinguishable than the molecular subtypes. These new subtypes present distinct profiles of epithelial, immune, fibroblast cells, and their interactions. Most importantly, this study identified and validated atypical subpopulations of TNBC patients with moderate prognosis (GATA3 over-expression) and Luminal A patients with poor prognosis (KRT6 and ACTA2 over-expression and CDH1 under-expression), using multiple large breast cancer cohorts."
2022,Machine Learning and Deep Learning Algorithms for Skin Cancer Classification from Dermoscopic Images,"We carry out a critical assessment of machine learning and deep learning models for the classification of skin tumors. Machine learning (ML) algorithms tested in this work include logistic regression, linear discriminant analysis, k-nearest neighbors classifier, decision tree classifier and Gaussian naive Bayes, while deep learning (DL) models employed are either based on a custom Convolutional Neural Network model, or leverage transfer learning via the use of pre-trained models (VGG16, Xception and ResNet50). We find that DL models, with accuracies up to 0.88, all outperform ML models. ML models exhibit accuracies below 0.72, which can be increased to up to 0.75 with ensemble learning. To further assess the performance of DL models, we test them on a larger and more imbalanced dataset. Metrics, such as the F-score and accuracy, indicate that, after fine-tuning, pre-trained models perform extremely well for skin tumor classification. This is most notably the case for VGG16, which exhibits an F-score of 0.88 and an accuracy of 0.88 on the smaller database, and metrics of 0.70 and 0.88, respectively, on the larger database."
2022,Hybrid Model for Breast Cancer Diagnosis on Mammograms Using Transfer Learning,"Abstract: Breast cancer is one of the most common types of cancer among women all over the world, which leads to the death of many women every year due to misdiagnosis and late treatment. Therefore, in this research, a new deep learning model was developed based on Python and using the mini-MIAS dataset. Initially image contrast optimization operations and segmentation were performed to enhance image and extract the region of interest (breast region) in order to improve the performance of the model and increase the accuracy of diagnosis and then extract the features using the transfer learning technique and based on a set of pre-trained networks. A comparison was made between a set of pre-trained convolutional network architectures (VGG16, ResNet50, MobileNetV2, InceptionV3) where the VGG16 network gave the best performance in the phase of extracting features and then building the final hybrid model by merging the VGG16 network with the random forest classifier. Our model achieved 94.25% average accuracy and the Area under curve (AUC) is 98% for all three classes, in addition to reducing the time required to build the system."
2022,Detection of Breast Cancer Images Based on Transfer and Deep Learning Models,"Abstract: Using a technology known as deep learning, which involves classifying photos based on the data they contain, it is possible to detect images, such as tumors and other signs. Because of the scarcity of pathologists and the growing number of patients with breast cancer, the manual numeration of biopsy echantillons must be mechanized (CS). To rectify the histopathological images of malignant tissue, preliminary study is required, which can be done utilizing BreaKHis' free database of data. An approach based on isolated image fragments is proposed, with the final categorization determined by an interconnected network of neurons (CNN) and a final combination of these pieces. Because of its unique architecture, capacity to recognize speech, identify objects, and analyze signals, as well as the popularity of neural language processing, the CNN is attracting increasing interest from industry and researchers. The employment of transfer learning methods is a problem with tiny collections of medical data. To improve the classification of defamatory and obscene photos, this article recommends integrating the impacts of many resolutions. In order to better depict the entering image's texture, many essential phases in CNN development are also used. Maintain a safe distance from the model's customization. Traditional CNN development may become more complex and expensive as a result. The simulation results achieved by running CNN in MATLAB outperform other artificial intelligence (AI) models recently published that used hand-crafted texture descriptors. With this in mind, we looked at all of CNN's possible combinations and discovered a technique to boost the execution rate by a little amount."
2021,Deep Multi-View Breast Cancer Detection: A Multi-View Concatenated Infrared Thermal Images Based Breast Cancer Detection System Using Deep Transfer Learning,"This paper simply presents a fully automated breast cancer detection system as “Deep Multi-view Breast cancer Detection” based on deep transfer learning. The deep transfer learning model i.e., Visual Geometry Group 16 (VGG 16) is used in this approach for the correct classification of Breast thermal images into either normal or abnormal. This VGG 16 model is trained with the help of Static as well as Dynamic breast thermal images dataset consisting of multi-view, single view breast thermal images. These Multi-view breast thermal images are generated in this approach by concatenating the conventional left, frontal and right view breast thermal images taken from the Database for Mastology Research with Infrared image for the first time in order to generate a more informative and complete thermal temperature map of breast for enhancing the accuracy of the overall system. For the sake of genuine comparison, three other popular deep transfer learning models like Residual Network 50 (ResNet50V2), InceptionV3 network and Visual Geometry Group 19 (VGG 19) are also trained with the same augmented dataset consisting of multi-view as well as single view breast thermal images. The VGG 16 based Deep Multi-view Breast cancer Detect system delivers the best training, validation as well as testing accuracies as compared to their other deep transfer learning models. The VGG 16 achieves an encouraging testing accuracy of 99% on the Dynamic breast thermal images testing dataset utilizing the multi-view breast thermal images as input. Whereas the testing accuracies of 95%, 94% and 89% are achieved by the VGG 19, ResNet50V2, InceptionV3 models respectively over the Dynamic breast thermal images testing dataset utilizing the same multi-view breast thermal images as input."
2017,Classification of breast cancer histology images using Convolutional Neural Networks,"Breast cancer is one of the main causes of cancer death worldwide. The diagnosis of biopsy tissue with hematoxylin and eosin stained images is non-trivial and specialists often disagree on the final diagnosis. Computer-aided Diagnosis systems contribute to reduce the cost and increase the efficiency of this process. Conventional classification approaches rely on feature extraction methods designed for a specific problem based on field-knowledge. To overcome the many difficulties of the feature-based approaches, deep learning methods are becoming important alternatives. A method for the classification of hematoxylin and eosin stained breast biopsy images using Convolutional Neural Networks (CNNs) is proposed. Images are classified in four classes, normal tissue, benign lesion, in situ carcinoma and invasive carcinoma, and in two classes, carcinoma and non-carcinoma. The architecture of the network is designed to retrieve information at different scales, including both nuclei and overall tissue organization. This design allows the extension of the proposed system to whole-slide histology images. The features extracted by the CNN are also used for training a Support Vector Machine classifier. Accuracies of 77.8% for four class and 83.3% for carcinoma/non-carcinoma are achieved. The sensitivity of our method for cancer cases is 95.6%."
2016,Breast cancer histopathological image classification using Convolutional Neural Networks,"The performance of most conventional classification systems relies on appropriate data representation and much of the efforts are dedicated to feature engineering, a difficult and time-consuming process that uses prior expert domain knowledge of the data to create useful features. On the other hand, deep learning can extract and organize the discriminative information from the data, not requiring the design of feature extractors by a domain expert. Convolutional Neural Networks (CNNs) are a particular type of deep, feedforward network that have gained attention from research community and industry, achieving empirical successes in tasks such as speech recognition, signal processing, object recognition, natural language processing and transfer learning. In this paper, we conduct some preliminary experiments using the deep learning approach to classify breast cancer histopathological images from BreaKHis, a publicly dataset available at http://web.inf.ufpr.br/vri/breast-cancer-database. We propose a method based on the extraction of image patches for training the CNN and the combination of these patches for final classification. This method aims to allow using the high-resolution histopathological images from BreaKHis as input to existing CNN, avoiding adaptations of the model that can lead to a more complex and computationally costly architecture. The CNN performance is better when compared to previously reported results obtained by other machine learning models trained with hand-crafted textural descriptors. Finally, we also investigate the combination of different CNNs using simple fusion rules, achieving some improvement in recognition rates."
2014,Automatic detection of invasive ductal carcinoma in whole slide images with convolutional neural networks,"This paper presents a deep learning approach for automatic detection and visual analysis of invasive ductal carcinoma (IDC) tissue regions in whole slide images (WSI) of breast cancer (BCa). Deep learning approaches are learn-from-data methods involving computational modeling of the learning process. This approach is similar to how human brain works using different interpretation levels or layers of most representative and useful features resulting into a hierarchical learned representation. These methods have been shown to outpace traditional approaches of most challenging problems in several areas such as speech recognition and object detection. Invasive breast cancer detection is a time consuming and challenging task primarily because it involves a pathologist scanning large swathes of benign regions to ultimately identify the areas of malignancy. Precise delineation of IDC in WSI is crucial to the subsequent estimation of grading tumor aggressiveness and predicting patient outcome. DL approaches are particularly adept at handling these types of problems, especially if a large number of samples are available for training, which would also ensure the generalizability of the learned features and classifier. The DL framework in this paper extends a number of convolutional neural networks (CNN) for visual semantic analysis of tumor regions for diagnosis support. The CNN is trained over a large amount of image patches (tissue regions) from WSI to learn a hierarchical part-based representation. The method was evaluated over a WSI dataset from 162 patients diagnosed with IDC. 113 slides were selected for training and 49 slides were held out for independent testing. Ground truth for quantitative evaluation was provided via expert delineation of the region of cancer by an expert pathologist on the digitized slides. The experimental evaluation was designed to measure classifier accuracy in detecting IDC tissue regions in WSI. Our method yielded the best quantitative results for automatic detection of IDC regions in WSI in terms of F-measure and balanced accuracy (71.80%, 84.23%), in comparison with an approach using handcrafted image features (color, texture and edges, nuclear textural and architecture), and a machine learning classifier for invasive tumor classification using a Random Forest. The best performing handcrafted features were fuzzy color histogram (67.53%, 78.74%) and RGB histogram (66.64%, 77.24%). Our results also suggest that at least some of the tissue classification mistakes (false positives and false negatives) were less due to any fundamental problems associated with the approach, than the inherent limitations in obtaining a very highly granular annotation of the diseased area of interest by an expert pathologist."
2016,AggNet: Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images,"The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions. 1) Can deep CNN be trained with data collected from crowdsourcing? 2) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)? 3) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration."
2019,Breast cancer detection using deep convolutional neural networks and support vector machines,"It is important to detect breast cancer as early as possible. In this manuscript, a new methodology for classifying breast cancer using deep learning and some segmentation techniques are introduced. A new computer aided detection (CAD) system is proposed for classifying benign and malignant mass tumors in breast mammography images. In this CAD system, two segmentation approaches are used. The first approach involves determining the region of interest (ROI) manually, while the second approach uses the technique of threshold and region based. The deep convolutional neural network (DCNN) is used for feature extraction. A well-known DCNN architecture named AlexNet is used and is fine-tuned to classify two classes instead of 1,000 classes. The last fully connected (fc) layer is connected to the support vector machine (SVM) classifier to obtain better accuracy. The results are obtained using the following publicly available datasets (1) the digital database for screening mammography (DDSM); and (2) the Curated Breast Imaging Subset of DDSM (CBIS-DDSM). Training on a large number of data gives high accuracy rate. Nevertheless, the biomedical datasets contain a relatively small number of samples due to limited patient volume. Accordingly, data augmentation is a method for increasing the size of the input data by generating new data from the original input data. There are many forms for the data augmentation; the one used here is the rotation. The accuracy of the new-trained DCNN architecture is 71.01% when cropping the ROI manually from the mammogram. The highest area under the curve (AUC) achieved was 0.88 (88%) for the samples obtained from both segmentation techniques. Moreover, when using the samples obtained from the CBIS-DDSM, the accuracy of the DCNN is increased to 73.6%. Consequently, the SVM accuracy becomes 87.2% with an AUC equaling to 0.94 (94%). This is the highest AUC value compared to previous work using the same conditions."
2016,Deep learning for magnification independent breast cancer histopathology image classification,"Microscopic analysis of breast tissues is necessary for a definitive diagnosis of breast cancer which is the most common cancer among women. Pathology examination requires time consuming scanning through tissue images under different magnification levels to find clinical assessment clues to produce correct diagnoses. Advances in digital imaging techniques offers assessment of pathology images using computer vision and machine learning methods which could automate some of the tasks in the diagnostic pathology workflow. Such automation could be beneficial to obtain fast and precise quantification, reduce observer variability, and increase objectivity. In this work, we propose to classify breast cancer histopathology images independent of their magnifications using convolutional neural networks (CNNs). We propose two different architectures; single task CNN is used to predict malignancy and multi-task CNN is used to predict both malignancy and image magnification level simultaneously. Evaluations and comparisons with previous results are carried out on BreaKHis dataset. Experimental results show that our magnification independent CNN approach improved the performance of magnification specific model. Our results in this limited set of training data are comparable with previous state-of-the-art results obtained by hand-crafted features. However, unlike previous methods, our approach has potential to directly benefit from additional training data, and such additional data could be captured with same or different magnification levels than previous data."
2017,A deep feature fusion methodology for breast cancer diagnosis demonstrated on three imaging modality datasets,"Background: Deep learning methods for radiomics/computer‐aided diagnosis (CADx) are often prohibited by small datasets, long computation time, and the need for extensive image preprocessing. Aims: We aim to develop a breast CADx methodology that addresses the aforementioned issues by exploiting the efficiency of pre‐trained convolutional neural networks (CNNs) and using pre‐existing handcrafted CADx features. Materials & Methods: We present a methodology that extracts and pools low‐ to mid‐level features using a pretrained CNN and fuses them with handcrafted radiomic features computed using conventional CADx methods. Our methodology is tested on three different clinical imaging modalities (dynamic contrast enhanced‐MRI [690 cases], full‐field digital mammography [245 cases], and ultrasound [1125 cases]). Results: From ROC analysis, our fusion‐based method demonstrates, on all three imaging modalities, statistically significant improvements in terms of AUC as compared to previous breast cancer CADx methods in the task of distinguishing between malignant and benign lesions. (DCE‐MRI [AUC = 0.89 (se = 0.01)], FFDM [AUC = 0.86 (se = 0.01)], and ultrasound [AUC = 0.90 (se = 0.01)]). Discussion/Conclusion: We proposed a novel breast CADx methodology that can be used to more effectively characterize breast lesions in comparison to existing methods. Furthermore, our proposed methodology is computationally efficient and circumvents the need for image preprocessing."
2019,Cancer Diagnosis Using Deep Learning: A Bibliographic Review,"In this paper, we first describe the basics of the field of cancer diagnosis, which includes steps of cancer diagnosis followed by the typical classification methods used by doctors, providing a historical idea of cancer classification techniques to the readers. These methods include Asymmetry, Border, Color and Diameter (ABCD) method, seven-point detection method, Menzies method, and pattern analysis. They are used regularly by doctors for cancer diagnosis, although they are not considered very efficient for obtaining better performance. Moreover, considering all types of audience, the basic evaluation criteria are also discussed. The criteria include the receiver operating characteristic curve (ROC curve), Area under the ROC curve (AUC), F1 score, accuracy, specificity, sensitivity, precision, dice-coefficient, average accuracy, and Jaccard index. Previously used methods are considered inefficient, asking for better and smarter methods for cancer diagnosis. Artificial intelligence and cancer diagnosis are gaining attention as a way to define better diagnostic tools. In particular, deep neural networks can be successfully used for intelligent image analysis. The basic framework of how this machine learning works on medical imaging is provided in this study, i.e., pre-processing, image segmentation and post-processing. The second part of this manuscript describes the different deep learning techniques, such as convolutional neural networks (CNNs), generative adversarial models (GANs), deep autoencoders (DANs), restricted Boltzmann’s machine (RBM), stacked autoencoders (SAE), convolutional autoencoders (CAE), recurrent neural networks (RNNs), long short-term memory (LTSM), multi-scale convolutional neural network (M-CNN), multi-instance learning convolutional neural network (MIL-CNN). For each technique, we provide Python codes, to allow interested readers to experiment with the cited algorithms on their own diagnostic problems. The third part of this manuscript compiles the successfully applied deep learning models for different types of cancers. Considering the length of the manuscript, we restrict ourselves to the discussion of breast cancer, lung cancer, brain cancer, and skin cancer. The purpose of this bibliographic review is to provide researchers opting to work in implementing deep learning and artificial neural networks for cancer diagnosis a knowledge from scratch of the state-of-the-art achievements."
2019,Lymph Node Metastasis Prediction from Primary Breast Cancer US Images Using Deep Learning.,"Background Deep learning (DL) algorithms are gaining extensive attention for their excellent performance in image recognition tasks. DL models can automatically make a quantitative assessment of complex medical image characteristics and achieve increased accuracy in diagnosis with higher efficiency. Purpose To determine the feasibility of using a DL approach to predict clinically negative axillary lymph node metastasis from US images in patients with primary breast cancer. Materials and Methods A data set of US images in patients with primary breast cancer with clinically negative axillary lymph nodes from Tongji Hospital (974 imaging studies from 2016 to 2018, 756 patients) and an independent test set from Hubei Cancer Hospital (81 imaging studies from 2018 to 2019, 78 patients) were collected. Axillary lymph node status was confirmed with pathologic examination. Three different convolutional neural networks (CNNs) of Inception V3, Inception-ResNet V2, and ResNet-101 architectures were trained on 90% of the Tongji Hospital data set and tested on the remaining 10%, as well as on the independent test set. The performance of the models was compared with that of five radiologists. The models' performance was analyzed in terms of accuracy, sensitivity, specificity, receiver operating characteristic curves, areas under the receiver operating characteristic curve (AUCs), and heat maps. Results The best-performing CNN model, Inception V3, achieved an AUC of 0.89 (95% confidence interval [CI]: 0.83, 0.95) in the prediction of the final clinical diagnosis of axillary lymph node metastasis in the independent test set. The model achieved 85% sensitivity (35 of 41 images; 95% CI: 70%, 94%) and 73% specificity (29 of 40 images; 95% CI: 56%, 85%), and the radiologists achieved 73% sensitivity (30 of 41 images; 95% CI: 57%, 85%; P = .17) and 63% specificity (25 of 40 images; 95% CI: 46%, 77%; P = .34). Conclusion Using US images from patients with primary breast cancer, deep learning models can effectively predict clinically negative axillary lymph node metastasis. Artificial intelligence may provide an early diagnostic strategy for lymph node metastasis in patients with breast cancer with clinically negative lymph nodes. Published under a CC BY 4.0 license. Online supplemental material is available for this article. See also the editorial by Bae in this issue."
2018,A deep learning method for classifying mammographic breast density categories,"PURPOSE Mammographic breast density is an established risk marker for breast cancer and is visually assessed by radiologists in routine mammogram image reading, using four qualitative Breast Imaging and Reporting Data System (BI-RADS) breast density categories. It is particularly difficult for radiologists to consistently distinguish the two most common and most variably assigned BI-RADS categories, i.e., ""scattered density"" and ""heterogeneously dense"". The aim of this work was to investigate a deep learning-based breast density classifier to consistently distinguish these two categories, aiming at providing a potential computerized tool to assist radiologists in assigning a BI-RADS category in current clinical workflow. METHODS In this study, we constructed a convolutional neural network (CNN)-based model coupled with a large (i.e., 22,000 images) digital mammogram imaging dataset to evaluate the classification performance between the two aforementioned breast density categories. All images were collected from a cohort of 1,427 women who underwent standard digital mammography screening from 2005 to 2016 at our institution. The truths of the density categories were based on standard clinical assessment made by board-certified breast imaging radiologists. Effects of direct training from scratch solely using digital mammogram images and transfer learning of a pretrained model on a large nonmedical imaging dataset were evaluated for the specific task of breast density classification. In order to measure the classification performance, the CNN classifier was also tested on a refined version of the mammogram image dataset by removing some potentially inaccurately labeled images. Receiver operating characteristic (ROC) curves and the area under the curve (AUC) were used to measure the accuracy of the classifier. RESULTS The AUC was 0.9421 when the CNN-model was trained from scratch on our own mammogram images, and the accuracy increased gradually along with an increased size of training samples. Using the pretrained model followed by a fine-tuning process with as few as 500 mammogram images led to an AUC of 0.9265. After removing the potentially inaccurately labeled images, AUC was increased to 0.9882 and 0.9857 for without and with the pretrained model, respectively, both significantly higher (P < 0.001) than when using the full imaging dataset. CONCLUSIONS Our study demonstrated high classification accuracies between two difficult to distinguish breast density categories that are routinely assessed by radiologists. We anticipate that our approach will help enhance current clinical assessment of breast density and better support consistent density notification to patients in breast cancer screening."
2021,A Novel Deep-Learning Model for Automatic Detection and Classification of Breast Cancer Using the Transfer-Learning Technique,"Breast cancer (BC) is one of the primary causes of cancer death among women. Early detection of BC allows patients to receive appropriate treatment, thus increasing the possibility of survival. In this work, a new deep-learning (DL) model based on the transfer-learning (TL) technique is developed to efficiently assist in the automatic detection and diagnosis of the BC suspected area based on two techniques namely 80–20 and cross-validation. DL architectures are modeled to be problem-specific. TL uses the knowledge gained during solving one problem in another relevant problem. In the proposed model, the features are extracted from the mammographic image analysis- society (MIAS) dataset using a pre-trained convolutional neural network (CNN) architecture such as Inception V3, ResNet50, Visual Geometry Group networks (VGG)-19, VGG-16, and Inception-V2 ResNet. Six evaluation metrics for evaluating the performance of the proposed model in terms of accuracy, sensitivity, specificity, precision, F-score, and area under the ROC curve (AUC) has been chosen. Experimental results show that the TL of the VGG16 model is powerful for BC diagnosis by classifying the mammogram breast images with overall accuracy, sensitivity, specificity, precision, F-score, and AUC of 98.96%, 97.83%, 99.13%, 97.35%, 97.66%, and 0.995, respectively for 80–20 method and 98.87%, 97.27%, 98.2%, 98.84%, 98.04%, and 0.993 for 10-fold cross-validation method."
2020,Deep Learning vs. Radiomics for Predicting Axillary Lymph Node Metastasis of Breast Cancer Using Ultrasound Images: Don't Forget the Peritumoral Region,"Objective: Axillary lymph node (ALN) metastasis status is important in guiding treatment in breast cancer. The aims were to assess how deep convolutional neural network (CNN) performed compared with radiomics analysis in predicting ALN metastasis using breast ultrasound, and to investigate the value of both intratumoral and peritumoral regions in ALN metastasis prediction. Methods: We retrospectively enrolled 479 breast cancer patients with 2,395 breast ultrasound images. Based on the intratumoral, peritumoral, and combined intra- and peritumoral regions, three CNNs were built using DenseNet, and three radiomics models were built using random forest, respectively. By combining the molecular subtype, another three CNNs and three radiomics models were built. All models were built on training cohort (343 patients 1,715 images) and evaluated on testing cohort (136 patients 680 images) with ROC analysis. Another prospective cohort of 16 patients was enrolled to further test the models. Results: AUCs of image-only CNNs in both training/testing cohorts were 0.957/0.912 for combined region, 0.944/0.775 for peritumoral region, and 0.937/0.748 for intratumoral region, which were numerically higher than their corresponding radiomics models with AUCs of 0.940/0.886, 0.920/0.724, and 0.913/0.693. The overall performance of image-molecular CNNs in terms of AUCs on training/testing cohorts slightly increased to 0.962/0.933, 0.951/0.813, and 0.931/0.794, respectively. AUCs of both CNNs and radiomics models built on combined region were significantly better than those on either intratumoral or peritumoral region on the testing cohort (p < 0.05). In the prospective study, the CNN model built on combined region achieved the highest AUC of 0.95 among all image-only models. Conclusions: CNNs showed numerically better overall performance compared with radiomics models in predicting ALN metastasis in breast cancer. For both CNNs and radiomics models, combining intratumoral, and peritumoral regions achieved significantly better performance."
2021,Novel Transfer Learning Approach for Medical Imaging with Limited Labeled Data,"Deep learning requires a large amount of data to perform well. However, the field of medical image analysis suffers from a lack of sufficient data for training deep learning models. Moreover, medical images require manual labeling, usually provided by human annotators coming from various backgrounds. More importantly, the annotation process is time-consuming, expensive, and prone to errors. Transfer learning was introduced to reduce the need for the annotation process by transferring the deep learning models with knowledge from a previous task and then by fine-tuning them on a relatively small dataset of the current task. Most of the methods of medical image classification employ transfer learning from pretrained models, e.g., ImageNet, which has been proven to be ineffective. This is due to the mismatch in learned features between the natural image, e.g., ImageNet, and medical images. Additionally, it results in the utilization of deeply elaborated models. In this paper, we propose a novel transfer learning approach to overcome the previous drawbacks by means of training the deep learning model on large unlabeled medical image datasets and by next transferring the knowledge to train the deep learning model on the small amount of labeled medical images. Additionally, we propose a new deep convolutional neural network (DCNN) model that combines recent advancements in the field. We conducted several experiments on two challenging medical imaging scenarios dealing with skin and breast cancer classification tasks. According to the reported results, it has been empirically proven that the proposed approach can significantly improve the performance of both classification scenarios. In terms of skin cancer, the proposed model achieved an F1-score value of 89.09% when trained from scratch and 98.53% with the proposed approach. Secondly, it achieved an accuracy value of 85.29% and 97.51%, respectively, when trained from scratch and using the proposed approach in the case of the breast cancer scenario. Finally, we concluded that our method can possibly be applied to many medical imaging problems in which a substantial amount of unlabeled image data is available and the labeled image data is limited. Moreover, it can be utilized to improve the performance of medical imaging tasks in the same domain. To do so, we used the pretrained skin cancer model to train on feet skin to classify them into two classes—either normal or abnormal (diabetic foot ulcer (DFU)). It achieved an F1-score value of 86.0% when trained from scratch, 96.25% using transfer learning, and 99.25% using double-transfer learning."
2022,Breast Cancer Detection on Histopathological Images Using a Composite Dilated Backbone Network,"Breast cancer is a lethal illness that has a high mortality rate. In treatment, the accuracy of diagnosis is crucial. Machine learning and deep learning may be beneficial to doctors. The proposed backbone network is critical for the present performance of CNN-based detectors. Integrating dilated convolution, ResNet, and Alexnet increases detection performance. The composite dilated backbone network (CDBN) is an innovative method for integrating many identical backbones into a single robust backbone. Hence, CDBN uses the lead backbone feature maps to identify objects. It feeds high-level output features from previous backbones into the next backbone in a stepwise way. We show that most contemporary detectors can easily include CDBN to improve performance achieved mAP improvements ranging from 1.5 to 3.0 percent on the breast cancer histopathological image classification (BreakHis) dataset. Experiments have also shown that instance segmentation may be improved. In the BreakHis dataset, CDBN enhances the baseline detector cascade mask R-CNN (mAP = 53.3). The proposed CDBN detector does not need pretraining. It creates high-level traits by combining low-level elements. This network is made up of several identical backbones that are linked together. The composite dilated backbone considers the linked backbones CDBN."
2022,Breast Cancer Classification from Ultrasound Images Using Probability-Based Optimal Deep Learning Feature Fusion,"After lung cancer, breast cancer is the second leading cause of death in women. If breast cancer is detected early, mortality rates in women can be reduced. Because manual breast cancer diagnosis takes a long time, an automated system is required for early cancer detection. This paper proposes a new framework for breast cancer classification from ultrasound images that employs deep learning and the fusion of the best selected features. The proposed framework is divided into five major steps: (i) data augmentation is performed to increase the size of the original dataset for better learning of Convolutional Neural Network (CNN) models; (ii) a pre-trained DarkNet-53 model is considered and the output layer is modified based on the augmented dataset classes; (iii) the modified model is trained using transfer learning and features are extracted from the global average pooling layer; (iv) the best features are selected using two improved optimization algorithms known as reformed differential evaluation (RDE) and reformed gray wolf (RGW); and (v) the best selected features are fused using a new probability-based serial approach and classified using machine learning algorithms. The experiment was conducted on an augmented Breast Ultrasound Images (BUSI) dataset, and the best accuracy was 99.1%. When compared with recent techniques, the proposed framework outperforms them."
2017,Deep Learning Algorithms for Detection of Lymph Node Metastases From Breast Cancer: Helping Artificial Intelligence Be Seen.,"Artificial intelligence (AI), the theory and development of computer systems able to perform tasks that normally require human intelligence, is creeping into almost every facet of modern life. Familiar examples include computer chess games, speech recognition, intelligent routing in content delivery networks, and autonomous driving cars. In the financial sector, AI is routinely used for fraud detection, algorithmic trading, and chatbots (ie, computer programs that appear to conduct conversations via auditory or textual methods, such as with online virtual assistants). Health care has been slower to adopt AI but the pace of implementation is accelerating at an impressive rate. In 2014, the acquisition of AI startups in health care was about $600 million; in 2021, it is anticipated to be $6.6 billion or a 40% compound annual growth rate.1 One reason health care is ripe for AI is “big data”: the health care industry has rich data sets that are ideal for AI given the requirement for large test sets of data with which the computer can “learn.” Most computer modeling enhancements in health care, particularly in the image analysis field, have focused on feature engineering, essentially asking a computer to evaluate explicit features specified by experts. This permits the algorithms to detect abnormalities or predict specified lesions. In contrast, deep learning is a form of AI that includes machine learning techniques that perform iterative optimization strategies that are based on pixel-by-pixel evaluation of the data from images.2 The promise of AI in health care is the delivery of improved quality and safety of care and the potential to democratize expertise. For example, in a study by Esteva et al,3 the authors compared the ability of a deep convolutional neural network (CNN) to discriminate the most common skin cancers including malignant melanoma. They compared and demonstrated at least equivalence in the performance of their algorithm against 21 board-certified dermatologists in evaluating biopsy-proven clinical images. In this example, AI was used to discriminate whether skin lesions were malignant. The authors suggested that mobile devices, like smartphones, could be deployed with similar algorithms, permitting potentially low-cost universal access to vital diagnostic care anywhere in the world. In another study, Gulshan et al4 applied a deep CNN approach to a test set of more than 128 000 retinal fundus images from adult patients with diabetes to identify referable diabetic retinopathy. The algorithm developed had very high sensitivity and specificity for detecting referable diabetic retinopathy and macular edema.4 This study established a clear path toward use of AI not to replace physicians, but rather to perform simple, cost-effective, and widely available examinations and analyses that could help identify at-risk patients who require referral for specialty care while reassuring other patients that potential retinal manifestations of their diabetes are not present or are stable. Radiology, having converted to digital images more than 25 years ago, is well-positioned to deploy AI for diagnostics. Several studies have shown considerable opportunity to support radiologists in evaluating a variety of scan types including mammography for breast lesions, computed tomographic scans for pulmonary nodules and infections, and magnetic resonance images for brain tumors including the molecular classification of brain tumors.5-9 In contrast to radiology, pathology has been late to adopt digital imaging and thus computer-assisted diagnostic technologies. In part, this is the result of practical and financial obstacles. With conversion to digital images, radiology eliminated film, chemicals, developers, and storage of the films. Radiology departments also solved problems related to loss of films and transport of films to where they are needed, for example, in operating rooms, emergency departments, and intensive care units. Unforeseen at the time, although anticipated by some, was the inherent value within these images for greater learning using computers to improve the quality, safety, and efficiency of radiologists. Many, if not most, of the practical benefits realized by radiology would not be achieved with pathology digitization. An anatomic pathology workflow that includes digital pathology will not reduce or remove the need to produce and ultimately store glass slides of pathology specimens. Instead of any reductions, digital pathology will require additional workflows, personnel, equipment, and importantly storage of data (it is estimated that digital pathology images are at least 10 times larger files than radiology images), all on top of an already financially and operationally stressed health care system. Certainly, the adoption of digital pathology will bring some advantages, particularly in areas such as rapid teleconsultations with experts and in quality and safety. Nonetheless, Author Video Interview and JAMA Report Video"
2017,Hybrid Approach of Relation Network and Localized Graph Convolutional Filtering for Breast Cancer Subtype Classification,"Network biology has been successfully used to help reveal complex mechanisms of disease, especially cancer. On the other hand, network biology requires in-depth knowledge to construct disease-specific networks, but our current knowledge is very limited even with the recent advances in human cancer biology. Deep learning has shown an ability to address the problem like this. However, it conventionally used grid-like structured data, thus application of deep learning technologies to the human disease subtypes is yet to be explored. To overcome the issue, we propose a hybrid model, which integrates two key components 1) graph convolution neural network (graph CNN) and 2) relation network (RN). Experimental results on synthetic data and breast cancer data demonstrate that our proposed method shows better performances than existing methods."
2020,Deep Learning Assisted Efficient AdaBoost Algorithm for Breast Cancer Detection and Early Diagnosis,"Breast cancer is one of the most dangerous diseases and the second largest cause of female cancer death. Breast cancer starts when malignant, cancerous lumps start to grow from the breast cells. Self-tests and Periodic clinical checks help to early diagnosis and thereby improve the survival chances significantly. The breast cancer classification is a medical method that provides researchers and scientists with a great challenge. Neural networks have recently become a popular tool in cancer data classification. In this paper, Deep Learning assisted Efficient Adaboost Algorithm (DLA-EABA) for breast cancer detection has been mathematically proposed with advanced computational techniques. In addition to traditional computer vision approaches, tumor classification methods using transfers are being actively developed through the use of deep convolutional neural networks (CNNs). This study starts with examining the CNN-based transfer learning to characterize breast masses for different diagnostic, predictive tasks or prognostic or in several imaging modalities, such as Magnetic Resonance Imaging (MRI), Ultrasound (US), digital breast tomosynthesis and mammography. The deep learning framework contains several convolutional layers, LSTM, Max-pooling layers. The classification and error estimation that has been included in a fully connected layer and a softmax layer. This paper focuses on combining these machine learning approaches with the methods of selecting features and extracting them through evaluating their output using classification and segmentation techniques to find the most appropriate approach. The experimental results show that the high accuracy level of 97.2%, Sensitivity 98.3%, and Specificity 96.5% has been compared to other existing systems."
2022,A Lightweight Hybrid Dilated Ghost Model-Based Approach for the Prognosis of Breast Cancer,"Most approaches use interactive priors to find tumours and then segment them based on tumour-centric candidates. A fully convolutional network is demonstrated for end-to-end breast tumour segmentation. When confronted with such a variety of options, to enhance tumour detection in digital mammograms, one uses multiscale picture information. Enhanced segmentation precision. The sampling of convolution layers are carefully chosen without adding parameters to prevent overfitting. The loss function is tuned to the tumor pixel fraction during training. Several studies have shown that the recommended method is effective. Tumour segmentation is automated for a variety of tumour sizes and forms postprocessing. Due to an increase in malignant cases, fundamental IoT malignant detection and family categorisation methodologies have been put to the test. In this paper, a novel malignant detection and family categorisation model based on the improved stochastic channel attention of convolutional neural networks (CNNs) is presented. The lightweight deep learning model complies with tougher execution, training, and energy limits in practice. The improved stochastic channel attention and DenseNet models are employed to identify malignant cells, followed by family classification. On our datasets, the proposed model detects malignant cells with 99.3 percent accuracy and family categorisation with 98.5 percent accuracy. The model can detect and classify malignancy."
2020,Artificial Intelligence-Based Mitosis Detection in Breast Cancer Histopathology Images Using Faster R-CNN and Deep CNNs,"Breast cancer is the leading cause of mortality in women. Early diagnosis of breast cancer can reduce the mortality rate. In the diagnosis, the mitotic cell count is an important biomarker for predicting the aggressiveness, prognosis, and grade of breast cancer. In general, pathologists manually examine histopathology images under high-resolution microscopes for the detection of mitotic cells. However, because of the minute differences between the mitotic and normal cells, this process is tiresome, time-consuming, and subjective. To overcome these challenges, artificial-intelligence-based (AI-based) techniques have been developed which automatically detect mitotic cells in the histopathology images. Such AI techniques accelerate the diagnosis and can be used as a second-opinion system for a medical doctor. Previously, conventional image-processing techniques were used for the detection of mitotic cells, which have low accuracy and high computational cost. Therefore, a number of deep-learning techniques that demonstrate outstanding performance and low computational cost were recently developed; however, they still require improvement in terms of accuracy and reliability. Therefore, we present a multistage mitotic-cell-detection method based on Faster region convolutional neural network (Faster R-CNN) and deep CNNs. Two open datasets (international conference on pattern recognition (ICPR) 2012 and ICPR 2014 (MITOS-ATYPIA-14)) of breast cancer histopathology were used in our experiments. The experimental results showed that our method achieves the state-of-the-art results of 0.876 precision, 0.841 recall, and 0.858 F1-measure for the ICPR 2012 dataset, and 0.848 precision, 0.583 recall, and 0.691 F1-measure for the ICPR 2014 dataset, which were higher than those obtained using previous methods. Moreover, we tested the generalization capability of our technique by testing on the tumor proliferation assessment challenge 2016 (TUPAC16) dataset and found that our technique also performs well in a cross-dataset experiment which proved the generalization capability of our proposed technique."
2019,Deep Learning for Breast Cancer Diagnosis from Mammograms—A Comparative Study,"Deep convolutional neural networks (CNNs) are investigated in the context of computer-aided diagnosis (CADx) of breast cancer. State-of-the-art CNNs are trained and evaluated on two mammographic datasets, consisting of ROIs depicting benign or malignant mass lesions. The performance evaluation of each examined network is addressed in two training scenarios: the first involves initializing the network with pre-trained weights, while for the second the networks are initialized in a random fashion. Extensive experimental results show the superior performance achieved in the case of fine-tuning a pretrained network compared to training from scratch."
2019,Convolutional neural networks for computer-aided detection or diagnosis in medical image analysis: An overview.,"Computer-aided detection or diagnosis (CAD) has been a promising area of research over the last two decades. Medical image analysis aims to provide a more efficient diagnostic and treatment process for the radiologists and clinicians. However, with the development of science and technology, data interpretation manually in the conventional CAD systems has gradually become a challenging task. Deep learning methods, especially convolutional neural networks (CNNs), are successfully used as tools to solve this problem. This includes applications such as breast cancer diagnosis, lung nodule detection and prostate cancer localization. In this overview, the current state-of-the-art medical image analysis techniques in CAD research are presented, which focus on the convolutional neural network (CNN) based methods. The commonly used medical image databases in literature are also listed. It is anticipated that this paper can provide researchers in radiomics, precision medicine, and imaging grouping with a systematic picture of the CNN-based methods used in CAD research."
2019,Detection and classification the breast tumors using mask R-CNN on sonograms,"Abstract Breast cancer is one of the most harmful diseases for women with the highest morbidity. An efficient way to decrease its mortality is to diagnose cancer earlier by screening. Clinically, the best approach of screening for Asian women is ultrasound images combined with biopsies. However, biopsy is invasive and it gets incomprehensive information of the lesion. The aim of this study is to build a model for automatic detection, segmentation, and classification of breast lesions with ultrasound images. Based on deep learning, a technique using Mask regions with convolutional neural network was developed for lesion detection and differentiation between benign and malignant. The mean average precision was 0.75 for the detection and segmentation. The overall accuracy of benign/malignant classification was 85%. The proposed method provides a comprehensive and noninvasive way to detect and classify breast lesions."
2022,Breast cancer detection based on thermographic images using machine learning and deep learning algorithms,"According to the latest data, breast carcinoma is the most prevalent kind of cancer in the world, and it is responsible for the deaths of almost 900 thousand people each year. If the disease is detected at the early stage and diagnosed properly, it can improve the chance of positive outcomes, thus reducing the fatality rate. An early diagnosis in fact can help in preventing it to spread and saves the premature victims from obtaining it. When trying to distinguish among benign and malignant tumors, as well as when trying to draw conclusions about mild and advanced breast cancer, researchers who study cancer encounter a number of challenges. The identification of all tumors is accomplished through the application of machine learning, which makes use of algorithms that are able to locate and recognize patterns. All of them, however, revolve around the concept of ""binary grouping,"" as was mentioned earlier (malignant and benign; no-cancer and cancer). In this study, we propose a Computer-aided Diagnosis (CAD) method for the identification and diagnosis of patients into 3 classes (cancer, no cancer, and non-cancerous) under the management of a database. CAD is an abbreviation for computer-aided diagnosis. The Convolutional Neural Network (CNN), the Support Vector Machine (SVM), and Random Forest are all remarkable classifiers (RF). Convolution Networks, Support Vector Machines (SVM), and Random Forest are the three effective classifiers that we look into and analyses for the classification stage (RF). In addition to this, we investigate the impact of the mammography pictures being pre-processed in advance, which allows for a higher success rate in categorization."
2021,Transfer Learning in Breast Cancer Diagnoses via Ultrasound Imaging,"Simple Summary Transfer learning plays a major role in medical image analyses; however, obtaining adequate training image datasets for machine learning algorithms can be challenging. Although many studies have attempted to employ transfer learning in medical image analyses, thus far, only a few review articles regarding the application of transfer learning to medical image analyses have been published. Moreover, reviews on the application of transfer learning in ultrasound breast imaging are rare. This work reviews previous studies that focused on detecting breast cancer from ultrasound images by using transfer learning, in order to summarize existing methods and identify their advantages and shortcomings. Additionally, this review presents potential future research directions for applying transfer learning in ultrasound imaging for the purposes of breast cancer detection and diagnoses. This review is expected to be significantly helpful in guiding researchers to identify potential improved methods and areas that can be improved through further research on transfer learning-based ultrasound breast imaging. Abstract Transfer learning is a machine learning approach that reuses a learning method developed for a task as the starting point for a model on a target task. The goal of transfer learning is to improve performance of target learners by transferring the knowledge contained in other (but related) source domains. As a result, the need for large numbers of target-domain data is lowered for constructing target learners. Due to this immense property, transfer learning techniques are frequently used in ultrasound breast cancer image analyses. In this review, we focus on transfer learning methods applied on ultrasound breast image classification and detection from the perspective of transfer learning approaches, pre-processing, pre-training models, and convolutional neural network (CNN) models. Finally, comparison of different works is carried out, and challenges—as well as outlooks—are discussed."
2020,Guided Soft Attention Network for Classification of Breast Cancer Histopathology Images,"An attention guided convolutional neural network (CNN) for the classification of breast cancer histopathology images is proposed. Neural networks are generally applied as black box models and often the network’s decisions are difficult to interpret. Making the decision process transparent, and hence reliable is important for a computer-assisted diagnosis (CAD) system. Moreover, it is crucial that the network’s decision be based on histopathological features that are in agreement with a human expert. To this end, we propose to use additional region-level supervision for the classification of breast cancer histopathology images using CNN, where the regions of interest (RoI) are localized and used to guide the attention of the classification network simultaneously. The proposed supervised attention mechanism specifically activates neurons in diagnostically relevant regions while suppressing activations in irrelevant and noisy areas. The class activation maps generated by the proposed method correlate well with the expectations of an expert pathologist. Moreover, the proposed method surpasses the state-of-the-art on the BACH microscopy test dataset (part A) with a significant margin."
2017,Deep learning model based breast cancer histopathological image classification,"The automatic and precision classification for breast cancer histopathological image has a great significance in clinical application. However, the existing analysis approaches are difficult to addressing the breast cancer classification problem because the feature subtle differences of inter-class histopathological image and the classification accuracy still hard to meet the clinical application. Recent advancements in data-driven sharing processing and multi-level hierarchical feature learning have made available considerable chance to dope out a solution to this problem. To address the challenging problem, we propose a novel breast cancer histopathological image classification method based on deep convolutional neural networks, named as BiCNN model, to address the two-class breast cancer classification on the pathological image. This deep learning model considers class and sub-class labels of breast cancer as prior knowledge, which can restrain the distance of features of different breast cancer pathological images. In addition, an advanced data augmented method is proposed to fit tolerance whole slide image recognition, which can full reserve image edge feature of cancerization region. The transfer learning and fine-tuning method are adopted as an optimal training strategy to improve breast cancer histopathological image classification accuracy. The experiment results show that the proposed method leads to a higher classification accuracy (up to 97%) and displays good robustness and generalization, which provides efficient tools for breast cancer clinical diagnosis."
2021,Boosting Breast Cancer Detection Using Convolutional Neural Network,"Breast cancer forms in breast cells and is considered as a very common type of cancer in women. Breast cancer is also a very life-threatening disease of women after lung cancer. A convolutional neural network (CNN) method is proposed in this study to boost the automatic identification of breast cancer by analyzing hostile ductal carcinoma tissue zones in whole-slide images (WSIs). The paper investigates the proposed system that uses various convolutional neural network (CNN) architectures to automatically detect breast cancer, comparing the results with those from machine learning (ML) algorithms. All architectures were guided by a big dataset of about 275,000, 50 × 50-pixel RGB image patches. Validation tests were done for quantitative results using the performance measures for every methodology. The proposed system is found to be successful, achieving results with 87% accuracy, which could reduce human mistakes in the diagnosis process. Moreover, our proposed system achieves accuracy higher than the 78% accuracy of machine learning (ML) algorithms. The proposed system therefore improves accuracy by 9% above results from machine learning (ML) algorithms."
2019,Classification of Breast Cancer Histology Images Using Multi-Size and Discriminative Patches Based on Deep Learning,"The diagnosis of breast cancer histology images with hematoxylin and eosin stained is non-trivial, labor-intensive and often leads to a disagreement between pathologists. Computer-assisted diagnosis systems contribute to help pathologists improve diagnostic consistency and efficiency. With the recent advances in deep learning, convolutional neural networks (CNNs) have been successfully used for histology images analysis. The classification of breast cancer histology images into normal, benign, and malignant sub-classes is related to cells’ density, variability, and organization along with overall tissue structure and morphology. Based on this, we extract both smaller and larger size patches from histology images, including cell-level and tissue-level features, respectively. However, there are some sampled cell-level patches that do not contain enough information that matches the image tag. Therefore, we propose a patches’ screening method based on the clustering algorithm and CNN to select more discriminative patches. The approach proposed in this paper is applied to the 4-class classification of breast cancer histology images and achieves 95% accuracy on the initial test set and 88.89% accuracy on the overall test set. The results are competitive compared to the results of other state-of-the-art methods."
2017,Involvement of Machine Learning for Breast Cancer Image Classification: A Survey,"Breast cancer is one of the largest causes of women's death in the world today. Advance engineering of natural image classification techniques and Artificial Intelligence methods has largely been used for the breast-image classification task. The involvement of digital image classification allows the doctor and the physicians a second opinion, and it saves the doctors' and physicians' time. Despite the various publications on breast image classification, very few review papers are available which provide a detailed description of breast cancer image classification techniques, feature extraction and selection procedures, classification measuring parameterizations, and image classification findings. We have put a special emphasis on the Convolutional Neural Network (CNN) method for breast image classification. Along with the CNN method we have also described the involvement of the conventional Neural Network (NN), Logic Based classifiers such as the Random Forest (RF) algorithm, Support Vector Machines (SVM), Bayesian methods, and a few of the semisupervised and unsupervised methods which have been used for breast image classification."
2018,Breast cancer detection in mammograms using convolutional neural network,"Breast cancer is among world's second most occurring cancer in all types of cancer. Most common cancer among women worldwide is breast cancer. There is always need of advancement when it comes to medical imaging. Early detection of cancer followed by the proper treatment can reduce the risk of deaths. Machine learning can help medical professionals to diagnose the disease with more accuracy. Where deep learning or neural networks is one of the techniques which can be used for the classification of normal and abnormal breast detection. CNN can be used for this detection. Mammograms-MIAS dataset is used for this purpose, having 322 mammograms in which almost 189 images are of normal and 133 are of abnormal breasts. Promising experimental results have been obtained which depict the efficacy of deep learning for breast cancer detection in mammogram images and further encourage the use of deep learning based modern feature extraction and classification methods in various medical imaging applications especially in breast cancer detection. It is an ongoing research and further developments are being made by optimizing the CNN architecture and also employing pre-trained networks which will hopefully lead to higher accuracy measures. Proper segmentation is mandatory for efficient feature extraction and classification."
2019,Parallel Structure Deep Neural Network Using CNN and RNN with an Attention Mechanism for Breast Cancer Histology Image Classification,"In this paper, we present a new deep learning model to classify hematoxylin–eosin-stained breast biopsy images into four classes (normal tissues, benign lesions, in situ carcinomas, and invasive carcinomas). Our model uses a parallel structure consist of a convolutional neural network (CNN) and a recurrent neural network (RNN) for image feature extraction, which is greatly different from the common existed serial method of extracting image features by CNN and then inputting them into RNN. Then, we introduce a special perceptron attention mechanism, which is derived from the natural language processing (NLP) field, to unify the features extracted by the two different neural network structures of the model. In the convolution layer, general batch normalization is replaced by the new switchable normalization method. And the latest regularization technology, targeted dropout, is used to substitute for the general dropout in the last three fully connected layers of the model. In the testing phase, we use the model fusion method and test time augmentation technology on three different datasets of hematoxylin–eosin-stained breast biopsy images. The results demonstrate that our model significantly outperforms state-of-the-art methods."
2019,A Technical Review of Convolutional Neural Network-Based Mammographic Breast Cancer Diagnosis,"This study reviews the technique of convolutional neural network (CNN) applied in a specific field of mammographic breast cancer diagnosis (MBCD). It aims to provide several clues on how to use CNN for related tasks. MBCD is a long-standing problem, and massive computer-aided diagnosis models have been proposed. The models of CNN-based MBCD can be broadly categorized into three groups. One is to design shallow or to modify existing models to decrease the time cost as well as the number of instances for training; another is to make the best use of a pretrained CNN by transfer learning and fine-tuning; the third is to take advantage of CNN models for feature extraction, and the differentiation of malignant lesions from benign ones is fulfilled by using machine learning classifiers. This study enrolls peer-reviewed journal publications and presents technical details and pros and cons of each model. Furthermore, the findings, challenges and limitations are summarized and some clues on the future work are also given. Conclusively, CNN-based MBCD is at its early stage, and there is still a long way ahead in achieving the ultimate goal of using deep learning tools to facilitate clinical practice. This review benefits scientific researchers, industrial engineers, and those who are devoted to intelligent cancer diagnosis."
2019,Classification of Histopathological Biopsy Images Using Ensemble of Deep Learning Networks,"Breast cancer is one of the leading causes of death across the world in women. Early diagnosis of this type of cancer is critical for treatment and patient care. Computer-aided detection (CAD) systems using convolutional neural networks (CNN) could assist in the classification of abnormalities. In this study, we proposed an ensemble deep learning-based approach for automatic binary classification of breast histology images. The proposed ensemble model adapts three pre-trained CNNs, namely VGG19, MobileNet, and DenseNet. The ensemble model is used for the feature representation and extraction steps. The extracted features are then fed into a multi-layer perceptron classifier to carry out the classification task. Various pre-processing and CNN tuning techniques such as stain-normalization, data augmentation, hyperparameter tuning, and fine-tuning are used to train the model. The proposed method is validated on four publicly available benchmark datasets, i.e., ICIAR, BreakHis, PatchCamelyon, and Bioimaging. The proposed multi-model ensemble method obtains better predictions than single classifiers and machine learning algorithms with accuracies of 98.13%, 95.00%, 94.64% and 83.10% for BreakHis, ICIAR, PatchCamelyon and Bioimaging datasets, respectively."
2019,Deep Learning Approaches for Data Augmentation and Classification of Breast Masses using Ultrasound Images,"Breast classification and detection using ultrasound imaging is considered a significant step in computer-aided diagno-sis systems. Over the previous decades, researchers have proved the opportunities to automate the initial tumor classification and detection. The shortage of popular datasets of ultrasound images of breast cancer prevents researchers from obtaining a good performance of the classification algorithms. Traditional augmentation approaches are firmly limited, especially in tasks where the images follow strict standards, as in the case of medical datasets. Therefore besides the traditional augmentation, we use a new methodology for data augmentation using Generative Adversarial Network (GAN). We achieved higher accuracies by integrating traditional with GAN-based augmentation. This paper uses two breast ultrasound image datasets obtained from two various ultrasound systems. The first dataset is our dataset which was collected from Baheya Hospital for Early Detection and Treatment of Women’s Cancer, Cairo (Egypt), we name it (BUSI) referring to Breast Ultrasound Images (BUSI) dataset. It contains 780 images (133 normal, 437 benign and 210 malignant). While the Dataset (B) is obtained from related work and it has 163 images (110 benign and 53 malignant). To overcome the shortage of public datasets in this field, BUSI dataset will be publicly available for researchers. Moreover, in this paper, deep learning approaches are proposed to be used for breast ultrasound classification. We examine two different methods: a Convolutional Neural Network (CNN) approach and a Transfer Learning (TL) approach and we compare their performance with and without augmentation. The results confirm an overall enhancement using augmentation methods with deep learning classification methods (especially transfer learning) when evaluated on the two datasets."
2018,Multi-Class Breast Cancer Classification using Deep Learning Convolutional Neural Network,"Breast cancer continues to be among the leading causes of death for women and much effort has been expended in the form of screening programs for prevention. Given the exponential growth in the number of mammograms collected by these programs, computer-assisted diagnosis has become a necessity. Computer-assisted detection techniques developed to date to improve diagnosis without multiple systematic readings have not resulted in a significant improvement in performance measures. In this context, the use of automatic image processing techniques resulting from deep learning represents a promising avenue for assisting in the diagnosis of breast cancer. In this paper, we present a deep learning approach based on a Convolutional Neural Network (CNN) model for multi-class breast cancer classification. The proposed approach aims to classify the breast tumors in non-just benign or malignant but we predict the subclass of the tumors like Fibroadenoma, Lobular carcinoma, etc. Experimental results on histopathological images using the BreakHis dataset show that the DenseNet CNN model achieved high processing performances with 95.4% of accuracy in the multi-class breast cancer classification task when compared with state-of-the-art models."
2018,Cancer Metastasis Detection With Neural Conditional Random Field,"Breast cancer diagnosis often requires accurate detection of metastasis in lymph nodes through Whole-slide Images (WSIs). Recent advances in deep convolutional neural networks (CNNs) have shown significant successes in medical image analysis and particularly in computational histopathology. Because of the outrageous large size of WSIs, most of the methods divide one slide into lots of small image patches and perform classification on each patch independently. However, neighboring patches often share spatial correlations, and ignoring these spatial correlations may result in inconsistent predictions. In this paper, we propose a neural conditional random field (NCRF) deep learning framework to detect cancer metastasis in WSIs. NCRF considers the spatial correlations between neighboring patches through a fully connected CRF which is directly incorporated on top of a CNN feature extractor. The whole deep network can be trained end-to-end with standard back-propagation algorithm with minor computational overhead from the CRF component. The CNN feature extractor can also benefit from considering spatial correlations via the CRF component. Compared to the baseline method without considering spatial correlations, we show that the proposed NCRF framework obtains probability maps of patch predictions with better visual quality. We also demonstrate that our method outperforms the baseline in cancer metastasis detection on the Camelyon16 dataset and achieves an average FROC score of 0.8096 on the test set. NCRF is open sourced at this https URL."
2017,A method for classifying medical images using transfer learning: A pilot study on histopathology of breast cancer,"The advance of deep learning has made huge changes in computer vision and produced various off-the-shelf trained models. Particularly, Convolutional Neural Network (CNN) has been widely used to build image classification model which allow researchers transfer the pre-trained learning model for other classifications. We propose a transfer learning method to detect breast cancer using histopathology images based on Google's Inception v3 model which were initially trained for the classification of non-medical images. The pilot study shows the feasibility of transfer learning in the detection of breast cancer with AUC of 0.93."
2016,Antibody-supervised deep learning for quantification of tumor-infiltrating immune cells in hematoxylin and eosin stained breast cancer samples,"Background: Immune cell infiltration in tumor is an emerging prognostic biomarker in breast cancer. The gold standard for quantification of immune cells in tissue sections is visual assessment through a microscope, which is subjective and semi-quantitative. In this study, we propose and evaluate an approach based on antibody-guided annotation and deep learning to quantify immune cell-rich areas in hematoxylin and eosin (H&E) stained samples. Methods: Consecutive sections of formalin-fixed parafin-embedded samples obtained from the primary tumor of twenty breast cancer patients were cut and stained with H&E and the pan-leukocyte CD45 antibody. The stained slides were digitally scanned, and a training set of immune cell-rich and cell-poor tissue regions was annotated in H&E whole-slide images using the CD45-expression as a guide. In analysis, the images were divided into small homogenous regions, superpixels, from which features were extracted using a pretrained convolutional neural network (CNN) and classified with a support of vector machine. The CNN approach was compared to texture-based classification and to visual assessments performed by two pathologists. Results: In a set of 123,442 labeled superpixels, the CNN approach achieved an F-score of 0.94 (range: 0.92-0.94) in discrimination of immune cell-rich and cell-poor regions, as compared to an F-score of 0.88 (range: 0.87-0.89) obtained with the texture-based classification. When compared to visual assessment of 200 images, an agreement of 90% (k = 0.79) to quantify immune infiltration with the CNN approach was achieved while the inter-observer agreement between pathologists was 90% (k = 0.78). Conclusions: Our findings indicate that deep learning can be applied to quantify immune cell infiltration in breast cancer samples using a basic morphology staining only. A good discrimination of immune cell-rich areas was achieved, well in concordance with both leukocyte antigen expression and pathologists′ visual assessment."
2017,Detection and classification of the breast abnormalities in digital mammograms via regional Convolutional Neural Network,"Automatic detection and classification of the masses in mammograms are still a big challenge and play a crucial role to assist radiologists for accurate diagnosis. In this paper, we propose a novel computer-aided diagnose (CAD) system based on one of the regional deep learning techniques: a ROI-based Convolutional Neural Network (CNN) which is called You Only Look Once (YOLO). Our proposed YOLO-based CAD system contains four main stages: mammograms preprocessing, feature extraction utilizing multi convolutional deep layers, mass detection with confidence model, and finally mass classification using fully connected neural network (FC-NN). A set of training mammograms with the information of ROI masses and their types are used to train YOLO. The trained YOLO-based CAD system detects the masses and classifies their types into benign or malignant. Our results show that the proposed YOLO-based CAD system detects the mass location with an overall accuracy of 96.33%. The system also distinguishes between benign and malignant lesions with an overall accuracy of 85.52%. Our proposed system seems to be feasible as a CAD system capable of detection and classification at the same time. It also overcomes some challenging breast cancer cases such as the mass existing in the pectoral muscles or dense regions."
2020,Breast Tumor Segmentation in 3D Automatic Breast Ultrasound Using Mask Scoring R-CNN.,"PURPOSE Automatic breast ultrasound (ABUS) imaging has become an essential tool in breast cancer diagnosis since it provides complementary information to other imaging modalities. Lesion segmentation on ABUS is a prerequisite step of breast cancer computer-aided diagnosis (CAD). This work aims to develop a deep learning-based method for breast tumor segmentation using three-dimensional ABUS automatically. METHODS For breast tumor segmentation in ABUS, we developed a Mask scoring region-based convolutional neural network (R-CNN) that consists of five subnetworks, i.e., a backbone, a regional proposal network, a region CNN head, a mask head, and a mask score head. A network block building direct correlation between mask quality and region class was integrated into a Mask scoring R-CNN based framework for the segmentation of new ABUS images with ambiguous regions of interest (ROIs). For segmentation accuracy evaluation, we retrospectively investigated 70 patients with breast tumor confirmed with needle biopsy and manually delineated on ABUS, of which 40 were used for five-fold cross-validation and 30 were used for hold-out test. The comparison between the automatic breast tumor segmentations and the manual contours was quantified by I) six metrics including Dice similarity coefficient (DSC), Jaccard index, 95% Hausdorff distance (HD95), mean surface distance (MSD), residual mean square distance (RMSD), and center of mass distance (CMD); II) Pearson correlation analysis and Bland-Altman analysis. RESULTS The mean (median) DSC was 85% ± 10.4% (89.4%) and 82.1% ± 14.5% (85.6%) for cross validation and hold-out test, respectively. The corresponding HD95, MSD, RMSD and CMD of the two tests was 1.646 ± 1.191 and 1.665 ± 1.129 mm, 0.489 ± 0.406 and 0.475 ± 0.371 mm, 0.755 ± 0.755 and 0.751 ± 0.508 mm, and 0.672 ± 0.612 and 0.665 ± 0.729 mm. The mean volumetric difference (mean and ± 1.96 standard deviation) was 0.47 cc ([-0.77, 1.71)) for the cross-validation and 0.23 cc ([-0.23 0.69]) for hold-out test respectively. CONCLUSION We developed a novel Mask scoring R-CNN approach for the automated segmentation of the breast tumor in ABUS images and demonstrated its accuracy for breast tumor segmentation. Our learning-based method can potentially assist the clinical CAD of breast cancer using 3D ABUS imaging."
2018,Deep Learning to Distinguish Recalled but Benign Mammography Images in Breast Cancer Screening,"Purpose: False positives in digital mammography screening lead to high recall rates, resulting in unnecessary medical procedures to patients and health care costs. This study aimed to investigate the revolutionary deep learning methods to distinguish recalled but benign mammography images from negative exams and those with malignancy. Experimental Design: Deep learning convolutional neural network (CNN) models were constructed to classify mammography images into malignant (breast cancer), negative (breast cancer free), and recalled-benign categories. A total of 14,860 images of 3,715 patients from two independent mammography datasets: Full-Field Digital Mammography Dataset (FFDM) and a digitized film dataset, Digital Dataset of Screening Mammography (DDSM), were used in various settings for training and testing the CNN models. The ROC curve was generated and the AUC was calculated as a metric of the classification accuracy. Results: Training and testing using only the FFDM dataset resulted in AUC ranging from 0.70 to 0.81. When the DDSM dataset was used, AUC ranged from 0.77 to 0.96. When datasets were combined for training and testing, AUC ranged from 0.76 to 0.91. When pretrained on a large nonmedical dataset and DDSM, the models showed consistent improvements in AUC ranging from 0.02 to 0.05 (all P > 0.05), compared with pretraining only on the nonmedical dataset. Conclusions: This study demonstrates that automatic deep learning CNN methods can identify nuanced mammographic imaging features to distinguish recalled-benign images from malignant and negative cases, which may lead to a computerized clinical toolkit to help reduce false recalls."
2017,Discriminating solitary cysts from soft tissue lesions in mammography using a pretrained deep convolutional neural network,"Purpose: It is estimated that 7% of women in the western world will develop palpable breast cysts in their lifetime. Even though cysts have been correlated with risk of developing breast cancer, many of them are benign and do not require follow‐up. We develop a method to discriminate benign solitary cysts from malignant masses in digital mammography. We think a system like this can have merit in the clinic as a decision aid or complementary to specialized modalities. Methods: We employ a deep convolutional neural network (CNN) to classify cyst and mass patches. Deep CNNs have been shown to be powerful classifiers, but need a large amount of training data for which medical problems are often difficult to come by. The key contribution of this paper is that we show good performance can be obtained on a small dataset by pretraining the network on a large dataset of a related task. We subsequently investigate the following: (a) when a mammographic exam is performed, two different views of the same breast are recorded. We investigate the merit of combining the output of the classifier from these two views. (b) We evaluate the importance of the resolution of the patches fed to the network. (c) A method dubbed tissue augmentation is subsequently employed, where we extract normal tissue from normal patches and superimpose this onto the actual samples aiming for a classifier invariant to occluding tissue. (d) We combine the representation extracted using the deep CNN with our previously developed features. Results: We show that using the proposed deep learning method, an area under the ROC curve (AUC) value of 0.80 can be obtained on a set of benign solitary cysts and malignant mass findings recalled in screening. We find that it works significantly better than our previously developed approach by comparing the AUC of the ROC using bootstrapping. By combining views, the results can be further improved, though this difference was not found to be significant. We find no significant difference between using a resolution of 100 versus 200 micron. The proposed tissue augmentations give a small improvement in performance, but this improvement was also not found to be significant. The final system obtained an AUC of 0.80 with 95% confidence interval [0.78, 0.83], calculated using bootstrapping. The system works best for lesions larger than 27 mm where it obtains an AUC value of 0.87. Conclusion: We have presented a computer‐aided diagnosis (CADx) method to discriminate cysts from solid lesion in mammography using features from a deep CNN trained on a large set of mass candidates, obtaining an AUC of 0.80 on a set of diagnostic exams recalled from screening. We believe the system shows great potential and comes close to the performance of recently developed spectral mammography. We think the system can be further improved when more data and computational power becomes available."
2018,Evolutionary pruning of transfer learned deep convolutional neural network for breast cancer diagnosis in digital breast tomosynthesis,"Deep learning models are highly parameterized, resulting in difficulty in inference and transfer learning for image recognition tasks. In this work, we propose a layered pathway evolution method to compress a deep convolutional neural network (DCNN) for classification of masses in digital breast tomosynthesis (DBT). The objective is to prune the number of tunable parameters while preserving the classification accuracy. In the first stage transfer learning, 19 632 augmented regions-of-interest (ROIs) from 2454 mass lesions on mammograms were used to train a pre-trained DCNN on ImageNet. In the second stage transfer learning, the DCNN was used as a feature extractor followed by feature selection and random forest classification. The pathway evolution was performed using genetic algorithm in an iterative approach with tournament selection driven by count-preserving crossover and mutation. The second stage was trained with 9120 DBT ROIs from 228 mass lesions using leave-one-case-out cross-validation. The DCNN was reduced by 87% in the number of neurons, 34% in the number of parameters, and 95% in the number of multiply-and-add operations required in the convolutional layers. The test AUC on 89 mass lesions from 94 independent DBT cases before and after pruning were 0.88 and 0.90, respectively, and the difference was not statistically significant (p  >  0.05). The proposed DCNN compression approach can reduce the number of required operations by 95% while maintaining the classification performance. The approach can be extended to other deep neural networks and imaging tasks where transfer learning is appropriate."
2016,AggNet : Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images,"The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions. 1) Can deep CNN be trained with data collected from crowdsourcing? 2) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)? 3) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration."
2020,Deep Neural Networks With Region-Based Pooling Structures for Mammographic Image Classification,"Breast cancer is one of the most frequently diagnosed solid cancers. Mammography is the most commonly used screening technology for detecting breast cancer. Traditional machine learning methods of mammographic image classification or segmentation using manual features require a great quantity of manual segmentation annotation data to train the model and test the results. But manual labeling is expensive, time-consuming, and laborious, and greatly increases the cost of system construction. To reduce this cost and the workload of radiologists, an end-to-end full-image mammogram classification method based on deep neural networks was proposed for classifier building, which can be constructed without bounding boxes or mask ground truth label of training data. The only label required in this method is the classification of mammographic images, which can be relatively easy to collect from diagnostic reports. Because breast lesions usually take up a fraction of the total area visualized in the mammographic image, we propose different pooling structures for convolutional neural networks(CNNs) instead of the common pooling methods, which divide the image into regions and select the few with high probability of malignancy as the representation of the whole mammographic image. The proposed pooling structures can be applied on most CNN-based models, which may greatly improve the models’ performance on mammographic image data with the same input. Experimental results on the publicly available INbreast dataset and CBIS dataset indicate that the proposed pooling structures perform satisfactorily on mammographic image data compared with previous state-of-the-art mammographic image classifiers and detection algorithm using segmentation annotations."
2019,MRI Breast Tumor Segmentation Using Different Encoder and Decoder CNN Architectures,"Breast tumor segmentation in medical images is a decisive step for diagnosis and treatment follow-up. Automating this challenging task helps radiologists to reduce the high manual workload of breast cancer analysis. In this paper, we propose two deep learning approaches to automate the breast tumor segmentation in dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) by building two fully convolutional neural networks (CNN) based on SegNet and U-Net. The obtained models can handle both detection and segmentation on each single DCE-MRI slice. In this study, we used a dataset of 86 DCE-MRIs, acquired before and after two cycles of chemotherapy, of 43 patients with local advanced breast cancer, a total of 5452 slices were used to train and validate the proposed models. The data were annotated manually by an experienced radiologist. To reduce the training time, a high-performance architecture composed of graphic processing units was used. The model was trained and validated, respectively, on 85% and 15% of the data. A mean intersection over union (IoU) of 68.88 was achieved using SegNet and 76.14% using U-Net architecture."
2021,Vision Transformer for Classification of Breast Ultrasound Images,"Medical ultrasound (US) imaging has become a prominent modality for breast cancer imaging due to its ease-of-use, low-cost and safety. In the past decade, convolutional neural networks (CNNs) have emerged as the method of choice in vision applications and have shown excellent potential in automatic classification of US images. Despite their success, their restricted local receptive field limits their ability to learn global context information. Recently, Vision Transformer (ViT) designs that are based on self-attention between image patches have shown great potential to be an alternative to CNNs. In this study, for the first time, we utilize ViT to classify breast US images using different augmentation strategies. The results are provided as classification accuracy and Area Under the Curve (AUC) metrics, and the performance is compared with the state-of-the-art CNNs. The results indicate that the ViT models have comparable efficiency with or even better than the CNNs in classification of US breast images."
2022,TTCNN: A Breast Cancer Detection and Classification towards Computer-Aided Diagnosis Using Digital Mammography in Early Stages,"Breast cancer is a major research area in the medical image analysis field; it is a dangerous disease and a major cause of death among women. Early and accurate diagnosis of breast cancer based on digital mammograms can enhance disease detection accuracy. Medical imagery must be detected, segmented, and classified for computer-aided diagnosis (CAD) systems to help the radiologists for accurate diagnosis of breast lesions. Therefore, an accurate breast cancer detection and classification approach is proposed for screening of mammograms. In this paper, we present a deep learning system that can identify breast cancer in mammogram screening images using an “end-to-end” training strategy that efficiently uses mammography images for computer-aided breast cancer recognition in the early stages. First, the proposed approach implements the modified contrast enhancement method in order to refine the detail of edges from the source mammogram images. Next, the transferable texture convolutional neural network (TTCNN) is presented to enhance the performance of classification and the energy layer is integrated in this work to extract the texture features from the convolutional layer. The proposed approach consists of only three layers of convolution and one energy layer, rather than the pooling layer. In the third stage, we analyzed the performance of TTCNN based on deep features of convolutional neural network models (InceptionResNet-V2, Inception-V3, VGG-16, VGG-19, GoogLeNet, ResNet-18, ResNet-50, and ResNet-101). The deep features are extracted by determining the best layers which enhance the classification accuracy. In the fourth stage, by using the convolutional sparse image decomposition approach, all the extracted feature vectors are fused and, finally, the best features are selected by using the entropy controlled firefly method. The proposed approach employed on DDSM, INbreast, and MIAS datasets and attained the average accuracy of 97.49%. Our proposed transferable texture CNN-based method for classifying screening mammograms has outperformed prior methods. These findings demonstrate that automatic deep learning algorithms can be easily trained to achieve high accuracy in diverse mammography images, and can offer great potential to improve clinical tools to minimize false positive and false negative screening mammography results."
2023,Deep Learning Based Methods for Breast Cancer Diagnosis: A Systematic Review and Future Direction,"Breast cancer is one of the precarious conditions that affect women, and a substantive cure has not yet been discovered for it. With the advent of Artificial intelligence (AI), recently, deep learning techniques have been used effectively in breast cancer detection, facilitating early diagnosis and therefore increasing the chances of patients’ survival. Compared to classical machine learning techniques, deep learning requires less human intervention for similar feature extraction. This study presents a systematic literature review on the deep learning-based methods for breast cancer detection that can guide practitioners and researchers in understanding the challenges and new trends in the field. Particularly, different deep learning-based methods for breast cancer detection are investigated, focusing on the genomics and histopathological imaging data. The study specifically adopts the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA), which offer a detailed analysis and synthesis of the published articles. Several studies were searched and gathered, and after the eligibility screening and quality evaluation, 98 articles were identified. The results of the review indicated that the Convolutional Neural Network (CNN) is the most accurate and extensively used model for breast cancer detection, and the accuracy metrics are the most popular method used for performance evaluation. Moreover, datasets utilized for breast cancer detection and the evaluation metrics are also studied. Finally, the challenges and future research direction in breast cancer detection based on deep learning models are also investigated to help researchers and practitioners acquire in-depth knowledge of and insight into the area."
2020,A Review on Recent Progress in Thermal Imaging and Deep Learning Approaches for Breast Cancer Detection,"Developing a breast cancer screening method is very important to facilitate early breast cancer detection and treatment. Building a screening method using medical imaging modality that does not cause body tissue damage (non-invasive) and does not involve physical touch is challenging. Thermography, a non-invasive and non-contact cancer screening method, can detect tumors at an early stage even under precancerous conditions by observing temperature distribution in both breasts. The thermograms obtained on thermography can be interpreted using deep learning models such as convolutional neural networks (CNNs). CNNs can automatically classify breast thermograms into categories such as normal and abnormal. Despite their demostrated utility, CNNs have not been widely used in breast thermogram classification. In this study, we aimed to summarize the current work and progress in breast cancer detection based on thermography and CNNs. We first discuss of breast thermography potential in early breast cancer detection, providing an overview of the availability of breast thermal datasets together with publicly accessible. We also discuss characteristics of breast thermograms and the differences between healthy and cancerous thermographic patterns. Breast thermogram classification using a CNN model is described step by step including a simulation example illustrating feature learning. We cover most research related to the implementation of deep neural networks for breast thermogram classification and propose future research directions for developing representative datasets, feeding the segmented image, assigning a good kernel, and building a lightweight CNN model to improve CNN performance."
2019,Computer-aided diagnosis system for breast ultrasound images using deep learning,"The purpose of this study was to develop a computer-aided diagnosis (CAD) system for the classification of malignant and benign masses in the breast using ultrasonography based on a convolutional neural network (CNN), a state-of-the-art deep learning technique. We explored the regions for the correct classification by generating a heat map that presented the important regions used by the CNN for human malignancy/benign classification. Clinical data was obtained from a large-scale clinical trial previously conducted by the Japan Association of Breast and Thyroid Sonology. Images of 1536 breast masses (897 malignant and 639 benign) confirmed by pathological examinations were collected, with each breast mass captured from various angles using an ultrasound (US) imaging probe. We constructed an ensemble network by combining two CNN models (VGG19 and ResNet152) fine-tuned on balanced training data with augmentation and used the mass-level classification method to enable the CNN to classify a given mass using all views. For an independent test set consisting of 154 masses (77 malignant and 77 benign), our network showed outstanding classification performance with a sensitivity of 90.9% (95% confidence interval 84.5–97.3), a specificity of 87.0% (79.5–94.5), and area under the curve (AUC) of 0.951 (0.916–0.987) compared to that of the two CNN models. In addition, our study indicated that the breast masses themselves were not detected by the CNN as important regions for correct mass classification. Collectively, this CNN-based CAD system is expected to assist doctors by improving the diagnosis of breast cancer in clinical practice."
2023,Quantum Machine Learning: A Review and Case Studies,"Despite its undeniable success, classical machine learning remains a resource-intensive process. Practical computational efforts for training state-of-the-art models can now only be handled by high speed computer hardware. As this trend is expected to continue, it should come as no surprise that an increasing number of machine learning researchers are investigating the possible advantages of quantum computing. The scientific literature on Quantum Machine Learning is now enormous, and a review of its current state that can be comprehended without a physics background is necessary. The objective of this study is to present a review of Quantum Machine Learning from the perspective of conventional techniques. Departing from giving a research path from fundamental quantum theory through Quantum Machine Learning algorithms from a computer scientist’s perspective, we discuss a set of basic algorithms for Quantum Machine Learning, which are the fundamental components for Quantum Machine Learning algorithms. We implement the Quanvolutional Neural Networks (QNNs) on a quantum computer to recognize handwritten digits, and compare its performance to that of its classical counterpart, the Convolutional Neural Networks (CNNs). Additionally, we implement the QSVM on the breast cancer dataset and compare it to the classical SVM. Finally, we implement the Variational Quantum Classifier (VQC) and many classical classifiers on the Iris dataset to compare their accuracies."
2021,Deep CNN Model based on VGG16 for Breast Cancer Classification,"Deep learning (DL) technologies are becoming a buzzword these days, especially for breast histopathology image tasks, such as diagnosing, due to the high performance obtained in image classification. Among deep learning types, Convolutional Neural Networks (CNN) are the most common types of DL models utilized for medical image diagnosis and analysis. However, CNN suffers from high computation cost to be implemented and may require to adapt huge number of parameters. Thus, and in order to address this issue; several pre-trained models have been established with the predefined network architecture. In this study, a transfer learning model based on Visual Geometry Group with 16-layer deep model architecture (VGG16) is utilized to extract high-level features from the BreaKHis benchmark histopathological images dataset. Then, multiple machine learning models (classifiers) are used to handle different Breast Cancer (BC) histopathological image classification tasks mainly: binary and multiclass with eight-class classifications. The experimental results on the public BreakHis benchmark dataset demonstrate that the proposed models are better than the previous works on the same dataset. Besides, the results show that the proposed models are able to outperform recent classical machine learning algorithms."
2020,Boosted EfficientNet: Detection of Lymph Node Metastases in Breast Cancer Using Convolutional Neural Networks,"Simple Summary The assistance of computer image analysis that automatically identifies tissue or cell types has greatly improved histopathologic interpretation and diagnosis accuracy. In this paper, the Convolutional Neural Network (CNN) has been adapted to predict and classify lymph node metastasis in breast cancer. We observe that image resolutions of lymph node metastasis datasets in breast cancer usually are quite smaller than the designed model input resolution, which defects the performance of the proposed model. To mitigate this problem, we propose a boosted CNN architecture and a novel data augmentation method called Random Center Cropping (RCC). Different from traditional image cropping methods only suitable for resolution images in large scale, RCC not only enlarges the scale of datasets but also preserves the resolution and the center area of images. In addition, the downsampling scale of the network is diminished to be more suitable for small resolution images. Furthermore, we introduce attention and feature fusion mechanisms to enhance the semantic information of image features extracted by CNN. Experiments illustrate that our methods significantly boost performance of fundamental CNN architectures, where the best-performed method achieves an accuracy of 97.96% ± 0.03% and an Area Under the Curve (AUC) of 99.68% ± 0.01% in Rectified Patch Camelyon (RPCam) datasets, respectively. Abstract (1) Purpose: To improve the capability of EfficientNet, including developing a cropping method called Random Center Cropping (RCC) to retain the original image resolution and significant features on the images’ center area, reducing the downsampling scale of EfficientNet to facilitate the small resolution images of RPCam datasets, and integrating attention and Feature Fusion (FF) mechanisms with EfficientNet to obtain features containing rich semantic information. (2) Methods: We adopt the Convolutional Neural Network (CNN) to detect and classify lymph node metastasis in breast cancer. (3) Results: Experiments illustrate that our methods significantly boost performance of basic CNN architectures, where the best-performed method achieves an accuracy of 97.96% ± 0.03% and an Area Under the Curve (AUC) of 99.68% ± 0.01% on RPCam datasets, respectively. (4) Conclusions: (1) To our limited knowledge, we are the only study to explore the power of EfficientNet on Metastatic Breast Cancer (MBC) classification, and elaborate experiments are conducted to compare the performance of EfficientNet with other state-of-the-art CNN models. It might provide inspiration for researchers who are interested in image-based diagnosis using Deep Learning (DL). (2) We design a novel data augmentation method named RCC to promote the data enrichment of small resolution datasets. (3) All of our four technological improvements boost the performance of the original EfficientNet."
2021,Preprocessing of Breast Cancer Images to Create Datasets for Deep-CNN,"Breast cancer is the most diagnosed cancer in Australia with crude incidence rates increasing drastically from 62.8 at ages 35–39 to 271.4 at ages 50–54 (cases per 100,000 women). Various researchers have proposed methods and tools based on Machine Learning and Convolutional Neural Networks for assessing mammographic images, but these methods have produced detection and interpretation errors resulting in false-positive and false-negative cases when used in the real world. We believe that this problem can potentially be resolved by implementing effective image pre-processing techniques to create training data for Deep-CNN. Therefore, the main aim of this research is to propose effective image pre-processing methods to create datasets that can save computational time for the neural network and improve accuracy and classification rates. To do so, this research proposes methods for background removal, pectoral muscle removal, adding noise to the images, and image enhancements. Adding noise without affecting the quality of details in the images makes the input images for the neural network more representative, which may improve the performance of the neural network model when used in the real world. The proposed method for background removal is the “Rolling Ball Algorithm” and “Huang’s Fuzzy Thresholding”, which succeed in removing background from 100% of the images. For pectoral muscle removal “Canny Edge Detection” and “Hough’s Line Transform” are used, which removed muscle from 99.06% of the images. “Invert”, “CTI_RAS” and “ISOCONTOUR” lookup tables (LUTs) were used for image enhancements to outline the ROIs and regions within the ROIs."
2016,Microscopic medical image classification framework via deep learning and shearlet transform,"Abstract. Cancer is the second leading cause of death in US after cardiovascular disease. Image-based computer-aided diagnosis can assist physicians to efficiently diagnose cancers in early stages. Existing computer-aided algorithms use hand-crafted features such as wavelet coefficients, co-occurrence matrix features, and recently, histogram of shearlet coefficients for classification of cancerous tissues and cells in images. These hand-crafted features often lack generalizability since every cancerous tissue and cell has a specific texture, structure, and shape. An alternative approach is to use convolutional neural networks (CNNs) to learn the most appropriate feature abstractions directly from the data and handle the limitations of hand-crafted features. A framework for breast cancer detection and prostate Gleason grading using CNN trained on images along with the magnitude and phase of shearlet coefficients is presented. Particularly, we apply shearlet transform on images and extract the magnitude and phase of shearlet coefficients. Then we feed shearlet features along with the original images to our CNN consisting of multiple layers of convolution, max pooling, and fully connected layers. Our experiments show that using the magnitude and phase of shearlet coefficients as extra information to the network can improve the accuracy of detection and generalize better compared to the state-of-the-art methods that rely on hand-crafted features. This study expands the application of deep neural networks into the field of medical image analysis, which is a difficult domain considering the limited medical data available for such analysis."
2019,Breast Cancer Diagnosis with Transfer Learning and Global Pooling,"Breast cancer is one of the most common causes of cancer-related death in women worldwide. Early and accurate diagnosis of breast cancer may significantly increase the survival rate of patients. In this study, we aim to develop a fully automatic, deep learning-based, method using descriptor features extracted by Deep Convolutional Neural Network (DCNN) models and pooling operation for the classification of hematoxylin and eosin stain (H#E) histological breast cancer images provided as a part of the International Conference on Image Analysis and Recognition (ICIAR) 2018 Grand Challenge on BreAst Cancer Histology (BACH) Images. Different data augmentation methods are applied to optimize the DCNN performance. We also investigated the efficacy of different stain normalization methods as a pre-processing step. The proposed network architecture using a pre-trained Xception model yields 92.50% average classification accuracy."
2018,Use of clinical MRI maximum intensity projections for improved breast lesion classification with deep convolutional neural networks,"Abstract. Deep learning methods have been shown to improve breast cancer diagnostic and prognostic decisions based on selected slices of dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI). However, incorporation of volumetric and temporal components into DCE-MRIs has not been well studied. We propose maximum intensity projection (MIP) images of subtraction MRI as a way to simultaneously include four-dimensional (4-D) images into lesion classification using convolutional neural networks (CNN). The study was performed on a dataset of 690 cases. Regions of interest were selected around each lesion on three MRI presentations: (i) the MIP image generated on the second postcontrast subtraction MRI, (ii) the central slice of the second postcontrast MRI, and (iii) the central slice of the second postcontrast subtraction MRI. CNN features were extracted from the ROIs using pretrained VGGNet. The features were utilized in the training of three support vector machine classifiers to characterize lesions as malignant or benign. Classifier performances were evaluated with fivefold cross-validation and compared based on area under the ROC curve (AUC). The approach using MIPs [AUC=0.88(se=0.01)] outperformed that using central-slices of either second postcontrast MRIs [0.80(se=0.02)] or second postcontrast subtraction MRIs [AUC=0.84(se=0.02)], at statistically significant levels."
2017,Deep learning in breast cancer risk assessment: evaluation of convolutional neural networks on a clinical dataset of full-field digital mammograms,"Abstract. To evaluate deep learning in the assessment of breast cancer risk in which convolutional neural networks (CNNs) with transfer learning are used to extract parenchymal characteristics directly from full-field digital mammographic (FFDM) images instead of using computerized radiographic texture analysis (RTA), 456 clinical FFDM cases were included: a “high-risk” BRCA1/2 gene-mutation carriers dataset (53 cases), a “high-risk” unilateral cancer patients dataset (75 cases), and a “low-risk dataset” (328 cases). Deep learning was compared to the use of features from RTA, as well as to a combination of both in the task of distinguishing between high- and low-risk subjects. Similar classification performances were obtained using CNN [area under the curve (AUC)=0.83; standard error (SE)=0.03] and RTA (AUC=0.82; SE=0.03) in distinguishing BRCA1/2 carriers and low-risk women. However, in distinguishing unilateral cancer patients and low-risk women, performance was significantly greater with CNN (AUC=0.82; SE=0.03) compared to RTA (AUC=0.73; SE=0.03). Fusion classifiers performed significantly better than the RTA-alone classifiers with AUC values of 0.86 and 0.84 in differentiating BRCA1/2 carriers from low-risk women and unilateral cancer patients from low-risk women, respectively. In conclusion, deep learning extracted parenchymal characteristics from FFDMs performed as well as, or better than, conventional texture analysis in the task of distinguishing between cancer risk populations."
2016,MO-DE-207B-06: Computer-Aided Diagnosis of Breast Ultrasound Images Using Transfer Learning From Deep Convolutional Neural Networks.,"PURPOSE To assess the performance of using transferred features from pre-trained deep convolutional networks (CNNs) in the task of classifying cancer in breast ultrasound images, and to compare this method of transfer learning with previous methods involving human-designed features. METHODS A breast ultrasound dataset consisting of 1125 cases and 2393 regions of interest (ROIs) was used. Each ROI was labeled as cystic, benign, or malignant. Features were extracted from each ROI using pre-trained CNNs and used to train support vector machine (SVM) classifiers in the tasks of distinguishing non-malignant (benign+cystic) vs malignant lesions and benign vs malignant lesions. For a baseline comparison, classifiers were also trained on prior analytically-extracted tumor features. Five-fold cross-validation (by case) was conducted with the area under the receiver operating characteristic curve (AUC) as the performance metric. RESULTS Classifiers trained on CNN-extracted features were comparable to classifiers trained on human-designed features. In the non-malignant vs malignant task, both the SVM trained on CNN-extracted features and the SVM trained on human-designed features obtained an AUC of 0.90. In the task of determining benign vs malignant, the SVM trained on CNN-extracted features obtained an AUC of 0.88, compared to the AUC of 0.85 obtained by the SVM trained on human-designed features. CONCLUSION We obtained strong results using transfer learning to characterize ultrasound breast cancer images. This method allows us to directly classify a small dataset of lesions in a computationally inexpensive fashion without any manual input. Modern deep learning methods in computer vision are contingent on large datasets and vast computational resources, which are often inaccessible for clinical applications. Consequently, we believe transfer learning methods will be important for computer-aided diagnosis schemes in order to utilize advancements in deep learning and computer vision without the associated costs. This work was partially funded by NIH grant U01 CA195564 and the University of Chicago Metcalf program. M.L.G. is a stockholder in R2/Hologic, co-founder and equity holder in Quantitative Insights, and receives royalties from Hologic, GE Medical Systems, MEDIAN Technologies, Riverain Medical, Mitsubishi, and Toshiba. K.D. received royalties from Hologic."
2022,Effective Class-Imbalance learning based on SMOTE and Convolutional Neural Networks,"Imbalanced Data (ID) is a problem that deters Machine Learning (ML) models from achieving satisfactory results. ID is the occurrence of a situation where the quantity of the samples belonging to one class outnumbers that of the other by a wide margin, making such models’ learning process biased towards the majority class. In recent years, to address this issue, several solutions have been put forward, which opt for either synthetically generating new data for the minority class or reducing the number of majority classes to balance the data. Hence, in this paper, we investigate the effectiveness of methods based on Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs) mixed with a variety of well-known imbalanced data solutions meaning oversampling and undersampling. Then, we propose a CNN-based model in combination with SMOTE to effectively handle imbalanced data. To evaluate our methods, we have used KEEL, breast cancer, and Z-Alizadeh Sani datasets. In order to achieve reliable results, we conducted our experiments 100 times with randomly shuffled data distributions. The classification results demonstrate that the mixed Synthetic Minority Oversampling Technique (SMOTE)-Normalization-CNN outperforms different methodologies achieving 99.08% accuracy on the 24 imbalanced datasets. Therefore, the proposed mixed model can be applied to imbalanced binary classification problems on other real datasets."
2020,A Deep-Learning Approach for Diagnosis of Metastatic Breast Cancer in Bones from Whole-Body Scans,"(1) Background: Bone metastasis is one of the most frequent diseases in breast, lung and prostate cancer; bone scintigraphy is the primary imaging method of screening that offers the highest sensitivity (95%) regarding metastases. To address the considerable problem of bone metastasis diagnosis, focused on breast cancer patients, artificial intelligence methods devoted to deep-learning algorithms for medical image analysis are investigated in this research work; (2) Methods: Deep learning is a powerful algorithm for automatic classification and diagnosis of medical images whereas its implementation is achieved by the use of convolutional neural networks (CNNs). The purpose of this study is to build a robust CNN model that will be able to classify images of whole-body scans in patients suffering from breast cancer, depending on whether or not they are infected by metastasis of breast cancer; (3) Results: A robust CNN architecture is selected based on CNN exploration performance for bone metastasis diagnosis using whole-body scan images, achieving a high classification accuracy of 92.50%. The best-performing CNN method is compared with other popular and well-known CNN architectures for medical imaging like ResNet50, VGG16, MobileNet, and DenseNet, reported in the literature, providing superior classification accuracy; and (4) Conclusions: Prediction results show the efficacy of the proposed deep learning approach in bone metastasis diagnosis for breast cancer patients in nuclear medicine."
2022,Intelligent Hybrid Deep Learning Model for Breast Cancer Detection,"Breast cancer (BC) is a type of tumor that develops in the breast cells and is one of the most common cancers in women. Women are also at risk from BC, the second most life-threatening disease after lung cancer. The early diagnosis and classification of BC are very important. Furthermore, manual detection is time-consuming, laborious work, and, possibility of pathologist errors, and incorrect classification. To address the above highlighted issues, this paper presents a hybrid deep learning (CNN-GRU) model for the automatic detection of BC-IDC (+,−) using whole slide images (WSIs) of the well-known PCam Kaggle dataset. In this research, the proposed model used different layers of architectures of CNNs and GRU to detect breast IDC (+,−) cancer. The validation tests for quantitative results were carried out using each performance measure (accuracy (Acc), precision (Prec), sensitivity (Sens), specificity (Spec), AUC and F1-Score. The proposed model shows the best performance measures (accuracy 86.21%, precision 85.50%, sensitivity 85.60%, specificity 84.71%, F1-score 88%, while AUC 0.89 which overcomes the pathologist’s error and miss classification problem. Additionally, the efficiency of the proposed hybrid model was tested and compared with CNN-BiLSTM, CNN-LSTM, and current machine learning and deep learning (ML/DL) models, which indicated that the proposed hybrid model is more robust than recent ML/DL approaches."
2019,Breast Cancer Classification in Ultrasound Images using Transfer Learning,"Computer-aided detection of malignant breast tumors in ultrasound images has been receiving growing attention. In this paper, we propose a deep learning methodology to tackle this problem. The training data, which contains several hundred images of benign and malignant cases, was used to train a deep convolutional neural network (CNN). Three training approaches are proposed: a baseline approach where the CNN architecture is trained from scratch, a transfer-learning approach where the pre-trained VGG16 CNN architecture is further trained with the ultrasound images, and a fine-tuned learning approach where the deep learning parameters are fine-tuned to overcome overfitting. The experimental results demonstrate that the fine-tuned model had the best performance (0.97 accuracy, 0.98 AUC), with pre-training on US images. Creating pre-trained models using medical imaging data would certainly improve deep learning outcomes in biomedical applications."
2021,Multi- class classification of breast cancer abnormalities using Deep Convolutional Neural Network (CNN),"The real cause of breast cancer is very challenging to determine and therefore early detection of the disease is necessary for reducing the death rate due to risks of breast cancer. Early detection of cancer boosts increasing the survival chance up to 8%. Primarily, breast images emanating from mammograms, X-Rays or MRI are analyzed by radiologists to detect abnormalities. However, even experienced radiologists face problems in identifying features like micro-calcifications, lumps and masses, leading to high false positive and high false negative. Recent advancement in image processing and deep learning create some hopes in devising more enhanced applications that can be used for the early detection of breast cancer. In this work, we have developed a Deep Convolutional Neural Network (CNN) to segment and classify the various types of breast abnormalities, such as calcifications, masses, asymmetry and carcinomas, unlike existing research work, which mainly classified the cancer into benign and malignant, leading to improved disease management. Firstly, a transfer learning was carried out on our dataset using the pre-trained model ResNet50. Along similar lines, we have developed an enhanced deep learning model, in which learning rate is considered as one of the most important attributes while training the neural network. The learning rate is set adaptively in our proposed model based on changes in error curves during the learning process involved. The proposed deep learning model has achieved a performance of 88% in the classification of these four types of breast cancer abnormalities such as, masses, calcifications, carcinomas and asymmetry mammograms."
2017,Convolutional Neural Network for Histopathological Analysis of Osteosarcoma,"Pathologists often deal with high complexity and sometimes disagreement over osteosarcoma tumor classification due to cellular heterogeneity in the dataset. Segmentation and classification of histology tissue in H&E stained tumor image datasets is a challenging task because of intra-class variations, inter-class similarity, crowded context, and noisy data. In recent years, deep learning approaches have led to encouraging results in breast cancer and prostate cancer analysis. In this article, we propose convolutional neural network (CNN) as a tool to improve efficiency and accuracy of osteosarcoma tumor classification into tumor classes (viable tumor, necrosis) versus nontumor. The proposed CNN architecture contains eight learned layers: three sets of stacked two convolutional layers interspersed with max pooling layers for feature extraction and two fully connected layers with data augmentation strategies to boost performance. The use of a neural network results in higher accuracy of average 92% for the classification. We compare the proposed architecture with three existing and proven CNN architectures for image classification: AlexNet, LeNet, and VGGNet. We also provide a pipeline to calculate percentage necrosis in a given whole slide image. We conclude that the use of neural networks can assure both high accuracy and efficiency in osteosarcoma classification."
2022,Medical Internet-of-Things Based Breast Cancer Diagnosis Using Hyperparameter-Optimized Neural Networks,"In today’s healthcare setting, the accurate and timely diagnosis of breast cancer is critical for recovery and treatment in the early stages. In recent years, the Internet of Things (IoT) has experienced a transformation that allows the analysis of real-time and historical data using artificial intelligence (AI) and machine learning (ML) approaches. Medical IoT combines medical devices and AI applications with healthcare infrastructure to support medical diagnostics. The current state-of-the-art approach fails to diagnose breast cancer in its initial period, resulting in the death of most women. As a result, medical professionals and researchers are faced with a tremendous problem in early breast cancer detection. We propose a medical IoT-based diagnostic system that competently identifies malignant and benign people in an IoT environment to resolve the difficulty of identifying early-stage breast cancer. The artificial neural network (ANN) and convolutional neural network (CNN) with hyperparameter optimization are used for malignant vs. benign classification, while the Support Vector Machine (SVM) and Multilayer Perceptron (MLP) were utilized as baseline classifiers for comparison. Hyperparameters are important for machine learning algorithms since they directly control the behaviors of training algorithms and have a significant effect on the performance of machine learning models. We employ a particle swarm optimization (PSO) feature selection approach to select more satisfactory features from the breast cancer dataset to enhance the classification performance using MLP and SVM, while grid-based search was used to find the best combination of the hyperparameters of the CNN and ANN models. The Wisconsin Diagnostic Breast Cancer (WDBC) dataset was used to test the proposed approach. The proposed model got a classification accuracy of 98.5% using CNN, and 99.2% using ANN."
2020,Artificial Neural Network Based Breast Cancer Screening: A Comprehensive Review,"Breast cancer is a common fatal disease for women. Early diagnosis and detection is necessary in order to improve the prognosis of breast cancer affected people. For predicting breast cancer, several automated systems are already developed using different medical imaging modalities. This paper provides a systematic review of the literature on artificial neural network (ANN) based models for the diagnosis of breast cancer via mammography. The advantages and limitations of different ANN models including spiking neural network (SNN), deep belief network (DBN), convolutional neural network (CNN), multilayer neural network (MLNN), stacked autoencoders (SAE), and stacked de-noising autoencoders (SDAE) are described in this review. The review also shows that the studies related to breast cancer detection applied different deep learning models to a number of publicly available datasets. For comparing the performance of the models, different metrics such as accuracy, precision, recall, etc. were used in the existing studies. It is found that the best performance was achieved by residual neural network (ResNet)-50 and ResNet-101 models of CNN algorithm."
2022,A Deep Learning Method for Breast Cancer Classification in the Pathology Images,"Objective: Breast cancer is the most common female cancer in the world, and it poses a huge threat to women's health. There is currently promising research concerning its early diagnosis using deep learning methodologies. However, some commonly used Convolutional Neural Network (CNN) and their variations, such as AlexNet, VGGNet, GoogleNet and so on, are prone to overfitting in breast cancer classification, due to both small-scale breast pathology image datasets and overconfident softmax-cross-entropy loss. To alleviate the overfitting issue for better classification accuracy, we propose a novel framework for breast pathology classification, called the AlexNet-BC model. The model is pre-trained using the ImageNet dataset and fine-tuned using an augmented dataset. We also devise an improved cross-entropy loss function to penalize overconfident low-entropy output distributions and make the predictions suitable for uniform distributions. The proposed approach is then validated through a series of comparative experiments on BreaKHis, IDC and UCSB datasets. The experimental results show that the proposed method outperforms the state-of-the-art methods at different magnifications. Its strong robustness and generalization capabilities make it suitable for histopathology clinical computer-aided diagnosis systems."
2019,Convolutional neural network for cell classification using microscope images of intracellular actin networks,"Automated cell classification is an important yet a challenging computer vision task with significant benefits to biomedicine. In recent years, there have been several studies attempted to build an artificial intelligence-based cell classifier using label-free cellular images obtained from an optical microscope. Although these studies showed promising results, such classifiers were not able to reflect the biological diversity of different types of cell. While in terms of malignant cell, it is well-known that intracellular actin filaments are altered substantially. This is thought to be closely related to the abnormal growth features of tumor cells, their ability to invade surrounding tissues and also to metastasize. Therefore, being able to classify different types of cell based on their biological behaviors using automated technique is more advantageous. This article reveals the difference in the actin cytoskeleton structures between breast normal and cancer cells, which may provide new information regarding malignant changes and be used as additional diagnostic marker. Since the features cannot be well detected by human eyes, we proposed the application of convolutional neural network (CNN) in cell classification based on actin-labeled fluorescence microscopy images. The CNN was evaluated on a large number of actin-labeled fluorescence microscopy images of one human normal breast epithelial cell line and two types of human breast cancer cell line with different levels of aggressiveness. The study revealed that the CNN performed better in the cell classification task compared to a human expert."
2021,Review of Breast Cancer Pathologigcal Image Processing,"Breast cancer is one of the most common malignancies. Pathological image processing of breast has become an important means for early diagnosis of breast cancer. Using medical image processing to assist doctors to detect potential breast cancer as early as possible has always been a hot topic in the field of medical image diagnosis. In this paper, a breast cancer recognition method based on image processing is systematically expounded from four aspects: breast cancer detection, image segmentation, image registration, and image fusion. The achievements and application scope of supervised learning, unsupervised learning, deep learning, CNN, and so on in breast cancer examination are expounded. The prospect of unsupervised learning and transfer learning for breast cancer diagnosis is prospected. Finally, the privacy protection of breast cancer patients is put forward."
2020,Breast Cancer Classification Using Deep Learning Approaches and Histopathology Image: A Comparison Study,"Convolutional Neural Network (CNN) models are a type of deep learning architecture introduced to achieve the correct classification of breast cancer. This paper has a two-fold purpose. The first aim is to investigate the various deep learning models in classifying breast cancer histopathology images. This study identified the most accurate models in terms of the binary, four, and eight classifications of breast cancer histopathology image databases. The different accuracy scores obtained for the deep learning models on the same database showed that other factors such as pre-processing, data augmentation, and transfer learning methods can impact the ability of the models to achieve higher accuracy. The second purpose of our manuscript is to investigate the latest models that have no or limited examination done in previous studies. The models like ResNeXt, Dual Path Net, SENet, and NASNet had been identified with the most cutting-edge results for the ImageNet database. These models were examined for the binary, and eight classifications on BreakHis, a breast cancer histopathology image database. Furthermore, the BACH database was used to investigate these models for four classifications. Then, these models were compared with the previous studies to find and propose the most state-of-the-art models for each classification. Since the Inception-ResNet-V2 architecture achieved the best results for binary and eight classifications, we have examined this model in our study as well to provide a better comparison result. In short, this paper provides an extensive evaluation and discussion about the experimental settings for each study that had been conducted on the breast cancer histopathology images."
2020,A Systematic Review of Breast Cancer Detection Using Thermography and Neural Networks,"Breast cancer plays a significant role in affecting female mortality. Researchers are actively seeking to develop early detection methods of breast cancer. Several technologies contributed to the reduction in mortality rate from this disease, but early detection contributes most to preventing disease spread, breast amputation and death. Thermography is a promising technology for early diagnosis where thermal cameras employed are of high resolution and sensitivity. The combination of Artificial Intelligence (AI) with thermal images is an effective tool to detect early stage breast cancer and is foreseen to provide impressive predictability levels. This paper reviews systematically the related works employing thermography with AI highlighting their contributions and drawbacks and proposing open issues for research. Several different types of Artificial Neural Networks (ANNs) and deep learning models were used in the literature to process thermographic images of breast cancer, such as Radial Basis Function Network (RBFN), K-Nearest Neighbors (KNN), Probability Neural Network (PNN), Support Vector Machine (SVM), ResNet50, SeResNet50, V Net, Bayes Net, Convolutional Neural Networks (CNN), Convolutional and DeConvolutional Neural Networks (C-DCNN), VGG-16, Hybrid (ResNet-50 and V-Net), ResNet101, DenseNet and InceptionV3. Previous studies were found limited to varying the numbers of thermal images used mostly from DMR-IR database. In addition, analysis of the literature indicate that several factors do affect the performance of the Neural Network used, such as Database, optimization method, Network model and extracted features. However, due to small sample size used, most of the studies achieved a classification accuracy of 80% to 100%."
2017,Computer-aided mammogram diagnosis system using deep learning convolutional fully complex-valued relaxation neural network classifier,"In this study, a novel deep learning-based framework for classifying the digital mammograms is introduced. The development of this methodology is based on deep learning strategies that model the presence of the tumour tissues with level sets. It is difficult to robustly segment mammogram image due to low contrast between normal and lesion tissues. Therefore, Chan-Vese level set method is used to extract the initial contour of mammograms and deep learning convolutional neural network (DL-CNN) algorithm is used to learn the features of mammary-specific mass and microcalcification clusters. To increase the classification accuracy and reduce the false positives, a well-known fully complex-valued relaxation network classifier is used in the last stage of DL-CNN network. Experimental results using the standard benchmarking breast cancer dataset (MIAS and BCDR) show that the proposed method exhibits significant improvement in performance over the traditional methods. Performance measures such as accuracy, sensitivity, specificity, AUC achieved are 99%, 0.9875, 1.0 and 0.9815, respectively. The proposed framework performs well in classifying the digital mammograms as normal, benign or malignant and its subclasses as well."
2018,A deep learning classifier for prediction of pathological complete response to neoadjuvant chemotherapy from baseline breast DCE-MRI,"Neoadjuvant chemotherapy (NAC) is routinely used to treat breast tumors before surgery to reduce tumor size and improve outcome. However, no current clinical or imaging metrics can effectively predict before treatment which NAC recipients will achieve pathological complete response (pCR), the absence of residual invasive disease in the breast or lymph nodes following surgical resection. In this work, we developed and applied a convolu- tional neural network (CNN) to predict pCR from pre-treatment dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) scans on a per-voxel basis. In this study, DCE-MRI data for a total of 166 breast cancer pa- tients from the ISPY1 Clinical Trial were split into a training set of 133 patients and a testing set of 33 patients. A CNN consisting of 6 convolutional blocks was trained over 30 epochs. The pre-contrast and post-contrast DCE-MRI phases were considered in isolation and conjunction. A CNN utilizing a combination of both pre- and post-contrast images best distinguished responders, with an AUC of 0.77; 82% of the patients in the testing set were correctly classified based on their treatment response. Within the testing set, the CNN was able to produce probability heatmaps that visualized tumor regions that most strongly predicted therapeutic response. Multi- variate analysis with prognostic clinical variables (age, largest diameter, hormone receptor and HER2 status), revealed that the network was an independent predictor of response (p=0.05), and that the inclusion of HER2 status could further improve capability to predict response (AUC = 0.85, accuracy = 85%)."
2019,Breast Cancer Detection using Machine Learning Way,"Affording in the direction of Breast Cancer Organization, Breast Cancer is solitary and one and only of the most perilous sorts of viruses that is located operative for females in the biosphere. By way of experimental professional distinguishing this cancer in her initial phase aids in abiding breathes. Based on cancer.net proposal individualized funnels for additional 120 kinds of cancer and correlated to genetic diseases. Aimed At discovering breast cancer fundamentally AI rehearses are utilized. We have foreseen adaptive ensemble voting scheme for broke down breast cancer with WBC (Wisconsin Breast Cancer) record. Intention of our effort is to associate & describe in what way CNN and logistic algorithm afford used for detecting breast cancer yet the variables are condensed. Here remain 2 categories of tumours be situated. Benign tumour and malignant tumours, where benign tumour is non-cancer and malignant is cancer tumour"
2020,Deep Learning Applied for Histological Diagnosis of Breast Cancer,"Deep learning, as one of the currently most popular computer science research trends, improves neural networks, which has more and deeper layers allowing higher abstraction levels and more accurate data analysis. Although deep convolutional neural networks, as a deep learning algorithm, has recently achieved promising results in data analysis, the requirement for a large amount of data prevents its use in medical data analysis since it is challenging to obtain data from the medical field. Breast cancer is a common cancer in women. To diagnose this kind of cancer, breast cell shapes in histopathology images should be examined by senior pathologists. The number of pathologists per population in the world is not enough, especially in Africa, and human mistake may occur in diagnosis procedure. After the evaluation of deep learning methods and algorithms in breast histological data processing, we tried to improve the current systems’ accuracy. As a result, this study proposes two effective deep transfer learning-based models, which rely on pre-trained DCNN using a large collection of ImageNet dataset images that improve current state-of-the-art systems in both binary and multiclass classification. We transfer pre-trained weights of the ResNet50 and DesneNet121 on the Imagenet as initial weights and fine-tune these models with a deep classifier with data augmentation to detect various malignant and benign samples tissues in the two categories of binary classification and multiclass classification. The proposed models have been examined with optimized hyperparameters in magnification-dependent and magnification-independent classification modes. In the multiclass classification, the proposed system achieved up to 98% accuracy. As for binary classification, the proposed system provides up to 100% accuracy. The results outperform previous studies accuracies in all defined performance metrics in breast cancer CAD systems from histological images."
2016,Mitosis detection using convolutional neural network based features,"Breast cancer is the second leading cause of cancer death in women according to World Health Organization (WHO). Development of computer aided diagnostic (CAD) systems has great importance as a secondary reader systems for a correct diagnosis and treatment process. In this paper, a deep learning based feature extraction method by convolutional neural network (CNN) is proposed for automated mitosis detection for cancer diagnosis and grading by histopathological images. The proposed framework is tested on the MITOS data set provided for a contest on mitosis detection in breast cancer histological images released for research purposes in International Conference on Pattern Recognition (ICPR'2014). By using provided histopathological images, cellular structures are initially found by combined clustering based segmentation and blob analysis after preprocessing step. Then, obtained cellular image patches are cropped automatically from the histopathological images for feature extraction stage. CNN, which is a prominent deep learning method on image processing tasks, is utilized for extracting discriminative features. Due to the high dimensional output of the CNN, combination of PCA and LDA dimension reduction methods are performed respectively for regularization and dimension reduction process. Afterwards, a robust kernel based classifier, support vector machine (SVM), is used for final classification of mitotic and non-mitotic cells. The test results on MITOS data set prove that the proposed framework achieved promising results for mitosis detection on histopathological images."
2020,Breast Cancer Image Classification via Multi-Network Features and Dual-Network Orthogonal Low-Rank Learning,"Histopathological image analysis is an important technique for early diagnosis and detection of breast cancer in clinical practice. However, it has limited efficiency and thus the detection of breast cancer is still an open issue in medical image analysis. To improve the early diagnostic accuracy of breast cancer and reduce the workload of doctors, we devise a classification framework based on histology images by combining deep learning with machine learning methodologies in this paper. Specifically, we devise a multi-network feature extraction model by using pre-trained deep convolution neural networks (DCNNs), develop an effective feature dimension reduction method and train an ensemble support vector machine (E-SVM). First, we preprocess the histological images via scale transformation and color enhancement methods. Second, the multi-network features are extracted by using four pre-trained DCNNs (e.g., DenseNet-121, ResNet-50, multi-level InceptionV3, and multi-level VGG-16). Third, a feature selection method via dual-network orthogonal low-rank learning (DOLL) is further developed for performance boosting and overfitting alleviation. Finally, an E-SVM is trained via fused features and voting strategy to perform the classification task, which classifies the images into four classes (i.e., benign, in situ carcinomas, invasive carcinomas, and normal). We evaluate the proposed method on the public ICIAR 2018 Challenge dataset of histology images of breast cancer and achieve a high classification accuracy of 97.70%. Experimental results show that our method can achieve quite promising performance and outperform state-of-the-art methods."
2022,Breast Tumour Classification Using Ultrasound Elastography with Machine Learning: A Systematic Scoping Review,"Simple Summary Breast cancer is one of the most common cancers among women globally. Early and accurate screening of breast tumours can improve survival. Ultrasound elastography is a non-invasive and non-ionizing imaging approach to characterize lesions for breast cancer screening, while machine learning techniques could improve the accuracy and reliability of computer-aided diagnosis. This review focuses on the state-of-the-art development and application of the machine learning model in breast tumour classification. Abstract Ultrasound elastography can quantify stiffness distribution of tissue lesions and complements conventional B-mode ultrasound for breast cancer screening. Recently, the development of computer-aided diagnosis has improved the reliability of the system, whilst the inception of machine learning, such as deep learning, has further extended its power by facilitating automated segmentation and tumour classification. The objective of this review was to summarize application of the machine learning model to ultrasound elastography systems for breast tumour classification. Review databases included PubMed, Web of Science, CINAHL, and EMBASE. Thirteen (n = 13) articles were eligible for review. Shear-wave elastography was investigated in six articles, whereas seven studies focused on strain elastography (5 freehand and 2 Acoustic Radiation Force). Traditional computer vision workflow was common in strain elastography with separated image segmentation, feature extraction, and classifier functions using different algorithm-based methods, neural networks or support vector machines (SVM). Shear-wave elastography often adopts the deep learning model, convolutional neural network (CNN), that integrates functional tasks. All of the reviewed articles achieved sensitivity ≥80%, while only half of them attained acceptable specificity ≥95%. Deep learning models did not necessarily perform better than traditional computer vision workflow. Nevertheless, there were inconsistencies and insufficiencies in reporting and calculation, such as the testing dataset, cross-validation, and methods to avoid overfitting. Most of the studies did not report loss or hyperparameters. Future studies may consider using the deep network with an attention layer to locate the targeted object automatically and online training to facilitate efficient re-training for sequential data."
2019,Deep Learning for Semantic Segmentation vs. Classification in Computational Pathology: Application to Mitosis Analysis in Breast Cancer Grading,"Existing computational approaches have not yet resulted in effective and efficient computer-aided tools that are used in pathologists' daily practice. Focusing on a computer-based qualification for breast cancer diagnosis, the present study proposes two deep learning architectures to efficiently and effectively detect and classify mitosis in a histopathological tissue sample. The first method consists of two parts, entailing a preprocessing of the digital histological image and a free-handcrafted-feature Convolutional Neural Network (CNN) used for binary classification. Results show that the methodology proposed can achieve 95% accuracy in testing, with an F1-score of 94.35%. This result is higher than the results using classical image processing techniques and also higher than the approaches combining CCNs with handcrafted features. The second approach is an end-to-end methodology using semantic segmentation. Results showed that this algorithm can achieve an accuracy higher than 95% in testing and an average Dice index of 0.6, higher than the existing results using CNNs (0.9 F1-score). Additionally, due to the semantic properties of the deep learning approach, an end-to-end deep learning framework is viable to perform both tasks: detection and classification of mitosis. The results show the potential of deep learning in the analysis of Whole Slide Images (WSI) and its integration to computer-aided systems. The extension of this work to whole slide images is also addressed in the last sections; as well as, some computational key points that are useful when constructing a computer-aided-system inspired by the proposed technology."
2023,Vision-Transformer-Based Transfer Learning for Mammogram Classification,"Breast mass identification is a crucial procedure during mammogram-based early breast cancer diagnosis. However, it is difficult to determine whether a breast lump is benign or cancerous at early stages. Convolutional neural networks (CNNs) have been used to solve this problem and have provided useful advancements. However, CNNs focus only on a certain portion of the mammogram while ignoring the remaining and present computational complexity because of multiple convolutions. Recently, vision transformers have been developed as a technique to overcome such limitations of CNNs, ensuring better or comparable performance in natural image classification. However, the utility of this technique has not been thoroughly investigated in the medical image domain. In this study, we developed a transfer learning technique based on vision transformers to classify breast mass mammograms. The area under the receiver operating curve of the new model was estimated as 1 ± 0, thus outperforming the CNN-based transfer-learning models and vision transformer models trained from scratch. The technique can, hence, be applied in a clinical setting, to improve the early diagnosis of breast cancer."
2021,MCUa: Multi-Level Context and Uncertainty Aware Dynamic Deep Ensemble for Breast Cancer Histology Image Classification,"Breast histology image classification is a crucial step in the early diagnosis of breast cancer. In breast pathological diagnosis, Convolutional Neural Networks (CNNs) have demonstrated great success using digitized histology slides. However, tissue classification is still challenging due to the high visual variability of the large-sized digitized samples and the lack of contextual information. In this paper, we propose a novel CNN, called Multi-level Context and Uncertainty aware (MCUa) dynamic deep learning ensemble model. MCUa model consists of several multi-level context-aware models to learn the spatial dependency between image patches in a layer-wise fashion. It exploits the high sensitivity to the multi-level contextual information using an uncertainty quantification component to accomplish a novel dynamic ensemble model. MCUa model has achieved a high accuracy of 98.11% on a breast cancer histology image dataset. Experimental results show the superior effectiveness of the proposed solution compared to the state-of-the-art histology classification models."
2017,Using deep learning for mammography classification,"Breast biopsies based on the results of mammography and ultrasound have been diagnosed as benign at a rate of approximately 40 to 60 percent. Negative biopsy results have negative impacts on many aspects such as unnecessary operations, fear, pain, and cost. Therefore, there is a need for a more reliable technique to reduce the number of unnecessary biopsies in the diagnosis of breast cancer. So, computer-aided diagnostic methods are very important for doctors to make more accurate decisions and to avoid unnecessary biopsies. For this purpose, we apply deep learning using Convolutional Neural Networks (CNN) to classify abnormalities as benign or malignant in mammogram images by using two different databases namely, mini-MIAS and BCDR. While mini-MIAS database has valuable information like location of the center of abnormality and radius of the circle that surrounds the abnormality, BCDR database does not have. When we use both dataset as they are, we observe accuracy, precision, recall, and f-score values between around 60% and 72%. In order to improve our results, we take the benefit of preprocessing methods containing cropping, augmentation, and balancing image data. In an effort to crop image data sourced from BCDR, we create a mask to find region of interest. After applying our preprocessing methods over the BCDR dataset, we observe that classification accuracy improves from 65% to around 85%. When we compare the classification accuracy, precision, recall and f-score obtained from the MIAS database with those obtained from the BCDR database we found that after applying preprocessing methods to BCDR dataset, the classification performance become very close to each other for the two datasets."
2021,Prediction of BRCA Gene Mutation in Breast Cancer Based on Deep Learning and Histopathology Images,"Background Breast cancer is one of the most common cancers and the leading cause of death from cancer among women worldwide. The genetic predisposition to breast cancer may be associated with a mutation in particular genes such as gene BRCA1/2. Patients who carry a germline pathogenic mutation in BRCA1/2 genes have a significantly increased risk of developing breast cancer and might benefit from targeted therapy. However, genetic testing is time consuming and costly. This study aims to predict the risk of gBRCA mutation by using the whole-slide pathology features of breast cancer H&E stains and the patients’ gBRCA mutation status. Methods In this study, we trained a deep convolutional neural network (CNN) of ResNet on whole-slide images (WSIs) to predict the gBRCA mutation in breast cancer. Since the dimensions are too large for slide-based training, we divided WSI into smaller tiles with the original resolution. The tile-based classification was then combined by adding the positive classification result to generate the combined slide-based accuracy. Models were trained based on the annotated tumor location and gBRCA mutation status labeled by a designated breast cancer pathologist. Four models were trained on tiles cropped at 5×, 10×, 20×, and 40× magnification, assuming that low magnification and high magnification may provide different levels of information for classification. Results A trained model was validated through an external dataset that contains 17 mutants and 47 wilds. In the external validation dataset, AUCs (95% CI) of DL models that used 40×, 20×, 10×, and 5× magnification tiles among all cases were 0.766 (0.763–0.769), 0.763 (0.758–0.769), 0.750 (0.738–0.761), and 0.551 (0.526–0.575), respectively, while the corresponding magnification slides among all cases were 0.774 (0.642–0.905), 0.804 (0.676–0.931), 0.828 (0.691–0.966), and 0.635 (0.471–0.798), respectively. The study also identified the influence of histological grade to the accuracy of the prediction. Conclusion In this paper, the combination of pathology and molecular omics was used to establish the gBRCA mutation risk prediction model, revealing the correlation between the whole-slide histopathological images and gRCA mutation risk. The results indicated that the prediction accuracy is likely to improve as the training data expand. The findings demonstrated that deep CNNs could be used to assist pathologists in the detection of gene mutation in breast cancer."
2020,CNN-Based Quality Assurance for Automatic Segmentation of Breast Cancer in Radiotherapy,"Purpose: More and more automatic segmentation tools are being introduced in routine clinical practice. However, physicians need to spend a considerable amount of time in examining the generated contours slice by slice. This greatly reduces the benefit of the tool's automaticity. In order to overcome this shortcoming, we developed an automatic quality assurance (QA) method for automatic segmentation using convolutional neural networks (CNNs). Materials and Methods: The study cohort comprised 680 patients with early-stage breast cancer who received whole breast radiation. The overall architecture of the automatic QA method for deep learning-based segmentation included the following two main parts: a segmentation CNN model and a QA network that was established based on ResNet-101. The inputs were from computed tomography, segmentation probability maps, and uncertainty maps. Two kinds of Dice similarity coefficient (DSC) outputs were tested. One predicted the DSC quality level of each slice ([0.95, 1] for “good,” [0.8, 0.95] for “medium,” and [0, 0.8] for “bad” quality), and the other predicted the DSC value of each slice directly. The performances of the method to predict the quality levels were evaluated with quantitative metrics: balanced accuracy, F score, and the area under the receiving operator characteristic curve (AUC). The mean absolute error (MAE) was used to evaluate the DSC value outputs. Results: The proposed methods involved two types of output, both of which achieved promising accuracy in terms of predicting the quality level. For the good, medium, and bad quality level prediction, the balanced accuracy was 0.97, 0.94, and 0.89, respectively; the F score was 0.98, 0.91, and 0.81, respectively; and the AUC was 0.96, 0.93, and 0.88, respectively. For the DSC value prediction, the MAE was 0.06 ± 0.19. The prediction time was approximately 2 s per patient. Conclusions: Our method could predict the segmentation quality automatically. It can provide useful information for physicians regarding further verification and revision of automatic contours. The integration of our method into current automatic segmentation pipelines can improve the efficiency of radiotherapy contouring."
2018,Breast cancer classification of image using convolutional neural network,"Convolutional Neural Network (CNN) has been set up as an intense class of models for image acknowledgment issues. CNN is a deep learning model which extracts the feature of an image and use these feature to classify an image. Other classification algorithm needs to extract the feature of an image using feature extraction algorithm like Gray Level Co-occurrence Matrix. Convolutional neural network is a class of deep, feed-forward artificial neural networks that have successfully been applied to recognizing image. It is also widely used in video recognition, image classification, recommender systems, natural language processing and speech recognition. In this paper, a dataset of 7909 breast cancer histopathology images acquired on 82 patients are taken. These images are of two different classes benign and malignant. We extract the patches of the image to train the network and finally we give the image as an input to classify the image. Performance of CNN is much better when compared to other reported results on MNSIT dataset using other classification algorithm for classifying an image."
2020,Dual Convolutional Neural Networks for Breast Mass Segmentation and Diagnosis in Mammography,"Deep convolutional neural networks (CNNs) have emerged as a new paradigm for Mammogram diagnosis. Contemporary CNN-based computer-aided-diagnosis systems (CADs) for breast cancer directly extract latent features from input mammogram image and ignore the importance of morphological features. In this paper, we introduce a novel end-to-end deep learning framework for mammogram image processing, which computes mass segmentation and simultaneously predicts diagnosis results. Specifically, our method is constructed in a dual-path architecture that solves the mapping in a dual-problem manner, with an additional consideration of important shape and boundary knowledge. One path, called the Locality Preserving Learner (LPL), is devoted to hierarchically extracting and exploiting intrinsic features of the input. Whereas the other path, called the Conditional Graph Learner (CGL), focuses on generating geometrical features via modeling pixel-wise image to mask correlations. By integrating the two learners, both the cancer semantics and cancer representations are well learned, and the component learning paths in return complement each other, contributing an improvement to the mass segmentation and cancer classification problem at the same time. In addition, by integrating an automatic detection set-up, the DualCoreNet achieves fully automatic breast cancer diagnosis practically. Experimental results show that in benchmark DDSM dataset, DualCoreNet has outperformed other related works in both segmentation and classification tasks, achieving 92.27% DI coefficient and 0.85 AUC score. In another benchmark INbreast dataset, DualCoreNet achieves the best mammography segmentation (93.69% DI coefficient) and competitive classification performance (0.93 AUC score)."
2022,Breast Cancer Detection and Classification Empowered With Transfer Learning,"Cancer is a major public health issue in the modern world. Breast cancer is a type of cancer that starts in the breast and spreads to other parts of the body. One of the most common types of cancer that kill women is breast cancer. When cells become uncontrollably large, cancer develops. There are various types of breast cancer. The proposed model discussed benign and malignant breast cancer. In computer-aided diagnosis systems, the identification and classification of breast cancer using histopathology and ultrasound images are critical steps. Investigators have demonstrated the ability to automate the initial level identification and classification of the tumor throughout the last few decades. Breast cancer can be detected early, allowing patients to obtain proper therapy and thereby increase their chances of survival. Deep learning (DL), machine learning (ML), and transfer learning (TL) techniques are used to solve many medical issues. There are several scientific studies in the previous literature on the categorization and identification of cancer tumors using various types of models but with some limitations. However, research is hampered by the lack of a dataset. The proposed methodology is created to help with the automatic identification and diagnosis of breast cancer. Our main contribution is that the proposed model used the transfer learning technique on three datasets, A, B, C, and A2, A2 is the dataset A with two classes. In this study, ultrasound images and histopathology images are used. The model used in this work is a customized CNN-AlexNet, which was trained according to the requirements of the datasets. This is also one of the contributions of this work. The results have shown that the proposed system empowered with transfer learning achieved the highest accuracy than the existing models on datasets A, B, C, and A2."
2022,A Novel Hybrid Deep Learning Model for Metastatic Cancer Detection,"Cancer has been found as a heterogeneous disease with various subtypes and aims to destroy the body's normal cells abruptly. As a result, it is essential to detect and prognosis the distinct type of cancer since they may help cancer survivors with treatment in the early stage. It must also divide cancer patients into high- and low-risk groups. While realizing efficient detection of cancer is frequently a time-taking and exhausting task with the high possibility of pathologist errors and previous studies employed data mining and machine learning (ML) techniques to identify cancer, these strategies rely on handcrafted feature extraction techniques that result in incorrect classification. On the contrary, deep learning (DL) is robust in feature extraction and has recently been widely used for classification and detection purposes. This research implemented a novel hybrid AlexNet-gated recurrent unit (AlexNet-GRU) model for the lymph node (LN) breast cancer detection and classification. We have used a well-known Kaggle (PCam) data set to classify LN cancer samples. This study is tested and compared among three models: convolutional neural network GRU (CNN-GRU), CNN long short-term memory (CNN-LSTM), and the proposed AlexNet-GRU. The experimental results indicated that the performance metrics accuracy, precision, sensitivity, and specificity (99.50%, 98.10%, 98.90%, and 97.50) of the proposed model can reduce the pathologist errors that occur during the diagnosis process of incorrect classification and significantly better performance than CNN-GRU and CNN-LSTM models. The proposed model is compared with other recent ML/DL algorithms to analyze the model's efficiency, which reveals that the proposed AlexNet-GRU model is computationally efficient. Also, the proposed model presents its superiority over state-of-the-art methods for LN breast cancer detection and classification."
2022,Breast Cancer Detection in Mammography Images Using Deep Convolutional Neural Networks and Fuzzy Ensemble Modeling Techniques,"Breast cancer has evolved as the most lethal illness impacting women all over the globe. Breast cancer may be detected early, which reduces mortality and increases the chances of a full recovery. Researchers all around the world are working on breast cancer screening tools based on medical imaging. Deep learning approaches have piqued the attention of many in the medical imaging field due to their rapid growth. In this research, mammography pictures were utilized to detect breast cancer. We have used four mammography imaging datasets with a similar number of 1145 normal, benign, and malignant pictures using various deep CNN (Inception V4, ResNet-164, VGG-11, and DenseNet121) models as base classifiers. The proposed technique employs an ensemble approach in which the Gompertz function is used to build fuzzy rankings of the base classification techniques, and the decision scores of the base models are adaptively combined to construct final predictions. The proposed fuzzy ensemble techniques outperform each individual transfer learning methodology as well as multiple advanced ensemble strategies (Weighted Average, Sugeno Integral) with reference to prediction and accuracy. The suggested Inception V4 ensemble model with fuzzy rank based Gompertz function has a 99.32% accuracy rate. We believe that the suggested approach will be of tremendous value to healthcare practitioners in identifying breast cancer patients early on, perhaps leading to an immediate diagnosis."
2020,Enhanced Artificial Intelligence System for Diagnosing and Predicting Breast Cancer Using Deep Learning,"<p>Breast cancer is the leading cause of death among women with cancer. Computer-aided diagnosis is an efficient method for assisting medical experts in early diagnosis, improving the chance of recovery. Employing artificial intelligence (AI) in the medical area is very crucial due to the sensitivity of this field. This means that the low accuracy of the classification methods used for cancer detection is a critical issue. This problem is accentuated when it comes to blurry mammogram images. In this paper, convolutional neural networks (CNNs) are employed to present the traditional convolutional neural network (TCNN) and supported convolutional neural network (SCNN) approaches. The TCNN and SCNN approaches contribute by overcoming the shift and scaling problems included in blurry mammogram images. In addition, the flipped rotation-based approach (FRbA) is proposed to enhance the accuracy of the prediction process (classification of the type of cancerous mass) by taking into account the different directions of the cancerous mass to extract effective features to form the map of the tumour. The proposed approaches are implemented on the MIAS medical dataset using 200 mammogram breast images. Compared to similar approaches based on KNN and RF, the proposed approaches show better performance in terms of accuracy, sensitivity, spasticity, precision, recall, time of performance, and quality of image metrics.</p>"
2023,A Transfer Learning-Based Deep Learning Model for Automated Breast Cancer Identification in Mammograms,"Abstract: Breast cancer is a severe health issue that affects women all over the world, underscoring the need for reliable and effective screening techniques. The early detection, diagnosis, and treatment of breast cancer are made possible by computer-aided diagnostic (CAD) systems that rely on mammograms. This study introduces a unique deep-learning model that uses transfer learning to identify and categorize breast cancer automatically. Deep convolutional neural networks have been shown in several recent studies to diagnose breast cancer in mammograms with performance comparable to or even outperforming that of human experts. In order to extract features from the dataset from the Mammographic Image Analysis Society (MIAS), the proposed model uses pre-trained convolutional neural network (CNN) architectures like ResNet50 and Visual Geometry Group networks (VGG)-16. This novel deep-learning model holds significant potential for enhancing the efficiency and accuracy of breast cancer detection and classification."
2022,Deep Residual Learning with Attention Mechanism for Breast Cancer Classification,"Abstract: Invasive Ductal Carcinoma (IDC) is a common form of breast cancer that can be found in women. In traditional medical practice, physicians have to manually test and classify the areas which they suspect to be cancerous. However, the literature strongly shows that that the process manual segmentation done by the medical practitioners, is neither time-efficient nor accurate as it depends on their subjective judgment. The model called Residual Attention Neural Network Breast Cancer Classification (RANNBCC) is introduced in this paper to help medical practitioners in the cancer diagnostic process. RANNBCC utilizes Residual Neural Network (ResNet) as an expert-supportive method to help medical practitioners in cancer diagnosis. The implementation of RANN-BCC can support the classification of Whole Slide Imaging (WSI) into non-IDC and IDC without prior information about the presence of a cancerous lesion. The result of classification shows that the RANN-BCC model achieved 92.45% accuracy, 0.98 recall, 0.91 precision, and 0.94 F-score which outperform other models such as CNN, AlexNet, Residual Neural Network 34 (ResNet34), and Feed Forward Neural Network. The developed RANN-BCC model aims to help medical experts classify IDC and non-IDC of breast cancer by learning the feature content of medical images."
2022,On the Wavelet Convolution Neural Network for Breast Cancer Image Analysis,"The purpose of this paper is to propose and study the structure of wavelet transformation (WT) and convolution neural networks (CNN). To get more insights into its effectiveness, three WCNN architectures are designed and tested against one another seeking which model provides the best performance in breast cancer detection using histopathological images. The Breast cancer histopathological database (BreakHis) is used for this task."
2022,Wavelet Pooling Scheme in the Convolution Neural Network (CNN) for Breast Cancer Detection,"In this work, the wavelet transformation (WT) under the context of convolution neural network (CNN) is developed and applied for breast cancer detection. The main objective is to investigate the effectiveness of the WCNN pooling architecture when compared to other two famous pooling strategies; max and average pooling, particularly targeting at the features extraction and classifying the phases of breast cancer by avoiding the under and overfitting problems. It is discovered in this work that the combination of WT and CNN outperforms the traditional and typical CNNs (with 96.49% of accuracy 95.81% of precision, 96.73% of recall and 96.23% of F measure)."
2021,"Abstract PO-056: Importance of artificial intelligence, machine learning deep learning in the field of medicine on the future role of the physician","Abstract: There are many ways to define the field of Artificial Intelligence. Here is one way for Artificial Intelligence is ""The Study of the computations that make it possible to perceive, reason, act and predict the future possible outcomes”. Deep learning, which is a popular research area of artificial intelligence (AI), enables the creation of end-to-end models to achieve promised results using input data. Deep learning techniques have been successfully applied in many problems such as arrhythmia detection, skin cancer classification, breast cancer detection, brain disease classification, pneumonia detection, COVID-19 from chest X-ray images, and CT scan images. Almost all hospitals have CT imaging machines; therefore, the chest CT images can be utilized for early classification of diseases. However, the chest CT classification involves a radiology expert and considerable time, which is valuable when any infection is growing at a rapid rate. Therefore, automated analysis of chest CT images is desirable to save the medical professionals precious time that shows the importance of Artificial Intelligence neural networks which is used to classify the infected patients as infected (+ve) or not (−ve). There is a vital need to detect the disease at an early stage and save the patient from the disease. Convolutional neural networks (CNN) are a powerful tool that comes under the platform of Neural Networks – Artificial Intelligence inspired by the human brain, which is extensively utilized for image classification. The hierarchical structure and efficient feature extraction characteristics from an image make CNN a dynamic model for image classification. Initially, the layers are organized into three dimensions: width, height, and depth. The neurons in a given layer do not attach to the entire set of neurons in the later layer, but only to limited neurons of it. Finally, the output is diminished to a single vector of probability scores, coordinated alongside the depth dimension. In a Convolutional Neural Network, the linear function that is used is called a convolutional layer. Each node in the hidden layer extracts different features by using image processing feature detectors. For example, in the first layer, the first node may extract the horizontal edges of an image, the second node may extract vertical edges and etc. These features are extracted using a kernel. The bottom is the original image and the top is the output of the convolutions. It is also worth noting that the output of the convolutions reduces the dimension of the original image, The next step the pooling layer happens tends to be computed after the convolutional layer. The reason why pooling is done is to further reduce the dimensions of the convolutional layer and just extract out the features to make the model more robust. AI could help to rapidly diagnose diseases if proper attention given in collecting the data."
2022,"Deep learning, Artificial Intelligence and machine learning in cancer: Prognosis, diagnosis and treatment","Thus, over the past years, the progress in AI, especially in machine learning and deep learning, has affected the area of oncology. It is in this context that this paper reviews the different changes in technologies for cancer prognosis, diagnosis, and treatment. Some of the ways that AI is helping improve cancer diagnosis and treatment are in the analysis of large clinical and genetic data to provide better forecast accuracy of cancer outcomes, the detailed image analysis to aid early cancer diagnosis, and the use of population, patient, and clinical data to create a custom-made treatment plan. For instance, ML performs well in prognostic evaluations where the algorithm tries to predict diseases’ progress and patients’ survival since it can recognize specific patterns in large databases; on the other hand, DL, particularly CNNs, are precise in interpreting medical images for early diagnosis. Also, AI assists in the application of enhanced therapies for genetic mutations as a form of precision medicine. During treatment strategy development, AI supports oncologists in determining the appropriate radiation doses and the proper combination of drugs; robotic systems increase the accuracy of operations due to AI. However, there is still information privacy and protection, algorithm and model bias, and implementation of AI applications in the context of clinical health care. These issues require special attention for the future development and adoption of AI in oncology. The present uses, advantages, and prospects of AI, ML, and DL in cancer treatment have been described in this paper, along with the focus on the capability of the interventions to transform the course of therapy and actual patient experience."
2022,From machine learning to deep learning: experimental comparison of machine learning and deep learning for skin cancer image segmentation,"Skin lesion analysis is a tedious and challenging task, thus, in this research the suitability of employing machine learning or deep learning approaches for automatic lesion segmentation on dermoscopic skin cancer images is determined. The segmented region can assist clinical experts in understanding the complex lesion structure and internal pattern to find the correct skin cancer type for its early diagnosis and prevention. In this study, I present two methodologies for performing lesion segmentation: machine learning-based optimized K-means with Firefly Algorithm (FA) and Convolutional Neural Network (CNN). In the first model, the FA is hybridized with K-means clustering based on the novel average intensity fitness function to optimize the segmentation map. It is observed in the experimental results that the K-means algorithm may lead to poor results due to the wrong selection of initial centroid value, thus FA is hybridized into it to improve the performance. The second model is an enhanced encoder-decoder-based CNN framework implemented in an end-to-end fashion. These two models are compared to understand whether machine learning or deep learning is suitable to perform medical image segmentation based on a few performance metrics such as accuracy, Intersection over Union (IoU), and DICE index. These methods are evaluated and compared on two benchmark datasets provided by the International Skin Imaging Collaboration (ISIC) named ISIC 2016 [1] and ISIC 2017 [2]. Experimental results showed that the CNN model outperformed the machine learning model with an accuracy difference of 7.98% on ISIC 2016, and 7.32% on ISIC 2017. I concluded from the experimental findings that the deep learning model is more accurate and efficient in segmenting the lesion area as compared to the machine learning model. Thus, findings from this experimental work will be considered for the design of an automatic classification system by incorporating a deep learning-based segmentation approach as a pre-processing step. "
2020,Deep Convolutional Neural Network-Based Analysis for Breast Cancer Histology Images,"Breast cancer is one of the main causes of cancer death worldwide, and early diagnostics significantly increases the chances of correct treatment and survival, but this process is tedious. The relevance and potential of automatic classification algorithms using Hematoxylin-Eosin stained histopathological images have already been demonstrated, but the reported results are still sub-optimal for clinical use. Deep learning-based computer-aided diagnosis (CAD) has been gaining popularity for analyzing histopathological images. Based on the predominant cancer type, the goal is to classify images into four categories of normal, benign, in situ carcinoma, and invasive carcinoma. The convolutional neural networks (CNN) is proposed to retrieve information at different scales, including both nuclei and overall tissue organization. This chapter utilizes several deep neural network architectures and gradient boosted trees classifier to classify the histology images among four classes. Hence, this approach has outperformed existing approaches in terms of accuracy and implementation complexity."
2023,Applying Deep Learning Methods for Mammography Analysis and Breast Cancer Detection,"Breast cancer is a serious medical condition that requires early detection for successful treatment. Mammography is a commonly used imaging technique for breast cancer screening, but its analysis can be time-consuming and subjective. This study explores the use of deep learning-based methods for mammogram analysis, with a focus on improving the performance of the analysis process. The study is focused on applying different computer vision models, with both CNN and ViT architectures, on a publicly available dataset. The innovative approach is represented by the data augmentation technique based on synthetic images, which are generated to improve the performance of the models. The results of the study demonstrate the importance of data pre-processing and augmentation techniques for achieving high classification performance. Additionally, the study utilizes explainable AI techniques, such as class activation maps and centered bounding boxes, to better understand the models’ decision-making process."
2023,Breast Cancer Detection Using Image Processing and Machine Learning,"Different breast cancer detection systems have been developed to help clinicians analyze screening mammograms. Breast cancer has been increasing gradually so scientists work to develop new methods to reduce the risks of this life-threatening disease. Convolutional Neural Networks (CNNs) have shown much promise In the field of medical imaging because of recent developments in deep learning. However, CNN’s based methods have been restricted due to the small size of the few public breast cancer datasets. This research has developed a new framework and introduced it to detect breast cancer. This framework utilizes Convolutional Neural Networks (CNNs) and image processing to achieve its goal because CNNs have been an important success in image recognition, reaching human performance. An efficient and fast CNN pre-trained object detector called RetinaNet has been used in this research. RetinaNet is an uncomplicated one-stage object detector. A two-stage transfer learning has been used with the selected detector to improve the performance. RetinaNet model is initially trained with a general-purpose dataset called COCO dataset. The transfer learning is then used to apply the RetinaNet model to another dataset of mammograms called the CBIS-DDSM dataset. Finally, the second transfer learning is used to test the RetinaNet model onto a small dataset of mammograms called the INbreast dataset. The results of the proposed two-stage transfer learning (RetinaNet → CBIS-DDSM → INbreast) are better than the other state-of-the-art methods on the public INbreast dataset. Furthermore, the True Positive Rate (TPR) is 0.99 ± 0.02 at 1.67 False Positives per Image (FPPI), which is better than the one-stage transfer learning with a TPR of 0.94 ± 0.02 at 1.67 FPPI."
2023,ML‐DSTnet: A Novel Hybrid Model for Breast Cancer Diagnosis Improvement Based on Image Processing Using Machine Learning and Dempster–Shafer Theory,"Medical intelligence detection systems have changed with the help of artificial intelligence and have also faced challenges. Breast cancer diagnosis and classification are part of this medical intelligence system. Early detection can lead to an increase in treatment options. On the other hand, uncertainty is a case that has always been with the decision‐maker. The system’s parameters cannot be accurately estimated, and the wrong decision is made. To solve this problem, we have proposed a method in this article that reduces the ignorance of the problem with the help of Dempster–Shafer theory so that we can make a better decision. This research on the MIAS dataset, based on image processing machine learning and Dempster–Shafer mathematical theory, tries to improve the diagnosis and classification of benign, malignant masses. We first determine the results of the diagnosis of mass type with MLP by using the texture feature and CNN. We combine the results of the two classifications with Dempster–Shafer theory and improve its accuracy. The obtained results show that the proposed approach has better performance than others based on evaluation criteria such as accuracy of 99.10%, sensitivity of 98.4%, and specificity of 100%."
2023,Rectal Cancer Prediction and Performance Based on Intelligent Variational Autoencoders Machine Using Deep Learning on CDAS Dataset,"A pathological complete response to neoadjuvant chemoradiotherapy offers patients with rectal cancer that has advanced locally the highest chance of survival. However, there isn't yet a valid prediction model available. An efficient feature extraction technique is also required to increase a prediction model's precision. CDAS (cancer data access system) program is a great place to look for cancer along with images or biospecimens. In this study, we look at data from the CDAS system, specifically Bowel cancer (colorectal cancer) datasets. This study suggested a survival prediction method for rectal cancer. In addition, determines which deep learning algorithm works best by comparing their performance in terms of prediction accuracy. The initial job that leads to correct findings is corpus cleansing. Moving forward, the data pre-processing activity will be performed, which will comprise ""exploratory data analysis and pruning and normalization or experimental study of data, which is required to obtain data features to design the model for cancer detection at an early stage."" Aside from that, the data corpus is separated into two sub-corpora: training data and test data, which will be utilized to assess the correctness of the constructed model. This study will compare our auto-encoder accuracy to that of other deep learning algorithms, such as ANN, CNN, and RBM, before implementing the suggested methodology and displaying the model's accuracy graphically after the suggested new methodology or algorithm for patients with rectal cancer. Various criteria, including true positive rate, ROC curve, and accuracy scores, are used in the experiments to determine the model's high accuracy. In the end, we determine the accuracy score for each model. The outcomes of the simulation demonstrated that rectal cancer patients may be estimated using prediction models. It is shown that variational deep encoders have excellent accuracy of 94% in this cancer prediction and 95% for ROC curve regions. The findings demonstrate that automated prediction algorithms are capable of properly estimating rectal cancer patients’ chances of survival. The best results, with 95% accuracy, were generated by deep autoencoders."
2022,A New Hybrid Breast Cancer Diagnosis Model Using Deep Learning Model and ReliefF,"Breast cancer is a dangerous type of cancer usually found in women and is a significant research topic in medical science. In patients who are diagnosed and not treated early, cancer spreads to other organs, making treatment difficult. In breast cancer diagnosis, the accuracy of the pathological diagnosis is of great importance to shorten the decision-making process, minimize unnoticed cancer cells and obtain a faster diagnosis. However, the similarity of images in histopathological breast cancer image analysis is a sensitive and difficult process that requires high competence for field experts. In recent years, researchers have been seeking solutions to this process using machine learning and deep learning methods, which have contributed to significant developments in medical diagnosis and image analysis. In this study, a hybrid DCNN + ReliefF is proposed for the classification of breast cancer histopathological images, utilizing the activation properties of pre-trained deep convolutional neural network (DCNN) models, and the dimension-reduction-based ReliefF feature selective algorithm. The model is based on a fine-tuned transfer-learning technique for fully connected layers. In addition, the models were compared to the k-nearest neighbor (kNN), naive Bayes (NB), and support vector machine (SVM) machine learning approaches. The performance of each feature extractor and classifier combination was analyzed using the sensitivity, precision, F1-Score, and ROC curves. The proposed hybrid model was trained separately at different magnifications using the BreakHis dataset. The results show that the model is an efficient classification model with up to 97.8% (AUC) accuracy."
2023,Deep Learning For Lung Cancer Detection,"By detecting lung cancer in advance, doctors can make the right decision to treat patients to ensure that they live long and healthy lives. This research aims to build a CNN model using a pre-trained model and functional API that would classify if a person had lung cancer or not based on a CT scan. This research uses CT scan images as input for the prediction model from the LUNA16 [Luna Nodule Analysis 2016] dataset for experimenting by using ResNet 50 and VGG 16. ResNet50 showed slightly high accuracy on test data compared to VGG16, which is 98%."
2023,Optimal Trained Deep Learning Model for Breast Cancer Segmentation and Classification,"Breast cancer is the most widespread cancer among women. Based on the International cancer research center analysis, the highest number of deaths among women is due to breast cancer. Hence, detecting breast cancer at the earliest may help the oncologist to make appropriate decisions. Due to variations in breast tissue density, there is still a challenge in precise diagnosis and classification. To overcome this challenge, a novel OTDEM-based breast cancer segmentation and classification is proposed with the following four stages: they are, preprocessing, segmentation, feature extraction and classification. The input image is passed to the initial stage using the CLAHE filter to enhance the image. Then the preprocessed image is given to the segmentation stage for the image sub-segments by correlation-based deep joint segmentation. Following that, the features such as statistical features, improved LGXP, texton features, and shape-based features are derived from the segmented image. Then the derived features are fed to the ensemble model that includes CNN, DBN, and BI-GRU classifier to finalize the classification outcome. Further, to enhance the performance of the ensemble model, the weight of BI-GRU is optimized via a new algorithm termed SIPOA. This ensures optimal training to make the model more appropriate in its classification process. Finally, the performance of the proposed work is validated over the traditional models concerning different performance measures."
2022,A Survey on Human Cancer Categorization Based on Deep Learning,"In recent years, we have witnessed the fast growth of deep learning, which involves deep neural networks, and the development of the computing capability of computer devices following the advance of graphics processing units (GPUs). Deep learning can prototypically and successfully categorize histopathological images, which involves imaging classification. Various research teams apply deep learning to medical diagnoses, especially cancer diseases. Convolutional neural networks (CNNs) detect the conventional visual features of disease diagnoses, e.g., lung, skin, brain, prostate, and breast cancer. A CNN has a procedure for perfectly investigating medicinal science images. This study assesses the main deep learning concepts relevant to medicinal image investigation and surveys several charities in the field. In addition, it covers the main categories of imaging procedures in medication. The survey comprises the usage of deep learning for object detection, classification, and human cancer categorization. In addition, the most popular cancer types have also been introduced. This article discusses the Vision-Based Deep Learning System among the dissimilar sorts of data mining techniques and networks. It then introduces the most extensively used DL network category, which is convolutional neural networks (CNNs) and investigates how CNN architectures have evolved. Starting with Alex Net and progressing with the Google and VGG networks, finally, a discussion of the revealed challenges and trends for upcoming research is held."
2022,Histopathological analyses of breast cancer using deep learning,"Deep Learning hosts a plethora of variants and models in Convolution Neural Networks (CNN), where the prudence of these methods is algorithmically proven when implemented with sturdy datasets. Much number of haphazard structures and textures are found in the histopathological images of breast cancer, where dealing with such multicolor and multi-structure components in the images is a challenging task. Working with such data in wet labs proves clinically consistent results, but added with the computational models will improvise them empirically. In this paper, we proposed a model to diagnose breast cancer using raw images of breast cancer with different resolutions, irrespective of the structures and textures. The floating image is mapped with the healthy reference image and examined using different statistics such as cross correlations and phase correlations. Experiments are carried out with the aim of establishing the optimal performance on histopathological images. The model attained satisfactory results and are proved good for decision making in cancer diagnosis."
2023,Breast Cancer Classification Using Deep Learning,"Breast cancer (breast carcinoma) is the most common type of cancer in women, and it is the most dangerous cancer, together with lung cancer. Early detection of this type of cancer is crucial to reduce the mortality rate since breast cancer is often treatable when it is diagnosed early. Cancer starts from a benign state, and without appropriate treatment at the early stages, it becomes malignant. A common way to detect breast cancer is histological biopsy evaluation. Deep learning, as one of the currently most popular computer science research trends, improves neural networks, which have more and deeper layers allowing higher abstraction levels and more accurate data analysis. AI and machine learning have gained a lot of popularity and acceptance in recent years. Here are the top path breaking applications of deep learning in healthcare. Although deep convolutional neural networks as a deep learning algorithm has recently achieved promising results in data analysis, the authors propose a new deep CNN architecture for the classification of breast tumours in ultrasound images."
2022,Machine Learning and Deep Learning Algorithms for Cancer Diagnostic Optimization,"Recently, advances in machine learning and artificial intelligence have made these techniques increasingly prominent. Companies and institutions have begun investing in healthcare research to improve the accuracy of disease prediction because of its widespread popularity and effective pattern detection and categorization capabilities. However, there are numerous difficulties that arise while employing these methods. The lack of a huge data set for medical pictures is one of the biggest challenges. This study aims to provide a reasonable introduction to deep learning in medical image processing, beginning with theoretical foundations and progressing to practical implementations. Deep learning (DL) has become increasingly popular due to a number of computer science discoveries, according to a new study. To get a better grasp of neural networks, the next step was to familiarise ourselves with the principles. That's why convolutional neural networks (CNNs) and deep learning are used. This gives us a better idea of why deep learning is advancing so quickly in so many different application domains, including medical image processing. Key Words: Machine Learning, Deep Learning, CNN, Cancer, Algorithm, ANN."
2022,Breast cancer detection using deep learning and cnn-based model,"The second-most dangerous cancer in the world is breast cancer. Not just in India, but all around the world, breast cancer is the primary cause of death for women. According to the USA in 2011, out of eight one woman had cancer. Inappropriate breast cell division can result in benign or malignant breast cancer. Consequently, this is how breast cancer progresses. Therefore, it is crucial to detect the breast cancer at the early stage. By doing this, many lives can be saved and the sickness can be adequately treated while also being treated as a very serious condition. Breast cancer is most dangerous disease and at present it treated as global disease. Invasive breast cancer will likely affect 246,660 women in the USA in 2016, and 40,450 women will likely pass away from the disease. Mammography continues to be labor-intensive and has acknowledged drawbacks despite its success as a tool for detecting breast cancer, including low sensitivity in women with dense breast tissue. The development of neural networks has been used to breast histopathology images during the past ten years to help radiologists operate more accurately and efficiently. The goal of this study is to use the most recent convolution neural network (CNN) expertise to images of breast histopathology. The first section of the research examines conventional Computer Assisted Detection (CAD) utilising machine learning and a more current CNN-based model for Breast Histopathology Images."
2022,Skin Cancer Detection Using Deep Learning and Artificial Intelligence: Incorporated model of deep features fusion,"Among the most frequent forms of cancer, skin cancer accounts for hundreds of thousands of fatalities annually throughout the globe. It shows up as excessive cell proliferation on the skin. The likelihood of a successful recovery is greatly enhanced by an early diagnosis. More than that, it might reduce the need for or the frequency of chemical, radiological, or surgical treatments. As a result, savings on healthcare expenses will be possible. Dermoscopy, which examines the size, form, and color features of skin lesions, is the first step in the process of detecting skin cancer and is followed by sample and lab testing to confirm any suspicious lesions. Deep learning AI has allowed for significant progress in image-based diagnostics in recent years. Deep neural networks known as convolutional neural networks (CNNs or ConvNets) are essentially an extended form of multi-layer perceptrons. In visual imaging challenges, CNNs have shown the best accuracy. The purpose of this research is to create a CNN model for the early identification of skin cancer. The backend of the CNN classification model will be built using Keras and Tensorflow in Python. Different network topologies, such as Convolutional layers, Dropout layers, Pooling layers, and Dense layers, are explored and tried out throughout the model's development and validation phases. Transfer Learning methods will also be included in the model to facilitate early convergence. The dataset gathered from the ISIC challenge archives will be used to both tests and train the model."
2020,A New Deep Learning Model Selection Method for Colorectal Cancer Classification,"<p>Deep learning is one of the most commonly used techniques in computer-aided diagnosis systems. Their exploitation for histopathological image analysis is important because of the complex morphology of whole slide images. However, the main limitation of these methods is the restricted number of available medical images, which can lead to an overfitting problem. Many studies have suggested the use of static ensemble learning methods to address this issue. This article aims to propose a new dynamic ensemble deep learning method. First, it generates a set of models based on the transfer learning strategy from deep neural networks. Then, the relevant subset of models is selected by the particle swarm optimization algorithm and combined by voting or averaging methods. The proposed approach was tested on a histopathological dataset for colorectal cancer classification, based on seven types of CNNs. The method has achieved accurate results (94.52%) by the Resnet121 model and the voting strategy, which provides important insights into the efficiency of dynamic ensembling in deep learning.</p>"
2023,Breast Masses Segmentation: A Framework of Skip Dilated Semantic Network and Machine Learning,"Many medical specialists used Computer Aided Diagnostic (CAD) systems as a second opinion to detect breast masses. The poor visualization of mass images makes it difficult to identify precisely. To segment the lesions from the mammograms is a difficult task due to different shapes, sizes, and locations of the masses. The motivation of this study is to develop a method that can segment breast mass lesions from mammogram images. The objective is to perform the segmentation of the breast mass mammogram images more precisely at an early stage. Breast mass segmentation is always a basic requirement in computer-aided diagnosis systems. In this study segmentation of the masses abnormalities from the mammogram images is performed by using the Skipping Dilated semantic segmentation approach. The study uses class weights and Dilation factor using semantic Convolutional Neural Network (CNN). It overcomes the class misbalance in tumors and background class, that affect the mean Intersection over Union (MIOU), and weighted-IOU (WIOU) by using class weights. Secondly, dilation convolution magnifies the receptive field exposure that enriches the convolutional operation with context attentiveness. Two public datasets of mammography INbreast and CBIS-DDSM are used. The WIOU of Skipping Dilated Semantic CNN for INbreast is 98.51% and CBIS-DDSM is 94.82% achieved."
2022,A Hybrid Deep Learning Methodology for Breast Cancer Diagnosis using Magnetic Resonance Images,"Abstract: Today, breast cancer is one of the most common causes of cancer in women. Precise diagnosis of cancerous tissues based on images is essential in disease treatment before the disease progression. Although there are several image techniques for diagnosing, magnetic resonance (MR) imaging contains extensive clinical information which usable with other image modalities such as mammography and ultrasound. In this study, the hybrid of an autoencoder network with ResNet architecture was proposed to significantly improve classification accuracy to diagnose breast cancer lesions into two categories: benign and malignant in MR images. Using the MR breast cancer images of the QIN-Breast database, the results present the employment of an autoencoder as a preprocessor can enhance the efficiency of CNN and ultimately lead to an accurate diagnosis of benign and malignant tissues by 97.65%. The proposed method significantly improved the classification from the point of view of speed, accuracy, and precision. This cancerous tissue classification was employed only using MR images without manual segmentation and feature extraction."
2023,Detection of Breast Cancer Using Deep Learning Techniques,"Evaluation of Histopathology images are a vital approach that is used for the breast cancer detection. To build up the efficiency of breast cancer detection and to reduce the burden of doctors and specialists, we layout various Deep Learning algorithms to recognize most cancers with the usage of histopathology scans. This paper follows several deep learning models like Convolutional Neural network (CNN) and Vgg16 for the recognition method. The dataset we used for class manner is Breast Histopathology Images which contain positive and negative images. We examined breast Histopathology images of 2,77,524 patients of which 198,748 images are IDC (-) and 78,786 images are IDC (+). This shows the deep learning algorithms can greatly facilitate the breast cancer detection, improving the accuracy and speed of detection. One of the most common cancers is Invasive Ductal Carcinoma (IDC). To determine the aggressiveness score to whole-mount specimen, doctors typically focus on areas containing IDC. Therefore, one of the common pre-processing steps for automatic aggressive categorization is to identify the exact region of IDC along the mounting side."
2022,Machine Learning-Aided Automatic Detection of Breast Cancer,"The expeditious progress of machine learning, especially the deep learning techniques, keep propelling the medical imaging community's heed in applying these techniques in improving the accuracy of cancer screening. Among various types of cancers, breast cancer is the most detrimental disease affecting women today. The prognosis of such types of disease becomes a very challenging task for radiologists due the huge number of cases together with careful and thorough examination it demands. The constraints of present CAD open up a need for new and accurate detection procedures. Deep learning approaches have gained a tremendous recognition in the areas of object detection, segmentation, image recognition, and computer vision. Precise and premature detection and classification of lesions is very critical for increasing the survival rates of patients. Recent CNN models are designed to enhance radiologists' understandings to identify even the least possible lesions at the very early stage."
2023,Classification of Melanoma Skin Cancer Based on Transformer Deep Learning Model,"An increasing number of genetic and metabolic anomalies have been determined to lead to cancer, which is generally fatal. Cancerous cells may spread to any body part, which can be life-threatening. Skin cancer is significant cancer, and its frequency is increasing worldwide. The main subtypes of skin cancer are squamous and basal cell carcinomas and melanoma. The deep learning methods were used to detect the two primary types of tumours, malignant and benign, by using the MELANOMA dataset. The proposed system utilizes a convolutional neural network (CNN), transformer, and InceptionV3 architecture to learn and extract meaningful features from skin lesion images. The CNN model was trained on a large dataset of dermoscopic images of melanoma and benign lesions. The transformer model in deep learning refers to a neural network architecture based on the transformer architecture specifically designed for image classification tasks. Inception is an image recognition model that has been shown to attain greater than 78.1% accuracy on the ImageNet dataset."
2021,Detection of Lung Cancer on Computed Tomography Using Artificial Intelligence Applications Developed by Deep Learning Methods and the Contribution of Deep Learning to the Classification of Lung Carcinoma,"Background:: Every year, lung cancer contributes to a high percentage deaths in the world. Early detection of lung cancer is important for its effective treatment, and non-invasive rapid methods are usually used for diagnosis. Introduction:: In this study, we aimed to detect lung cancer using deep learning methods and determine the contribution of deep learning to the classification of lung carcinoma using a convolutional neural network (CNN). Methods:: A total of 301 patients diagnosed with lung carcinoma pathologies in our hospital were included in the study. In the thorax, Computed Tomography (CT) was performed for diagnostic purposes prior to the treatment. After tagging the section images, tumor detection, small and non-small cell lung carcinoma differentiation, adenocarcinoma-squamous cell lung carcinoma differentiation, and adenocarcinoma-squamous cell-small cell lung carcinoma differentiation were sequentially performed using deep CNN methods. Result:: In total, 301 lung carcinoma images were used to detect tumors, and the model obtained with the deep CNN system exhibited 0.93 sensitivity, 0.82 precision, and 0.87 F1 score in detecting lung carcinoma. In the differentiation of small cell-non-small cell lung carcinoma, the sensitivity, precision and F1 score of the CNN model at the test stage were 0.92, 0.65, and 0.76, respectively. In the adenocarcinoma-squamous cancer differentiation, the sensitivity, precision, and F1 score were 0.95, 0.80, and 0.86, respectively. The patients were finally grouped as small cell lung carcinoma, adenocarcinoma, and squamous cell lung carcinoma, and the CNN model was used to determine whether it could differentiate these groups. The sensitivity, specificity, and F1 score of this model were 0.90, 0.44, and 0.59, respectively, in this differentiation. Conclusion.:: In this study, we successfully detected tumors and differentiated between adenocarcinoma- squamous cell carcinoma groups with the deep learning method using the CNN model. Due to their non-invasive nature and the success of the deep learning methods, they should be integrated into radiology to diagnose lung carcinoma."
2023,FA -WSI -CNN Model for Predicting Breast Cancer using Deep Learning,"Deep Learning is used for predicting a large volume of data sets in the medical field particularly for breast cancer prediction and diagnosis. The most effective and broadly applied model for detecting breast cancer is the Conventional Neural Network (CNN) among the various deep learning algorithms available. The existing CNN models are lacking in the analysis of a fully labeled Whole Set Image (WSI) data set. The proposed Fully Automate WSI with the CNN model will analyze the whole slide images and patch the input image for improving the accuracy. Then CNN model will get input from patched images and creates classified data for predicting breast cancer. The scikit-learn deep learning framework with Python is used to analyze the result and build a generalized tissue classifier, the WSI data set should include tissues generated under numerous different preparation circumstances. The proposed model experimental results shows promising WSI patch values, accuracy, precision, re-call, and F1 score of the breast cancer tissues which are used for diagnosis purposes. The FA -WSI -CNN model can reduce the training time by evaluating the inference time"
2023,Employing Atrous Pyramid Convolutional Deep Learning Approach for Detection to Diagnose Breast Cancer Tumors,"Breast cancer is among the most common diseases and one of the most common causes of death in the female population worldwide. Early identification of breast cancer improves survival. Therefore, radiologists will be able to make more accurate diagnoses if a computerized system is developed to detect breast cancer. Computer‐aided design techniques have the potential to help medical professionals to determine the specific location of breast tumors and better manage this disease more rapidly and accurately. MIAS datasets were used in this study. The aim of this study is to evaluate a noise reduction for mammographic pictures and to identify salt and pepper, Gaussian, and Poisson so that precise mass detection operations can be estimated. As a result, it provides a method for noise reduction known as quantum wavelet transform (QWT) filtering and an image morphology operator for precise mass segmentation in mammographic images by utilizing an Atrous pyramid convolutional neural network as the deep learning model for classification of mammographic images. The hybrid methodology dubbed QWT‐APCNN is compared to earlier methods in terms of peak signal‐to‐noise ratio (PSNR) and mean square error (MSE) in noise reduction and detection accuracy for mass area recognition. Compared to state‐of‐the‐art approaches, the proposed method performed better at noise reduction and segmentation according to different evaluation criteria such as an accuracy rate of 98.57%, 92% sensitivity, 88% specificity, 90% DSS, and ROC and AUC rate of 88.77."
2022,Automated multi-class skin cancer classification through concatenated deep learning models,"Skin cancer is the most annoying type of cancer diagnosis according to its fast spread to various body areas, so it was necessary to establish computer-assisted diagnostic support systems. State-of-the-art classifiers based on convolutional neural networks (CNNs) are used to classify images of skin cancer. This paper tries to get the most accurate model to classify and detect skin cancer types from seven different classes using deep learning techniques; ResNet-50, VGG-16, and the merged model of these two techniques through the concatenate function. The performance of the proposed model was evaluated through a set of experiments on the HAM10000 database. The proposed system has succeeded in achieving a recognition accuracy of up to 94.14%."
2022,Models of Artificial Intelligence-Assisted Diagnosis of Lung Cancer Pathology Based on Deep Learning Algorithms,"In this article, in order to explore the application of a diagnosis system for lung cancer, we use an auxiliary diagnostic system to predict and diagnose the good and evil attributes of chest CT pulmonary nodules. This research improves the new diagnosis method based on the convolutional neural network (CNN) and the recurrent neural network (RNN) and combines the dual effects of the two algorithms to process the classification of benign and malignant nodules. By collecting H-E-stained pathological slices of 652 patients' lung lesions from two hospitals between January 2018 and January 2019, the output results of the improved 3D U-net system and the consistent results of two-person reading were compared. This article analyzes the sensitivity, specificity, positive flammability rate, and negative flammability rate of different lung nodule detection methods. In addition, the artificial intelligence system’s and the radiologist's judgment results of benign and malignant pulmonary nodules are used to draw ROC curves for further analysis. The improved model has an accuracy rate of 92.3% for predicting malignant lung nodules and an accuracy rate of 82.8% for benign lung nodules. The new diagnostic method using the convolutional neural network and the recurrent neural network can be very effective for improving the accuracy of predicting lung cancer diagnosis. It can play a very effective role in the disease prediction of lung cancer patients, thereby improving the treatment effect."
2022,Detection of Breast Cancer Images Based on Transfer and Deep Learning Models,"Abstract: Using a technology known as deep learning, which involves classifying photos based on the data they contain, it is possible to detect images, such as tumors and other signs. Because of the scarcity of pathologists and the growing number of patients with breast cancer, the manual numeration of biopsy echantillons must be mechanized (CS). To rectify the histopathological images of malignant tissue, preliminary study is required, which can be done utilizing BreaKHis' free database of data. An approach based on isolated image fragments is proposed, with the final categorization determined by an interconnected network of neurons (CNN) and a final combination of these pieces. Because of its unique architecture, capacity to recognize speech, identify objects, and analyze signals, as well as the popularity of neural language processing, the CNN is attracting increasing interest from industry and researchers. The employment of transfer learning methods is a problem with tiny collections of medical data. To improve the classification of defamatory and obscene photos, this article recommends integrating the impacts of many resolutions. In order to better depict the entering image's texture, many essential phases in CNN development are also used. Maintain a safe distance from the model's customization. Traditional CNN development may become more complex and expensive as a result. The simulation results achieved by running CNN in MATLAB outperform other artificial intelligence (AI) models recently published that used hand-crafted texture descriptors. With this in mind, we looked at all of CNN's possible combinations and discovered a technique to boost the execution rate by a little amount."
2021,Deep learning for breast cancer classification: Enhanced tangent function,"Abstract: Recently, deep learning using convolutional neural network (CNN) has been used successfully to classify the images of breast cells accurately. However, the accuracy of manual classification of those histopathological images is comparatively low. This research aims to increase the accuracy of the classification of breast cancer images by utilizing a patch‐based classifier (PBC) along with deep learning architecture. The proposed system consists of a deep convolutional neural network that helps in enhancing and increasing the accuracy of the classification process. This is done by the use of the PBC. CNN has completely different layers where images are first fed through convolutional layers using hyperbolic tangent function together with the max‐pooling layer, drop out layers, and SoftMax function for classification. Further, the output obtained is fed to a PBC that consists of patch‐wise classification output followed by majority voting. The results are obtained throughout the classification stage for breast cancer images that are collected from breast‐histology datasets. The proposed solution improves the accuracy of classification whether or not the images had normal, benign, in‐situ, or invasive carcinoma from 87% to 94% with a decrease in processing time from 0.45 to 0.2 s on average. The proposed solution focused on increasing the accuracy of classifying cancer in the breast by enhancing the image contrast and reducing the vanishing gradient. Finally, this solution for the implementation of the contrast limited adaptive histogram equalization technique and modified tangent function helps in increasing the accuracy."
2022,Deep Learning-based and Machine Learning-based Application in Skin Cancer Image Classification,"Abstract: Skin cancer arises from the skin and is capable of invading other parts of the body. The earlier detection of malignant skin lesions effectively helps cure skin disease and prevents fatal skin cancer. As part of AI, machine learning and deep learning can learn the characteristics of input datasets and perform classifications with high accuracy. In this paper, the CNN, KNN, and SVM models are implemented and tested based on the datasets collected from ISIC. The idea of the implementation is to classify the images of skin lesions into benign and malignant. The information of GANs based model is gathered. The results display the accuracy of using these models to classify different types of lesions. And the discussion of the results focuses on the efficiency to implement the machine learning and deep learning models and the accuracy of using them. The goal of the study is to figure out which method is more useful in skin cancer identification. And some of the possible practices are also discussed as future expectations."
2022,Optimal Histopathological Magnification Factors for Deep Learning-Based Breast Cancer Prediction,"Pathologists use histopathology to examine tissues or cells under a microscope to compare healthy and abnormal tissue structures. Differentiating benign from malignant tumors is the most critical aspect of cancer histopathology. Pathologists use a range of magnification factors, including 40x, 100x, 200x, and 400x, to identify abnormal tissue structures. It is a painful process because specialists must spend much time sitting and gazing into the microscope lenses. Hence, pathologists are more likely to make errors due to being overworked or fatigued. Automating cancer detection in histopathology is the best way to mitigate humans’ erroneous diagnostics. Multiple approaches in the literature suggest methods to automate the detection of breast cancer based on the use of histopathological images. This work performs a comprehensive analysis to identify which magnification factors, 40x, 100x, 200x, and 400x, induce higher prediction accuracy. This study found that training Convolutional Neural Networks (CNNs) on 200x and 400x magnification factors increased the prediction accuracy compared to training on 40x and 100x. More specifically, this study finds that the CNN model performs better when trained on 200x than on 400x."
2020,Abstract P5-02-06: Improved histologic grading of breast cancer by a novel deep learning-based model,"Abstract: Breast cancer histologic grade is a well-established prognostic factor utilized in clinical decision making. In current clinical practice grading is conducted manually by pathologists and this procedure is associated with a substantial inter-observer variability. Furthermore, patients classified as histologic grade 2 has been reported to exhibit an intermediate recurrence risk, resulting in less prognostic value. With the aim of improving patient stratification, we have developed a model-based approach for histological grading using deep convolutional neural networks (CNNs). In this study, we developed a CNN model for improved histologic grading, with a focus on further stratification of grade 2 patients into high and low risk groups."
2020,Learning Deep Features for Stain-free Live-dead Human Breast Cancer Cell Classification,"Abstract: Automated cell classification in cancer biology is a challenging topic in computer vision and machine learning research. Breast cancer is the most common malignancy in women that usually involves phenotypically diverse populations of breast cancer cells and an heterogeneous stroma. In recent years, automated microscopy technologies are allowing the study of live cells over extended periods of time, simplifying the task of compiling large image databases. For instance, there have been several studies oriented towards building machine learning systems capable of automatically classifying images of different cell types (i.e. motor neurons, stem cells). In this work we were interested in classifying breast cancer cells as live or dead, based on a set of automatically retrieved morphological characteristics using image processing techniques. Our hypothesis is that live-dead classification can be performed without any staining and using only bright-field images as input. To our knowledge, there is no previous work attempting this task on in vitro studies of breast cancer cells, nor is there a dataset available to explore solutions related to this issue. We tackled this problem using the JIMT-1 breast cancer cell line that grows as an adherent monolayer. First, a vast image set composed by JIMT-1 human breast cancer cells that had been exposed to a chemotherapeutic drug treatment (doxorubicin and paclitaxel) or vehicle control was compiled. Next, several state-of-the-art classifiers were trained based on convolutional neural networks (CNN) to perform supervised classification using labels obtained from fluorescence microscopy images associated with each bright-field image. Model performances were evaluated and compared on a large number of bright-field images. The best model reached an AUC = 0.941 for classifying breast cancer cells without treatment. Furthermore, it reached AUC = 0.978 when classifying breast cancer cells under drug treatment. Our results highlight the potential of machine learning and computational image analysis to build new diagnosis tools that benefit the biomedical field by reducing cost, time, and stimulating work reproducibility. More importantly, we analyzed the way our classifiers clusterize bright-field images in the learned high-dimensional embedding and linked these groups to salient visual characteristics in live-dead cell biology observed by trained experts."
2022,The Efforts of Deep Learning Approaches for Breast Cancer Detection Based on X-Ray Images,"In this chapter, deep learning-based approaches, namely deep feature extraction, fine-tuning of pre-trained convolutional neural networks (CNN), and end-to-end training of a developed CNN model, are used to classify the malignant and normal breast X-ray images. For deep feature extraction, pre-trained deep CNN models such as ResNet18, ResNet50, ResNet101, VGG16, and VGG19 are used. For classification of the deep features, the support vector machines (SVM) classifier is used with various kernel functions namely linear, quadratic, cubic, and Gaussian, respectively. The aforementioned pre-trained deep CNN models are also used in fine-tuning procedure. A new CNN model is also proposed in end-to-end training fashion. The classification accuracy is used as performance measurements. The experimental works show that the deep learning has potential in detection of the breast cancer from the X-ray images. The deep features that are extracted from the ResNet50 model and SVM classifier with linear kernel function produced 94.7% accuracy score which the highest among all obtained."
2022,Optimization of Machine Learning and Deep Learning Algorithms for Diagnosis of Cancer,"Machine learning and artificial intelligence has recently become a prominent technology. Given its popularity and strength in pattern recognition and categorization, many corporations and institutions have begun investing in healthcare research to improve illness prediction accuracy. Using these strategies, however, has several drawbacks. One of the primary issues is the lack of huge datasets for medical pictures. An introduction to deep learning in medical image processing from theoretical foundations to real-world applications. The article examines the general appeal of deep learning (DL), a collection of computer science advances. The next step was to learn the basics of neural networks. That explains the use of deep learning and CNNs. So we can see why deep learning is rapidly advancing in various application fields, including medical image processing. The goal of this research was to use innovative methodologies on cancer datasets to explore the feasibility of combining machine learning and deep learning algorithms for cancer detection. This study used text and picture databases to classify cancer. This article provides optimization methods that outperform the suggested approaches' accuracy. Using two alternative training methods, Levenberg Marquardt (lm) and Resilient back propagation (rp), two classification algorithms were evaluated with different groups of neurons to identify benign and malignant patients. Cascade correlation utilizing the train (rp) outperformed feed forward back propagation using the train (lm). The second deep neural network model presented a technique (based on CNN) for automated brain tumor identification using MRI data."
2021,Breast cancer analysis using Machine Learning algorithms,"Breast cancer (BC) is one of the most common types of cancer and one of the leading causes of death for women around the world. Breast cancer occurs when cells in the breast cells mutate and form a malignant tumor. State-of-the-art technologies can detect BC at an early stage, which helps in treatment and reduces the risk of death. Medical doctors commonly use breast tissue biopsy when diagnosing breast cancer, enabling them to take a microscopic look for breast tissue and determine whether the tissue is benign or malignant. To improve biopsy results, many researchers have studied the feasibility of using artificial intelligence (AI) to help doctors detect any harmful changes that may lead to cancer. In this research work detail analysis of Breast Cancer using support vector machine (SVM) and convolutional neural networks (CNN) algorithms is performed and the results show CNN has more superior results in comparison to SVM in the recognition of images affected by Breast Cancer."
2019,Cancer Diagnosis Using Deep Learning: A Bibliographic Review,"In this paper, we first describe the basics of the field of cancer diagnosis, which includes steps of cancer diagnosis followed by the typical classification methods used by doctors, providing a historical idea of cancer classification techniques to the readers. These methods include Asymmetry, Border, Color and Diameter (ABCD) method, seven-point detection method, Menzies method, and pattern analysis. They are used regularly by doctors for cancer diagnosis, although they are not considered very efficient for obtaining better performance. Moreover, considering all types of audience, the basic evaluation criteria are also discussed. The criteria include the receiver operating characteristic curve (ROC curve), Area under the ROC curve (AUC), F1 score, accuracy, specificity, sensitivity, precision, dice-coefficient, average accuracy, and Jaccard index. Previously used methods are considered inefficient, asking for better and smarter methods for cancer diagnosis. Artificial intelligence and cancer diagnosis are gaining attention as a way to define better diagnostic tools. In particular, deep neural networks can be successfully used for intelligent image analysis. The basic framework of how this machine learning works on medical imaging is provided in this study, i.e., pre-processing, image segmentation and post-processing. The second part of this manuscript describes the different deep learning techniques, such as convolutional neural networks (CNNs), generative adversarial models (GANs), deep autoencoders (DANs), restricted Boltzmann’s machine (RBM), stacked autoencoders (SAE), convolutional autoencoders (CAE), recurrent neural networks (RNNs), long short-term memory (LTSM), multi-scale convolutional neural network (M-CNN), multi-instance learning convolutional neural network (MIL-CNN). For each technique, we provide Python codes, to allow interested readers to experiment with the cited algorithms on their own diagnostic problems. The third part of this manuscript compiles the successfully applied deep learning models for different types of cancers. Considering the length of the manuscript, we restrict ourselves to the discussion of breast cancer, lung cancer, brain cancer, and skin cancer. The purpose of this bibliographic review is to provide researchers opting to work in implementing deep learning and artificial neural networks for cancer diagnosis a knowledge from scratch of the state-of-the-art achievements."
2019,Parallel Structure Deep Neural Network Using CNN and RNN with an Attention Mechanism for Breast Cancer Histology Image Classification,"In this paper, we present a new deep learning model to classify hematoxylin–eosin-stained breast biopsy images into four classes (normal tissues, benign lesions, in situ carcinomas, and invasive carcinomas). Our model uses a parallel structure consist of a convolutional neural network (CNN) and a recurrent neural network (RNN) for image feature extraction, which is greatly different from the common existed serial method of extracting image features by CNN and then inputting them into RNN. Then, we introduce a special perceptron attention mechanism, which is derived from the natural language processing (NLP) field, to unify the features extracted by the two different neural network structures of the model. In the convolution layer, general batch normalization is replaced by the new switchable normalization method. And the latest regularization technology, targeted dropout, is used to substitute for the general dropout in the last three fully connected layers of the model. In the testing phase, we use the model fusion method and test time augmentation technology on three different datasets of hematoxylin–eosin-stained breast biopsy images. The results demonstrate that our model significantly outperforms state-of-the-art methods."
2022,Federated Learning aided Breast Cancer Detection with Intelligent Heuristic-based Deep Learning Framework,"Abstract: Breast cancer is the second largest cause of female cancer death and one of the most hazardous diseases that leads to a higher mortality rate. Breast cancer is initialized with the malignant stage, where the abnormal growth of cancerous lumps is initiated from the breast cells. Periodic clinical checks and self-tests assist in early identification and thus progress the survival rates considerably. One of the eminent medical approaches is breast cancer recognition, which offers scientists and researchers huge complications. Breast cancer detection at an early stage permits the patients to receive suitable treatment, which increases the chances of survival. Thus, this paper utilizes a new form of artificial intelligence training called Federated Learning (FL), especially for breast cancer detection, the most eminent technique in the last few years. FL permits individual hospitals to benefit from the rich datasets of multiple non-affiliated hospitals without centralizing the data in one place. Hence, FL utilizes numerous collaborators for building a strong deep-learning model using a large dataset. In this paper, a hybridization of this type of training with a meta-heuristic and deep learning is aimed to be proposed for breast cancer diagnosis. This model encloses diverse steps that include (a) image collection, (b) feature extraction, and (c) classification phase. Initially, the mammogram images related to breast cancer are collected with the concept of FL from the affected individuals. The federated learning helps in reducing the processing time and ensures better performance of the proposed model. The obtained images are considered for the feature extraction phase. The Densenet architecture is used to extract the features used in the classification phase with the help of Enhanced Recurrent Neural Networks (E-RNN) for detecting breast cancer. Here, the performance is enhanced by tuning the certain parameter in the RNN network using a hybrid optimization algorithm called Hybrid Dragon-Rider Optimization (HDRO) with Dragonfly Algorithm (DA) and Red deer algorithm (RDA) to achieve accurate classification results. The experimental results demonstrate the effectiveness of the suggested breast cancer diagnosis model compared with conventional approaches using diverse quantitative measures."
2023,Breast Tumor Detection Using Efficient Machine Learning and Deep Learning Techniques,"Breast cancer tissues grow when cells in the breast expand and divide uncontrollably, resulting in a lump of tissue commonly called and named tumor. Breast cancer is the second most prevalent cancer among women, following skin cancer. While it is more commonly diagnosed in women aged 50 and above, it can affect individuals of any age. Although it is rare, men can also develop breast cancer, accounting for less than 1% of all cases, with approximately 2,600 cases reported annually in the United States. Early detection of breast tumors is crucial in reducing the risk of developing breast cancer. A publicly available dataset containing features of breast tumors was utilized to identify breast tumors using machine learning and deep learning techniques. Various prediction models were constructed, including logistic regression (LR), decision tree (DT), random forest (RF), support vector machine (SVM), Gradient Boosting (GB), Extreme Gradient Boosting (XGB), Light GBM, and a recurrent neural network (RNN) model. These models were trained to classify and predict breast tumor cases based on the provided features."
2022,Predicting Breast Cancer Based on Optimized Deep Learning Approach,"Breast cancer is a dangerous disease with a high morbidity and mortality rate. One of the most important aspects in breast cancer treatment is getting an accurate diagnosis. Machine-learning (ML) and deep learning techniques can help doctors in making diagnosis decisions. This paper proposed the optimized deep recurrent neural network (RNN) model based on RNN and the Keras–Tuner optimization technique for breast cancer diagnosis. The optimized deep RNN consists of the input layer, five hidden layers, five dropout layers, and the output layer. In each hidden layer, we optimized the number of neurons and rate values of the dropout layer. Three feature-selection methods have been used to select the most important features from the database. Five regular ML models, namely decision tree (DT), support vector machine (SVM), random forest (RF), naive Bayes (NB), and K-nearest neighbor algorithm (KNN) were compared with the optimized deep RNN. The regular ML models and the optimized deep RNN have been applied the selected features. The results showed that the optimized deep RNN with the selected features by univariate has achieved the highest performance for CV and the testing results compared to the other models."
2022,Models of Artificial Intelligence-Assisted Diagnosis of Lung Cancer Pathology Based on Deep Learning Algorithms,"In this article, in order to explore the application of a diagnosis system for lung cancer, we use an auxiliary diagnostic system to predict and diagnose the good and evil attributes of chest CT pulmonary nodules. This research improves the new diagnosis method based on the convolutional neural network (CNN) and the recurrent neural network (RNN) and combines the dual effects of the two algorithms to process the classification of benign and malignant nodules. By collecting H-E-stained pathological slices of 652 patients' lung lesions from two hospitals between January 2018 and January 2019, the output results of the improved 3D U-net system and the consistent results of two-person reading were compared. This article analyzes the sensitivity, specificity, positive flammability rate, and negative flammability rate of different lung nodule detection methods. In addition, the artificial intelligence system’s and the radiologist's judgment results of benign and malignant pulmonary nodules are used to draw ROC curves for further analysis. The improved model has an accuracy rate of 92.3% for predicting malignant lung nodules and an accuracy rate of 82.8% for benign lung nodules. The new diagnostic method using the convolutional neural network and the recurrent neural network can be very effective for improving the accuracy of predicting lung cancer diagnosis. It can play a very effective role in the disease prediction of lung cancer patients, thereby improving the treatment effect."
2019,Cancer Diagnosis Using Deep Learning: A Bibliographic Review,"In this paper, we first describe the basics of the field of cancer diagnosis, which includes steps of cancer diagnosis followed by the typical classification methods used by doctors, providing a historical idea of cancer classification techniques to the readers. These methods include Asymmetry, Border, Color and Diameter (ABCD) method, seven-point detection method, Menzies method, and pattern analysis. They are used regularly by doctors for cancer diagnosis, although they are not considered very efficient for obtaining better performance. Moreover, considering all types of audience, the basic evaluation criteria are also discussed. The criteria include the receiver operating characteristic curve (ROC curve), Area under the ROC curve (AUC), F1 score, accuracy, specificity, sensitivity, precision, dice-coefficient, average accuracy, and Jaccard index. Previously used methods are considered inefficient, asking for better and smarter methods for cancer diagnosis. Artificial intelligence and cancer diagnosis are gaining attention as a way to define better diagnostic tools. In particular, deep neural networks can be successfully used for intelligent image analysis. The basic framework of how this machine learning works on medical imaging is provided in this study, i.e., pre-processing, image segmentation and post-processing. The second part of this manuscript describes the different deep learning techniques, such as convolutional neural networks (CNNs), generative adversarial models (GANs), deep autoencoders (DANs), restricted Boltzmann’s machine (RBM), stacked autoencoders (SAE), convolutional autoencoders (CAE), recurrent neural networks (RNNs), long short-term memory (LTSM), multi-scale convolutional neural network (M-CNN), multi-instance learning convolutional neural network (MIL-CNN). For each technique, we provide Python codes, to allow interested readers to experiment with the cited algorithms on their own diagnostic problems. The third part of this manuscript compiles the successfully applied deep learning models for different types of cancers. Considering the length of the manuscript, we restrict ourselves to the discussion of breast cancer, lung cancer, brain cancer, and skin cancer. The purpose of this bibliographic review is to provide researchers opting to work in implementing deep learning and artificial neural networks for cancer diagnosis a knowledge from scratch of the state-of-the-art achievements."
2018,Staingan: Stain Style Transfer for Digital Histological Images,"Digitized Histological diagnosis is in increasing demand. However, color variations due to various factors are imposing obstacles to the diagnosis process. The problem of stain color variations is a well-defined problem with many proposed solutions. Most of these solutions are highly dependent on a reference template slide. We propose a deep-learning solution inspired by CycleGANs that is trained end-to-end, eliminating the need for an expert to pick a representative reference slide. Our approach showed superior results quantitatively and qualitatively against the state of the art methods (10% improvement visually using SSIM). We further validated our method on a clinical use-case, namely Breast Cancer tumor classification, showing a 12% increase in AUC. The code is made publicly available 1.1https://github.com/xtarx/StainGAN"
2019,Deep Learning Approaches for Data Augmentation and Classification of Breast Masses using Ultrasound Images,"Breast classification and detection using ultrasound imaging is considered a significant step in computer-aided diagno-sis systems. Over the previous decades, researchers have proved the opportunities to automate the initial tumor classification and detection. The shortage of popular datasets of ultrasound images of breast cancer prevents researchers from obtaining a good performance of the classification algorithms. Traditional augmentation approaches are firmly limited, especially in tasks where the images follow strict standards, as in the case of medical datasets. Therefore besides the traditional augmentation, we use a new methodology for data augmentation using Generative Adversarial Network (GAN). We achieved higher accuracies by integrating traditional with GAN-based augmentation. This paper uses two breast ultrasound image datasets obtained from two various ultrasound systems. The first dataset is our dataset which was collected from Baheya Hospital for Early Detection and Treatment of Women’s Cancer, Cairo (Egypt), we name it (BUSI) referring to Breast Ultrasound Images (BUSI) dataset. It contains 780 images (133 normal, 437 benign and 210 malignant). While the Dataset (B) is obtained from related work and it has 163 images (110 benign and 53 malignant). To overcome the shortage of public datasets in this field, BUSI dataset will be publicly available for researchers. Moreover, in this paper, deep learning approaches are proposed to be used for breast ultrasound classification. We examine two different methods: a Convolutional Neural Network (CNN) approach and a Transfer Learning (TL) approach and we compare their performance with and without augmentation. The results confirm an overall enhancement using augmentation methods with deep learning classification methods (especially transfer learning) when evaluated on the two datasets."
2020,Feature article: A generative adversarial network for artifact removal in photoacoustic computed tomography with a linear-array transducer,"With balanced spatial resolution, penetration depth, and imaging speed, photoacoustic computed tomography (PACT) is promising for clinical translation such as in breast cancer screening, functional brain imaging, and surgical guidance. Typically using a linear ultrasound (US) transducer array, PACT has great flexibility for hand-held applications. However, the linear US transducer array has a limited detection angle range and frequency bandwidth, resulting in limited-view and limited-bandwidth artifacts in the reconstructed PACT images. These artifacts significantly reduce the imaging quality. To address these issues, existing solutions often have to pay the price of system complexity, cost, and/or imaging speed. Here, we propose a deep-learning-based method that explores the Wasserstein generative adversarial network with gradient penalty (WGAN-GP) to reduce the limited-view and limited-bandwidth artifacts in PACT. Compared with existing reconstruction and convolutional neural network approach, our model has shown improvement in imaging quality and resolution. Our results on simulation, phantom, and in vivo data have collectively demonstrated the feasibility of applying WGAN-GP to improve PACT’s image quality without any modification to the current imaging set-up. Impact statement This study has the following main impacts. It offers a promising solution for removing limited-view and limited-bandwidth artifact in PACT using a linear-array transducer and conventional image reconstruction, which have long hindered its clinical translation. Our solution shows unprecedented artifact removal ability for in vivo image, which may enable important applications such as imaging tumor angiogenesis and hypoxia. The study reports, for the first time, the use of an advanced deep-learning model based on stabilized generative adversarial network. Our results have demonstrated its superiority over other state-of-the-art deep-learning methods."
2019,Pathology GAN: Learning deep representations of cancer tissue,"Histopathological images of tumours contain abundant information about how tumours grow and how they interact with their micro-environment. Better understanding of tissue phenotypes in these images could reveal novel determinants of pathological processes underlying cancer, and in turn improve diagnosis and treatment options. Advances of Deep learning makes it ideal to achieve those goals, however, its application is limited by the cost of high quality labels from patients data. Unsupervised learning, in particular, deep generative models with representation learning properties provides an alternative path to further understand cancer tissue phenotypes, capturing tissue morphologies. In this paper, we develop a framework which allows Generative Adversarial Networks (GANs) to capture key tissue features and uses these characteristics to give structure to its latent space. To this end, we trained our model on two different datasets, an H&E colorectal cancer tissue from the National Center for Tumor diseases (NCT, Germany) and an H&E breast cancer tissue from the Netherlands Cancer Institute (NKI, Netherlands) and Vancouver General Hospital (VGH, Canada). Composed of 86 slide images and 576 tissue micro-arrays (TMAs) respectively. We show that our model generates high quality images, with a Frechet Inception Distance (FID) of 16.65 (breast cancer) and 32.05 (colorectal cancer). We further assess the quality of the images with cancer tissue characteristics (e.g. count of cancer, lymphocytes, or stromal cells), using quantitative information to calculate the FID and showing consistent performance of 9.86. Additionally, the latent space of our model shows an interpretable structure and allows semantic vector operations that translate into tissue feature transformations. Furthermore, ratings from two expert pathologists found no significant difference between our generated tissue images from real ones. The code, generated images, and pretrained model are available at https://github.com/AdalbertoCq/Pathology-GAN"
2020,Classification of Breast Cancer Histopathological Images Using Discriminative Patches Screened by Generative Adversarial Networks,"Computer-aided diagnosis (CAD) systems of breast cancer histopathological images automated classification can help reduce the manual observation workload of pathologists. In the classification of breast cancer histopathology images, due to the small number and high-resolution of the training samples, the patch-based image classification methods have become very necessary. However, adopting a patches-based classification method is very challenging, since the patch-level datasets extracted from whole slide images (WSIs) contain many mislabeled patches. Existing patch-based classification methods have paid little attention to addressing the mislabeled patches for improving the performance of classification. To solve this problem, we propose a novel approach, named DenseNet121-AnoGAN, for classifying breast histopathological images into benign and malignant classes. The proposed approach consists of two major parts: using an unsupervised anomaly detection with generative adversarial networks (AnoGAN) to screen mislabeled patches and using densely connected convolutional network (DenseNet) to extract multi-layered features of the discriminative patches. The performance of the proposed approach is evaluated on the publicly available BreaKHis dataset using 5-fold cross validation. The proposed DenseNet121-AnoGAN can be better suited to coarse-grained high-resolution images and achieved satisfactory classification performance in 40X and 100X images. The best accuracy of 99.13% and the best $F1_{score}$ of 99.38% have been obtained at the image level for the 40X magnification factor. We have also investigated the performance of AnoGAN on the other classification networks, including AlexNet, VGG16, VGG19, and ResNet50. Our experiments show that whether it is at the patient-level accuracy or at the image-level accuracy, the classification networks with AnoGAN have provided better performance than the classification networks without AnoGAN."
2023,"Classification of Breast Masses Using Ultrasound Images by Approaching GAN, Transfer Learning and Deep Learning Techniques","Breast cancer is a common cause of death among women worldwide. Ultrasonic imaging is a valuable diagnostic tool in breast cancer detection. However, the accuracy of computer-aided diagnosis systems for breast cancer classification is limited due to the lack of well-annotated datasets. This study proposes a deep learning-based framework for breast mass classification using ultrasound images, which incorporates a novel data augmentation technique, Generative Adversarial Network (GAN), and Transfer Learning (TL). Automating early tumor identification and classification in breast cancer diagnosis can save lives by improving the accuracy of diagnoses and reducing the need for invasive procedures. However, the limited availability of well-annotated datasets for ultrasound images of breast cancer has hampered the development of accurate computer-aided diagnosis systems. The accuracy of breast mass classification using ultrasound images is limited due to the lack of well-annotated datasets. Conventional data augmentation techniques have limitations in applications with strict guidelines, such as medical datasets. Therefore, there is a need to develop a novel data augmentation technique to improve the accuracy of breast mass classification using ultrasound images. The proposed framework can be extended to other medical imaging applications, where the availability of well-annotated datasets is limited. The GAN-based data augmentation technique and TL-based feature extraction can be used to improve the accuracy of classification models in other medical imaging applications. Additionally, the proposed framework can be used to develop accurate computer-aided diagnosis systems for breast cancer detection in clinical settings. The proposed framework incorporates a deep learning-based approach for breast mass classification using ultrasound images. The framework includes a GAN-based data augmentation technique and TL for feature extraction. The dataset used for training and testing the model is the Breast Ultrasound Images (BUSI) dataset, which includes 1311 images with normal and abnormal breast masses. The proposed framework achieved an accuracy of 99.6% for breast mass classification using ultrasound images, which outperformed existing methods. The GAN-based data augmentation technique and TL-based feature extraction improved the accuracy of the classification model. The results suggest that deep learning algorithms can be effectively applied for breast ultrasound categorization. The proposed framework presents a novel approach for breast mass classification using ultrasound images, which incorporates a GAN-based data augmentation technique and TL-based feature extraction. The results demonstrate that the proposed framework outperforms existing methods and achieves high accuracy in breast mass classification using ultrasound images. This framework can be useful for developing accurate computer-aided diagnosis systems for breast cancer detection."
2023,Deep Learning Theories and Methods for Breast Cancer Classification,"Breast cancer is a common malignant tumour and studies have shown that early and accurate detection is crucial for patients. With the maturity of medical imaging and deep learning development, significant progress has been made in breast cancer classification, which greatly improves the accuracy and efficiency of classification. This review focuses on deep learning, migration learning, GAN, and lifelong learning to elaborate and summarise the important roles arising from breast cancer detection. This review also examines the dataset and labeling issues required for breast cancer classification. In conclusion, at the end of the article, we look at future directions for breast cancer classification research, including cross-migration learning, multimodal data fusion, model interpretability, and lifelong learning, and also explore how to provide personalized treatment plans for patients."
2023,Assessing VTE Risk in Cancer Patients Using Deep Learning Synthetic Data Generation and Domain Adaptation Techniques,"This article focuses on the use of deep learning synthetic data generation methods to assess the risk of future treatments and medication for preventing venous thromboembolism (VTE) in cancer patients, based on a small dataset of genetic and clinical variables. The study employs CopulaGANs to generate synthetic tabular data, which is then used to train a Deep Learning-based classifier using domain adaptation techniques. The trained model is fine-tuned using real data and performs better than current state-of-the-art medical scores in assessing VTE risk. Additionally, the resulting Precision-Recall curve offers flexibility in selecting different and better operational points for VTE risk assessment."
2021,Connected-UNets: a deep learning architecture for breast mass segmentation,"Abstract: Breast cancer analysis implies that radiologists inspect mammograms to detect suspicious breast lesions and identify mass tumors. Artificial intelligence techniques offer automatic systems for breast mass segmentation to assist radiologists in their diagnosis. With the rapid development of deep learning and its application to medical imaging challenges, UNet and its variations is one of the state-of-the-art models for medical image segmentation that showed promising performance on mammography. In this paper, we propose an architecture, called Connected-UNets, which connects two UNets using additional modified skip connections. We integrate Atrous Spatial Pyramid Pooling (ASPP) in the two standard UNets to emphasize the contextual information within the encoder–decoder network architecture. We also apply the proposed architecture on the Attention UNet (AUNet) and the Residual UNet (ResUNet). We evaluated the proposed architectures on two publically available datasets, the Curated Breast Imaging Subset of Digital Database for Screening Mammography (CBIS-DDSM) and INbreast, and additionally on a private dataset. Experiments were also conducted using additional synthetic data using the cycle-consistent Generative Adversarial Network (CycleGAN) model between two unpaired datasets to augment and enhance the images. Qualitative and quantitative results show that the proposed architecture can achieve better automatic mass segmentation with a high Dice score of 89.52%, 95.28%, and 95.88% and Intersection over Union (IoU) score of 80.02%, 91.03%, and 92.27%, respectively, on CBIS-DDSM, INbreast, and the private dataset."
2021,PathologyGAN: Learning deep representations of cancer tissue,"Histopathological images of tumours contain abundant information about how tumours grow and how they interact with their micro-environment. Better understanding of tissue phenotypes in these images could reveal novel determinants of pathological processes underlying cancer, and in turn improve diagnosis and treatment options. Advances of Deep learning makes it ideal to achieve those goals, however, its application is limited by the cost of high quality labels from patients data. Unsupervised learning, in particular, deep generative models with representation learning properties provides an alternative path to further understand cancer tissue phenotypes, capturing tissue morphologies. In this paper, we develop a framework which allows Generative Adversarial Networks (GANs) to capture key tissue features and uses these characteristics to give structure to its latent space. To this end, we trained our model on two different datasets, an H&E colorectal cancer tissue from the National Center for Tumor diseases (NCT, Germany) and an H&E breast cancer tissue from the Netherlands Cancer Institute (NKI, Netherlands) and Vancouver General Hospital (VGH, Canada). Composed of 86 slide images and 576 tissue micro-arrays (TMAs) respectively. We show that our model generates high quality images, with a Frechet Inception Distance (FID) of 16.65 (breast cancer) and 32.05 (colorectal cancer). We further assess the quality of the images with cancer tissue characteristics (e.g. count of cancer, lymphocytes, or stromal cells), using quantitative information to calculate the FID and showing consistent performance of 9.86. Additionally, the latent space of our model shows an interpretable structure and allows semantic vector operations that translate into tissue feature transformations. Furthermore, ratings from two expert pathologists found no significant difference between our generated tissue images from real ones. The code, generated images, and pretrained model are available at https://github.com/AdalbertoCq/Pathology-GAN"
2022,Deep Learning-based and Machine Learning-based Application in Skin Cancer Image Classification,"Abstract: Skin cancer arises from the skin and is capable of invading other parts of the body. The earlier detection of malignant skin lesions effectively helps cure skin disease and prevents fatal skin cancer. As part of AI, machine learning and deep learning can learn the characteristics of input datasets and perform classifications with high accuracy. In this paper, the CNN, KNN, and SVM models are implemented and tested based on the datasets collected from ISIC. The idea of the implementation is to classify the images of skin lesions into benign and malignant. The information of GANs based model is gathered. The results display the accuracy of using these models to classify different types of lesions. And the discussion of the results focuses on the efficiency to implement the machine learning and deep learning models and the accuracy of using them. The goal of the study is to figure out which method is more useful in skin cancer identification. And some of the possible practices are also discussed as future expectations."
2018,Breast cancer classification using machine learning,"During their life, among 8% of women are diagnosed with Breast cancer (BC), after lung cancer, BC is the second popular cause of death in both developed and undeveloped worlds. BC is characterized by the mutation of genes, constant pain, changes in the size, color(redness), skin texture of breasts. Classification of breast cancer leads pathologists to find a systematic and objective prognostic, generally the most frequent classification is binary (benign cancer/malign cancer). Today, Machine Learning (ML) techniques are being broadly used in the breast cancer classification problem. They provide high classification accuracy and effective diagnostic capabilities. In this paper, we present two different classifiers: Naive Bayes (NB) classifier and knearest neighbor (KNN) for breast cancer classification. We propose a comparison between the two new implementations and evaluate their accuracy using cross validation. Results show that KNN gives the highest accuracy (97.51%) with lowest error rate then NB classifier (96.19 %)."
2022,Computational Technique Based on Machine Learning and Image Processing for Medical Image Analysis of Breast Cancer Diagnosis,"Breast cancer is the most lethal type of cancer for all women worldwide. At the moment, there are no effective techniques for preventing or curing breast cancer, as the source of the disease is unclear. Early diagnosis is a highly successful means of detecting and managing breast cancer, and early identification may result in a greater likelihood of complete recovery. Mammography is the most effective method of detecting breast cancer early. Additionally, this instrument enables the detection of additional illnesses and may provide information about the nature of cancer, such as benign, malignant, or normal. This article discusses an evolutionary approach for classifying and detecting breast cancer that is based on machine learning and image processing. This model combines image preprocessing, feature extraction, feature selection, and machine learning techniques to aid in the classification and identification of skin diseases. To enhance the image’s quality, a geometric mean filter is used. AlexNet is used for extracting features. Feature selection is performed using the relief algorithm. For disease categorization and detection, the model makes use of the machine learning techniques such as least square support vector machine, KNN, random forest, and Naïve Bayes. The experimental investigation makes use of MIAS data collection. This proposed technology is advantageous for accurately identifying breast cancer disease using image analysis."
2019,Analysis of Decision Tree and K-Nearest Neighbor Algorithm in the Classification of Breast Cancer,"Objective: The death rate of breast tumour is falling as there is progress in its research area. However, it is the most common disease among women. It is a great challenge in designing a machine learning model to evaluate the performance of the classification of breast tumour. Methods: Implementing an efficient classification methodology will support in resolving the complications in analyzing breast cancer. This proposed model employs two machine learning (ML) algorithms for the categorization of breast tumour; Decision Tree and K-Nearest Neighbour (KNN) algorithm is used for the breast tumour classification. Result: This classification includes the two levels of disease as benign or malignant. These two machine learning algorithms are verified using the Wisconsin Diagnostic Breast Cancer (WDBC) dataset after feature selection using Principal Component Analysis (PCA). The comparison of these two ML algorithms is done using the standard performance metrics. Conclusion: The comparative analysis results indicate that the KNN classifier outperforms the result of the decision-tree classifier in the breast cancer classification."
2018,Diagnostic Accuracy of Different Machine Learning Algorithms for Breast Cancer Risk Calculation: a Meta-Analysis,"Objective The aim of this study was to determine the diagnostic accuracy of different machine learning algorithms for breast cancer risk calculation. Methods A meta-analysis was conducted of published research articles on diagnostic test accuracy of different machine learning algorithms for breast cancer risk calculation published between January 2000 and May 2018 in the online article databases of PubMed, ProQuest and EBSCO. Paired forest plots were employed for the analysis. Numerical values for sensitivity and specificity were obtained from false negative (FN), false positive (FP), true negative (TN) and true positive (TP) rates, presented alongside graphical representations with boxes marking the values and horizontal lines showing the confidence intervals (CIs). Summary receiver operating characteristic (SROC) curves were applied to assess the performance of diagnostic tests. Data were processed using Review Manager 5.3 (RevMan 5.3). Results A total of 1,879 articles were reviewed, of which 11 were selected for systematic review and meta-analysis. Fve algorithms for machine learning able to predict breast cancer risk were identified: Super Vector Machine (SVM); Artificial Neural Networks (ANN); Decision Tree (DT); Naive Bayes (NB); and K-Nearest Neighbor (KNN). With the SVM, the Area Under Curve (AUC) from the SROC was > 90%, therefore classified into the excellent category. Conclusion The meta-analysis confirmed that the SVM algorithm is able to calculate breast cancer risk with better accuracy value than other machine learning algorithms."
2019,Prediction of Breast Cancer Using Supervised Machine Learning Techniques,": Breast Cancer is the most often identified cancer among women and major reason for increasing mortality rate among women. As the diagnosis of this disease manually takes long hours and the lesser availability of systems, there is a need to develop the automatic diagnosis system for early detection of cancer. Data mining techniques contribute a lot in the development of such system. For the classification of benign and malignant tumor we have used classification techniques of machine learning in which the machine is learned from the past data and can predict the category of new input. This paper is a relative study on the implementation of models using Logistic Regression, Support Vector Machine (SVM) and K Nearest Neighbor (KNN) is done on the dataset taken from the UCI repository. With respect to the results of accuracy, precision, sensitivity, specificity and False Positive Rate the efficiency of each algorithm is measured and compared. These techniques are coded in python and executed in Spyder, the Scientific Python Development Environment. Our experiments have shown that SVM is the best for predictive analysis with an accuracy of 92.7%.We infer from our study that SVM is the well suited algorithm for prediction and on the whole KNN presented well next to SVM."
2022,Improved Machine Learning-Based Predictive Models for Breast Cancer Diagnosis,"Breast cancer death rates are higher than any other cancer in American women. Machine learning-based predictive models promise earlier detection techniques for breast cancer diagnosis. However, making an evaluation for models that efficiently diagnose cancer is still challenging. In this work, we proposed data exploratory techniques (DET) and developed four different predictive models to improve breast cancer diagnostic accuracy. Prior to models, four-layered essential DET, e.g., feature distribution, correlation, elimination, and hyperparameter optimization, were deep-dived to identify the robust feature classification into malignant and benign classes. These proposed techniques and classifiers were implemented on the Wisconsin Diagnostic Breast Cancer (WDBC) and Breast Cancer Coimbra Dataset (BCCD) datasets. Standard performance metrics, including confusion matrices and K-fold cross-validation techniques, were applied to assess each classifier’s efficiency and training time. The models’ diagnostic capability improved with our DET, i.e., polynomial SVM gained 99.3%, LR with 98.06%, KNN acquired 97.35%, and EC achieved 97.61% accuracy with the WDBC dataset. We also compared our significant results with previous studies in terms of accuracy. The implementation procedure and findings can guide physicians to adopt an effective model for a practical understanding and prognosis of breast cancer tumors."
2022,A Systematic Method for Breast Cancer Classification using RFE Feature Selection,"Breast cancer is among leading reasons for the deaths of women globally. Machine learning techniques can help to classify breast cancer based on some features. In order to find a systematic method for breast cancer classification, authors have compared the performance of four different classifiers: Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Logistic Regression (LR), and Random Forest (RF) on Wisconsin Breast Cancer Original (WBCO) dataset. The classifiers were used alone as well as along with techniques of feature selection. The performance with regard to accuracy, specificity, sensitivity, precision, and F -Measure, was compared for both types of experiments: classification with feature selection and without feature selection. The Recursive Feature Selection (RFE) technique was applied to select promising features out of available features. There was a significant increase in the performance of classifiers after using the RFE technique. KNN with feature selection provided the highest accuracy (98.31 %) among all other classifiers."
2018,Early Detection of Breast Cancer Using Machine Learning Techniques,"Cancer is the second cause of death in the world. 8.8 million patients died due to cancer in 2015. Breast cancer is the leading cause of death among women. Several types of research have been done on early detection of breast cancer to start treatment and increase the chance of survival. Most of the studies concentrated on mammogram images. However, mammogram images sometimes have a risk of false detection that may endanger the patient’s health. It is vital to find alternative methods which are easier to implement and work with different data sets, cheaper and safer, that can produce a more reliable prediction. This paper proposes a hybrid model combined of several Machine Learning (ML) algorithms including Support Vector Machine (SVM), Artificial Neural Network (ANN), K-Nearest Neighbor (KNN), Decision Tree (DT) for effective breast cancer detection. This study also discusses the datasets used for breast cancer detection and diagnosis. The proposed model can be used with different data types such as image, blood, etc."
2020,A Systematic Review of Breast Cancer Detection Using Thermography and Neural Networks,"Breast cancer plays a significant role in affecting female mortality. Researchers are actively seeking to develop early detection methods of breast cancer. Several technologies contributed to the reduction in mortality rate from this disease, but early detection contributes most to preventing disease spread, breast amputation and death. Thermography is a promising technology for early diagnosis where thermal cameras employed are of high resolution and sensitivity. The combination of Artificial Intelligence (AI) with thermal images is an effective tool to detect early stage breast cancer and is foreseen to provide impressive predictability levels. This paper reviews systematically the related works employing thermography with AI highlighting their contributions and drawbacks and proposing open issues for research. Several different types of Artificial Neural Networks (ANNs) and deep learning models were used in the literature to process thermographic images of breast cancer, such as Radial Basis Function Network (RBFN), K-Nearest Neighbors (KNN), Probability Neural Network (PNN), Support Vector Machine (SVM), ResNet50, SeResNet50, V Net, Bayes Net, Convolutional Neural Networks (CNN), Convolutional and DeConvolutional Neural Networks (C-DCNN), VGG-16, Hybrid (ResNet-50 and V-Net), ResNet101, DenseNet and InceptionV3. Previous studies were found limited to varying the numbers of thermal images used mostly from DMR-IR database. In addition, analysis of the literature indicate that several factors do affect the performance of the Neural Network used, such as Database, optimization method, Network model and extracted features. However, due to small sample size used, most of the studies achieved a classification accuracy of 80% to 100%."
2022,Deep Learning and Machine Learning with Grid Search to Predict Later Occurrence of Breast Cancer Metastasis Using Clinical Data,"Background: It is important to be able to predict, for each individual patient, the likelihood of later metastatic occurrence, because the prediction can guide treatment plans tailored to a specific patient to prevent metastasis and to help avoid under-treatment or over-treatment. Deep neural network (DNN) learning, commonly referred to as deep learning, has become popular due to its success in image detection and prediction, but questions such as whether deep learning outperforms other machine learning methods when using non-image clinical data remain unanswered. Grid search has been introduced to deep learning hyperparameter tuning for the purpose of improving its prediction performance, but the effect of grid search on other machine learning methods are under-studied. In this research, we take the empirical approach to study the performance of deep learning and other machine learning methods when using non-image clinical data to predict the occurrence of breast cancer metastasis (BCM) 5, 10, or 15 years after the initial treatment. We developed prediction models using the deep feedforward neural network (DFNN) methods, as well as models using nine other machine learning methods, including naïve Bayes (NB), logistic regression (LR), support vector machine (SVM), LASSO, decision tree (DT), k-nearest neighbor (KNN), random forest (RF), AdaBoost (ADB), and XGBoost (XGB). We used grid search to tune hyperparameters for all methods. We then compared our feedforward deep learning models to the models trained using the nine other machine learning methods. Results: Based on the mean test AUC (Area under the ROC Curve) results, DFNN ranks 6th, 4th, and 3rd when predicting 5-year, 10-year, and 15-year BCM, respectively, out of 10 methods. The top performing methods in predicting 5-year BCM are XGB (1st), RF (2nd), and KNN (3rd). For predicting 10-year BCM, the top performers are XGB (1st), RF (2nd), and NB (3rd). Finally, for 15-year BCM, the top performers are SVM (1st), LR and LASSO (tied for 2nd), and DFNN (3rd). The ensemble methods RF and XGB outperform other methods when data are less balanced, while SVM, LR, LASSO, and DFNN outperform other methods when data are more balanced. Our statistical testing results show that at a significance level of 0.05, DFNN overall performs comparably to other machine learning methods when predicting 5-year, 10-year, and 15-year BCM. Conclusions: Our results show that deep learning with grid search overall performs at least as well as other machine learning methods when using non-image clinical data. It is interesting to note that some of the other machine learning methods, such as XGB, RF, and SVM, are very strong competitors of DFNN when incorporating grid search. It is also worth noting that the computation time required to do grid search with DFNN is much more than that required to do grid search with the other nine machine learning methods."
2018,Microarray breast cancer data classification using machine learning methods,"In this study We used microarray breast cancer data for classification of the patients using machine learning methods. First, 8 different machine learning algorithms are applied to the data, without applying any feature selection methods. Then two different feature selection methods are applied. The results of the classifications are compared with each other and with the results of the first case. The methods applied are SVM, KNN, MLP, Decision Trees, Random Forest, Logistic Regression, Adaboost and Gradient Boosting Machines. After applying the two different feature selection methods with the best 50 features are applied, SVM gave the best results. MLP is applied using different number of layers and neurons to examine the effect of the number of layers and neurons on the classification accuracy. It is determined that the increase in the number of layers sometimes decreased, sometimes didn't change the accuracy."
2015,BREAST CANCER DIAGNOSIS AND RECURRENCE PREDICTION USING MACHINE LEARNING TECHNIQUES,"Breast Cancer has become the common cause of death among women. Due to long hours invested in manual diagnosis and lesser diagnostic system available emphasize the development of automated diagnosis for early diagnosis of the disease. Our aim is to classify whether the breast cancer is benign or malignant and predict the recurrence and non-recurrence of malignant cases after a certain period. To achieve this we have used machine learning techniques such as Support Vector Machine, Logistic Regression, KNN and Naive Bayes. These techniques are coded in MATLAB using UCI machine learning depository. We have compared the accuracies of different techniques and observed the results. We found SVM most suited for predictive analysis and KNN performed best for our overall methodology."
2019,Effective K-nearest neighbor classifications for Wisconsin breast cancer data sets,"ABSTRACT Using machine learning algorithms for early prediction of the signs and symptoms of breast cancer is in demand nowadays. One of these algorithms is the K-nearest neighbor (KNN), which uses a technique for measuring the distance among data. The performance of KNN depends on the number of neighboring elements known as the K value. This study involves the exploration of KNN performance by using various distance functions and K values to find an effective KNN. Wisconsin breast cancer (WBC) and Wisconsin diagnostic breast cancer (WDBC) datasets from the UC Irvine machine learning repository were used as our main data sources. Experiments with each dataset were composed of three iterations. The first iteration of the experiment was without feature selection. The second one was the L1-norm based selection from the model, which used the linear support vector classifier feature selection, and the third iteration was with Chi-square-based feature selection. Numerous evaluation metrics like accuracy, receiver operating characteristic (ROC) curve with the area under curve (AUC) and sensitivity, etc., were used for the assessment of the implemented techniques. The results indicated that the technique involving the Chi-square-based feature selection achieved the highest accuracy with the Canberra or Manhattan distance functions for both datasets. The optimal K values for these distance functions ranged from 1 to 9. This study indicated that with the appropriate selection of the K value and a distance function in KNN, the Chi-square-based feature selection for the WBC datasets gives the highest accuracy rate as compared with the existing models. Abbreviations: KNN: K-nearest neighbor; Chi2: Chi-square; WBC: Wisconsin breast cancer"
2022,Machine learning and deep learning for breast cancer risk prediction and diagnosis: a Survey,"Breast cancer is the widest spreading disease among women globally. The prevalence rate of breast cancer continued to rise in the last few decades. The mitotic count is a relevant factor for grading invasive breast cancer. Early analysis is an extremely imperative step in treatment. However, it is not an easy one due to several skepticisms in detection which employ mammograms. Since it is subject to human prone error, requires more time for completion and the nuclei look similar during all stages of mitosis, automatic detection of mitosis is a good solution to overcome these problems. Detailed analysis of breast cancer normally requires medical images of different methods. The sensitivity and specificity of the diagnosis largely depend on the experiences of the radiologists, and uncertain diagnosis is quite frequent because of resolution limitations and the concerns of lawsuits arisen from wrong diagnosis or undetected lesions. In this paper, the top methodologies used for mitosis detection are analyzed. There are many algorithms for classification and prediction of breast cancer: Support Vector Machine (SVM), Decision Tree (CART), k Nearest Neighbors (KNN), Random Forest (RF), and Bayesian Networks (BN). The Wisconsin data set was used to analyze breast cancer as a training set to assess and measure the performance of the three ML classifiers in terms of key frameworks such as accuracy, recall, precision, and ROC. The outcome obtained in this paper provides a critique of the stateofart ML techniques for breast cancer detection. It was also found that the ensemble classifier gives better performance. A preliminary experiment conducted on cascaded RF and Artificial Neural Network (ANN) results in better accuracy than individual classifiers. The paper shows how we can use deep learning technology diagnosis of breast cancer using MIAS Dataset. A deep learning approach is almost used for immense task objective Image processing, Computer Vision, Medical Diagnosis, and Neural Language Processing."
2020,Enhanced Artificial Intelligence System for Diagnosing and Predicting Breast Cancer Using Deep Learning,"<p>Breast cancer is the leading cause of death among women with cancer. Computer-aided diagnosis is an efficient method for assisting medical experts in early diagnosis, improving the chance of recovery. Employing artificial intelligence (AI) in the medical area is very crucial due to the sensitivity of this field. This means that the low accuracy of the classification methods used for cancer detection is a critical issue. This problem is accentuated when it comes to blurry mammogram images. In this paper, convolutional neural networks (CNNs) are employed to present the traditional convolutional neural network (TCNN) and supported convolutional neural network (SCNN) approaches. The TCNN and SCNN approaches contribute by overcoming the shift and scaling problems included in blurry mammogram images. In addition, the flipped rotation-based approach (FRbA) is proposed to enhance the accuracy of the prediction process (classification of the type of cancerous mass) by taking into account the different directions of the cancerous mass to extract effective features to form the map of the tumour. The proposed approaches are implemented on the MIAS medical dataset using 200 mammogram breast images. Compared to similar approaches based on KNN and RF, the proposed approaches show better performance in terms of accuracy, sensitivity, spasticity, precision, recall, time of performance, and quality of image metrics.</p>"
2023,DEEP AND MACHINE LEARNING FOR IMPROVING BREAST CANCER DETECTION,"Breast cancer is the most common type of cancer in the world, as the number of people infected with it reached 2.2 million women in 2020, and World Health Organization reports indicated that the incidence of it is 1 to 12 women, that is, one woman out of every woman. every 12 women. As a result, it is crucial to have high cancer-predictive accuracy to update patient survival criteria and treatment options. Research on machine learning and deep learning, whether using traditional neural networks or using convolutional neural networks, has spread widely and has proven to be a useful technology. It can be very helpful in early detection and prognosis of breast cancer. According to the six machine learning algorithms used in this study and based on the Wisconsin breast cancer diagnostic dataset, they are as follows: Naive Bays (NB), K-Nearest Neighbors (KNN), Random Forest (RF), Decision Tree (DT), Logistic Regression (LR), and Support Vector Machine (SVM), we reached an accuracy of 99.1% with SVM that surpassed all competitors and achieved the highest accuracy. As for deep learning, we have reached an accuracy of up to 99.9%, and this is a reliable result for analysis purposes. In the presented work, the Anaconda environment (Jupyter platform) was used, which uses the Python programming language in all work."
2022,Improving Clinical Prediction of Later Occurrence of Breast Cancer Metastasis Using Deep Learning and Machine Learning with Grid Search,"ABSTRACT Background It is important to be able to predict, for each individual patient, the likelihood of later metastatic occurrence, because the prediction can guide treatment plans tailored to a specific patient to prevent metastasis and to help avoid under- or over-treatment. Deep Neural Network (DNN) learning, commonly referred to as deep learning, has become popular due to its success in image detection and prediction, but questions such as whether deep learning outperforms other machine learning methods when using non-image clinical data remain unanswered. Grid search has been introduced to deep learning hyperparameter tunning for the purpose of improving its prediction performance, but the effect of grid search on other machine learning methods are under-studied. In this research, we take the empirical approach to study the performance of deep learning and other machine learning methods when using non-image clinical data to predict the occurrence of breast cancer metastasis (BCM) 5, 10, or 15-years after the initial treatment. We developed DNN models as well as models using 9 other machine learning methods including Naive Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), LASSO, Decision Tree (DT), k-Nearest Neighbors (KNN), Random Forrest (RF), AdaBoost (ADB), and XGBoost (XGB). We used grid search to tune hyperparameters for all methods. We then compared the deep learning models to the models trained using the 9 other machine learning methods. Results Based on the mean test AUC results, DNN ranks 6th, 4th, and 3rd when predicting 5-year, 10-year, and 15-year BCM respectively, out of 10 machine learning methods. The top performing methods in predicting 5-year BCM are XGB(1st), RF(2nd), and KNN(3rd). For predicting 10-year BCM the top performers are XGB (1st), RF(2nd), and NB(3rd) . Finally, for 15-year BCM the top performers are SVM (1st), LR and LASSO (tied for 2nd), and DNN (3rd). The ensemble methods RF and XGB outperform other methods when data are less balanced, while SVM, LR, LASSO, and DNN outperform other methods when data are more balanced. Our statistical testing results show that at a significance level of 0.05 DNN overall performs no worse than other machine learning methods when predicting 5-year, 10-year, and 15-year BCM. Conclusions Our results show that deep learning with grid search overall performs at least as well as other machine learning methods when using non-image clinical data. It is interesting to note that some of the other machine learning methods such as XGB, RF, and SVM are very strong competitors of DNN when incorporating grid search. It is also worth noting that the computation time required to do grid search with DNN is way more than that required to do grid search with the other 9 machine learning methods."
2023,Marvelous Machine-Learning-Based Breast Cancer Predictive Model,"Abstract: Breast cancer is a major health concern for women all over the world. In order to reduce mortality rates and provide the most effective treatment, Histopathology image prognosis is essential. When a pathologist examines a biopsy specimen under a microscope, they are engaging in histopathology. The pathologist looks for the picture, determines its type, labels it, and assigns a grade. Tissue architecture, cell distribution, and cellular form all play a role in determining whether a histopathological scan is benign or malignant. Manual picture classification is the slowest and most error-prone method. Automated diagnosis based on machine learning is necessary for early and precise diagnosis, but this challenge has prevented it from being addressed thus far. In this study, we apply curvelet transform to a picture that has been segmented using k-means clustering to isolate individual cell nuclei. We analysed data from the Wisconsin Diagnosis Breast Cancer database for this article. in the context of similar studies in the literature. It is demonstrated that compared to another machine learning algorithm, the IICA-ANN IICA-KNN and IICA-SVM-KNN method using the logistic algorithm achieves 98.04% accuracy."
2023,Machine Learning Approaches for MRI Image Analysis-Based Prostate Cancer Detection,"The sooner the patient receives a diagnosis for their condition, the higher their chances will be of surviving it. As is the case with conventional diagnosis, medical imaging is analyzed by trained professionals who look for any signs that the body may be displaying cancerous tendencies. The great quality and multidimensionality of MRI images need the use of an appropriate diagnostic system in addition to CAD tools. Because it is useful, researchers are now concentrating their efforts on developing methods to improve the accuracy, specificity, and speed of these systems. A model that is efficient in terms of image processing, feature extraction, and machine learning is presented in this study. This chapter presents machine learning techniques for prostate cancer detection by analyzing MRI images. Image preprocessing is done using histogram equalization. It improves image quality. Image segmentation is performed using the fuzzy C means algorithm. Features are extracted using the gray level co-occurrence matrix algorithm. Classification is performed using the KNN."
2023,Comparison of Machine Learning and Deep Learning Algorithms for Classification of Breast Cancer,"Statistical data from the American Cancer Society which shows that breast cancer ranks first with the highest number of cases of all types of cases of malignant tumors (cancer) worldwide. through a data mining process that is used to extract information and data analysis, a classification process can be carried out to carry out further analysis of the pattern of a data. The dataset used in this study is the Breast Cancer Wisconsin (Diagnostic) Dataset obtained from UCI Machine Learning. The purpose of this study is to compare five algorithms, namely Logistic Regression, K Neighbors Classifier (KNN), Decision Tree Classifier, Deep Neural Network, Genetic Algorithm. The results showed that deep neural network algorithms and multilayer perceptron-genetic algorithms get 96% accuracy, logistic regression algorithms have 96% accuracy, then KNN with 94%, and decision tree classifier with 92%."
2023,Early Breast Cancer Prediction using Machine Learning and Deep Learning Techniques,"Breast Cancer (BC) is a considered as one of the utmost lethal diseases across the globe that has a very high morbidity and mortality rate. Accurate and early prediction along with diagnosis is one of the most crucial characteristics for the treatment of Breast Cancer. Doctors can have an edge over Breast cancer if they are able to predict it in its early stages using deep learning and machine learning techniques. This paper proposed consists of comparison between the and accuracy of various machine learning models like Support vector machine (SVM), K-Nearest Neighbours (KNN), Naïve Bayes (NB), Logistic Regression (LR), Random Forest (RF), Decision Tree (DT), XGB Classifier and deep learning model of Artificial neural networks (ANN) for the precise detection of breast cancer. The most crucial properties from the database have been chosen using one feature-selection technique. Correlation is also used to choose the most correlated features from the data. Implementing the ANN model consists of one input layer, two hidden layers, and one output layer. All Machine Learning models and ANN model are then applied to selected features. The results demonstrated that the SVM classifier achieved the highest performance with an accuracy of ~98.24%."
2023,Machine Learning Approaches for Detecting and Classifying the Cancer type using Imbalanced Data Downsampling,"One of the most important applications of medical data mining is the early diagnosis of diseases with high accuracy. In the meantime, timely diagnosis of cancer as one of the main causes of death is of special importance. However, the classification and diagnosis of cancer is challenging due to the unbalanced nature of related data. In the data related to cancer disease, there is usually a minority class (patient samples) and a majority class (healthy people samples), which diagnoses the disease from the minority samples, and this is a challenge for the classifiers. This work investigated the problem of classifying the imbalanced data related to cancer disease using a machine learning approach based on the K-Nearest Neighbor (KNN) clustering technique. In this method, the insignificant samples of the majority class are removed, and the data are balanced. The proposed method is simulated and evaluated on 15 cancer datasets selected from the general SEER database. The simulation results approve a high classification of cancer type based on the average detecting accuracy criterion of more than 90%. Moreover, the current result is more efficient and improves classification accuracy compared to the methods proposed by other researchers in the literature survey."
2019,Machine Learning Models of Breast Cancer Risk Prediction,"Abstract: Breast cancer is the most common cancer in women both in the developed and less developed world. Early detection based on clinical features can greatly increase the chances for successful treatment. Our goal was to construct a breast cancer prediction model based on machine learning algorithms. A total of 10 potential clinical features like age, BMI, glucose, insulin, HOMA, leptin, adiponectin, resistin, and MCP-1 were collected from 116 patients. In this report, most commonly used machine learning model such as decision tree (DT), random forest (RF), K-nearest neighbors (KNN), support vector machine (SVM), logistic regression (LR), and artificial neural network (ANN) models were tested for breast cancer prediction. A repeated 10-fold cross-validation model was used to rank variables on the randomly split dataset. The accuracy of DT, RF, SVM, LR, ANN, and KNN was 0.71, 0.71, 0.77, 0.80, 0.81, and 0.86 respectively. However, The KNN model showed most higher accuracy with area under receiver operating curve, sensitivity, and specificity of 0.95, 0.80, 0.91. Therefore, identification of breast cancer patients correctly would create care opportunities such as monitoring and adopting intervention plans may benefit the quality of care in long-term."
2023,Research on Breast Cancer Classification and Prediction Model Based on Principal Component Analysis and Machine Learning,"In recent years, breast cancer has become one of the biggest threats to women's health, accounting for the majority of cancer deaths among women. Because early treatment of breast cancer has a great effect on the recovery of breast cancer, the diagnosis of breast cancer is particularly important. Machine learning, as the most popular method, is also used for model construction in this field. This study is based on data from breast tumors, which contain 10 morphological features of breast tumor nucleus. In this study, homogenization, standardization and feature selection were used to process the data and KNN algorithm was used to construct the classification prediction model, with principal component analysis (PCA) used to optimize the model. Finally, the original 30 variables were reduced to 3 variables and the model parameters were adjusted in order to achieve the best model with the accuracy of 98.54%. The final model achieves the highest operating efficiency and accuracy. In this study, through the visualization of PCA and the comparison of different models, the classification effect of the final model can be the best. This model can be applied to the clinical diagnosis of breast cancer patients, which is helpful to the early treatment efficiency and greatly reduce the mortality of breast cancer patients"
2022,Tree-Based and Machine Learning Algorithm Analysis for Breast Cancer Classification,"Breast cancer (BC) is the second leading cause of death in developed and developing nations, accounting for 8% of deaths after lung cancer. Gene mutation, constant pain, size fluctuations, colour (roughness), and breast skin texture are all characteristics of BC. The University of Wisconsin Hospital donated the WDBC dataset, which was created via fine-needle aspiration (biopsies) of the breast. We have implemented multilayer perceptron (MLP), K-nearest neighbor (KNN), genetic programming (GP), and random forest (RF) on the WBCD dataset to classify the benign and malignant patients. The results show that RF has a classification accuracy of 96.24%, which outperforms all the other classifiers."
2022,Predicting Breast Cancer Based on Optimized Deep Learning Approach,"Breast cancer is a dangerous disease with a high morbidity and mortality rate. One of the most important aspects in breast cancer treatment is getting an accurate diagnosis. Machine-learning (ML) and deep learning techniques can help doctors in making diagnosis decisions. This paper proposed the optimized deep recurrent neural network (RNN) model based on RNN and the Keras–Tuner optimization technique for breast cancer diagnosis. The optimized deep RNN consists of the input layer, five hidden layers, five dropout layers, and the output layer. In each hidden layer, we optimized the number of neurons and rate values of the dropout layer. Three feature-selection methods have been used to select the most important features from the database. Five regular ML models, namely decision tree (DT), support vector machine (SVM), random forest (RF), naive Bayes (NB), and K-nearest neighbor algorithm (KNN) were compared with the optimized deep RNN. The regular ML models and the optimized deep RNN have been applied the selected features. The results showed that the optimized deep RNN with the selected features by univariate has achieved the highest performance for CV and the testing results compared to the other models."
2023,Optimization of Breast Cancer Prediction using Optimaze Parameter on Machine Learning,"At present, a very common cancer disease in women is breast cancer. This cancer develops in the female breast tissue and is the cancer with the highest mortality rate. This needs great attention. Forecasting breast cancer has been studied by a number of researchers and is considered a serious threat to women. Clinical difficulties in creating treatment approaches that will help patients live longer, due to the lack of solid predictive models that can predict outcomes at an early stage by analyzing patient history data. Because it can affect women all over the world. Early detection of breast cancer is crucial in determining the path of action. Cancer types can be distinguished into two types: benign and malignant. this research aims to provide information and science to medical professionals and also cancer patients to know the classification of the two types of cancer. The research project aims to also leverage data mining techniques using several algorithms on Machine Learning (ML) such as Decision Tree(DT), Random Forest (RF), K-Nearest Neighbors (KNN), Logistic Regression (LR), Support Vector Machine (SVM), and Gradient Boosting Tress (XGBoost). The results of this algorithm will determine the prediction of the most common types of cancer. The study used 683 samples of breast cancer patients, including 10 characteristics. This test is measured through mammography and biopsy tests. Using K-Fold Validation operators, then the sresults of the study showed that the K-Nearest Neighbor (KNN) algorithm produced the highest accuracy of 96.87% compared to the other five algorithms. Then, as a comparison again, the researchers also optimized the accuracy value using the parameter optimize operator. Where the number produced becomes more overwhelming. The highest accuracy result after calculated with the parameter optimize is the Random Forest (RF) algorithm. Where the result is 100% accurate compared to other ML algorithms. "
2023,Develop and validate a radiomics space-time model to predict the pathological complete response in patients undergoing neoadjuvant treatment of rectal cancer: an artificial intelligence model study based on machine learning,"Objective: In this study, we aimed to investigate the predictive efficacy of magnetic resonance imaging (MRI) radiomics features at different time points of neoadjuvant therapy for rectal cancer in patients with pathological complete response (pCR). Furthermore, we aimed to develop and validate a radiomics space–time model (RSTM) using machine learning for artificial intelligence interventions in predicting pCR in patients. Methods: Clinical and imaging data of 83 rectal cancer patients were retrospectively analyzed, and the patients were classified as pCR and non-pCR patients according to their postoperative pathological results. All patients received one MRI examination before and after neoadjuvant therapy to extract radiomics features, including pre-treatment, post-treatment, and delta features. Delta features were defined by the ratio of the difference between the pre- and the post-treatment features to the pre-treatment feature. After feature dimensionality reduction based on the above three feature types, the RSTM was constructed using machine learning methods, and its performance was evaluated using the area under the curve (AUC). Results: The AUC values of the individual basic models constructed by pre-treatment, post-treatment, and delta features were 0.771, 0.681, and 0.871, respectively. Their sensitivity values were 0.727, 0.864, and 0.909, respectively, and their specificity values were 0.803, 0.492, and 0.656, respectively. The AUC, sensitivity, and specificity values of the combined basic model constructed by combining pre-treatment, post-treatment, and delta features were 0.901, 0.909, and 0.803, respectively. The AUC, sensitivity, and specificity values of the RSTM constructed using the K-Nearest Neighbor (KNN) classifier on the basis of the combined basic model were 0.944, 0.871, and 0.983, respectively. The Delong test showed that the performance of RSTM was significantly different from that of pre-treatment, post-treatment, and delta models ( Conclusions: The RSTM constructed using the KNN classifier based on the combined features of before and after neoadjuvant therapy and delta features had the best predictive efficacy for pCR of neoadjuvant therapy. It may emerge as a new clinical tool to assist with individualized management of rectal cancer patients."
2021,Breast Cancer Detection Using Random Forest Classifier,"Breast cancer is the second most prevalent type of cancer among women. Breast ultrasound (BUS) imaging is one of the most frequently used diagnostic tools to detect and classify abnormalities in the breast. To improve the diagnostic accuracy, computer-aided diagnosis (CAD) system is helpful for breast cancer detection and classification. Normally, a CAD system consists of four stages: pre-processing, segmentation, feature extraction, and classification. In this chapter, the pre-processing step includes speckle noise removal using speckle reducing anisotropic diffusion (SRAD) filter. The goal of segmentation is to locate the region of interest (ROI) and active contour-based segmentation and fuzzy C means segmentation (FCM) are used in this work. The texture features are extracted and fed to a classifier to categorize the images as normal, benign, and malignant. In this work, three classifiers, namely k-nearest neighbors (KNN) algorithm, decision tree algorithm, and random forest classifier, are used and the performance is compared based on the accuracy of classification."
2022,Deep Learning-based and Machine Learning-based Application in Skin Cancer Image Classification,"Abstract: Skin cancer arises from the skin and is capable of invading other parts of the body. The earlier detection of malignant skin lesions effectively helps cure skin disease and prevents fatal skin cancer. As part of AI, machine learning and deep learning can learn the characteristics of input datasets and perform classifications with high accuracy. In this paper, the CNN, KNN, and SVM models are implemented and tested based on the datasets collected from ISIC. The idea of the implementation is to classify the images of skin lesions into benign and malignant. The information of GANs based model is gathered. The results display the accuracy of using these models to classify different types of lesions. And the discussion of the results focuses on the efficiency to implement the machine learning and deep learning models and the accuracy of using them. The goal of the study is to figure out which method is more useful in skin cancer identification. And some of the possible practices are also discussed as future expectations."
2023,BREAST CANCER DETECTION WITH MACHINE LEARNING APPROACH,"One of the most widespread diseases among women today is breast cancer. Early and accurate diagnosis is key in rehabilitation and treatment. The usage of mammograms has some uncertainties in the detection rate. To develop tools for physicians for effective and early detection and diagnosis, machine learning techniques can be adopted. The introduction of Machine Learning (ML) in developing the tool will increase the survival rate of patients with breast cancer. This research work proposed different six ML techniques; Logistic Regression, Linear Discriminant Analysis, Decision Tree (DT), KNN, Naïve Bayes (NB), and Support Vector Machine (SVM), and then recommended the model with the highest accuracy for breast cancer detection. The experiment was carried out in a python environment and all the aforementioned techniques were validated with Wisconsin Breast Cancer dataset and evaluated with accuracy, precision, and recall."
2023,Breast Cancer 6th Stage Prediction Based on Machine Learning Models,"The differences between each 6th stage of the breast cancer are subtle, and doctors’ judgement alone is not sufficient to determine the 6th stage accurately. 6th stage is the different levels of breast cancer development and it represents the current status of the cancer. Therefore, it is crucial to determine it correctly in order to conduct corresponding treatments. The incorrect categorization of the 6th stage and misuse of treatments can be catastrophic, and there are currently no such models to help doctors predicting the 6th stage. The dataset Seer Breast Cancer Data is used which include features like race, t-stage, n-stage, etc. This paper proposed to use random forest and K Nearest Neighbor (KNN) methods to build models and use features related to the patients and their cancer as training data. The random forest model achieved a predictive result of 99% for precision, recall, and f1 score after data normalization. The only mistake this model made is when differentiating stage IIIA and IIIB. The KNN model achieved an accuracy of 95% after normalization. The result shows that Random Forest model is best suited for predicting the 6th stage. The random forest model with 99% accuracy can effectively help doctors determine the 6th stage when they are having difficulties."
2023,Identification of Novel Diagnostic and Prognostic Gene Signature Biomarkers for Breast Cancer Using Artificial Intelligence and Machine Learning Assisted Transcriptomics Analysis,"Background: Breast cancer (BC) is one of the most common female cancers. Clinical and histopathological information is collectively used for diagnosis, but is often not precise. We applied machine learning (ML) methods to identify the valuable gene signature model based on differentially expressed genes (DEGs) for BC diagnosis and prognosis. Methods: A cohort of 701 samples from 11 GEO BC microarray datasets was used for the identification of significant DEGs. Seven ML methods, including RFECV-LR, RFECV-SVM, LR-L1, SVC-L1, RF, and Extra-Trees were applied for gene reduction and the construction of a diagnostic model for cancer classification. Kaplan–Meier survival analysis was performed for prognostic signature construction. The potential biomarkers were confirmed via qRT-PCR and validated by another set of ML methods including GBDT, XGBoost, AdaBoost, KNN, and MLP. Results: We identified 355 DEGs and predicted BC-associated pathways, including kinetochore metaphase signaling, PTEN, senescence, and phagosome-formation pathways. A hub of 28 DEGs and a novel diagnostic nine-gene signature (COL10A, S100P, ADAMTS5, WISP1, COMP, CXCL10, LYVE1, COL11A1, and INHBA) were identified using stringent filter conditions. Similarly, a novel prognostic model consisting of eight-gene signatures (CCNE2, NUSAP1, TPX2, S100P, ITM2A, LIFR, TNXA, and ZBTB16) was also identified using disease-free survival and overall survival analysis. Gene signatures were validated by another set of ML methods. Finally, qRT-PCR results confirmed the expression of the identified gene signatures in BC. Conclusion: The ML approach helped construct novel diagnostic and prognostic models based on the expression profiling of BC. The identified nine-gene signature and eight-gene signatures showed excellent potential in BC diagnosis and prognosis, respectively."
2023,Research on Prediction of Breast Cancer Type using Machine Learning,"The most typical cancer type among women worldwide is breast cancer. In 2020 alone, it afflicts about 0.68 million people and 6.9% of all cancer cases. How to categorize tumors as benign (non-cancerous) or malignant (cancerous) is one of the main obstacles to its diagnosis. This study helps to make an accurate and reliable diagnosis based on the initial data of the tumor, such as smoothness, texture, area using machine learning models. This study uses five machine learning models, Logistic Regression (RF), Random Forest (RF), Support Vector Machine (SVM), K-nearest Neighbor (KNN), Naive Bayes Classifier (NBC) and three modelling systems, feature selection-ML and principal component analysis (PCA)-ML system to make predictions of the type of the tumor of Wisconsin Breast Cancer Dataset. Model performance are assessed by three performance evaluation which are accuracy, precision, recall. The results of full model show that random forest has the highest prediction accuracy of 98.25% out of the sample and 100% in the sample, and SVM's sigmoid-based kernel model has the lowest prediction accuracy of 83.33% outside and 85.27% inside the sample. The results of the feature selection model based on RF and LR shows that the RF with only 13 variables has the highest prediction accuracy 98.25% out-of-sample and 100% in-sample. Among all the PCA--ML models, PCA--NBC has the highest prediction accuracy of 97.33% out-of-sample. Nevertheless, PCA-RF has the highest prediction accuracy of 100% in-sample."
2019,Impact of Machine Learning With Multiparametric Magnetic Resonance Imaging of the Breast for Early Prediction of Response to Neoadjuvant Chemotherapy and Survival Outcomes in Breast Cancer Patients,"PurposeThe aim of this study was to assess the potential of machine learning with multiparametric magnetic resonance imaging (mpMRI) for the early prediction of pathological complete response (pCR) to neoadjuvant chemotherapy (NAC) and of survival outcomes in breast cancer patients. Materials and MethodsThis institutional review board–approved prospective study included 38 women (median age, 46.5 years; range, 25–70 years) with breast cancer who were scheduled for NAC and underwent mpMRI of the breast at 3 T with dynamic contrast-enhanced (DCE), diffusion-weighted imaging (DWI), and T2-weighted imaging before and after 2 cycles of NAC. For each lesion, 23 features were extracted: qualitative T2-weighted and DCE-MRI features according to BI-RADS (Breast Imaging Reporting and Data System), quantitative pharmacokinetic DCE features (mean plasma flow, volume distribution, mean transit time), and DWI apparent diffusion coefficient (ADC) values. To apply machine learning to mpMRI, 8 classifiers including linear support vector machine, linear discriminant analysis, logistic regression, random forests, stochastic gradient descent, decision tree, adaptive boosting, and extreme gradient boosting (XGBoost) were used to rank the features. Histopathologic residual cancer burden (RCB) class (with RCB 0 being a pCR), recurrence-free survival (RFS), and disease-specific survival (DSS) were used as the standards of reference. Classification accuracy with area under the receiving operating characteristic curve (AUC) was assessed using all the extracted qualitative and quantitative features for pCR as defined by RCB class, RFS, and DSS using recursive feature elimination. To overcome overfitting, 4-fold cross-validation was used. ResultsMachine learning with mpMRI achieved stable performance as shown by mean classification accuracies for the prediction of RCB class (AUC, 0.86) and DSS (AUC, 0.92) based on XGBoost and the prediction of RFS (AUC, 0.83) with logistic regression. The XGBoost classifier achieved the most stable performance with high accuracies compared with other classifiers. The most relevant features for the prediction of RCB class were as follows: changes in lesion size, complete pattern of shrinkage, and mean transit time on DCE-MRI; minimum ADC on DWI; and peritumoral edema on T2-weighted imaging. The most relevant features for prediction of RFS were as follows: volume distribution, mean plasma flow, and mean transit time; DCE-MRI lesion size; minimum, maximum, and mean ADC with DWI. The most relevant features for prediction of DSS were as follows: lesion size, volume distribution, and mean plasma flow on DCE-MRI, and maximum ADC with DWI. ConclusionsMachine learning with mpMRI of the breast enables early prediction of pCR to NAC as well as survival outcomes in breast cancer patients with high accuracy and thus may provide valuable predictive information to guide treatment decisions."
2017,LightGBM: An Effective miRNA Classification Method in Breast Cancer Patients,"miRNAs are small noncoding RNA molecules, mainly responsible for post-transcriptional control of gene expressions. Machine learning is becoming more and more widely used in breast tumor classification and diagnosis. In this paper, we compared the performance of different machine learning methods, such as Random Forest (RF), eXtreme Gradient Boosting(XGBoost) and Light Gradient Boosting Machine(LightGBM), for miRNAs identification in breast cancer patients. The performance comparison of each algorithm was evaluated based on the accuracy and logistic loss and where LightGBM was found better performing in several aspects. hsa-mir-139 was found as an important target for the breast cancer classification. As a powerful tool, LightGBM can be used to identify and classify miRNA target in breast cancer."
2020,Optimizing Survival Analysis of XGBoost for Ties to Predict Disease Progression of Breast Cancer,"Objective: Some excellent prognostic models based on survival analysis methods for breast cancer have been proposed and extensively validated, which provide an essential means for clinical diagnosis and treatment to improve patient survival. To analyze clinical and follow-up data of 12119 breast cancer patients, derived from the Clinical Research Center for Breast (CRCB) in West China Hospital of Sichuan University, we developed a gradient boosting algorithm, called EXSA, by optimizing survival analysis of XGBoost framework for ties to predict the disease progression of breast cancer. Methods: EXSA is based on the XGBoost framework in machine learning and the Cox proportional hazards model in survival analysis. By taking Efron approximation of partial likelihood function as a learning objective for ties, EXSA derives gradient formulas of a more precise approximation. It optimizes and enhances the ability of XGBoost for survival data with ties. After retaining 4575 patients (3202 cases for training, 1373 cases for test), we exploit the developed EXSA method to build an excellent prognostic model to estimate disease progress. Risk score of disease progress is evaluated by the model, and the risk grouping and continuous functions between risk scores and disease progress rate at 5- and 10-year are also demonstrated. Results: Experimental results on test set show that the EXSA method achieves competitive performance with concordance index of 0.83454, 5-year and 10-year AUC of 0.83851 and 0.78155, respectively. Conclusion: The proposed EXSA method can be utilized as an effective method for survival analysis. Significance: The proposed method in this paper can provide an important means for follow-up data of breast cancer or other disease research."
2020,Breast Cancer Risk Prediction using XGBoost and Random Forest Algorithm,"Breast cancer is as one of the common and serious cause of death among women globally. This is a disease where the cells grow out of control inside the breast. Family History of cancer disease, physical inactivity, psychological stress, increase in breast size are the risk factors of breast cancer. In this research paper, breast cancer dataset was analyzed to predict breast cancer using popular two ensemble machine learning algorithms. Random Forest and Extreme Gradient Boosting (XGBoost) were used to predict breast cancer. A total of 275 instances with 12 features were used for this analysis. With Random forest algorithm 74.73% accuracy and 73.63% using XGBoost had obtained in this analysis."
2022,Deep Learning and Machine Learning with Grid Search to Predict Later Occurrence of Breast Cancer Metastasis Using Clinical Data,"Background: It is important to be able to predict, for each individual patient, the likelihood of later metastatic occurrence, because the prediction can guide treatment plans tailored to a specific patient to prevent metastasis and to help avoid under-treatment or over-treatment. Deep neural network (DNN) learning, commonly referred to as deep learning, has become popular due to its success in image detection and prediction, but questions such as whether deep learning outperforms other machine learning methods when using non-image clinical data remain unanswered. Grid search has been introduced to deep learning hyperparameter tuning for the purpose of improving its prediction performance, but the effect of grid search on other machine learning methods are under-studied. In this research, we take the empirical approach to study the performance of deep learning and other machine learning methods when using non-image clinical data to predict the occurrence of breast cancer metastasis (BCM) 5, 10, or 15 years after the initial treatment. We developed prediction models using the deep feedforward neural network (DFNN) methods, as well as models using nine other machine learning methods, including naïve Bayes (NB), logistic regression (LR), support vector machine (SVM), LASSO, decision tree (DT), k-nearest neighbor (KNN), random forest (RF), AdaBoost (ADB), and XGBoost (XGB). We used grid search to tune hyperparameters for all methods. We then compared our feedforward deep learning models to the models trained using the nine other machine learning methods. Results: Based on the mean test AUC (Area under the ROC Curve) results, DFNN ranks 6th, 4th, and 3rd when predicting 5-year, 10-year, and 15-year BCM, respectively, out of 10 methods. The top performing methods in predicting 5-year BCM are XGB (1st), RF (2nd), and KNN (3rd). For predicting 10-year BCM, the top performers are XGB (1st), RF (2nd), and NB (3rd). Finally, for 15-year BCM, the top performers are SVM (1st), LR and LASSO (tied for 2nd), and DFNN (3rd). The ensemble methods RF and XGB outperform other methods when data are less balanced, while SVM, LR, LASSO, and DFNN outperform other methods when data are more balanced. Our statistical testing results show that at a significance level of 0.05, DFNN overall performs comparably to other machine learning methods when predicting 5-year, 10-year, and 15-year BCM. Conclusions: Our results show that deep learning with grid search overall performs at least as well as other machine learning methods when using non-image clinical data. It is interesting to note that some of the other machine learning methods, such as XGB, RF, and SVM, are very strong competitors of DFNN when incorporating grid search. It is also worth noting that the computation time required to do grid search with DFNN is much more than that required to do grid search with the other nine machine learning methods."
2022,Breast Cancer Early Detection Comparison with Deep Learning and Machine Learning Models: A Case of Study,"Breast cancer is one of the most widespread in the female population, being able to predict its developments and capturing the inputs of the onset of the disease is one of the main objectives that science is pursuing. Clinical Decision Support Systems (CDSS) in recent decades are extensively using these technological tools, such as Machine Learning (ML) and Deep Learning (DL). In this paper, two of the main methods of these subset of AI are compared: an ensemble-type algorithm, XGBoost (or Extreme Gradient Boosting) and a deep neural network (DNN) are applied to the data of a study conducted on an Indonesian population. The results obtained are very interesting as despite being tabular, binary categorical and multiclass data, the DNN model achieves performance and results much higher than the well-known XGB used in literature for data of this type."
2022,Improving Clinical Prediction of Later Occurrence of Breast Cancer Metastasis Using Deep Learning and Machine Learning with Grid Search,"ABSTRACT Background It is important to be able to predict, for each individual patient, the likelihood of later metastatic occurrence, because the prediction can guide treatment plans tailored to a specific patient to prevent metastasis and to help avoid under- or over-treatment. Deep Neural Network (DNN) learning, commonly referred to as deep learning, has become popular due to its success in image detection and prediction, but questions such as whether deep learning outperforms other machine learning methods when using non-image clinical data remain unanswered. Grid search has been introduced to deep learning hyperparameter tunning for the purpose of improving its prediction performance, but the effect of grid search on other machine learning methods are under-studied. In this research, we take the empirical approach to study the performance of deep learning and other machine learning methods when using non-image clinical data to predict the occurrence of breast cancer metastasis (BCM) 5, 10, or 15-years after the initial treatment. We developed DNN models as well as models using 9 other machine learning methods including Naive Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), LASSO, Decision Tree (DT), k-Nearest Neighbors (KNN), Random Forrest (RF), AdaBoost (ADB), and XGBoost (XGB). We used grid search to tune hyperparameters for all methods. We then compared the deep learning models to the models trained using the 9 other machine learning methods. Results Based on the mean test AUC results, DNN ranks 6th, 4th, and 3rd when predicting 5-year, 10-year, and 15-year BCM respectively, out of 10 machine learning methods. The top performing methods in predicting 5-year BCM are XGB(1st), RF(2nd), and KNN(3rd). For predicting 10-year BCM the top performers are XGB (1st), RF(2nd), and NB(3rd) . Finally, for 15-year BCM the top performers are SVM (1st), LR and LASSO (tied for 2nd), and DNN (3rd). The ensemble methods RF and XGB outperform other methods when data are less balanced, while SVM, LR, LASSO, and DNN outperform other methods when data are more balanced. Our statistical testing results show that at a significance level of 0.05 DNN overall performs no worse than other machine learning methods when predicting 5-year, 10-year, and 15-year BCM. Conclusions Our results show that deep learning with grid search overall performs at least as well as other machine learning methods when using non-image clinical data. It is interesting to note that some of the other machine learning methods such as XGB, RF, and SVM are very strong competitors of DNN when incorporating grid search. It is also worth noting that the computation time required to do grid search with DNN is way more than that required to do grid search with the other 9 machine learning methods."
2022,Optimized Stacking Ensemble Learning Model for Breast Cancer Detection and Classification Using Machine Learning,"Breast cancer is the most frequently encountered medical hazard for women in their forties, affecting one in every eight women. It is the greatest cause of death worldwide, and early detection and diagnosis of the disease are extremely challenging. Breast cancer currently exceeds all other female cancers, including ovarian cancer. Researchers can use access to healthcare records to find previously unknown healthcare trends. According to the National Cancer Institute (NCI), breast cancer mortality rates can be lowered if the disease is detected early. The novelty of our work is to develop an optimized stacking ensemble learning (OSEL) model capable of early breast cancer prediction. A dataset from the University of California, Irvine repository was used, and comparisons to modern classifier models were undertaken. The implementation analyses reveal the unique approach’s efficacy and superiority when compared to existing contemporary categorization models (AdaBoostM1, gradient boosting, stochastic gradient boosting, CatBoost, and XGBoost). In every classification task, predictive models may be used to predict the class level, and the current research explores a range of predictive models. It is better to integrate multiple classification algorithms to generate a set of prediction models capable of predicting each class level with 91–99% accuracy. On the breast cancer Wisconsin dataset, the suggested OSEL model attained a maximum accuracy of 99.45%, much higher than any single classifier. Thus, the study helps healthcare professionals find breast cancer and prevent it from happening."
2023,Cancer Metastasis Prediction and Genomic Biomarker Identification through Machine Learning and eXplainable Artificial Intelligence in Breast Cancer Research,"Aim: Method: This research presents a model combining machine learning (ML) techniques and eXplainable artificial intelligence (XAI) to predict breast cancer (BC) metastasis and reveal important genomic biomarkers in metastasis patients. Method: A total of 98 primary BC samples was analyzed, comprising 34 samples from patients who developed distant metastases within a 5-year follow-up period and 44 samples from patients who remained disease-free for at least 5 years after diagnosis. Genomic data were then subjected to biostatistical analysis, followed by the application of the elastic net feature selection method. This technique identified a restricted number of genomic biomarkers associated with BC metastasis. A light gradient boosting machine (LightGBM), categorical boosting (CatBoost), Extreme Gradient Boosting (XGBoost), Gradient Boosting Trees (GBT), and Ada boosting (AdaBoost) algorithms were utilized for prediction. To assess the models’ predictive abilities, the accuracy, F1 score, precision, recall, area under the ROC curve (AUC), and Brier score were calculated as performance evaluation metrics. To promote interpretability and overcome the “black box” problem of ML models, a SHapley Additive exPlanations (SHAP) method was employed. Results: The LightGBM model outperformed other models, yielding remarkable accuracy of 96% and an AUC of 99.3%. In addition to biostatistical evaluation, in XAI-based SHAP results, increased expression levels of TSPYL5, ATP5E, CA9, NUP210, SLC37A1, ARIH1, PSMD7, UBQLN1, PRAME, and UBE2T (p ≤ 0.05) were found to be associated with an increased incidence of BC metastasis. Finally, decreased levels of expression of CACTIN, TGFB3, SCUBE2, ARL4D, OR1F1, ALDH4A1, PHF1, and CROCC (p ≤ 0.05) genes were also determined to increase the risk of metastasis in BC. Conclusion: The findings of this study may prevent disease progression and metastases and potentially improve clinical outcomes by recommending customized treatment approaches for BC patients."
2023,Stacked ensemble deep learning for pancreas cancer classification using extreme gradient boosting,"Ensemble learning aims to improve prediction performance by combining several models or forecasts. However, how much and which ensemble learning techniques are useful in deep learning-based pipelines for pancreas computed tomography (CT) image classification is a challenge. Ensemble approaches are the most advanced solution to many machine learning problems. These techniques entail training multiple models and combining their predictions to improve the predictive performance of a single model. This article introduces the idea of Stacked Ensemble Deep Learning (SEDL), a pipeline for classifying pancreas CT medical images. The weak learners are Inception V3, VGG16, and ResNet34, and we employed a stacking ensemble. By combining the first-level predictions, an input train set for XGBoost, the ensemble model at the second level of prediction, is created. Extreme Gradient Boosting (XGBoost), employed as a strong learner, will make the final classification. Our findings showed that SEDL performed better, with a 98.8% ensemble accuracy, after some adjustments to the hyperparameters. The Cancer Imaging Archive (TCIA) public access dataset consists of 80 pancreas CT scans with a resolution of 512 * 512 pixels, from 53 male and 27 female subjects. A sample of two hundred and twenty-two images was used for training and testing data. We concluded that implementing the SEDL technique is an effective way to strengthen the robustness and increase the performance of the pipeline for classifying pancreas CT medical images. Interestingly, grouping like-minded or talented learners does not make a difference."
2023,Optimization of Breast Cancer Prediction using Optimaze Parameter on Machine Learning,"At present, a very common cancer disease in women is breast cancer. This cancer develops in the female breast tissue and is the cancer with the highest mortality rate. This needs great attention. Forecasting breast cancer has been studied by a number of researchers and is considered a serious threat to women. Clinical difficulties in creating treatment approaches that will help patients live longer, due to the lack of solid predictive models that can predict outcomes at an early stage by analyzing patient history data. Because it can affect women all over the world. Early detection of breast cancer is crucial in determining the path of action. Cancer types can be distinguished into two types: benign and malignant. this research aims to provide information and science to medical professionals and also cancer patients to know the classification of the two types of cancer. The research project aims to also leverage data mining techniques using several algorithms on Machine Learning (ML) such as Decision Tree(DT), Random Forest (RF), K-Nearest Neighbors (KNN), Logistic Regression (LR), Support Vector Machine (SVM), and Gradient Boosting Tress (XGBoost). The results of this algorithm will determine the prediction of the most common types of cancer. The study used 683 samples of breast cancer patients, including 10 characteristics. This test is measured through mammography and biopsy tests. Using K-Fold Validation operators, then the sresults of the study showed that the K-Nearest Neighbor (KNN) algorithm produced the highest accuracy of 96.87% compared to the other five algorithms. Then, as a comparison again, the researchers also optimized the accuracy value using the parameter optimize operator. Where the number produced becomes more overwhelming. The highest accuracy result after calculated with the parameter optimize is the Random Forest (RF) algorithm. Where the result is 100% accurate compared to other ML algorithms. "
2023,Identification of Breast Cancer Metastasis Markers Using Machine Learning Approaches with Gene Expression Profiles,"Cancer metastasis accounts for approximately 90% of cancer deaths, and elucidating markers in metastasis is the first step in its prevention. To characterize metastasis marker genes of breast cancer (MGs), XGBoost models that classify metastasis status were trained with gene expression profiles from TCGA. Then, a metastasis score (MS) was assigned to each gene by calculating the inner product between the feature importance and AUC performance of the models. As a result, the 54, 202, and 357 genes with the highest MS were characterized as MGs by empirical P-value cutoffs of 0.001, 0.005, and 0.01, respectively. The three sets of MGs were compared with those from existing metastasis marker databases, which provided significant results in most comparisons. We noticed that the set of MGs with the median EP cutoff showed better performance than the other two sets, suggesting the importance of the cutoff used in determining MGs. They were also significantly enriched in biological processes associated to breast cancer metastasis. The MGs that could not be identified by statistical analysis (e.g., GOLM1, ELAVL1, UBP1, and AZGP1) as well as the MGs with the highest MS (e.g., ZNF676, FAM163B, LDOC2, IRF1, and STK40) were verified via the literature. Additionally, we checked how close the MGs are located to each other in the protein–protein interaction networks. We expect that the characterized markers will help understand and prevent breast cancer metastasis."
2023,Classification Prediction of Breast Cancer Based on Machine Learning,"Breast cancer is the most common and deadly type of cancer in the world. Based on machine learning algorithms such as XGBoost, random forest, logistic regression, and K‐nearest neighbor, this paper establishes different models to classify and predict breast cancer, so as to provide a reference for the early diagnosis of breast cancer. Recall indicates the probability of detecting malignant cancer cells in medical diagnosis, which is of great significance for the classification of breast cancer, so this article takes recall as the primary evaluation index and considers the precision, accuracy, and"
2022,An effective up-sampling approach for breast cancer prediction with imbalanced data: A machine learning model-based comparative analysis,"Early detection of breast cancer plays a critical role in successful treatment that saves thousands of lives of patients every year. Despite massive clinical data have been collected and stored by healthcare organizations, only a small portion of the data has been used to support decision-making for treatments. In this study, we proposed an engineered up-sampling method (ENUS) for handling imbalanced data to improve predictive performance of machine learning models. Our experiment results showed that when the ratio of the minority to the majority class is less than 20%, training models with ENUS improved the balanced accuracy 3.74%, sensitivity 8.36% and F1 score 3.83%. Our study also identified that XGBoost Tree ("
2023,Identification of Novel Diagnostic and Prognostic Gene Signature Biomarkers for Breast Cancer Using Artificial Intelligence and Machine Learning Assisted Transcriptomics Analysis,"Background: Breast cancer (BC) is one of the most common female cancers. Clinical and histopathological information is collectively used for diagnosis, but is often not precise. We applied machine learning (ML) methods to identify the valuable gene signature model based on differentially expressed genes (DEGs) for BC diagnosis and prognosis. Methods: A cohort of 701 samples from 11 GEO BC microarray datasets was used for the identification of significant DEGs. Seven ML methods, including RFECV-LR, RFECV-SVM, LR-L1, SVC-L1, RF, and Extra-Trees were applied for gene reduction and the construction of a diagnostic model for cancer classification. Kaplan–Meier survival analysis was performed for prognostic signature construction. The potential biomarkers were confirmed via qRT-PCR and validated by another set of ML methods including GBDT, XGBoost, AdaBoost, KNN, and MLP. Results: We identified 355 DEGs and predicted BC-associated pathways, including kinetochore metaphase signaling, PTEN, senescence, and phagosome-formation pathways. A hub of 28 DEGs and a novel diagnostic nine-gene signature (COL10A, S100P, ADAMTS5, WISP1, COMP, CXCL10, LYVE1, COL11A1, and INHBA) were identified using stringent filter conditions. Similarly, a novel prognostic model consisting of eight-gene signatures (CCNE2, NUSAP1, TPX2, S100P, ITM2A, LIFR, TNXA, and ZBTB16) was also identified using disease-free survival and overall survival analysis. Gene signatures were validated by another set of ML methods. Finally, qRT-PCR results confirmed the expression of the identified gene signatures in BC. Conclusion: The ML approach helped construct novel diagnostic and prognostic models based on the expression profiling of BC. The identified nine-gene signature and eight-gene signatures showed excellent potential in BC diagnosis and prognosis, respectively."
