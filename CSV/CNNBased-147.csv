Yeojin Jeong- Jeesoo Lee- Young-jin Lee- Jiyun Hwang- Sae Byul Lee- Tae-Kyung Yoo- Myeong-Seong Kim- Jae Il Kim- John L Hopper- Tuong L Nguyen- Jong Won Lee- Joohon Sung,Artificial-Intelligence Powered Identification of High-Risk Breast Cancer Subgroups Using Mammography: A Multicenter Study Integrating Automated Brightest Density Measures with Deep Learning Metrics,Breast Cancer is a significant global health challenge- particularly affecting women with higher mortality compared with other cancer types. Timely detection of such cancer types is crucial- and recent research- employing deep learning techniques- shows promise in earlier detection. The research focuses on the early detection of such tumors using mammogram images with deep-learning models. The paper utilized four public databases where a similar amount of 986 mammograms each for three classes (normal- benign- malignant) are taken for evaluation. Herein- three deep CNN models such as VGG-11- Inception v3- and ResNet50 are employed as base classifiers. The research adopts an ensemble method where the proposed approach makes use of the modified Gompertz function for building a fuzzy ranking of the base classification models and their decision scores are integrated in an adaptive manner for constructing the final prediction of results. The classification results of the proposed fuzzy ensemble approach outperform transfer learning models and other ensemble approaches such as weighted average and Sugeno integral techniques. The proposed ResNet50 ensemble network using the modified Gompertz function-based fuzzy ranking approach provides a superior classification accuracy of 98.986%.
W Wang- Y Li- X Yan- M Xiao- M Gao,Breast cancer image classification method based on deep transfer learning,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ By addressing these areas in future research- we aim to build upon our current findings and make further advancements in utilizing deep learning models for breast cancer detection. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
N. Alabi- M. Guillaud- S. El Hallani- F. Inaba- A. Nichol,A Machine-Learning Model to Predict Axillary Node Positivity from Clinical Characteristics and Large-Scale DNA Organization Features in Breast Cancer Biopsy Specimens,A lot of underdeveloped nations particularly in Africa struggle with cancer-related- deadly diseases. Particularly in women- the incidence of breast cancer is rising daily because of ignorance and delayed diagnosis. Only by correctly identifying and diagnosing cancer in its very early stages of development can be effectively treated. The classification of cancer can be accelerated and automated with the aid of computer-aided diagnosis and medical image analysis techniques. This research provides the use of transfer learning from a Residual Network 18 (ResNet18) and Residual Network 34 (ResNet34) architectures to detect breast cancer. The study examined how breast cancer can be identified in breast mammography pictures using transfer learning from ResNet18 and ResNet34- and developed a demo app for radiologists using the trained models with the best validation accuracy. 1- 200 datasets of breast x-ray mammography images from the National Radiological Society's (NRS) archives were employed in the study. The dataset was categorised as implant cancer negative- implant cancer positive- cancer negative and cancer positive in order to increase the consistency of x-ray mammography images classification and produce better features. For the multi-class classification of the images- the study gave an average accuracy for binary classification of benign or malignant cancer cases of 86.7% validation accuracy for ResNet34 and 92% validation accuracy for ResNet18. A prototype web application showcasing ResNet18 performance has been created. The acquired results show how transfer learning can improve the accuracy of breast cancer detection- providing invaluable assistance to medical professionals- particularly in an African scenario.
Yuan Yao- Yang Zhao- Xu Guo- Xiangli Xu- Baiyang Fu- Hao Cui- Jian Xue- Jiawei Tian- Ke Lu- Lei Zhang,Deep Learning for Distinguishing Mucinous Breast Carcinoma From Fibroadenoma on Ultrasound,"Abstract: Breast cancer poses a significant global health threat to women, underscoring the crucial need for reliable and effective screening approaches. The utilization of computer-aided diagnostic (CAD) systems, leveraging mammograms, enables early detection, diagnosis, and treatment of breast cancer, thereby offering vital support in combating this disease. This study introduces a unique deep-learning model that uses transfer learning to identify and categorize breast cancer automatically. Several recent studies have shown that deep convolutional neural networks (DCNNs) can be used to diagnose breast cancer in mammograms with performances comparable to or even superior to those of human experts. The proposed model extracts features from the Mammographic Image Analysis Society (MIAS) dataset using pre-trained convolutional neural network (CNN) architectures such as ResNet50 and VGG-16. This revolutionary deep-learning model has the potential to improve the efficiency and accuracy of breast cancer detection and categorization."
Muniraj Gupta- Nidhi Verma- Naveen Sharma- Satyendra  Narayan Singh- R. K. Brojen Singh- Saurabh Kumar Sharma,Hybrid Deep Transfer Learning Technique for the Classification of Breast Cancer Tumor Histopathology Images,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ over large volumes of histopathological images. Consequently- this increasing trend in artificial intelligence â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ paper focuses on deep learning for breast cancer histopathological image â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Guyomard- AD Bouhnik- L Tassy- ...,Encoding breast cancer patients' medical pathways from reimbursement data using representation learning: a benchmark for clustering tasks,Neoadjuvant chemotherapy (NAC) is a key element of treatment for locally advanced breast cancer (LABC). Predicting the response to NAC for patients with Locally Advanced Breast Cancer (LABC) before treatment initiation could be beneficial to optimize therapy- ensuring the administration of effective treatments. The objective of the work here was to develop a predictive model to predict tumor response to NAC for LABC using deep learning networks and computed tomography (CT). Several deep learning approaches were investigated including ViT transformer and VGG16- VGG19- ResNet-50- Res-Net-101- Res-Net-152- InceptionV3 and Xception transfer learning networks. These deep learning networks were applied on CT images to assess the response to NAC. Performance was evaluated based on balanced_accuracy- accuracy- sensitivity and specificity classification metrics. A ViT transformer was applied to utilize the attention mechanism in order to increase the weight of important part image which leads to better discrimination between classes. Amongst the 117 LABC patients studied- 82 (70%) had clinical-pathological response and 35 (30%) had no response to NAC. The ViT transformer obtained the best performance range (accuracy = 71 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to accuracy = 77 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- specificity = 86 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 76 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 56 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- and balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%) depending on the split ratio of train-data and test-data. Xception network obtained the second best results (accuracy = 72 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to accuracy = 65 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4- specificity = 81 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 73 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 55 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5%- and balanced_accuracy = 66 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5% to balanced_accuracy = 60 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%). The worst results were obtained using VGG-16 transfer learning network. Deep learning networks in conjunction with CT imaging are able to predict the tumor response to NAC for patients with LABC prior to start. A ViT transformer could obtain the best performance- which demonstrated the importance of attention mechanism.
Lu Gan,Research on Prediction Model of Benign and Malignant Breast Cancer Based on Machine Learning,Breast cancer continues to be a major global health issue- emphasizing the importance of precise and prompt detection to enhance the well-being of patients. In this study- a novel approach is proposed for breast cancer detection using transfer learning with the InceptionV3 model. Our research focuses on analyzing histopathology images to classify breast tissue samples as benign or malignant. Additionally- the effectiveness of alternative models- including ResNet- DenseNet- NasNet- and NasNet Mobile- for the same classification task is explored. To train the models- a comprehensive dataset comprising a diverse range of histopathology images is utilizsed. Transfer learning enabled us to leverage the rich representations learned by InceptionV3- ResNet- DenseNet- NasNet- and NasNet Mobile on large-scale image datasets- which greatly expedited the training process and enhanced overall classification performance. Through extensive evaluations- the superior performance of the InceptionV3 model in accurately distinguishing between benign and malignant breast tissue samples is highlighted. The outcomes of this research present a significant step forward in breast cancer detection- showcasing the potential of transfer learning and the utility of InceptionV3 as a robust classifier for histopathology images. The findings also shed light on the comparative performance of alternative deep learning models- providing valuable insights for future research and clinical applications. Ultimately- this study contributes to the ongoing efforts in improving early detection and diagnosis of breast cancer- paving the way for enhanced patient care and outcomes.
SM Thwin- SJ Malebary- AW Abulfaraj- HS Park,Attention-Based Ensemble Network for Effective Breast Cancer Classification over Benchmarks,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ and classification of breast cancer using transfer learning. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ [19] used the DL-CNN for breast cancer classification from â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ -negative breast cancer based on images of primary breast cancer. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Erin J. Kim- Enoch Chung- Bernard T. Lee- Dhruv Singhal,D134. Application of Machine Learning to Predict Breast Cancer Related-lymphedema Development,Introduction: When considering cancer mortality rates in general- Breast Cancer (BC) is a major contributor among females. Patientsâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ chances of survival increase when BC is detected early and treated with the appropriate treatment at the right time. There is strong evidence that mammography- when used as a screening tool- can detect BC at an early stage. Mammography is a diagnostic tool that uses low-dose X-rays to visualise the breast and evaluate its anatomy. For screening purposes- it is currently the preferred method. The present study employs deep learning models trained using Transfer Learning (TL) techniques. Aim: To automate the process of BC diagnosis in mammograms. The main goal of this approach is to simplify the process of early detection and diagnosis of BC for healthcare practitioners. Materials and Methods: The dataset obtained from the Mammographic Image Analysis Society (MIAS) was categorised into three distinct categories: benign- malignant and normal. The initial MIAS dataset underwent several preprocessing techniques- including noise reduction- breast image contrast enhancement- non breast region deletion and malignant lesion identification- before analysis. An intricately designed fully connected classifier complements pretrained Convolutional Neural Network (CNN) architectures like ResNet50 and VGG16 in the proposed model. Results: The VGG16 model performed admirably- achieving an Area Under the Curve (AUC) of 0.950 and an accuracy rate of 96.00%. In addition- it displayed an outstanding F-score of 97%- along with high sensitivity- specificity and accuracy. These outcomes are significantly better compared to the other methods. Conclusion: The modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s enhanced capabilities for early-stage cancer detection could improve patient outcomes and reduce mortality rates. Furthermore- new tools can ease the workload for radiologists- leading to more standardised and efficient diagnostic procedures.
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
Emmanuel Ahishakiye- Fredrick Kanobe,Breast Cancer Classification Using Breast Ultrasound Images with a Hybrid of Transfer Learning and Bayesian-Optimized Fast Learning Network,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ summary based on transformer language model approaches. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ self-attention mechanism within the transformer architecture â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ the shortcomings of traditional deep learning models- such as â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Muniraj Gupta- Nidhi Verma- Naveen Sharma- Satyendra Narayan Singh- R. K. Brojen Singh- Saurabh Kumar Sharma,Deep Transfer Learning Hybrid Techniques for Precision in Breast Cancer Tumor Histopathology Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ development of artificial intelligence- CAD systems utilizing deep learning technology have â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Compared to CNNs- the self-attention mechanism in Transformers exhibits robust global â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Juan Gutierrez-Cardenas,"Breast Cancer Classification through Transfer Learning with Vision Transformer, PCA, and Machine Learning Models",The objective of our study was to explore the feasibility of integrating artificial intelligence (AI) algorithms for breast cancer detection into a portable- point-of-care ultrasound device (POCUS). This proof-of-concept implementation is to demonstrate the platform for integrating AI algorithms into a POCUS device to achieve a performance benchmark of at least 15 frames/second. Our methodology involved the application of five AI models (FasterRCNN+MobileNetV3- FasterRCNN+ResNet50- RetinaNet+ResNet50- SSD300+VGG16- and SSDLite320+MobileNetV3)- pretrained on public datasets of natural images- fine-tuned using a dataset of gelatin-based breast phantom images with both anechoic and hyperechoic lesions- mimicking real tissue characteristics. We created various gelatin-based ultrasound phantoms containing ten simulated lesions- ranging from 4-20 mm in size. Our experimental setup used the Clarius L15 scanning probe- which was connected via Wi-Fi to both a tablet and a laptop- forming the core of our development platform. The phantom data was divided into training- validation- and held-out testing sets on a per-video basis. We executed 200 timing trials for each finetuned AI model- streaming scanning video from the ultrasound probe in real-time. SSDLite320+MobileNetV3 emerged as a standout- showing a mean frame-to-frame timing of 0.068 seconds (SD=0.005)- which is approximately 14.71 FPS- closely followed by FasterRCNN+MobileNetV3- with a mean timing of 0.123 seconds (SD=0.016)- or about 8.13 FPS. Both models show acceptable performance in lesion localization. Compared to our goal of 15 frames/second- only the SSDLite320+MobileNetV3 architecture performed with sufficient evaluation speed to be used in real-time. Our findings show the necessity of using AI architectures designed for edge devices for real-time use- as well as the potential need for hardware acceleration to encode AI models for use in POCUS.
T Xie- A L Huang- L Y Xiang- H C Xue- Z Z Chen- A L Ma- H L Yan- J P Yuan,[Value of the deep learning automated quantification of tumor-stroma ratio in predicting efficacy and prognosis of neoadjuvant therapy for breast cancer based on residual cancer burden grading],Breast cancer is one of the major causes of deaths in women. However- the early diagnosis is important for screening and control the mortality rate. Thus for the diagnosis of breast cancer at the early stage- a computerâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢aided diagnosis system is highly required. Ultrasound is an important examination technique for breast cancer diagnosis due to its low cost. Recently- many learningâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢based techniques have been introduced to classify breast cancer using breast ultrasound imaging dataset (BUSI) datasets; however- the manual handling is not an easy process and time consuming. The authors propose an EfficientNetâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢integrated ResNet deep network and XAIâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢based framework for accurately classifying breast cancer (malignant and benign). In the initial step- data augmentation is performed to increase the number of training samples. For this purpose- threeâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢pixel flip mathematical equations are introduced: horizontal- vertical- and 90Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšâ€ âˆšÂª. Later- two preâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢trained deep learning models were employed- skipped some layers- and fineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢tuned. Both fineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢tuned models are later trained using a deep transfer learning process and extracted features from the deeper layer. Explainable artificial intelligenceâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢based analysed the performance of trained models. After that- a new feature selection technique is proposed based on the cuckoo search algorithm called cuckoo search controlled standard error mean. This technique selects the best features and fuses using a new parallel zeroâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢padding maximum correlated coefficient features. In the end- the selection algorithm is applied again to the fused feature vector and classified using machine learning algorithms. The experimental process of the proposed framework is conducted on a publicly available BUSI and obtained 98.4% and 98% accuracy in two different experiments. Comparing the proposed framework is also conducted with recent techniques and shows improved accuracy. In addition- the proposed framework was executed less than the original deep learning models.
Lin Yan- Zhiying Liang- Hao Zhang- Gaosong Zhang- Weiwei Zheng- Chunguang Han- Dongsheng Yu- Hanqi Zhang- Xinxin Xie- Chang Liu- Wenxin Zhang- Hui Zheng- Jing Pei- Dinggang Shen- Xuejun Qian,A domain knowledge-based interpretable deep learning system for improving clinical breast ultrasound diagnosis,Abstract: Breast cancer (BC) is one of leading cause of cancer death among women. Early detection of this pathology allows to define- for patients- the appropriate treatment which improve the possibility of survival. Consequently- the earlier it is detected- the better the survival rate will be. In last years- big interest has been made on applying deep learning neural networks to BC analysis- detection and classification. Several interesting results have been found but they still needing more improvement and validation. In this frame is located our work which consists on developing and comparing different deep leaning approaches for earlier detection and classification of BC from mammogram images. Different new deep learning techniques are developed resulting on a considerable improvement in the rate of the classification accuracy with more robust models. Simulations are carried out on two data bases illustrating that the new proposed approaches provide significant evaluation metrics in comparison with several commonly known transfer learning architectures.
Lizhe Wang- Yu Wang- Yueyang Li- Li Zhou- Sihan Liu- Yongyi Cao- Yuzhi Li- Shenting Liu- Jiahui Du- Jin Wang- Ting Zhu,A prospective diagnostic model for breast cancer utilizing machine learning to examine the molecular immune infiltrate in HSPB6,Breast cancer (BC) is the most dominant kind of cancer- which grows continuously and serves as the second highest cause of death for women worldwide. Early BC prediction helps decrease the BC mortality rate and improve treatment plans. Ultrasound is a popular and widely used imaging technique to detect BC at an earlier stage. Segmenting and classifying the tumors from ultrasound images is difficult. This paper proposes an optimal deep learning (DL)-based BC detection system with effective pre-trained transfer learning models-based segmentation and feature learning mechanisms. The proposed system comprises five phases: preprocessing- segmentation- feature learning- selection- and classification. Initially- the ultrasound images are collected from the breast ultrasound images (BUSI) dataset- and the preprocessing operations- such as noise removal using the Wiener filter and contrast enhancement using histogram equalization- are performed on the collected data to improve the dataset quality. Then- the segmentation of cancer-affected regions from the preprocessed data is done using a dilated convolution-based U-shaped network (DCUNet). The features are extracted or learned from the segmented images using spatial and channel attention including densely connected convolutional network-121 (SCADN-121). Afterwards- the system applies an enhanced cuckoo search optimization (ECSO) algorithm to select the features from the extracted feature set optimally. Finally- the ECSO-tuned long short-term memory (ECSO-LSTM) was utilized to classify BC into '3' classes- such as normal- benign- and malignant. The experimental outcomes proved that the proposed system attains 99.86% accuracy for BC classification- which is superior to the existing state-of-the-art methods.
Arpana Parihar- Kritika Gaur- Paromita Sarbadhikary,Advanced 2D Nanomaterials for Phototheranostics of Breast Cancer: A Paradigm Shift,Breast cancer is a worldwide fatal disease that exists mostly among women. The deep learning technique has proven its effectiveness- but the performance of the existing deep learning systems is quite compromising. In this work- a deep transfer learning system is suggested for efficient breast cancer classification from histopathology images. This system is based on a novel multiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢level progressive feature aggregation (MPFA) and a spatial domain learning approach. The combination of a pretrained Resnet101 backbone network with MPFA is implemented to extract more significant features. In addition- a mixedâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢dilated spatial domain learning network (MSLN) is further incorporated to enhance the receptive field and increase discrimination between features. The proposed method achieved superior performance as compared to the existing stateâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ofâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢theâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢art methods- offering 99.24% accuracy- a 98.79% Fâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢1 score- 98.59% precision- and 98.99% recall values over BreaKHis dataset. An ablation study is carried out over the ICIAR2018 dataset to verify the generalizability and effectiveness of the system.
Wei Wang- Lei Liu- Jianxiong Zhu- Youqiang Xing- Songlong Jiao- Ze Wu,AI-Enhanced Visual-Spectral Synergy for Fast and Ultrasensitive Biodetection of Breast Cancer-Related miRNAs.,Breast cancer is a dangerous disease- contributing to a high mortality rate in women. Early detection plays a pivotal role in enhancing survival rates. Breast ultrasound is considered an effective method to help diagnose breast diseases early. Breast ultrasound is inexpensive- easy to perform- non-invasive and painless- so it is often prescribed by doctors in cases where it is necessary to examine the nature of clinically palpable lesions or related symptoms in the breast. In this paper- we introduce a method based on transfer learning and deep feature fusion to classify breast cancer using ultrasound images. The results from our experiments involving 780 breast ultrasound images across three categories (benign- malignant- and normal) indicated that the model using max fusion of deep features outperformed an original CNN in terms of performance- the combination of the maximum value between deep features has a higher performance level with an accuracy of about 1% to 4% compared to the original model. The concatenation fusion of VGG19 and ViT features delivers 1% - 4% times more accuracy than the original model alone
Aslâ€šÃ Ãœâˆšâ‰ Â¬Â¨Â¬Â±nur Albayrak- Kayhan Nuri Cengiz,Assessment of breast cancer awareness among female pharmacy students at a university in Turkey,Breast cancer remains a pressing global health concern- necessitating accurate diagnostics for effective interventions. Deep learning models (AlexNet- ResNet-50- VGG16- GoogLeNet) show remarkable microcalcification identification (>90%). However- distinct architectures and methodologies pose challenges. We propose an ensemble model- merging unique perspectives- enhancing precision- and understanding critical factors for breast cancer intervention. Evaluation favors GoogleNet and ResNet-50- driving their selection for combined functionalities- ensuring improved precision- and dependability in microcalcification detection in clinical settings. This study presents a comprehensive mammogram preprocessing framework using an optimized deep learning ensemble approach. The proposed framework begins with artifact removal using Otsu Segmentation and morphological operation. Subsequent steps include image resizing- adaptive median filtering- and deep convolutional neural network (D-CNN) development via transfer learning with ResNet-50 model. Hyperparameters are optimized- and ensemble optimization (AlexNet- GoogLeNet- VGG16- ResNet-50) are constructed to identify the localized area of microcalcification. Rigorous evaluation protocol validates the efficacy of individual models- culminating in the ensemble model demonstrating superior predictive accuracy. Based on our analysis- the proposed ensemble model exhibited exceptional performance in the classification of microcalcifications. This was evidenced by the model's average confidence score- which indicated a high degree of dependability and certainty in differentiating these critical characteristics. The proposed model demonstrated a noteworthy average confidence level of 0.9305 in the classification of microcalcification- outperforming alternative models and providing substantial insights into the dependability of the model. The average confidence of the ensemble model in classifying normal cases was 0.8859- which strengthened the model's consistent and dependable predictions. In addition- the ensemble models attained remarkably high performances in terms of accuracy- precision- recall- F1-score- and area under the curve (AUC). The proposed model's thorough dataset integration and focus on average confidence ratings within classes improve clinical diagnosis accuracy and effectiveness for breast cancer. This study introduces a novel methodology that takes advantage of an ensemble model and rigorous evaluation standards to substantially improve the accuracy and dependability of breast cancer diagnostics- specifically in the detection of microcalcifications.
Yiqi Sun- Bohan Wan- Xin Liu- Jianguo Dong- Shengjie Yin- Yiqi Wu,Breast cancer and neoplasms of the thyroid gland: a bidirectional two-sample Mendelian randomization study,Small cohorts of certain disease states are common especially in medical imaging. Despite the growing culture of data sharing- information safety often precludes open sharing of these datasets for creating generalizable machine learning models. To overcome this barrier and maintain proper health information protection- foundational models are rapidly evolving to provide deep learning solutions that have been pretrained on the native feature spaces of the data. Although this has been optimized in Large Language Models (LLMs)- there is still a sparsity of foundational models for computer vision tasks. It is in this space that we provide an investigation into pretraining Visual Geometry Group (VGG)-16- Residual Network (ResNet)-50- and Dense Network (DenseNet)-121 on an unrelated dataset of 8500 chest CTs which was subsequently fine-tuned to classify bone mineral density (BMD) in 199 breast cancer patients using the L1 vertebra on CT. These semi-foundational models showed significant improved ternary classification into mild- moderate- and severe demineralization in comparison to ground truth Hounsfield Unit (HU) measurements in trabecular bone with the semi-foundational ResNet50 architecture demonstrating the best relative performance. Specifically- the holdout testing AUC was 0.99 (p-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.05- ANOVA versus no pretraining versus ImageNet transfer learning) and F1-score 0.99 (p-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.05) for the holdout testing set. In this study- the use of a semi-foundational model trained on the native feature space of CT provided improved classification in a completely disparate disease state with different window levels. Future implementation with these models may provide better generalization despite smaller numbers of a disease state to be classified.
S R Sannasi Chakravarthy- N Bharanidharan- V Vinoth Kumar- T R Mahesh- Mohammed S Alqahtani- Suresh Guluwadi,Deep transfer learning with fuzzy ensemble approach for the early detection of breast cancer,The efficacy of immune checkpoint inhibitors is significantly influenced by the tumor immune microenvironment (TIME). RNA sequencing of tumor tissue can offer valuable insights into TIME- but its high cost and long turnaround time seriously restrict its utility in routine clinical examinations. Several recent studies have suggested that ultrahigh-resolution pathology images can infer cellular and molecular characteristics. However- few study pay attention to the quantitative estimation of various tumor infiltration immune cells from pathology images. In this paper- we integrated contrastive learning and weakly supervised learning to infer tumor-associated macrophages and potential immunotherapy benefit from whole slide images (WSIs) of H &E stained pathological sections. We split the high-resolution WSIs into tiles and then apply contrastive learning to extract features of each tile. After aggregating the features at the tile level- we employ weak supervisory signals to fine-tune the encoder for various downstream tasks. Comprehensive experiments on two independent breast cancer cohorts and spatial transcriptomics data demonstrate that the computational pathological features accurately predict the proportion of tumor-infiltrating immune cells- particularly the infiltration level of macrophages- as well as the immune subtypes and potential immunotherapy benefit. These findings demonstrate that our model effectively captures pathological features beyond human vision- establishing a mapping relationship between cellular compositions and histological morphology- thus expanding the clinical applications of digital pathology images.
Hea Lim Choi- Su Min Jeong- Keun Hye Jeon- Bongseong Kim- Wonyoung Jung- Ansuk Jeong- Kyungdo Han- Dong Wook Shin,Depression risk among breast cancer survivors: a nationwide cohort study in South Korea,Photoacoustic tomography (PAT) has emerged as a promising imaging modality for breast cancer detection- offering unique advantages in visualizing tissue composition without ionizing radiation. However- limited-view scenarios in clinical settings present significant challenges for image reconstruction quality and computational efficiency. This paper introduces novel unrolled deep learning networks based on split Bregman total variation (SBTV) and relaxed basis pursuit alternating direction method of multipliers (rBP-ADMM) algorithms to address these challenges. Our approach combines transfer learning from full-view to limited-view scenarios with U-Net denoiser integration- achieving state-of-the-art reconstruction quality (MS-SSIM> 0.95) while reducing reconstruction time by 92% compared to traditional methods. The effectiveness of different sensor configurations is analyzed through restricted isometry property (RIP) analysis and coherence values- demonstrating that semicircular arrays achieve a RIP constant of 0.76 and coherence of 0.77- closely approximating full-view performance (RIP: 0.75- coherence: 0.78). These metrics validate the theoretical foundation for accurate sparse signal recovery in limited-view scenarios. Comprehensive evaluations across semicircular- concave- and convex sensor arrangements show that the proposed U-SBTV network consistently outperforms existing methods- particularly when combined with the U-Net denoiser. This advancement in limited-view PAT reconstruction brings the technology closer to practical clinical application- potentially improving early breast cancer detection capabilities.
Shahad Awadelkarim,Feature Selection using Extra Trees for Breast Cancer Prediction,Breast cancer continues to pose a significant global health challenge- emphasizing the need for advancements in early detection methods. This study explores the application of transfer learning techniques- specifically utilizing EfficientNet- to enhance the accuracy of breast cancer detection through medical imaging. Leveraging a dataset of mammography images from the Digital Database for Screening Mammography (DDSM)- the research implements various data preprocessing methods- including median filtering- contrast enhancement- and artifact removal- to ensure the quality of input data. The EfficientNet model- trained with these preprocessed images- is evaluated against other transfer learning architectures- such as DenseNet and ResNeXt50- using metrics like accuracy- AUC- precision- and F1-score. The results demonstrate that EfficientNet outperforms other models- achieving an accuracy of 95.23%- with a sensitivity of 96.67% and specificity of 93.82%. These findings suggest that transfer learning- particularly with EfficientNet- can significantly improve the predictive accuracy of breast cancer detection- offering a reliable tool for early diagnosis and personalized treatment planning. The study also discusses the potential integration of these models into clinical workflows- addressing challenges such as data privacy- model generalizability- and clinical applicability. Future research will focus on expanding the dataset and exploring the use of other advanced deep learning techniques to further enhance detection accuracy and robustness.
Ko Un Park- Stuart R. Lipsitz- L. Dominici- F. Lynce- Christina A. Minami- F. Nakhlis- Adrienne G. Waks- Laura E. Warren- Nadine Eidman- Jeannie Frazier- Lourdes Hernandez- Carla Leslie- Susan Rafte- Delia Stroud- J. Weissman- T. King- E. Mittendorf,Generative artificial intelligence as a source of breast cancer information for patients: Proceed with caution.,<title>Abstract</title> <p>Breast cancer is one of the most prevalent causes of cancer-related death globally. Preliminary diagnosis of breast cancer increases the patient's chances of survival and healing. In this paper- we propose a hybrid deep transfer learning model integrating xception with support vector classifier (XSV) and xception with random forest (XRF) along with pre-processing technique to classify breast cancer as cancerous (malignant) or non-cancerous (benign) along comparative analysis of prominent machine learning classifiers- such as Random Forest Classifier (RFC)- Logistic Regression (LR)- Support Vector Classifier (SVC)- K-Nearest Neighbors (K-NN)- and Ada-boost. In experiment all the models are implemented on two openly accessible datasets: BreakHis and Breast Histopathology Images Database (BHID) across various metrics such as accuracy- area under the receiver operating curve- precision- recall- f1-score- Matthew's correlation coefficient- classification success index- and kappa at different magnification levels of images. Our proposed model that utilized the fine tuning of xception model in conjunction with RFC and SVC- surpass existing breast cancer classification methodologies. Specifically- the XSV that achieved accuracies of 89.26%- 85.87%- 90.17%- and 88.98%- while the XRF attained accuracies of 87.78%- 84.78%- 88.98%- and 87.61% for BreakHis at 40X- 100X- 200X- and 400X magnifications- respectively. For BHID at 40X magnification- the XSV and XRF models achieved accuracies of 87.35% and 87.29%- respectively. Employing this study will aid our medical practitioners and researchers in choosing an accurate model for tumor classification and our results will help medical professionals to classify the disease with precision.</p>
Yushu Ma- Chien-Hung Shih- Jinxiong Cheng- Hsiao-Chun Chen- Li-Ju Wang- Yanhao Tan- Yu-Chiao Chiu- Yu-Chih Chen,High-Throughput Empirical and Virtual Screening to Discover Novel Inhibitors of Polyploid Giant Cancer Cells in Breast Cancer,Breast cancer (BC) is a type of cancer which progresses and spreads from breast tissues and gradually exceeds the entire body; this kind of cancer originates in both sexes. Prompt recognition of this disorder is most significant in this phase- and it is measured by providing patients with the essential treatment so their efficient lifetime can be protected. Scientists and researchers in numerous studies have initiated techniques to identify tumours in early phases. Still- misperception in classifying skeptical lesions can be due to poor image excellence and dissimilar breast density. BC is a primary health concern- requiring constant initial detection and improvement in analysis. BC analysis has made major progress recently with combining multi-modal image modalities.Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ These studies deliver an overview of the segmentation- classification- or grading of numerous cancer types- including BC- by employing conventional machine learning (ML) models over hand-engineered features. Therefore- this study uses multi-modality medical imaging to propose a Computer Vision with Fusion Joint Transfer Learning for Breast Cancer Diagnosis (CVFBJTL-BCD) technique. The presented CVFBJTL-BCD technique utilizes feature fusion and DL models to effectively detect and identify BC diagnoses. The CVFBJTL-BCD technique primarily employs the Gabor filtering (GF) technique for noise removal. Next- the CVFBJTL-BCD technique uses a fusion-based joint transfer learning (TL) process comprising three models- namely DenseNet201- InceptionV3- and MobileNetV2. The stacked autoencoders (SAE) model is implemented to classify BC diagnosis. Finally- the horse herd optimization algorithm (HHOA) model is utilized to select parameters involved in the SAE method optimally. To demonstrate the improved results of the CVFBJTL-BCD methodology- a comprehensive series of experimentations are performed on two benchmark datasets. The comparative analysis of the CVFBJTL-BCD technique portrayed a superior accuracy value of 98.18% and 99.15% over existing methods under Histopathological and Ultrasound datasets.
Massimiliano Berretta- Daniele Garozzo- Calogero Foti- Mario Roselli- Marco Materazzo- Giulia Vita- Ferdinando Iellamo- Marco Scordari- Giordana Di Mauro- Giovanna Spatari- Alessandro Ottaiano- Annalisa Noce- Marco Pellicciaro- Alessia Bignucolo- Gianluca Vanni- Oreste Claudio Buonomo,Implementing fencing as adapted physical activity in non-metastatic breast cancer patients: design and early rehabilitation strategy of the FENICE study protocol,Background: Breast cancer is one of the most lethal cancers among women. Early detection and proper treatment reduce mortality rates. Histopathological images provide detailed information for diagnosing and staging breast cancer disease. Methods: The BreakHis dataset- which includes histopathological images- is used in this study. Medical images are prone to problems such as different textural backgrounds and overlapping cell structures- unbalanced class distribution- and insufficiently labeled data. In addition to these- the limitations of deep learning models in overfitting and insufficient feature extraction make it extremely difficult to obtain a high-performance model in this dataset. In this study- 20 state-of-the-art models are trained to diagnose eight types of breast cancer using the fine-tuning method. In addition- a comprehensive experimental study was conducted to determine the most successful new model- with 20 different custom models reported. As a result- we propose a novel model called MultiHisNet. Results: The most effective new model- which included a pointwise convolution layer- residual link- channel- and spatial attention module- achieved 94.69% accuracy in multi-class breast cancer classification. An ensemble model was created with the best-performing transfer learning and custom models obtained in the study- and model weights were determined with an Equilibrium Optimizer. The proposed ensemble model achieved 96.71% accuracy in eight-class breast cancer detection. Conclusions: The results show that the proposed model will support pathologists in successfully diagnosing breast cancer.
Christiana Subaar- Fosberg Tweneboah Addai- Eric Clement Kotei Addison- Olivia Christos- Joseph Adom- Martin Owusu-Mensah- Nelson Appiah-Agyei- Shadrack Abbey,Investigating the detection of breast cancer with deep transfer learning using ResNet18 and ResNet34,A novel nomogram incorporating artificial intelligence (AI) and clinical features for enhanced ultrasound prediction of benign and malignant breast masses. This study analyzed 340 breast masses identified through ultrasound in 308 patients. The masses were divided into training (n = 260) and validation (n = 80) groups. The AI-based analysis employed the Samsung Ultrasound AI system (S-detect). Univariate and multivariate analyses were conducted to construct nomograms using logistic regression. The AI-Nomogram was based solely on AI results- while the ClinAI- Nomogram incorporated additional clinical factors. Both nomograms underwent internal validation with 1000 bootstrap resamples and external validation using the independent validation group. Performance was evaluated by analyzing the area under the receiver operating characteristic (ROC) curve (AUC) and calibration curves. The ClinAI-Nomogram- which incorporates patient age- AI-based mass size- and AI-based diagnosis- outperformed an existing AI-Nomogram in differentiating benign from malignant breast masses. The ClinAI-Nomogram surpassed the AI-Nomogram in predicting malignancy with significantly higher AUC scores in both training (0.873- 95% CI: 0.830-0.917 vs. 0.792- 95% CI: 0.748-0.836; p = 0.016) and validation phases (0.847- 95% CI: 0.763-0.932 vs. 0.770- 95% CI: 0.709-0.833; p < 0.001). Calibration curves further revealed excellent agreement between the ClinAI-Nomogram's predicted probabilities and actual observed risks of malignancy. The ClinAI- Nomogram- combining AI alongside clinical data- significantly enhanced the differentiation of benign and malignant breast masses in clinical AI-facilitated ultrasound examinations.
Sang Won Park- Ye-Lin Park- Eun-Gyeong Lee- Heejung Chae- Phillip Park- Dong-Woo Choi- Yeon Ho Choi- Juyeon Hwang- Seohyun Ahn- Keunkyun Kim- Woo Jin Kim- Sun-Young Kong- So-Youn Jung- Hyun-Jin Kim,Mortality Prediction Modeling for Patients with Breast Cancer Based on Explainable Machine Learning,Background/Objectives: Breast cancer is a leading cause of mortality among women in Taiwan and globally. Non-invasive imaging methods- such as mammography and ultrasound- are critical for early detection- yet standalone modalities have limitations in regard to their diagnostic accuracy. This study aims to enhance breast cancer detection through a cross-modality fusion approach combining mammography and ultrasound imaging- using advanced convolutional neural network (CNN) architectures. Materials and Methods: Breast images were sourced from public datasets- including the RSNA- the PAS- and Kaggle- and categorized into malignant and benign groups. Data augmentation techniques were used to address imbalances in the ultrasound dataset. Three models were developed: (1) pre-trained CNNs integrated with machine learning classifiers- (2) transfer learning-based CNNs- and (3) a custom-designed 17-layer CNN for direct classification. The performance of the models was evaluated using metrics such as accuracy and the Kappa score. Results: The custom 17-layer CNN outperformed the other models- achieving an accuracy of 0.964 and a Kappa score of 0.927. The transfer learning model achieved moderate performance (accuracy 0.846- Kappa 0.694)- while the pre-trained CNNs with machine learning classifiers yielded the lowest results (accuracy 0.780- Kappa 0.559). Cross-modality fusion proved effective in leveraging the complementary strengths of mammography and ultrasound imaging. Conclusions: This study demonstrates the potential of cross-modality imaging and tailored CNN architectures to significantly improve diagnostic accuracy and reliability in breast cancer detection. The custom-designed model offers a practical solution for early detection- potentially reducing false positives and false negatives- and improving patient outcomes through timely and accurate diagnosis.
Yini Li- Cao Li- Tao Yang- Lingzhi Chen- Mingquan Huang- Lu Yang- Shuxian Zhou- Huaqing Liu- Jizhu Xia- Shijie Wang,Multiview deep learning networks based on automated breast volume scanner images for identifying breast cancer in BI-RADS 4,Single-vesicle molecular profiling of cancer-associated extracellular vesicles (EVs) is increasingly being recognized as a powerful tool for cancer detection and monitoring. Mask and target dual imaging is a facile method to quantify the fraction of the molecularly targeted population of EVs in biofluids at the single-vesicle level. However- accurate and efficient dual imaging vesicle analysis has been challenging due to the interference of false signals on the mask images and the need to analyze a large number of images in clinical samples. In this work- we report a fully automatic dual imaging analysis method based on machine learning and use it with dual imaging single-vesicle technology (DISVT) to detect breast cancer at different stages. The convolutional neural network Resnet34 was used along with transfer learning to produce a suitable machine learning model that could accurately identify areas of interest in experimental data. A combination of experimental and synthetic data were used to train the model. Using DISVT and our machine learning-assisted image analysis platform- we determined the fractions of EpCAM-positive EVs and CD24-positive EVs over captured plasma EVs with CD81 marker in the blood plasma of pilot HER2-positive breast cancer patients and compared to those from healthy donors. The amount of both EpCAM-positive and CD24-positive EVs was found negligible for both healthy donors and Stage I patients. The amount of EpCAM-positive EVs (also CD81-positive) increased from 18% to 29% as the cancer progressed from Stage II to III. No significant increase was found with further progression to Stage IV. A similar trend was found for the CD24-positive EVs. Statistical analysis showed that both EpCAM and CD24 markers can detect HER2-positive breast cancer at Stages II- III- or IV. They can also differentiate individual cancer stages except those between Stage III and Stage IV. Due to the simplicity- high sensitivity- and high efficiency- the DISVT with the AI-assisted dual imaging analysis can be widely used for both basic research and clinical applications to quantitatively characterize molecularly targeted EV subtypes in biofluids.
Jung In Park- Steven Johnson- Lisiane Pruinelli,Optimizing pain management in breast cancer care: Utilizing 'All of Us' data and deep learning to identify patients at elevated risk for chronic pain,Segmentation is a technique for separating an image into discrete areas in order to separate objects of interest from their surroundings. In image analysis- segmentationâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶âˆšÃœwhich encompasses detection- feature extraction- classification- and treatmentâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶âˆšÃœis crucial. In order to plan treatments- segmentation aids doctors in measuring the amount of tissue in the breast. Categorizing the input data into two groups that are mutually exclusive is the aim of a binary classification problem. In this case- the training data is labeled in a binary format based on the problem being solved. Identifying breast lumps accurately in mammography pictures is essential for the purpose of prenatal testing for breast cancer. The proposed TLA (Transfer Learning Approach) based CNN (Convolution Neural Network) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®TLA based CNN aims to offer binary classification for rapid and precise breast cancer diagnosis (benign and malignant). In order to predict the sub-type of cancer- this exploration as used Deep Learning techniques on the Histogram of Oriented Gradient (HOG) - Feature extraction technique that creates a local histogram of the image to extract features from each place in the image with CNN classifier. This research work employs two well-known pre-trained models- ResNet-50 and VGG16- to extract characteristics from mammography images. The high-level features from the Mammogram dataset are extracted using a transfer learning model based on Visual Geometry Group (VGG) with 16-layer and Residual Neural Network with 50-layers deep model architecture (ResNet-50). The proposed model TLA based CNN has achieved 96.49% and 95.48% accuracy as compared to ResNet50 and VGG16 in the breast cancer classification and segmentation.
Andreas Ekholm- Yinxi Wang- Johan Vallon-Christersson- Constance Boissin- Mattias Rantalainen,Prediction of gene expression-based breast cancer proliferation scores from histopathology whole slide images using deep learning,Breast cancer is a leading cause of death among women- and early detection is crucial for improving survival rates. The manual breast cancer diagnosis utilizes more time and is subjective. Also- the previous CAD models mostly depend on manmade visual details that are complex to generalize across ultrasound images utilizing distinct techniques. Distinct imaging tools have been utilized in previous works such as mammography and MRI. However- these imaging tools are costly and less portable than ultrasound imaging. Also- ultrasound imaging is a non-invasive method commonly used for breast cancer screening. Hence- the paper presents a novel deep learning model- BCDNet- for classifying breast tumors as benign or malignant using ultrasound images. The primary aim of the study is to design an effective breast cancer diagnosis model that can accurately classify tumors in their early stages- thus reducing mortality rates. The model aims to optimize the weight and parameters using the RPAOSM-ESO algorithm to enhance accuracy and minimize false negative rates. The BCDNet model utilizes transfer learning from a pre-trained VGG16 network for feature extraction and employs an AHDNAM classification approach- which includes ASPP- DTCN- 1DCNN- and an attention mechanism. The RPAOSM-ESO algorithm is used to fine-tune the weights and parameters. The RPAOSM-ESO-BCDNet-based breast cancer diagnosis model provided 94.5 accuracy rates. This value is relatively higher than the previous models such as DTCN (88.2)- 1DCNN (89.6)- MobileNet (91.3)- and ASPP-DTC-1DCNN-AM (93.8). Hence- it is guaranteed that the designed RPAOSM-ESO-BCDNet produces relatively accurate solutions for the classification than the previous models. The BCDNet model- with its sophisticated feature extraction and classification techniques optimized by the RPAOSM-ESO algorithm- shows promise in accurately classifying breast tumors using ultrasound images. The study suggests that the model could be a valuable tool in the early detection of breast cancer- potentially saving lives and reducing the burden on healthcare systems.
Morteza Rakhshaninejad- Mohammad Fathian- Reza Shirkoohi- F. Barzinpour- Amir H. Gandomi,Refining breast cancer biomarker discovery and drug targeting through an advanced data-driven approach,Objectives: The research aims to enhance breast cancer detection accuracy and effectiveness using deep transfer learning and pre-trained neural networks. It analyses breast ultrasound images and identifies important characteristics using pre-trained networks. The goal is to create a more efficient and accurate automated system for breast cancer detection. Methods: The study uses breast ultrasound cancer image data from the Kaggle Data Repository to extract informative features- identify cancer-related characteristics- and classify them into benign- malignant- and normal tissue. Pre-trained Deep Neural Networks (DNNs) extract these features and feed them into a 10-fold cross-validation SVM classifier. The SVM is evaluated using various kernel functions to identify the best kernel for separating data points. This methodology aims to achieve accurate classification of breast cancer in ultrasound images. Findings: The study confirms the effectiveness of deep transfer learning for breast cancer detection in ultrasound images- with Inception V3 outperforming VGG-16 and VGG-19 in extracting relevant features. The combination of Inception V3 and the SVM classifier with a polynomial kernel achieved the highest classification accuracy- indicating its ability to model complex relationships. The study demonstrated an AUC of 0.944 and a classification accuracy of 87.44% using the Inception V3 + SVM polynomial. Novelty: This research demonstrates the potential of deep transfer learning and SVM classifiers for accurate breast cancer detection in ultrasound images. It integrates Inception V3- VGG-16- and VGG-19 for breast cancer detection- demonstrating improved classification accuracy. The combination of Inception V3 and SVM (polynomial) achieved a significant AUC (0.944) and classification accuracy (87.44%)- outperforming other models tested. This research underscores the potential of these technologies for accurate breast cancer detection in ultrasound images. Keywords: Breast Cancer- Deep Learning- Feature Extraction- Inception-v3- SVM- Transfer Learning
Xuefeng Fu- Yang Jiao- Yao Feng- Fengwei Lin- Bing Zhang- Qing Mao- Jiahui Wang- Wen Jiang- Yanhua Mou- Han Wang- Shaojie Wang,Scaffold Hopping of Pristimerin Provides Derivatives Containing a Privileged Quinoxaline Substructure as Potent Autophagy Inducers in Breast Cancer Cells,Digital Breast Tomosynthesis (DBT) has revolutionized more traditional breast imaging through its three-dimensional (3D) visualization capability that significantly enhances lesion discernibility- reduces tissue overlap- and improves diagnostic precision as compared to conventional two-dimensional (2D) mammography. In this study- we propose an advanced Computer-Aided Detection (CAD) system that harnesses the power of vision transformers to augment DBT's diagnostic efficiency. This scheme uses a neural network to glean attributes from the 2D slices of DBT followed by post-processing that considers features from neighboring slices to categorize the entire 3D scan. By leveraging a transfer learning technique- we trained and validated our CAD framework on a unique dataset consisting of 3-831 DBT scans and subsequently tested it on 685 scans. Of the architectures tested- the Swin Transformer outperformed the ResNet101 and vanilla Vision Transformer. It achieved an impressive AUC score of 0.934 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 0.026 at a resolution of 384 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 384. Increasing the image resolution from 224 to 384 not only maintained vital image attributes but also led to a marked improvement in performance (p-value = 0.0003). The Mean Teacher algorithm- a semi-supervised method using both labeled and unlabeled DBT slices- showed no significant improvement over the supervised approach. Comprehensive analyses across different lesion types- sizes- and patient ages revealed consistent performance. The integration of attention mechanisms yielded a visual narrative of the model's decision-making process that highlighted the prioritized regions during assessments. These findings should significantly propel the methodologies employed in DBT image analysis by setting a new benchmark for breast cancer diagnostic precision.
Shengnan Hao- Yihan Jia- Jianuo Liu- Zhiwu Wang- Chunling Liu- Zhanlin Ji- Ivan Ganchev,ST-Double-Net: A Two-Stage Breast Tumor Classification Model Based on Swin Transformer and Weakly Supervised Target Localization,"The Deep learning (DL) models for diagnosing breast cancer from mammographic images often operate as""black boxes""- making it difficult for healthcare professionals to trust and understand their decision-making processes. The study presents an integrated framework combining Convolutional Neural Networks (CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an elaborate data preprocessing pipeline and advanced data augmentation techniques to counteract dataset limitations and transfer learning using pre-trained networks such as VGG-16- Inception-V3 and ResNet was employed. A focal point of our study is the evaluation of XAI's effectiveness in interpreting model predictions- highlighted by utilizing the Hausdorff measure to assess the alignment between AI-generated explanations and expert annotations quantitatively. This approach is critical for XAI in promoting trustworthiness and ethical fairness in AI-assisted diagnostics. The findings from our research illustrate the effective collaboration between CNNs and XAI in advancing diagnostic methods for breast cancer- thereby facilitating a more seamless integration of advanced AI technologies within clinical settings. By enhancing the interpretability of AI driven decisions- this work lays the groundwork for improved collaboration between AI systems and medical practitioners- ultimately enriching patient care. Furthermore- the implications of our research extended well beyond the current methodologies. It encourages further research into how to combine multimodal data and improve AI explanations to meet the needs of clinical practice."
Olya Rezaeian- Onur Asan- A. E. Bayrak,The Impact of AI Explanations on Clinicians Trust and Diagnostic Accuracy in Breast Cancer,Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer. Breast tissue histopathological examination is critical in diagnosing and classifying breast cancer. Although existing methods have shown promising results- there is still room for improvement in the classification accuracy and generalization of IDC using histopathology images. We present a novel approach- Supervised Contrastive Vision Transformer (SupCon-ViT)- for improving the classification of invasive ductal carcinoma in terms of accuracy and generalization by leveraging the inherent strengths and advantages of both transfer learning- i.e.- pre-trained vision transformer- and supervised contrastive learning. Our results on a benchmark breast cancer dataset demonstrate that SupCon-ViT achieves state-of-the-art performance in IDC classification- with an F1-score of 0.8188- precision of 0.7692- and specificity of 0.8971- outperforming existing methods. In addition- the proposed model demonstrates resilience in scenarios with minimal labeled data- making it highly efficient in real-world clinical settings where labeled data is limited. Our findings suggest that supervised contrastive learning in conjunction with pre-trained vision transformers appears to be a viable strategy for an accurate classification of IDC- thus paving the way for a more efficient and reliable diagnosis of breast cancer through histopathological image analysis.
Eleonore Baum- Daniela Bernhardsgrâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Â´tter- Ramona Engst- Carola Maurer- Jessica Ebneter- Adrienne Zenklusen- Barbara Wartlsteiner- Lotti Barandun- Andrea Neher- Antje Koller- Andrea Kobleder,The meaning of trust along the treatment pathway of women with breast cancer: a mixed-methods study among cancer survivors,Objective Early diagnosis of breast cancer can lead to effective treatment- possibly increase long-term survival rates- and improve quality of life. The objective of this study is to present an automated analysis and classification system for breast cancer using clinical markers such as tumor shape- orientation- margin- and surrounding tissue. The novelty and uniqueness of the study lie in the approach of considering medical features based on the diagnosis of radiologists. Methods Using clinical markers- a graph is generated where each feature is represented by a node- and the connection between them is represented by an edge which is derived through Pearson's correlation method. A graph convolutional network (GCN) model is proposed to classify breast tumors into benign and malignant- using the graph data. Several statistical tests are performed to assess the importance of the proposed features. The performance of the proposed GCN model is improved by experimenting with different layer configurations and hyper-parameter settings. Results Results show that the proposed model has a 98.73% test accuracy. The performance of the model is compared with a graph attention network- a one-dimensional convolutional neural network- and five transfer learning models- ten machine learning models- and three ensemble learning models. The performance of the model was further assessed with three supplementary breast cancer ultrasound image datasets- where the accuracies are 91.03%- 94.37%- and 89.62% for Dataset A- Dataset B- and Dataset C (combining Dataset A and Dataset B) respectively. Overfitting issues are assessed through k-fold cross-validation. Conclusion Several variants are utilized to present a more rigorous and fair evaluation of our work- especially the importance of extracting clinically relevant features. Moreover- a GCN model using graph data can be a promising solution for an automated feature-based breast image classification system.
Pritpal Singh- Rakesh Kumar- Meenu Gupta- Ahmed J. Obaid,Transfer Learning based Breast Cancer Classification using Histopathology Images,BACKGROUND The aim of this study is an improved understanding of drug distribution in brain metastases. Rather than single point snapshots- we analyzed the time course and route of drug/probe elimination (clearance)- focusing on the Intramural Periarterial Drainage (IPAD) pathway. METHODS Mice with JIMT1-BR HER2+ experimental brain metastases were injected with biocytin-TMR and either trastuzumab or human IgG. Drugs/probes circulated for 5 min-48h- followed by perfusion. Brain sections were stained for human IgG- vascular basement membrane proteins laminin or collagen IV- and periarterial â€šÃ¢Ã âˆšâ‰ Â¬Â¨Â¬Â±-SMA. A machine learning algorithm was developed to identify metastases- metastatic microenvironment- and uninvolved brain in confocally scanned brain sections. Drug/probe intensity over time and total imaged drug exposure (iAUC) were calculated for 27-249 lesions and co-immunofluorescence with IPAD- vascular matrix analyzed in 11-668 metastases. RESULTS In metastases- peak trastuzumab levels were 5-fold higher than human IgG but 4-fold less than biocytin-TMR. The elimination phase constituted 85-93% of total iAUC for all drugs/probes tested. For trastuzumab- total iAUC during uptake was similar to the small molecule drug probe biocytin-TMR- but slower trastuzumab elimination resulted in a 1.7-fold higher total iAUC. During elimination trastuzumab and IgG were preferentially enriched in the â€šÃ¢Ã âˆšâ‰ Â¬Â¨Â¬Â±-SMA+ periarterial vascular matrix- consistent with the IPAD clearance route; biocytin-TMR showed heterogeneous elimination pathways. CONCLUSIONS Drug/probe elimination is an important component of drug development for brain metastases. We identified a prolonged elimination pathway for systemically administered antibodies through the periarterial vascular matrix that may contribute to the sustained presence and efficacy of large antibody therapeutics.
A. Tien- M. Sadar,Treatments Targeting the Androgen Receptor and Its Splice Variants in Breast Cancer,Cytological evaluation through microscopic image analysis of fine needle aspiration cytology (FNAC) is pivotal in the initial screening of breast cancer. The sensitivity of FNAC as a screening tool relies on both image quality and the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s expertise. To enhance diagnostic accuracy and alleviate the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s workload- a computer-aided diagnosis (CAD) system was developed. A comparative study was conducted- assessing twelve candidate pre-trained models. Utilizing a locally gathered FNAC image dataset- three superior models-MobileNet-V2- DenseNet-121- and Inception-V3-were selected based on their training- validation- and testing accuracies. Further- these models underwent evaluation in four transfer learning scenarios to enhance testing accuracy. While the outcomes were promising- they left room for improvement- motivating us to create a novel deep convolutional neural network (CNN). The newly proposed model exhibited robust performance with testing accuracy at 85%. Our research concludes that the most lightweight- high-accuracy model is the one we propose. Weâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ve integrated it into our user-friendly Android App- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Breast Cancer Detection System-â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Å“Ã„ in TensorFlow Lite format- with cloud database support- showcasing its effectiveness. Implementing an artificial intelligent (AI)-based diagnosis system with a user-friendly interface holds the potential to enhance early breast cancer detection using FNAC.
Alexander S Millar- John Arnn- Sam Himes- Julio C. Facelli,Uncertainty in Breast Cancer Risk Prediction: A Conformal Prediction Study of Race Stratification,Breast cancer (BC) is one of the most fatal forms of cancer- making it a significant contributor to mortality rates worldwide. Early detection and timely treatment of breast cancer are crucial in reducing its mortality rate. To ensure a healthy lifestyle- it is essential to develop systems that can accurately diagnose breast cancer. Recent advances in modern computing and information technologies have enabled significant progress in the early detection and prediction of diseases within healthcare systems. This study proposes a method for precise and automatic breast cancer prediction using deep-modified transfer learning-based Convolutional Neural Networks (CNNs). The CNN architectures employed include ResNet50- MobileNetV2- DenseNet121- and Xception- which serve as feature extractors to capture the most relevant features of breast Ultrasound images (BUSI). These extracted features are then accurately classified as benign or malignant using various high-performance classifiers- including Support Vector Machine (SVM)- K-Nearest Neighbors (KNN)- XGBoost- and Softmax. The experimental results demonstrate that the proposed deep modified DenseNet121 network with the Softmax classifier outperformed other models and existing techniques. This latter achieved remarkable performance metrics- including an accuracy of 95.34%- a precision of 90.90%- and an F1 score of 93.02%. These results highlight the effectiveness of our approach in enhancing the accuracy of breast cancer prediction. The superior performance of the proposed method provides significant improvements in decision-making speed and reduces the time- effort- and laboratory resources required for healthcare services. Consequently- this method has the potential to significantly enhance early diagnosis and enable more tailored treatment plans- ultimately contributing to better patient outcomes and reducing the overall mortality rates associated with breast cancer.
Ali Hendi- Jalal Abu Halimah- Naif Majrashi- Sarah Daghriri- Mohammed Alhafaf- Mohammed Alshaikh- Mohammed Akkam- Saleha Haroobi- Rahaf Othathi- Reem Harbi- Abdulrahman Zalah- Elham Maghrabi- Alanoud Masmali- Mohammed Mojiri,Understanding Breast Cancer Awareness- Perceptions- and Screening Practices Among the Population of Jazan- Saudi Arabia: A Cross-Sectional Study,A comprehensive evaluation of the relationship between the densities of various cell types in the breast cancer tumor microenvironment and patient prognosis is currently lacking. Additionally- the absence of a large patch-level whole slide imaging (WSI) dataset of breast cancer with annotated cell types hinders the ability of artificial intelligence to evaluate cell density in breast cancer WSI. We first employed Lasso-Cox regression to build a breast cancer prognosis assessment model based on cell density in a population study. Pathology experts manually annotated a dataset containing over 70-000 patches and used transfer learning based on ResNet152 to develop an artificial intelligence model for identifying different cell types in these patches. The results showed that significant prognostic differences were observed among breast cancer patients stratified by cell density score (P = 0.0018)- with the cell density score identified as an independent prognostic factor for breast cancer patients (P < 0.05). In the validation cohort- the predictive performance for overall survival (OS) was satisfactory- with area under the curve (AUC) values of 0.893 (OS) at 1-year- 0.823 (OS) at 3-year- and 0.861 (OS) at 5-year intervals. We trained a robust model based on ResNet152- achieving over 99% classification accuracy for different cell types in patches. These achievements offer new public resources and tools for personalized treatment and prognosis assessment.
Shiping Li- Yihao Lin- Guangyu Liu- Zhimin Shao- Yinlong Yang,Unveiling the potential of breast MRI: a game changer for BI-RADS 4A microcalcifications.,Breast cancer can progress silently in its early stages and frequently without noticeable symptoms. However- it poses a serious risk to women. It is imperative to recognize this potential health concern to mitigate it early. In the last few years- Convolutional Neural Networks (CNNs) have advanced significantly in their ability to classify images of breast cancer. Their capacity to automatically extract discriminant features from images has enhanced the performances and accuracy of image classification tasks. They outperform state-of-the-art techniques in this area. Furthermore- complicated models that were first learned for certain tasks can be easily adapted to complete new tasks by using transfer-learning approaches. However- deep learning-based categorization techniques could experience overfitting issues- particularly in cases where the dataset is small. The primary goal of this work is to investigate the performances of certain deep learning models to classify breast cancer images and to study the effects of data augmentation techniques- such as image rotation or displacement when utilizing a transfer learning approach. Using certain image datasets- the ResNet18- Resnet50- and VGG16 models demonstrated accuracy improvements- according to our experimental results.
GHB Andrade- T Nishiyama- T Fujimaki- S Yada- ...,Assessing domain adaptation in adverse drug event extraction on real-world breast cancer records,Objectives This study explored the familiarity- perceptions and confidence of Australian radiology clinicians involved in reading screening mammograms- regarding artificial intelligence (AI) applications in breast cancer detection. Methods Sixty-five radiologists- breast physicians and radiology trainees participated in an online survey that consisted of 23 multiple choice questions asking about their experience and familiarity with AI products. Furthermore- the survey asked about their confidence in using AI outputs and their preference for AI modes applied in a breast screening context. Participants' responses to questions were compared using Pearson's â€šÃ¢Ã âˆšÂ¨â€šÃ Ã¶Â¬âˆž 2 test. Bonferroni-adjusted significance tests were used for pairwise comparisons. Results Fifty-five percent of respondents had experience with AI in their workplaces- with automatic density measurement powered by machine learning being the most familiar AI product (69.4%). The top AI outputs with the highest ranks of perceived confidence were 'Displaying suspicious areas on mammograms with the percentage of cancer possibility' (67.8%) and 'Automatic mammogram classification (normal- benign- cancer- uncertain)' (64.6%). Radiology and breast physicians preferred using AI as second-reader mode (75.4% saying 'somewhat happy' to 'extremely happy') over triage (47.7%)- pre-screening and first-reader modes (both with 26.2%) (P â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.001). Conclusion The majority of screen readers expressed increased confidence in utilising AI for highlighting suspicious areas on mammograms and for automatically classifying mammograms. They considered AI as an optimal second-reader mode being the most ideal use in a screening program. The findings provide valuable insights into the familiarities and expectations of radiologists and breast clinicians for the AI products that can enhance the effectiveness of the breast cancer screening programs- benefitting both healthcare professionals and patients alike.
Usman Haider- Muhammad Hanif- Ahmer Rashid- Khursheed Aurangzeb- A. Khalil- Musaed A. Alhussein,Discriminative Dictionary Learning Using Penalized Rank-1 Approximation for Breast Cancer Classification With Imbalanced Dataset,Analysis of histopathological images (HIs) is crucial for detecting breast cancer (BR). However- because they vary- it is still very difficult to extract well-designed elements. Deep learning (DL) is a recent development that is used to extract high-level features. However- DL techniques continue to confront several difficult problems- such as the need for sufficient training data for DL models- which reduces the classification findings. In this study- an ensemble deep transfer convolutional neural network is presented to address this problem. The pre-trained models (ResNet50 and MobileNet) are employed to extract high-level features by freezing the front layer parameters while fine-tuning the last layers. In the proposed ensemble framework- KNN- SVM- logistic regression and neural networks are used as base classifiers. The majority vote and product approaches are used to integrate the predictions of each separate classifier. In the benchmark BreaKHis dataset- the suggested ensemble model is compared to some current approaches. It demonstrates that while the ensemble model obtains a considerable accuracy of 97.72% for the multiclass classification test- it achieves an accuracy of 99.2% for the binary task. The suggested ensemble modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s effectiveness in extracting useful features for BR images is demonstrated by comparison with existing cutting-edge models.
Massimiliano Berretta- Daniele Garozzo- Calogero Foti- Mario Roselli- Marco Materazzo- Giulia Vita- Ferdinando Iellamo- Marco Scordari- Giordana Di Mauro- Giovanna Spatari- Alessandro Ottaiano- Annalisa Noce- Marco Pellicciaro- Alessia Bignucolo- Gianluca Vanni- Oreste Claudio Buonomo,Implementing fencing as adapted physical activity in non-metastatic breast cancer patients: design and early rehabilitation strategy of the FENICE study protocol,Background: Breast cancer is one of the most lethal cancers among women. Early detection and proper treatment reduce mortality rates. Histopathological images provide detailed information for diagnosing and staging breast cancer disease. Methods: The BreakHis dataset- which includes histopathological images- is used in this study. Medical images are prone to problems such as different textural backgrounds and overlapping cell structures- unbalanced class distribution- and insufficiently labeled data. In addition to these- the limitations of deep learning models in overfitting and insufficient feature extraction make it extremely difficult to obtain a high-performance model in this dataset. In this study- 20 state-of-the-art models are trained to diagnose eight types of breast cancer using the fine-tuning method. In addition- a comprehensive experimental study was conducted to determine the most successful new model- with 20 different custom models reported. As a result- we propose a novel model called MultiHisNet. Results: The most effective new model- which included a pointwise convolution layer- residual link- channel- and spatial attention module- achieved 94.69% accuracy in multi-class breast cancer classification. An ensemble model was created with the best-performing transfer learning and custom models obtained in the study- and model weights were determined with an Equilibrium Optimizer. The proposed ensemble model achieved 96.71% accuracy in eight-class breast cancer detection. Conclusions: The results show that the proposed model will support pathologists in successfully diagnosing breast cancer.
Ayman Alsabry- Malek Algabri,Iterative Tuning of Tree-Ensemble-Based Models' parameters Using Bayesian Optimization for Breast Cancer Prediction,Breast cancer- a widespread malignancy predominantly affecting women aged 40 and above- presents a significant global health challenge with high mortality rates. The scarcity of medical data underscores the need for collaborative efforts among hospitals to enhance automated breast cancer detection. This research employs decentralized Federated Learning (FL) to facilitate cooperative learning across an interconnected smart hospital network- addressing data privacy- regulatory compliance- voluminous medical image data- and the necessity for distributed machine learning. Our innovative approach integrates Ant Colony Optimization (ACO) for hyperparameter fine-tuning and Neural Architecture Search (NAS) in a collaborative framework for smart hospitals linked with decentralized edge intelligent networks. This optimization strategy significantly improves the performance of our breast cancer detection system. Through a comprehensive experimental study (including diverse datasets)- we classify Normal vs. Mass and Benign vs. Malignant regions in mammograms within a decentralized- federated collaborative learning environment. Empirical results consistently highlight the superiority of models trained using our method over individual hospital client-level training. Our method yielded significant improvements across evaluation measures: for Normal vs. Mass- achieving 92.6% sensitivity- 93.0% specificity- and 93.0% accuracy; for Benign vs. Malignant- achieving 89.6% sensitivity- 91.6% specificity- and 89.7% accuracy. Moreover- it has obtained a 6% and 5% increase in accuracy for Normal vs. Mass and Benign vs. Malignant cases- respectively- compared to the PSO-based HPO method. This evidence underscores the potential of collaborative approaches- emphasizing decentralized FL as a robust paradigm in medical research. The incorporation of ACO optimization reinforces the effectiveness of the proposed computer-aided diagnosis (CAD) system- marking a noteworthy advancement in the ongoing fight against breast cancer.
Boya Manasa Sai- Yirivinti Hayagreeva Dinakar- Hitesh Kumar- Rupshee Jain- Sharyu Kesharwani- Siddharth S Kesharwani- Shyam Lal Mudavath- Ajmeer Ramkishan- Vikas Jain,Therapeutic delivery of siRNA for the management of breast cancer and triple-negative breast cancer,Breast cancer is the most prevalent cancer among women globally- making early and accurate detection essential for effective treatment and improved survival rates. This paper presents a method designed to detect and localize breast cancer using deep learning- specifically convolutional neural networks. The approach classifies histological images of breast tissue as either tumor-positive or tumor-negative. We utilize several deep learning models- including a custom-built CNN- EfficientNet- ResNet50- VGG-16- VGG-19- and MobileNet. Fine-tuning was also applied to VGG-16- VGG-19- and MobileNet to enhance performance. Additionally- we introduce a novel deep learning model called MR_Net- aimed at providing a more accurate network for breast cancer detection and localization- potentially assisting clinicians in making informed decisions. This model could also accelerate the diagnostic process- enabling early detection of the disease. Furthermore- we propose a method for explainable predictions by generating heatmaps that highlight the regions within tissue images that the model focuses on when predicting a label- revealing the detection of benign- atypical- and malignant tumors. We evaluate both the quantitative and qualitative performance of MR_Net and the other models- also presenting explainable results that allow visualization of the tissue areas identified by the model as relevant to the presence of breast cancer.
Ko Un Park- Stuart R. Lipsitz- L. Dominici- F. Lynce- Christina A. Minami- F. Nakhlis- Adrienne G. Waks- Laura E. Warren- Nadine Eidman- Jeannie Frazier- Lourdes Hernandez- Carla Leslie- Susan Rafte- Delia Stroud- J. Weissman- T. King- E. Mittendorf,Generative artificial intelligence as a source of breast cancer information for patients: Proceed with caution.,<title>Abstract</title> <p>Breast cancer is one of the most prevalent causes of cancer-related death globally. Preliminary diagnosis of breast cancer increases the patient's chances of survival and healing. In this paper- we propose a hybrid deep transfer learning model integrating xception with support vector classifier (XSV) and xception with random forest (XRF) along with pre-processing technique to classify breast cancer as cancerous (malignant) or non-cancerous (benign) along comparative analysis of prominent machine learning classifiers- such as Random Forest Classifier (RFC)- Logistic Regression (LR)- Support Vector Classifier (SVC)- K-Nearest Neighbors (K-NN)- and Ada-boost. In experiment all the models are implemented on two openly accessible datasets: BreakHis and Breast Histopathology Images Database (BHID) across various metrics such as accuracy- area under the receiver operating curve- precision- recall- f1-score- Matthew's correlation coefficient- classification success index- and kappa at different magnification levels of images. Our proposed model that utilized the fine tuning of xception model in conjunction with RFC and SVC- surpass existing breast cancer classification methodologies. Specifically- the XSV that achieved accuracies of 89.26%- 85.87%- 90.17%- and 88.98%- while the XRF attained accuracies of 87.78%- 84.78%- 88.98%- and 87.61% for BreakHis at 40X- 100X- 200X- and 400X magnifications- respectively. For BHID at 40X magnification- the XSV and XRF models achieved accuracies of 87.35% and 87.29%- respectively. Employing this study will aid our medical practitioners and researchers in choosing an accurate model for tumor classification and our results will help medical professionals to classify the disease with precision.</p>
Yeojin Jeong- Jeesoo Lee- Young-jin Lee- Jiyun Hwang- Sae Byul Lee- Tae-Kyung Yoo- Myeong-Seong Kim- Jae Il Kim- John L Hopper- Tuong L Nguyen- Jong Won Lee- Joohon Sung,Artificial-Intelligence Powered Identification of High-Risk Breast Cancer Subgroups Using Mammography: A Multicenter Study Integrating Automated Brightest Density Measures with Deep Learning Metrics,Breast Cancer is a significant global health challenge- particularly affecting women with higher mortality compared with other cancer types. Timely detection of such cancer types is crucial- and recent research- employing deep learning techniques- shows promise in earlier detection. The research focuses on the early detection of such tumors using mammogram images with deep-learning models. The paper utilized four public databases where a similar amount of 986 mammograms each for three classes (normal- benign- malignant) are taken for evaluation. Herein- three deep CNN models such as VGG-11- Inception v3- and ResNet50 are employed as base classifiers. The research adopts an ensemble method where the proposed approach makes use of the modified Gompertz function for building a fuzzy ranking of the base classification models and their decision scores are integrated in an adaptive manner for constructing the final prediction of results. The classification results of the proposed fuzzy ensemble approach outperform transfer learning models and other ensemble approaches such as weighted average and Sugeno integral techniques. The proposed ResNet50 ensemble network using the modified Gompertz function-based fuzzy ranking approach provides a superior classification accuracy of 98.986%.
W Wang- Y Li- X Yan- M Xiao- M Gao,Breast cancer image classification method based on deep transfer learning,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ By addressing these areas in future research- we aim to build upon our current findings and make further advancements in utilizing deep learning models for breast cancer detection. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
N. Alabi- M. Guillaud- S. El Hallani- F. Inaba- A. Nichol,A Machine-Learning Model to Predict Axillary Node Positivity from Clinical Characteristics and Large-Scale DNA Organization Features in Breast Cancer Biopsy Specimens,A lot of underdeveloped nations particularly in Africa struggle with cancer-related- deadly diseases. Particularly in women- the incidence of breast cancer is rising daily because of ignorance and delayed diagnosis. Only by correctly identifying and diagnosing cancer in its very early stages of development can be effectively treated. The classification of cancer can be accelerated and automated with the aid of computer-aided diagnosis and medical image analysis techniques. This research provides the use of transfer learning from a Residual Network 18 (ResNet18) and Residual Network 34 (ResNet34) architectures to detect breast cancer. The study examined how breast cancer can be identified in breast mammography pictures using transfer learning from ResNet18 and ResNet34- and developed a demo app for radiologists using the trained models with the best validation accuracy. 1- 200 datasets of breast x-ray mammography images from the National Radiological Society's (NRS) archives were employed in the study. The dataset was categorised as implant cancer negative- implant cancer positive- cancer negative and cancer positive in order to increase the consistency of x-ray mammography images classification and produce better features. For the multi-class classification of the images- the study gave an average accuracy for binary classification of benign or malignant cancer cases of 86.7% validation accuracy for ResNet34 and 92% validation accuracy for ResNet18. A prototype web application showcasing ResNet18 performance has been created. The acquired results show how transfer learning can improve the accuracy of breast cancer detection- providing invaluable assistance to medical professionals- particularly in an African scenario.
Yuan Yao- Yang Zhao- Xu Guo- Xiangli Xu- Baiyang Fu- Hao Cui- Jian Xue- Jiawei Tian- Ke Lu- Lei Zhang,Deep Learning for Distinguishing Mucinous Breast Carcinoma From Fibroadenoma on Ultrasound,"Abstract: Breast cancer poses a significant global health threat to women, underscoring the crucial need for reliable and effective screening approaches. The utilization of computer-aided diagnostic (CAD) systems, leveraging mammograms, enables early detection, diagnosis, and treatment of breast cancer, thereby offering vital support in combating this disease. This study introduces a unique deep-learning model that uses transfer learning to identify and categorize breast cancer automatically. Several recent studies have shown that deep convolutional neural networks (DCNNs) can be used to diagnose breast cancer in mammograms with performances comparable to or even superior to those of human experts. The proposed model extracts features from the Mammographic Image Analysis Society (MIAS) dataset using pre-trained convolutional neural network (CNN) architectures such as ResNet50 and VGG-16. This revolutionary deep-learning model has the potential to improve the efficiency and accuracy of breast cancer detection and categorization."
Muniraj Gupta- Nidhi Verma- Naveen Sharma- Satyendra  Narayan Singh- R. K. Brojen Singh- Saurabh Kumar Sharma,Hybrid Deep Transfer Learning Technique for the Classification of Breast Cancer Tumor Histopathology Images,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ over large volumes of histopathological images. Consequently- this increasing trend in artificial intelligence â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ paper focuses on deep learning for breast cancer histopathological image â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Ziming Liu,Improving breast cancer classification using histopathology images through deep learning,The most fatal disease affecting women worldwide now is breast cancer. Early detection of breast cancer enhances the likelihood of a full recovery and lowers mortality. Based on medical imaging- researchers from all around the world are developing breast cancer screening technologies. Due to their rapid progress- deep learning algorithms have caught the interest of many in the field of medical imaging. This research proposes a novel method in mammogram image feature extraction with classification and optimization using machine learning in breast cancer detection. The input image has been processed for noise removal- smoothening- and normalization. The input image features were extracted using probabilistic principal component analysis for detecting the presence of tumors in mammogram images. The extracted tumor region is classified using the Naâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšâ‰¤ve Bayes classifier and transfer integrated convolution neural networks. The classified output has been optimized using firefly binary grey optimization and metaheuristic moth flame lion optimization. The experimental analysis has been carried out in terms of different parameters based on datasets. The proposed framework used an ensemble model for breast cancer that made use of the proposed Bayesâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢FBGO and TCNNâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢MMFLO classifier and optimizer for diverse mammography image datasets. The INbreast dataset was evaluated using the proposed Bayesâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢FBGO and TCNNâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢MMFLO classifiers- which achieved 95% and 98% accuracy- respectively.
Tooba Mujtaba- Saif Ullah Hashmi- Usama Bin Imtiaz- Sheikh Jameel Fathima Nusra,Devising a Breast Cancer Diagnosis Protocol through Machine Learning,Background: Breast cancer (BC) metastasis is the common cause of high mortality. Conventional prognostic criteria cannot accurately predict the BC metastasis risk. The machine learning technologies can overcome the disadvantage of conventional models. Aim: We developed a model to predict BC metastasis using the random survival forest (RSF) method. Methods: Based on demographic data and routine clinical data- we used RSFâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢recursive feature elimination to identify the predictive variables and developed a model to predict metastasis using RSF method. The area under the receiver operating characteristic curve (AUROC) and Kaplanâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®Meier survival (KM) analyses were plotted to validate the predictive effect when Câ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢index was plotted to assess the discrimination and Brier scores was plotted to assess the calibration of the predictive model. Results: We developed a metastasis prediction model comprising three variables (pathological stage- aspartate aminotransferase- and neutrophil count) selected by RSFâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢recursive feature elimination. The model was reliable and stable when assessed by the AUROC (0.932 in training set and 0.905 in validation set) and KM survival analyses ( Conclusions: This model relies on routine data and examination indicators in realâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢time clinical practice and exhibits an accurate prediction performance without increasing the cost for patients. Using this model- clinicians can facilitate risk communication and provide precise and efficient individualized therapy to patients with breast cancer.
M Guyomard- AD Bouhnik- L Tassy- ...,Encoding breast cancer patients' medical pathways from reimbursement data using representation learning: a benchmark for clustering tasks,Neoadjuvant chemotherapy (NAC) is a key element of treatment for locally advanced breast cancer (LABC). Predicting the response to NAC for patients with Locally Advanced Breast Cancer (LABC) before treatment initiation could be beneficial to optimize therapy- ensuring the administration of effective treatments. The objective of the work here was to develop a predictive model to predict tumor response to NAC for LABC using deep learning networks and computed tomography (CT). Several deep learning approaches were investigated including ViT transformer and VGG16- VGG19- ResNet-50- Res-Net-101- Res-Net-152- InceptionV3 and Xception transfer learning networks. These deep learning networks were applied on CT images to assess the response to NAC. Performance was evaluated based on balanced_accuracy- accuracy- sensitivity and specificity classification metrics. A ViT transformer was applied to utilize the attention mechanism in order to increase the weight of important part image which leads to better discrimination between classes. Amongst the 117 LABC patients studied- 82 (70%) had clinical-pathological response and 35 (30%) had no response to NAC. The ViT transformer obtained the best performance range (accuracy = 71 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to accuracy = 77 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- specificity = 86 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 76 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 56 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- and balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%) depending on the split ratio of train-data and test-data. Xception network obtained the second best results (accuracy = 72 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to accuracy = 65 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4- specificity = 81 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 73 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 55 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5%- and balanced_accuracy = 66 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5% to balanced_accuracy = 60 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%). The worst results were obtained using VGG-16 transfer learning network. Deep learning networks in conjunction with CT imaging are able to predict the tumor response to NAC for patients with LABC prior to start. A ViT transformer could obtain the best performance- which demonstrated the importance of attention mechanism.
Sanitha P S -- Jayakrishnan B -,Breast Cancer Diagnosis and Prognosis Using Triple Hybrid Deep Learning Approach,Assistive medical image classifiers can greatly reduce the workload of medical personnel. However- traditional machine learning methods require large amounts of well-labeled data and long learning times to solve medical image classification problems- which can lead to high training costs and poor applicability. To address this problem- a novel unsupervised breast cancer image classification model based on multiscale texture analysis and a dynamic learning strategy for mammograms is proposed in this paper. First- a gray-level cooccurrence matrix and Tamura coarseness are used to transfer images to multiscale texture feature vectors. Then- an unsupervised dynamic learning mechanism is used to classify these vectors. In the simulation experiments with a resolution of 40 pixels- the accuracy- precision- F1-score and AUC of the proposed method reach 91.500%- 92.780%- 91.370%- and 91.500%- respectively. The experimental results show that the proposed method can provide an effective reference for breast cancer diagnosis.
Lu Gan,Research on Prediction Model of Benign and Malignant Breast Cancer Based on Machine Learning,Breast cancer continues to be a major global health issue- emphasizing the importance of precise and prompt detection to enhance the well-being of patients. In this study- a novel approach is proposed for breast cancer detection using transfer learning with the InceptionV3 model. Our research focuses on analyzing histopathology images to classify breast tissue samples as benign or malignant. Additionally- the effectiveness of alternative models- including ResNet- DenseNet- NasNet- and NasNet Mobile- for the same classification task is explored. To train the models- a comprehensive dataset comprising a diverse range of histopathology images is utilizsed. Transfer learning enabled us to leverage the rich representations learned by InceptionV3- ResNet- DenseNet- NasNet- and NasNet Mobile on large-scale image datasets- which greatly expedited the training process and enhanced overall classification performance. Through extensive evaluations- the superior performance of the InceptionV3 model in accurately distinguishing between benign and malignant breast tissue samples is highlighted. The outcomes of this research present a significant step forward in breast cancer detection- showcasing the potential of transfer learning and the utility of InceptionV3 as a robust classifier for histopathology images. The findings also shed light on the comparative performance of alternative deep learning models- providing valuable insights for future research and clinical applications. Ultimately- this study contributes to the ongoing efforts in improving early detection and diagnosis of breast cancer- paving the way for enhanced patient care and outcomes.
SM Thwin- SJ Malebary- AW Abulfaraj- HS Park,Attention-Based Ensemble Network for Effective Breast Cancer Classification over Benchmarks,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ and classification of breast cancer using transfer learning. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ [19] used the DL-CNN for breast cancer classification from â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ -negative breast cancer based on images of primary breast cancer. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Erin J. Kim- Enoch Chung- Bernard T. Lee- Dhruv Singhal,D134. Application of Machine Learning to Predict Breast Cancer Related-lymphedema Development,Introduction: When considering cancer mortality rates in general- Breast Cancer (BC) is a major contributor among females. Patientsâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ chances of survival increase when BC is detected early and treated with the appropriate treatment at the right time. There is strong evidence that mammography- when used as a screening tool- can detect BC at an early stage. Mammography is a diagnostic tool that uses low-dose X-rays to visualise the breast and evaluate its anatomy. For screening purposes- it is currently the preferred method. The present study employs deep learning models trained using Transfer Learning (TL) techniques. Aim: To automate the process of BC diagnosis in mammograms. The main goal of this approach is to simplify the process of early detection and diagnosis of BC for healthcare practitioners. Materials and Methods: The dataset obtained from the Mammographic Image Analysis Society (MIAS) was categorised into three distinct categories: benign- malignant and normal. The initial MIAS dataset underwent several preprocessing techniques- including noise reduction- breast image contrast enhancement- non breast region deletion and malignant lesion identification- before analysis. An intricately designed fully connected classifier complements pretrained Convolutional Neural Network (CNN) architectures like ResNet50 and VGG16 in the proposed model. Results: The VGG16 model performed admirably- achieving an Area Under the Curve (AUC) of 0.950 and an accuracy rate of 96.00%. In addition- it displayed an outstanding F-score of 97%- along with high sensitivity- specificity and accuracy. These outcomes are significantly better compared to the other methods. Conclusion: The modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s enhanced capabilities for early-stage cancer detection could improve patient outcomes and reduce mortality rates. Furthermore- new tools can ease the workload for radiologists- leading to more standardised and efficient diagnostic procedures.
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
Emmanuel Ahishakiye- Fredrick Kanobe,Breast Cancer Classification Using Breast Ultrasound Images with a Hybrid of Transfer Learning and Bayesian-Optimized Fast Learning Network,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ summary based on transformer language model approaches. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ self-attention mechanism within the transformer architecture â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ the shortcomings of traditional deep learning models- such as â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Muniraj Gupta- Nidhi Verma- Naveen Sharma- Satyendra Narayan Singh- R. K. Brojen Singh- Saurabh Kumar Sharma,Deep Transfer Learning Hybrid Techniques for Precision in Breast Cancer Tumor Histopathology Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ development of artificial intelligence- CAD systems utilizing deep learning technology have â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Compared to CNNs- the self-attention mechanism in Transformers exhibits robust global â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Juan Gutierrez-Cardenas,"Breast Cancer Classification through Transfer Learning with Vision Transformer, PCA, and Machine Learning Models",The objective of our study was to explore the feasibility of integrating artificial intelligence (AI) algorithms for breast cancer detection into a portable- point-of-care ultrasound device (POCUS). This proof-of-concept implementation is to demonstrate the platform for integrating AI algorithms into a POCUS device to achieve a performance benchmark of at least 15 frames/second. Our methodology involved the application of five AI models (FasterRCNN+MobileNetV3- FasterRCNN+ResNet50- RetinaNet+ResNet50- SSD300+VGG16- and SSDLite320+MobileNetV3)- pretrained on public datasets of natural images- fine-tuned using a dataset of gelatin-based breast phantom images with both anechoic and hyperechoic lesions- mimicking real tissue characteristics. We created various gelatin-based ultrasound phantoms containing ten simulated lesions- ranging from 4-20 mm in size. Our experimental setup used the Clarius L15 scanning probe- which was connected via Wi-Fi to both a tablet and a laptop- forming the core of our development platform. The phantom data was divided into training- validation- and held-out testing sets on a per-video basis. We executed 200 timing trials for each finetuned AI model- streaming scanning video from the ultrasound probe in real-time. SSDLite320+MobileNetV3 emerged as a standout- showing a mean frame-to-frame timing of 0.068 seconds (SD=0.005)- which is approximately 14.71 FPS- closely followed by FasterRCNN+MobileNetV3- with a mean timing of 0.123 seconds (SD=0.016)- or about 8.13 FPS. Both models show acceptable performance in lesion localization. Compared to our goal of 15 frames/second- only the SSDLite320+MobileNetV3 architecture performed with sufficient evaluation speed to be used in real-time. Our findings show the necessity of using AI architectures designed for edge devices for real-time use- as well as the potential need for hardware acceleration to encode AI models for use in POCUS.
T Xie- A L Huang- L Y Xiang- H C Xue- Z Z Chen- A L Ma- H L Yan- J P Yuan,[Value of the deep learning automated quantification of tumor-stroma ratio in predicting efficacy and prognosis of neoadjuvant therapy for breast cancer based on residual cancer burden grading],Breast cancer is one of the major causes of deaths in women. However- the early diagnosis is important for screening and control the mortality rate. Thus for the diagnosis of breast cancer at the early stage- a computerâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢aided diagnosis system is highly required. Ultrasound is an important examination technique for breast cancer diagnosis due to its low cost. Recently- many learningâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢based techniques have been introduced to classify breast cancer using breast ultrasound imaging dataset (BUSI) datasets; however- the manual handling is not an easy process and time consuming. The authors propose an EfficientNetâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢integrated ResNet deep network and XAIâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢based framework for accurately classifying breast cancer (malignant and benign). In the initial step- data augmentation is performed to increase the number of training samples. For this purpose- threeâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢pixel flip mathematical equations are introduced: horizontal- vertical- and 90Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšâ€ âˆšÂª. Later- two preâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢trained deep learning models were employed- skipped some layers- and fineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢tuned. Both fineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢tuned models are later trained using a deep transfer learning process and extracted features from the deeper layer. Explainable artificial intelligenceâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢based analysed the performance of trained models. After that- a new feature selection technique is proposed based on the cuckoo search algorithm called cuckoo search controlled standard error mean. This technique selects the best features and fuses using a new parallel zeroâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢padding maximum correlated coefficient features. In the end- the selection algorithm is applied again to the fused feature vector and classified using machine learning algorithms. The experimental process of the proposed framework is conducted on a publicly available BUSI and obtained 98.4% and 98% accuracy in two different experiments. Comparing the proposed framework is also conducted with recent techniques and shows improved accuracy. In addition- the proposed framework was executed less than the original deep learning models.
Lin Yan- Zhiying Liang- Hao Zhang- Gaosong Zhang- Weiwei Zheng- Chunguang Han- Dongsheng Yu- Hanqi Zhang- Xinxin Xie- Chang Liu- Wenxin Zhang- Hui Zheng- Jing Pei- Dinggang Shen- Xuejun Qian,A domain knowledge-based interpretable deep learning system for improving clinical breast ultrasound diagnosis,Abstract: Breast cancer (BC) is one of leading cause of cancer death among women. Early detection of this pathology allows to define- for patients- the appropriate treatment which improve the possibility of survival. Consequently- the earlier it is detected- the better the survival rate will be. In last years- big interest has been made on applying deep learning neural networks to BC analysis- detection and classification. Several interesting results have been found but they still needing more improvement and validation. In this frame is located our work which consists on developing and comparing different deep leaning approaches for earlier detection and classification of BC from mammogram images. Different new deep learning techniques are developed resulting on a considerable improvement in the rate of the classification accuracy with more robust models. Simulations are carried out on two data bases illustrating that the new proposed approaches provide significant evaluation metrics in comparison with several commonly known transfer learning architectures.
Lizhe Wang- Yu Wang- Yueyang Li- Li Zhou- Sihan Liu- Yongyi Cao- Yuzhi Li- Shenting Liu- Jiahui Du- Jin Wang- Ting Zhu,A prospective diagnostic model for breast cancer utilizing machine learning to examine the molecular immune infiltrate in HSPB6,Breast cancer (BC) is the most dominant kind of cancer- which grows continuously and serves as the second highest cause of death for women worldwide. Early BC prediction helps decrease the BC mortality rate and improve treatment plans. Ultrasound is a popular and widely used imaging technique to detect BC at an earlier stage. Segmenting and classifying the tumors from ultrasound images is difficult. This paper proposes an optimal deep learning (DL)-based BC detection system with effective pre-trained transfer learning models-based segmentation and feature learning mechanisms. The proposed system comprises five phases: preprocessing- segmentation- feature learning- selection- and classification. Initially- the ultrasound images are collected from the breast ultrasound images (BUSI) dataset- and the preprocessing operations- such as noise removal using the Wiener filter and contrast enhancement using histogram equalization- are performed on the collected data to improve the dataset quality. Then- the segmentation of cancer-affected regions from the preprocessed data is done using a dilated convolution-based U-shaped network (DCUNet). The features are extracted or learned from the segmented images using spatial and channel attention including densely connected convolutional network-121 (SCADN-121). Afterwards- the system applies an enhanced cuckoo search optimization (ECSO) algorithm to select the features from the extracted feature set optimally. Finally- the ECSO-tuned long short-term memory (ECSO-LSTM) was utilized to classify BC into '3' classes- such as normal- benign- and malignant. The experimental outcomes proved that the proposed system attains 99.86% accuracy for BC classification- which is superior to the existing state-of-the-art methods.
Arpana Parihar- Kritika Gaur- Paromita Sarbadhikary,Advanced 2D Nanomaterials for Phototheranostics of Breast Cancer: A Paradigm Shift,Breast cancer is a worldwide fatal disease that exists mostly among women. The deep learning technique has proven its effectiveness- but the performance of the existing deep learning systems is quite compromising. In this work- a deep transfer learning system is suggested for efficient breast cancer classification from histopathology images. This system is based on a novel multiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢level progressive feature aggregation (MPFA) and a spatial domain learning approach. The combination of a pretrained Resnet101 backbone network with MPFA is implemented to extract more significant features. In addition- a mixedâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢dilated spatial domain learning network (MSLN) is further incorporated to enhance the receptive field and increase discrimination between features. The proposed method achieved superior performance as compared to the existing stateâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ofâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢theâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢art methods- offering 99.24% accuracy- a 98.79% Fâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢1 score- 98.59% precision- and 98.99% recall values over BreaKHis dataset. An ablation study is carried out over the ICIAR2018 dataset to verify the generalizability and effectiveness of the system.
Wei Wang- Lei Liu- Jianxiong Zhu- Youqiang Xing- Songlong Jiao- Ze Wu,AI-Enhanced Visual-Spectral Synergy for Fast and Ultrasensitive Biodetection of Breast Cancer-Related miRNAs.,Breast cancer is a dangerous disease- contributing to a high mortality rate in women. Early detection plays a pivotal role in enhancing survival rates. Breast ultrasound is considered an effective method to help diagnose breast diseases early. Breast ultrasound is inexpensive- easy to perform- non-invasive and painless- so it is often prescribed by doctors in cases where it is necessary to examine the nature of clinically palpable lesions or related symptoms in the breast. In this paper- we introduce a method based on transfer learning and deep feature fusion to classify breast cancer using ultrasound images. The results from our experiments involving 780 breast ultrasound images across three categories (benign- malignant- and normal) indicated that the model using max fusion of deep features outperformed an original CNN in terms of performance- the combination of the maximum value between deep features has a higher performance level with an accuracy of about 1% to 4% compared to the original model. The concatenation fusion of VGG19 and ViT features delivers 1% - 4% times more accuracy than the original model alone
Aslâ€šÃ Ãœâˆšâ‰ Â¬Â¨Â¬Â±nur Albayrak- Kayhan Nuri Cengiz,Assessment of breast cancer awareness among female pharmacy students at a university in Turkey,Breast cancer remains a pressing global health concern- necessitating accurate diagnostics for effective interventions. Deep learning models (AlexNet- ResNet-50- VGG16- GoogLeNet) show remarkable microcalcification identification (>90%). However- distinct architectures and methodologies pose challenges. We propose an ensemble model- merging unique perspectives- enhancing precision- and understanding critical factors for breast cancer intervention. Evaluation favors GoogleNet and ResNet-50- driving their selection for combined functionalities- ensuring improved precision- and dependability in microcalcification detection in clinical settings. This study presents a comprehensive mammogram preprocessing framework using an optimized deep learning ensemble approach. The proposed framework begins with artifact removal using Otsu Segmentation and morphological operation. Subsequent steps include image resizing- adaptive median filtering- and deep convolutional neural network (D-CNN) development via transfer learning with ResNet-50 model. Hyperparameters are optimized- and ensemble optimization (AlexNet- GoogLeNet- VGG16- ResNet-50) are constructed to identify the localized area of microcalcification. Rigorous evaluation protocol validates the efficacy of individual models- culminating in the ensemble model demonstrating superior predictive accuracy. Based on our analysis- the proposed ensemble model exhibited exceptional performance in the classification of microcalcifications. This was evidenced by the model's average confidence score- which indicated a high degree of dependability and certainty in differentiating these critical characteristics. The proposed model demonstrated a noteworthy average confidence level of 0.9305 in the classification of microcalcification- outperforming alternative models and providing substantial insights into the dependability of the model. The average confidence of the ensemble model in classifying normal cases was 0.8859- which strengthened the model's consistent and dependable predictions. In addition- the ensemble models attained remarkably high performances in terms of accuracy- precision- recall- F1-score- and area under the curve (AUC). The proposed model's thorough dataset integration and focus on average confidence ratings within classes improve clinical diagnosis accuracy and effectiveness for breast cancer. This study introduces a novel methodology that takes advantage of an ensemble model and rigorous evaluation standards to substantially improve the accuracy and dependability of breast cancer diagnostics- specifically in the detection of microcalcifications.
Yiqi Sun- Bohan Wan- Xin Liu- Jianguo Dong- Shengjie Yin- Yiqi Wu,Breast cancer and neoplasms of the thyroid gland: a bidirectional two-sample Mendelian randomization study,Small cohorts of certain disease states are common especially in medical imaging. Despite the growing culture of data sharing- information safety often precludes open sharing of these datasets for creating generalizable machine learning models. To overcome this barrier and maintain proper health information protection- foundational models are rapidly evolving to provide deep learning solutions that have been pretrained on the native feature spaces of the data. Although this has been optimized in Large Language Models (LLMs)- there is still a sparsity of foundational models for computer vision tasks. It is in this space that we provide an investigation into pretraining Visual Geometry Group (VGG)-16- Residual Network (ResNet)-50- and Dense Network (DenseNet)-121 on an unrelated dataset of 8500 chest CTs which was subsequently fine-tuned to classify bone mineral density (BMD) in 199 breast cancer patients using the L1 vertebra on CT. These semi-foundational models showed significant improved ternary classification into mild- moderate- and severe demineralization in comparison to ground truth Hounsfield Unit (HU) measurements in trabecular bone with the semi-foundational ResNet50 architecture demonstrating the best relative performance. Specifically- the holdout testing AUC was 0.99 (p-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.05- ANOVA versus no pretraining versus ImageNet transfer learning) and F1-score 0.99 (p-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.05) for the holdout testing set. In this study- the use of a semi-foundational model trained on the native feature space of CT provided improved classification in a completely disparate disease state with different window levels. Future implementation with these models may provide better generalization despite smaller numbers of a disease state to be classified.
S R Sannasi Chakravarthy- N Bharanidharan- V Vinoth Kumar- T R Mahesh- Mohammed S Alqahtani- Suresh Guluwadi,Deep transfer learning with fuzzy ensemble approach for the early detection of breast cancer,The efficacy of immune checkpoint inhibitors is significantly influenced by the tumor immune microenvironment (TIME). RNA sequencing of tumor tissue can offer valuable insights into TIME- but its high cost and long turnaround time seriously restrict its utility in routine clinical examinations. Several recent studies have suggested that ultrahigh-resolution pathology images can infer cellular and molecular characteristics. However- few study pay attention to the quantitative estimation of various tumor infiltration immune cells from pathology images. In this paper- we integrated contrastive learning and weakly supervised learning to infer tumor-associated macrophages and potential immunotherapy benefit from whole slide images (WSIs) of H &E stained pathological sections. We split the high-resolution WSIs into tiles and then apply contrastive learning to extract features of each tile. After aggregating the features at the tile level- we employ weak supervisory signals to fine-tune the encoder for various downstream tasks. Comprehensive experiments on two independent breast cancer cohorts and spatial transcriptomics data demonstrate that the computational pathological features accurately predict the proportion of tumor-infiltrating immune cells- particularly the infiltration level of macrophages- as well as the immune subtypes and potential immunotherapy benefit. These findings demonstrate that our model effectively captures pathological features beyond human vision- establishing a mapping relationship between cellular compositions and histological morphology- thus expanding the clinical applications of digital pathology images.
Hea Lim Choi- Su Min Jeong- Keun Hye Jeon- Bongseong Kim- Wonyoung Jung- Ansuk Jeong- Kyungdo Han- Dong Wook Shin,Depression risk among breast cancer survivors: a nationwide cohort study in South Korea,Photoacoustic tomography (PAT) has emerged as a promising imaging modality for breast cancer detection- offering unique advantages in visualizing tissue composition without ionizing radiation. However- limited-view scenarios in clinical settings present significant challenges for image reconstruction quality and computational efficiency. This paper introduces novel unrolled deep learning networks based on split Bregman total variation (SBTV) and relaxed basis pursuit alternating direction method of multipliers (rBP-ADMM) algorithms to address these challenges. Our approach combines transfer learning from full-view to limited-view scenarios with U-Net denoiser integration- achieving state-of-the-art reconstruction quality (MS-SSIM> 0.95) while reducing reconstruction time by 92% compared to traditional methods. The effectiveness of different sensor configurations is analyzed through restricted isometry property (RIP) analysis and coherence values- demonstrating that semicircular arrays achieve a RIP constant of 0.76 and coherence of 0.77- closely approximating full-view performance (RIP: 0.75- coherence: 0.78). These metrics validate the theoretical foundation for accurate sparse signal recovery in limited-view scenarios. Comprehensive evaluations across semicircular- concave- and convex sensor arrangements show that the proposed U-SBTV network consistently outperforms existing methods- particularly when combined with the U-Net denoiser. This advancement in limited-view PAT reconstruction brings the technology closer to practical clinical application- potentially improving early breast cancer detection capabilities.
Usman Haider- Muhammad Hanif- Ahmer Rashid- Khursheed Aurangzeb- A. Khalil- Musaed A. Alhussein,Discriminative Dictionary Learning Using Penalized Rank-1 Approximation for Breast Cancer Classification With Imbalanced Dataset,Analysis of histopathological images (HIs) is crucial for detecting breast cancer (BR). However- because they vary- it is still very difficult to extract well-designed elements. Deep learning (DL) is a recent development that is used to extract high-level features. However- DL techniques continue to confront several difficult problems- such as the need for sufficient training data for DL models- which reduces the classification findings. In this study- an ensemble deep transfer convolutional neural network is presented to address this problem. The pre-trained models (ResNet50 and MobileNet) are employed to extract high-level features by freezing the front layer parameters while fine-tuning the last layers. In the proposed ensemble framework- KNN- SVM- logistic regression and neural networks are used as base classifiers. The majority vote and product approaches are used to integrate the predictions of each separate classifier. In the benchmark BreaKHis dataset- the suggested ensemble model is compared to some current approaches. It demonstrates that while the ensemble model obtains a considerable accuracy of 97.72% for the multiclass classification test- it achieves an accuracy of 99.2% for the binary task. The suggested ensemble modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s effectiveness in extracting useful features for BR images is demonstrated by comparison with existing cutting-edge models.
Shahad Awadelkarim,Feature Selection using Extra Trees for Breast Cancer Prediction,Breast cancer continues to pose a significant global health challenge- emphasizing the need for advancements in early detection methods. This study explores the application of transfer learning techniques- specifically utilizing EfficientNet- to enhance the accuracy of breast cancer detection through medical imaging. Leveraging a dataset of mammography images from the Digital Database for Screening Mammography (DDSM)- the research implements various data preprocessing methods- including median filtering- contrast enhancement- and artifact removal- to ensure the quality of input data. The EfficientNet model- trained with these preprocessed images- is evaluated against other transfer learning architectures- such as DenseNet and ResNeXt50- using metrics like accuracy- AUC- precision- and F1-score. The results demonstrate that EfficientNet outperforms other models- achieving an accuracy of 95.23%- with a sensitivity of 96.67% and specificity of 93.82%. These findings suggest that transfer learning- particularly with EfficientNet- can significantly improve the predictive accuracy of breast cancer detection- offering a reliable tool for early diagnosis and personalized treatment planning. The study also discusses the potential integration of these models into clinical workflows- addressing challenges such as data privacy- model generalizability- and clinical applicability. Future research will focus on expanding the dataset and exploring the use of other advanced deep learning techniques to further enhance detection accuracy and robustness.
Ko Un Park- Stuart R. Lipsitz- L. Dominici- F. Lynce- Christina A. Minami- F. Nakhlis- Adrienne G. Waks- Laura E. Warren- Nadine Eidman- Jeannie Frazier- Lourdes Hernandez- Carla Leslie- Susan Rafte- Delia Stroud- J. Weissman- T. King- E. Mittendorf,Generative artificial intelligence as a source of breast cancer information for patients: Proceed with caution.,<title>Abstract</title> <p>Breast cancer is one of the most prevalent causes of cancer-related death globally. Preliminary diagnosis of breast cancer increases the patient's chances of survival and healing. In this paper- we propose a hybrid deep transfer learning model integrating xception with support vector classifier (XSV) and xception with random forest (XRF) along with pre-processing technique to classify breast cancer as cancerous (malignant) or non-cancerous (benign) along comparative analysis of prominent machine learning classifiers- such as Random Forest Classifier (RFC)- Logistic Regression (LR)- Support Vector Classifier (SVC)- K-Nearest Neighbors (K-NN)- and Ada-boost. In experiment all the models are implemented on two openly accessible datasets: BreakHis and Breast Histopathology Images Database (BHID) across various metrics such as accuracy- area under the receiver operating curve- precision- recall- f1-score- Matthew's correlation coefficient- classification success index- and kappa at different magnification levels of images. Our proposed model that utilized the fine tuning of xception model in conjunction with RFC and SVC- surpass existing breast cancer classification methodologies. Specifically- the XSV that achieved accuracies of 89.26%- 85.87%- 90.17%- and 88.98%- while the XRF attained accuracies of 87.78%- 84.78%- 88.98%- and 87.61% for BreakHis at 40X- 100X- 200X- and 400X magnifications- respectively. For BHID at 40X magnification- the XSV and XRF models achieved accuracies of 87.35% and 87.29%- respectively. Employing this study will aid our medical practitioners and researchers in choosing an accurate model for tumor classification and our results will help medical professionals to classify the disease with precision.</p>
Yushu Ma- Chien-Hung Shih- Jinxiong Cheng- Hsiao-Chun Chen- Li-Ju Wang- Yanhao Tan- Yu-Chiao Chiu- Yu-Chih Chen,High-Throughput Empirical and Virtual Screening to Discover Novel Inhibitors of Polyploid Giant Cancer Cells in Breast Cancer,Breast cancer (BC) is a type of cancer which progresses and spreads from breast tissues and gradually exceeds the entire body; this kind of cancer originates in both sexes. Prompt recognition of this disorder is most significant in this phase- and it is measured by providing patients with the essential treatment so their efficient lifetime can be protected. Scientists and researchers in numerous studies have initiated techniques to identify tumours in early phases. Still- misperception in classifying skeptical lesions can be due to poor image excellence and dissimilar breast density. BC is a primary health concern- requiring constant initial detection and improvement in analysis. BC analysis has made major progress recently with combining multi-modal image modalities.Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ These studies deliver an overview of the segmentation- classification- or grading of numerous cancer types- including BC- by employing conventional machine learning (ML) models over hand-engineered features. Therefore- this study uses multi-modality medical imaging to propose a Computer Vision with Fusion Joint Transfer Learning for Breast Cancer Diagnosis (CVFBJTL-BCD) technique. The presented CVFBJTL-BCD technique utilizes feature fusion and DL models to effectively detect and identify BC diagnoses. The CVFBJTL-BCD technique primarily employs the Gabor filtering (GF) technique for noise removal. Next- the CVFBJTL-BCD technique uses a fusion-based joint transfer learning (TL) process comprising three models- namely DenseNet201- InceptionV3- and MobileNetV2. The stacked autoencoders (SAE) model is implemented to classify BC diagnosis. Finally- the horse herd optimization algorithm (HHOA) model is utilized to select parameters involved in the SAE method optimally. To demonstrate the improved results of the CVFBJTL-BCD methodology- a comprehensive series of experimentations are performed on two benchmark datasets. The comparative analysis of the CVFBJTL-BCD technique portrayed a superior accuracy value of 98.18% and 99.15% over existing methods under Histopathological and Ultrasound datasets.
Massimiliano Berretta- Daniele Garozzo- Calogero Foti- Mario Roselli- Marco Materazzo- Giulia Vita- Ferdinando Iellamo- Marco Scordari- Giordana Di Mauro- Giovanna Spatari- Alessandro Ottaiano- Annalisa Noce- Marco Pellicciaro- Alessia Bignucolo- Gianluca Vanni- Oreste Claudio Buonomo,Implementing fencing as adapted physical activity in non-metastatic breast cancer patients: design and early rehabilitation strategy of the FENICE study protocol,Background: Breast cancer is one of the most lethal cancers among women. Early detection and proper treatment reduce mortality rates. Histopathological images provide detailed information for diagnosing and staging breast cancer disease. Methods: The BreakHis dataset- which includes histopathological images- is used in this study. Medical images are prone to problems such as different textural backgrounds and overlapping cell structures- unbalanced class distribution- and insufficiently labeled data. In addition to these- the limitations of deep learning models in overfitting and insufficient feature extraction make it extremely difficult to obtain a high-performance model in this dataset. In this study- 20 state-of-the-art models are trained to diagnose eight types of breast cancer using the fine-tuning method. In addition- a comprehensive experimental study was conducted to determine the most successful new model- with 20 different custom models reported. As a result- we propose a novel model called MultiHisNet. Results: The most effective new model- which included a pointwise convolution layer- residual link- channel- and spatial attention module- achieved 94.69% accuracy in multi-class breast cancer classification. An ensemble model was created with the best-performing transfer learning and custom models obtained in the study- and model weights were determined with an Equilibrium Optimizer. The proposed ensemble model achieved 96.71% accuracy in eight-class breast cancer detection. Conclusions: The results show that the proposed model will support pathologists in successfully diagnosing breast cancer.
Christiana Subaar- Fosberg Tweneboah Addai- Eric Clement Kotei Addison- Olivia Christos- Joseph Adom- Martin Owusu-Mensah- Nelson Appiah-Agyei- Shadrack Abbey,Investigating the detection of breast cancer with deep transfer learning using ResNet18 and ResNet34,A novel nomogram incorporating artificial intelligence (AI) and clinical features for enhanced ultrasound prediction of benign and malignant breast masses. This study analyzed 340 breast masses identified through ultrasound in 308 patients. The masses were divided into training (n = 260) and validation (n = 80) groups. The AI-based analysis employed the Samsung Ultrasound AI system (S-detect). Univariate and multivariate analyses were conducted to construct nomograms using logistic regression. The AI-Nomogram was based solely on AI results- while the ClinAI- Nomogram incorporated additional clinical factors. Both nomograms underwent internal validation with 1000 bootstrap resamples and external validation using the independent validation group. Performance was evaluated by analyzing the area under the receiver operating characteristic (ROC) curve (AUC) and calibration curves. The ClinAI-Nomogram- which incorporates patient age- AI-based mass size- and AI-based diagnosis- outperformed an existing AI-Nomogram in differentiating benign from malignant breast masses. The ClinAI-Nomogram surpassed the AI-Nomogram in predicting malignancy with significantly higher AUC scores in both training (0.873- 95% CI: 0.830-0.917 vs. 0.792- 95% CI: 0.748-0.836; p = 0.016) and validation phases (0.847- 95% CI: 0.763-0.932 vs. 0.770- 95% CI: 0.709-0.833; p < 0.001). Calibration curves further revealed excellent agreement between the ClinAI-Nomogram's predicted probabilities and actual observed risks of malignancy. The ClinAI- Nomogram- combining AI alongside clinical data- significantly enhanced the differentiation of benign and malignant breast masses in clinical AI-facilitated ultrasound examinations.
Sang Won Park- Ye-Lin Park- Eun-Gyeong Lee- Heejung Chae- Phillip Park- Dong-Woo Choi- Yeon Ho Choi- Juyeon Hwang- Seohyun Ahn- Keunkyun Kim- Woo Jin Kim- Sun-Young Kong- So-Youn Jung- Hyun-Jin Kim,Mortality Prediction Modeling for Patients with Breast Cancer Based on Explainable Machine Learning,Background/Objectives: Breast cancer is a leading cause of mortality among women in Taiwan and globally. Non-invasive imaging methods- such as mammography and ultrasound- are critical for early detection- yet standalone modalities have limitations in regard to their diagnostic accuracy. This study aims to enhance breast cancer detection through a cross-modality fusion approach combining mammography and ultrasound imaging- using advanced convolutional neural network (CNN) architectures. Materials and Methods: Breast images were sourced from public datasets- including the RSNA- the PAS- and Kaggle- and categorized into malignant and benign groups. Data augmentation techniques were used to address imbalances in the ultrasound dataset. Three models were developed: (1) pre-trained CNNs integrated with machine learning classifiers- (2) transfer learning-based CNNs- and (3) a custom-designed 17-layer CNN for direct classification. The performance of the models was evaluated using metrics such as accuracy and the Kappa score. Results: The custom 17-layer CNN outperformed the other models- achieving an accuracy of 0.964 and a Kappa score of 0.927. The transfer learning model achieved moderate performance (accuracy 0.846- Kappa 0.694)- while the pre-trained CNNs with machine learning classifiers yielded the lowest results (accuracy 0.780- Kappa 0.559). Cross-modality fusion proved effective in leveraging the complementary strengths of mammography and ultrasound imaging. Conclusions: This study demonstrates the potential of cross-modality imaging and tailored CNN architectures to significantly improve diagnostic accuracy and reliability in breast cancer detection. The custom-designed model offers a practical solution for early detection- potentially reducing false positives and false negatives- and improving patient outcomes through timely and accurate diagnosis.
Yini Li- Cao Li- Tao Yang- Lingzhi Chen- Mingquan Huang- Lu Yang- Shuxian Zhou- Huaqing Liu- Jizhu Xia- Shijie Wang,Multiview deep learning networks based on automated breast volume scanner images for identifying breast cancer in BI-RADS 4,Single-vesicle molecular profiling of cancer-associated extracellular vesicles (EVs) is increasingly being recognized as a powerful tool for cancer detection and monitoring. Mask and target dual imaging is a facile method to quantify the fraction of the molecularly targeted population of EVs in biofluids at the single-vesicle level. However- accurate and efficient dual imaging vesicle analysis has been challenging due to the interference of false signals on the mask images and the need to analyze a large number of images in clinical samples. In this work- we report a fully automatic dual imaging analysis method based on machine learning and use it with dual imaging single-vesicle technology (DISVT) to detect breast cancer at different stages. The convolutional neural network Resnet34 was used along with transfer learning to produce a suitable machine learning model that could accurately identify areas of interest in experimental data. A combination of experimental and synthetic data were used to train the model. Using DISVT and our machine learning-assisted image analysis platform- we determined the fractions of EpCAM-positive EVs and CD24-positive EVs over captured plasma EVs with CD81 marker in the blood plasma of pilot HER2-positive breast cancer patients and compared to those from healthy donors. The amount of both EpCAM-positive and CD24-positive EVs was found negligible for both healthy donors and Stage I patients. The amount of EpCAM-positive EVs (also CD81-positive) increased from 18% to 29% as the cancer progressed from Stage II to III. No significant increase was found with further progression to Stage IV. A similar trend was found for the CD24-positive EVs. Statistical analysis showed that both EpCAM and CD24 markers can detect HER2-positive breast cancer at Stages II- III- or IV. They can also differentiate individual cancer stages except those between Stage III and Stage IV. Due to the simplicity- high sensitivity- and high efficiency- the DISVT with the AI-assisted dual imaging analysis can be widely used for both basic research and clinical applications to quantitatively characterize molecularly targeted EV subtypes in biofluids.
Jung In Park- Steven Johnson- Lisiane Pruinelli,Optimizing pain management in breast cancer care: Utilizing 'All of Us' data and deep learning to identify patients at elevated risk for chronic pain,Segmentation is a technique for separating an image into discrete areas in order to separate objects of interest from their surroundings. In image analysis- segmentationâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶âˆšÃœwhich encompasses detection- feature extraction- classification- and treatmentâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶âˆšÃœis crucial. In order to plan treatments- segmentation aids doctors in measuring the amount of tissue in the breast. Categorizing the input data into two groups that are mutually exclusive is the aim of a binary classification problem. In this case- the training data is labeled in a binary format based on the problem being solved. Identifying breast lumps accurately in mammography pictures is essential for the purpose of prenatal testing for breast cancer. The proposed TLA (Transfer Learning Approach) based CNN (Convolution Neural Network) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®TLA based CNN aims to offer binary classification for rapid and precise breast cancer diagnosis (benign and malignant). In order to predict the sub-type of cancer- this exploration as used Deep Learning techniques on the Histogram of Oriented Gradient (HOG) - Feature extraction technique that creates a local histogram of the image to extract features from each place in the image with CNN classifier. This research work employs two well-known pre-trained models- ResNet-50 and VGG16- to extract characteristics from mammography images. The high-level features from the Mammogram dataset are extracted using a transfer learning model based on Visual Geometry Group (VGG) with 16-layer and Residual Neural Network with 50-layers deep model architecture (ResNet-50). The proposed model TLA based CNN has achieved 96.49% and 95.48% accuracy as compared to ResNet50 and VGG16 in the breast cancer classification and segmentation.
Andreas Ekholm- Yinxi Wang- Johan Vallon-Christersson- Constance Boissin- Mattias Rantalainen,Prediction of gene expression-based breast cancer proliferation scores from histopathology whole slide images using deep learning,Breast cancer is a leading cause of death among women- and early detection is crucial for improving survival rates. The manual breast cancer diagnosis utilizes more time and is subjective. Also- the previous CAD models mostly depend on manmade visual details that are complex to generalize across ultrasound images utilizing distinct techniques. Distinct imaging tools have been utilized in previous works such as mammography and MRI. However- these imaging tools are costly and less portable than ultrasound imaging. Also- ultrasound imaging is a non-invasive method commonly used for breast cancer screening. Hence- the paper presents a novel deep learning model- BCDNet- for classifying breast tumors as benign or malignant using ultrasound images. The primary aim of the study is to design an effective breast cancer diagnosis model that can accurately classify tumors in their early stages- thus reducing mortality rates. The model aims to optimize the weight and parameters using the RPAOSM-ESO algorithm to enhance accuracy and minimize false negative rates. The BCDNet model utilizes transfer learning from a pre-trained VGG16 network for feature extraction and employs an AHDNAM classification approach- which includes ASPP- DTCN- 1DCNN- and an attention mechanism. The RPAOSM-ESO algorithm is used to fine-tune the weights and parameters. The RPAOSM-ESO-BCDNet-based breast cancer diagnosis model provided 94.5 accuracy rates. This value is relatively higher than the previous models such as DTCN (88.2)- 1DCNN (89.6)- MobileNet (91.3)- and ASPP-DTC-1DCNN-AM (93.8). Hence- it is guaranteed that the designed RPAOSM-ESO-BCDNet produces relatively accurate solutions for the classification than the previous models. The BCDNet model- with its sophisticated feature extraction and classification techniques optimized by the RPAOSM-ESO algorithm- shows promise in accurately classifying breast tumors using ultrasound images. The study suggests that the model could be a valuable tool in the early detection of breast cancer- potentially saving lives and reducing the burden on healthcare systems.
Morteza Rakhshaninejad- Mohammad Fathian- Reza Shirkoohi- F. Barzinpour- Amir H. Gandomi,Refining breast cancer biomarker discovery and drug targeting through an advanced data-driven approach,Objectives: The research aims to enhance breast cancer detection accuracy and effectiveness using deep transfer learning and pre-trained neural networks. It analyses breast ultrasound images and identifies important characteristics using pre-trained networks. The goal is to create a more efficient and accurate automated system for breast cancer detection. Methods: The study uses breast ultrasound cancer image data from the Kaggle Data Repository to extract informative features- identify cancer-related characteristics- and classify them into benign- malignant- and normal tissue. Pre-trained Deep Neural Networks (DNNs) extract these features and feed them into a 10-fold cross-validation SVM classifier. The SVM is evaluated using various kernel functions to identify the best kernel for separating data points. This methodology aims to achieve accurate classification of breast cancer in ultrasound images. Findings: The study confirms the effectiveness of deep transfer learning for breast cancer detection in ultrasound images- with Inception V3 outperforming VGG-16 and VGG-19 in extracting relevant features. The combination of Inception V3 and the SVM classifier with a polynomial kernel achieved the highest classification accuracy- indicating its ability to model complex relationships. The study demonstrated an AUC of 0.944 and a classification accuracy of 87.44% using the Inception V3 + SVM polynomial. Novelty: This research demonstrates the potential of deep transfer learning and SVM classifiers for accurate breast cancer detection in ultrasound images. It integrates Inception V3- VGG-16- and VGG-19 for breast cancer detection- demonstrating improved classification accuracy. The combination of Inception V3 and SVM (polynomial) achieved a significant AUC (0.944) and classification accuracy (87.44%)- outperforming other models tested. This research underscores the potential of these technologies for accurate breast cancer detection in ultrasound images. Keywords: Breast Cancer- Deep Learning- Feature Extraction- Inception-v3- SVM- Transfer Learning
Xuefeng Fu- Yang Jiao- Yao Feng- Fengwei Lin- Bing Zhang- Qing Mao- Jiahui Wang- Wen Jiang- Yanhua Mou- Han Wang- Shaojie Wang,Scaffold Hopping of Pristimerin Provides Derivatives Containing a Privileged Quinoxaline Substructure as Potent Autophagy Inducers in Breast Cancer Cells,Digital Breast Tomosynthesis (DBT) has revolutionized more traditional breast imaging through its three-dimensional (3D) visualization capability that significantly enhances lesion discernibility- reduces tissue overlap- and improves diagnostic precision as compared to conventional two-dimensional (2D) mammography. In this study- we propose an advanced Computer-Aided Detection (CAD) system that harnesses the power of vision transformers to augment DBT's diagnostic efficiency. This scheme uses a neural network to glean attributes from the 2D slices of DBT followed by post-processing that considers features from neighboring slices to categorize the entire 3D scan. By leveraging a transfer learning technique- we trained and validated our CAD framework on a unique dataset consisting of 3-831 DBT scans and subsequently tested it on 685 scans. Of the architectures tested- the Swin Transformer outperformed the ResNet101 and vanilla Vision Transformer. It achieved an impressive AUC score of 0.934 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 0.026 at a resolution of 384 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 384. Increasing the image resolution from 224 to 384 not only maintained vital image attributes but also led to a marked improvement in performance (p-value = 0.0003). The Mean Teacher algorithm- a semi-supervised method using both labeled and unlabeled DBT slices- showed no significant improvement over the supervised approach. Comprehensive analyses across different lesion types- sizes- and patient ages revealed consistent performance. The integration of attention mechanisms yielded a visual narrative of the model's decision-making process that highlighted the prioritized regions during assessments. These findings should significantly propel the methodologies employed in DBT image analysis by setting a new benchmark for breast cancer diagnostic precision.
Shengnan Hao- Yihan Jia- Jianuo Liu- Zhiwu Wang- Chunling Liu- Zhanlin Ji- Ivan Ganchev,ST-Double-Net: A Two-Stage Breast Tumor Classification Model Based on Swin Transformer and Weakly Supervised Target Localization,"The Deep learning (DL) models for diagnosing breast cancer from mammographic images often operate as""black boxes""- making it difficult for healthcare professionals to trust and understand their decision-making processes. The study presents an integrated framework combining Convolutional Neural Networks (CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an elaborate data preprocessing pipeline and advanced data augmentation techniques to counteract dataset limitations and transfer learning using pre-trained networks such as VGG-16- Inception-V3 and ResNet was employed. A focal point of our study is the evaluation of XAI's effectiveness in interpreting model predictions- highlighted by utilizing the Hausdorff measure to assess the alignment between AI-generated explanations and expert annotations quantitatively. This approach is critical for XAI in promoting trustworthiness and ethical fairness in AI-assisted diagnostics. The findings from our research illustrate the effective collaboration between CNNs and XAI in advancing diagnostic methods for breast cancer- thereby facilitating a more seamless integration of advanced AI technologies within clinical settings. By enhancing the interpretability of AI driven decisions- this work lays the groundwork for improved collaboration between AI systems and medical practitioners- ultimately enriching patient care. Furthermore- the implications of our research extended well beyond the current methodologies. It encourages further research into how to combine multimodal data and improve AI explanations to meet the needs of clinical practice."
Olya Rezaeian- Onur Asan- A. E. Bayrak,The Impact of AI Explanations on Clinicians Trust and Diagnostic Accuracy in Breast Cancer,Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer. Breast tissue histopathological examination is critical in diagnosing and classifying breast cancer. Although existing methods have shown promising results- there is still room for improvement in the classification accuracy and generalization of IDC using histopathology images. We present a novel approach- Supervised Contrastive Vision Transformer (SupCon-ViT)- for improving the classification of invasive ductal carcinoma in terms of accuracy and generalization by leveraging the inherent strengths and advantages of both transfer learning- i.e.- pre-trained vision transformer- and supervised contrastive learning. Our results on a benchmark breast cancer dataset demonstrate that SupCon-ViT achieves state-of-the-art performance in IDC classification- with an F1-score of 0.8188- precision of 0.7692- and specificity of 0.8971- outperforming existing methods. In addition- the proposed model demonstrates resilience in scenarios with minimal labeled data- making it highly efficient in real-world clinical settings where labeled data is limited. Our findings suggest that supervised contrastive learning in conjunction with pre-trained vision transformers appears to be a viable strategy for an accurate classification of IDC- thus paving the way for a more efficient and reliable diagnosis of breast cancer through histopathological image analysis.
Eleonore Baum- Daniela Bernhardsgrâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Â´tter- Ramona Engst- Carola Maurer- Jessica Ebneter- Adrienne Zenklusen- Barbara Wartlsteiner- Lotti Barandun- Andrea Neher- Antje Koller- Andrea Kobleder,The meaning of trust along the treatment pathway of women with breast cancer: a mixed-methods study among cancer survivors,Objective Early diagnosis of breast cancer can lead to effective treatment- possibly increase long-term survival rates- and improve quality of life. The objective of this study is to present an automated analysis and classification system for breast cancer using clinical markers such as tumor shape- orientation- margin- and surrounding tissue. The novelty and uniqueness of the study lie in the approach of considering medical features based on the diagnosis of radiologists. Methods Using clinical markers- a graph is generated where each feature is represented by a node- and the connection between them is represented by an edge which is derived through Pearson's correlation method. A graph convolutional network (GCN) model is proposed to classify breast tumors into benign and malignant- using the graph data. Several statistical tests are performed to assess the importance of the proposed features. The performance of the proposed GCN model is improved by experimenting with different layer configurations and hyper-parameter settings. Results Results show that the proposed model has a 98.73% test accuracy. The performance of the model is compared with a graph attention network- a one-dimensional convolutional neural network- and five transfer learning models- ten machine learning models- and three ensemble learning models. The performance of the model was further assessed with three supplementary breast cancer ultrasound image datasets- where the accuracies are 91.03%- 94.37%- and 89.62% for Dataset A- Dataset B- and Dataset C (combining Dataset A and Dataset B) respectively. Overfitting issues are assessed through k-fold cross-validation. Conclusion Several variants are utilized to present a more rigorous and fair evaluation of our work- especially the importance of extracting clinically relevant features. Moreover- a GCN model using graph data can be a promising solution for an automated feature-based breast image classification system.
Pritpal Singh- Rakesh Kumar- Meenu Gupta- Ahmed J. Obaid,Transfer Learning based Breast Cancer Classification using Histopathology Images,BACKGROUND The aim of this study is an improved understanding of drug distribution in brain metastases. Rather than single point snapshots- we analyzed the time course and route of drug/probe elimination (clearance)- focusing on the Intramural Periarterial Drainage (IPAD) pathway. METHODS Mice with JIMT1-BR HER2+ experimental brain metastases were injected with biocytin-TMR and either trastuzumab or human IgG. Drugs/probes circulated for 5 min-48h- followed by perfusion. Brain sections were stained for human IgG- vascular basement membrane proteins laminin or collagen IV- and periarterial â€šÃ¢Ã âˆšâ‰ Â¬Â¨Â¬Â±-SMA. A machine learning algorithm was developed to identify metastases- metastatic microenvironment- and uninvolved brain in confocally scanned brain sections. Drug/probe intensity over time and total imaged drug exposure (iAUC) were calculated for 27-249 lesions and co-immunofluorescence with IPAD- vascular matrix analyzed in 11-668 metastases. RESULTS In metastases- peak trastuzumab levels were 5-fold higher than human IgG but 4-fold less than biocytin-TMR. The elimination phase constituted 85-93% of total iAUC for all drugs/probes tested. For trastuzumab- total iAUC during uptake was similar to the small molecule drug probe biocytin-TMR- but slower trastuzumab elimination resulted in a 1.7-fold higher total iAUC. During elimination trastuzumab and IgG were preferentially enriched in the â€šÃ¢Ã âˆšâ‰ Â¬Â¨Â¬Â±-SMA+ periarterial vascular matrix- consistent with the IPAD clearance route; biocytin-TMR showed heterogeneous elimination pathways. CONCLUSIONS Drug/probe elimination is an important component of drug development for brain metastases. We identified a prolonged elimination pathway for systemically administered antibodies through the periarterial vascular matrix that may contribute to the sustained presence and efficacy of large antibody therapeutics.
A. Tien- M. Sadar,Treatments Targeting the Androgen Receptor and Its Splice Variants in Breast Cancer,Cytological evaluation through microscopic image analysis of fine needle aspiration cytology (FNAC) is pivotal in the initial screening of breast cancer. The sensitivity of FNAC as a screening tool relies on both image quality and the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s expertise. To enhance diagnostic accuracy and alleviate the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s workload- a computer-aided diagnosis (CAD) system was developed. A comparative study was conducted- assessing twelve candidate pre-trained models. Utilizing a locally gathered FNAC image dataset- three superior models-MobileNet-V2- DenseNet-121- and Inception-V3-were selected based on their training- validation- and testing accuracies. Further- these models underwent evaluation in four transfer learning scenarios to enhance testing accuracy. While the outcomes were promising- they left room for improvement- motivating us to create a novel deep convolutional neural network (CNN). The newly proposed model exhibited robust performance with testing accuracy at 85%. Our research concludes that the most lightweight- high-accuracy model is the one we propose. Weâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ve integrated it into our user-friendly Android App- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Breast Cancer Detection System-â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Å“Ã„ in TensorFlow Lite format- with cloud database support- showcasing its effectiveness. Implementing an artificial intelligent (AI)-based diagnosis system with a user-friendly interface holds the potential to enhance early breast cancer detection using FNAC.
Alexander S Millar- John Arnn- Sam Himes- Julio C. Facelli,Uncertainty in Breast Cancer Risk Prediction: A Conformal Prediction Study of Race Stratification,Breast cancer (BC) is one of the most fatal forms of cancer- making it a significant contributor to mortality rates worldwide. Early detection and timely treatment of breast cancer are crucial in reducing its mortality rate. To ensure a healthy lifestyle- it is essential to develop systems that can accurately diagnose breast cancer. Recent advances in modern computing and information technologies have enabled significant progress in the early detection and prediction of diseases within healthcare systems. This study proposes a method for precise and automatic breast cancer prediction using deep-modified transfer learning-based Convolutional Neural Networks (CNNs). The CNN architectures employed include ResNet50- MobileNetV2- DenseNet121- and Xception- which serve as feature extractors to capture the most relevant features of breast Ultrasound images (BUSI). These extracted features are then accurately classified as benign or malignant using various high-performance classifiers- including Support Vector Machine (SVM)- K-Nearest Neighbors (KNN)- XGBoost- and Softmax. The experimental results demonstrate that the proposed deep modified DenseNet121 network with the Softmax classifier outperformed other models and existing techniques. This latter achieved remarkable performance metrics- including an accuracy of 95.34%- a precision of 90.90%- and an F1 score of 93.02%. These results highlight the effectiveness of our approach in enhancing the accuracy of breast cancer prediction. The superior performance of the proposed method provides significant improvements in decision-making speed and reduces the time- effort- and laboratory resources required for healthcare services. Consequently- this method has the potential to significantly enhance early diagnosis and enable more tailored treatment plans- ultimately contributing to better patient outcomes and reducing the overall mortality rates associated with breast cancer.
Ali Hendi- Jalal Abu Halimah- Naif Majrashi- Sarah Daghriri- Mohammed Alhafaf- Mohammed Alshaikh- Mohammed Akkam- Saleha Haroobi- Rahaf Othathi- Reem Harbi- Abdulrahman Zalah- Elham Maghrabi- Alanoud Masmali- Mohammed Mojiri,Understanding Breast Cancer Awareness- Perceptions- and Screening Practices Among the Population of Jazan- Saudi Arabia: A Cross-Sectional Study,A comprehensive evaluation of the relationship between the densities of various cell types in the breast cancer tumor microenvironment and patient prognosis is currently lacking. Additionally- the absence of a large patch-level whole slide imaging (WSI) dataset of breast cancer with annotated cell types hinders the ability of artificial intelligence to evaluate cell density in breast cancer WSI. We first employed Lasso-Cox regression to build a breast cancer prognosis assessment model based on cell density in a population study. Pathology experts manually annotated a dataset containing over 70-000 patches and used transfer learning based on ResNet152 to develop an artificial intelligence model for identifying different cell types in these patches. The results showed that significant prognostic differences were observed among breast cancer patients stratified by cell density score (P = 0.0018)- with the cell density score identified as an independent prognostic factor for breast cancer patients (P < 0.05). In the validation cohort- the predictive performance for overall survival (OS) was satisfactory- with area under the curve (AUC) values of 0.893 (OS) at 1-year- 0.823 (OS) at 3-year- and 0.861 (OS) at 5-year intervals. We trained a robust model based on ResNet152- achieving over 99% classification accuracy for different cell types in patches. These achievements offer new public resources and tools for personalized treatment and prognosis assessment.
Shiping Li- Yihao Lin- Guangyu Liu- Zhimin Shao- Yinlong Yang,Unveiling the potential of breast MRI: a game changer for BI-RADS 4A microcalcifications.,Breast cancer can progress silently in its early stages and frequently without noticeable symptoms. However- it poses a serious risk to women. It is imperative to recognize this potential health concern to mitigate it early. In the last few years- Convolutional Neural Networks (CNNs) have advanced significantly in their ability to classify images of breast cancer. Their capacity to automatically extract discriminant features from images has enhanced the performances and accuracy of image classification tasks. They outperform state-of-the-art techniques in this area. Furthermore- complicated models that were first learned for certain tasks can be easily adapted to complete new tasks by using transfer-learning approaches. However- deep learning-based categorization techniques could experience overfitting issues- particularly in cases where the dataset is small. The primary goal of this work is to investigate the performances of certain deep learning models to classify breast cancer images and to study the effects of data augmentation techniques- such as image rotation or displacement when utilizing a transfer learning approach. Using certain image datasets- the ResNet18- Resnet50- and VGG16 models demonstrated accuracy improvements- according to our experimental results.
Yeojin Jeong- Jeesoo Lee- Young-jin Lee- Jiyun Hwang- Sae Byul Lee- Tae-Kyung Yoo- Myeong-Seong Kim- Jae Il Kim- John L Hopper- Tuong L Nguyen- Jong Won Lee- Joohon Sung,Artificial-Intelligence Powered Identification of High-Risk Breast Cancer Subgroups Using Mammography: A Multicenter Study Integrating Automated Brightest Density Measures with Deep Learning Metrics,Breast Cancer is a significant global health challenge- particularly affecting women with higher mortality compared with other cancer types. Timely detection of such cancer types is crucial- and recent research- employing deep learning techniques- shows promise in earlier detection. The research focuses on the early detection of such tumors using mammogram images with deep-learning models. The paper utilized four public databases where a similar amount of 986 mammograms each for three classes (normal- benign- malignant) are taken for evaluation. Herein- three deep CNN models such as VGG-11- Inception v3- and ResNet50 are employed as base classifiers. The research adopts an ensemble method where the proposed approach makes use of the modified Gompertz function for building a fuzzy ranking of the base classification models and their decision scores are integrated in an adaptive manner for constructing the final prediction of results. The classification results of the proposed fuzzy ensemble approach outperform transfer learning models and other ensemble approaches such as weighted average and Sugeno integral techniques. The proposed ResNet50 ensemble network using the modified Gompertz function-based fuzzy ranking approach provides a superior classification accuracy of 98.986%.
Koagne Longpa T. Silas,Breast Cancer Diagnosis with Machine Learning Using Feed-Forward Multilayer Perceptron Analog Artificial Neural Network,OBJECTIVES:: This study explores a deep learning (DL) approach to predicting bone metastases in breast cancer (BC) patients using clinical information- such as the fat index- and features like Computed Tomography (CT) images. METHODS:: CT imaging data and clinical information were collected from 431 BC patients who underwent radical surgical resection at Harbin Medical University Cancer Hospital. The area of muscle and adipose tissue was obtained from CT images at the level of the eleventh thoracic vertebra. The corresponding histograms of oriented gradients (HOG) and local binary pattern (LBP) features were extracted from the CT images- and the network features were derived from the LBP and HOG features as well as the CT images through deep learning (DL). The combination of network features with clinical information was utilized to predict bone metastases in BC patients using the Gradient Boosting Decision Tree (GBDT) algorithm. Regularized Cox regression models were employed to identify independent prognostic factors for bone metastasis. RESULTS:: The combination of clinical information and network features extracted from LBP features- HOG features- and CT images using a convolutional neural network (CNN) yielded the best performance- achieving an AUC of 0.922 (95% confidence interval [CI]: 0.843â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®0.964- [Formula: see text] 0.01). Regularized Cox regression results indicated that the subcutaneous fat index was an independent prognostic factor for bone metastasis in breast cancer (BC). CONCLUSION:: Subcutaneous fat index could predict bone metastasis in BC patients. Deep learning multimodal algorithm demonstrates superior performance in assessing bone metastases in BC patients.
T Liu- H Wang- F Feng- W Li- F Zheng- K Wu- ...,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ clinicopathologic information and dynamic contrast-enhanced MRI for augmented prediction of neoadjuvant chemotherapy response in breast cancer,Breast UltraSound (BUS) imaging is a commonly used diagnostic tool in the field of counter fighting breast diseases- especially for early detection and diagnosis of breast cancer. Due to the inherent characteristics of ultrasound images such as blurry boundaries and diverse tumor morphologies- it is challenging for doctors to manually segment breast tumors. In recent years- the Convolutional Neural Network (CNN) technology has been widely applied to automatically segment BUS images. However- due to the inherent limitations of CNNs in capturing global contextual information- it is difficult to capture the full context. To address this issue- the paper proposes a novel BGRD-TransUNet model for breast lesion segmentation- based on TransUNet. The proposed model- first- replaces the original ResNet50 backbone network of TransUNet with DenseNet121 for initial feature extraction. Next- newly designed Residual Multi-Scale Feature Modules (RMSFMs) are employed to extract features from various layers of DenseNet121- thus capturing richer features within specific layers. Thirdly- a Boundary Guidance (BG) network is added to enhance the contour information of BUS images. Additionally- newly designed Boundary Attentional Feature Fusion Modules (BAFFMs) are used to integrate edge information and features extracted through RMSFMs. Finally- newly designed Parallel Channel and Spatial Attention Modules (PCSAMs) are used to refine feature extraction using channel and spatial attention. An extensive experimental testing performed on two public datasets demonstrates that the proposed BGRD-TransUNet model outperforms all state-of-the-art medical image segmentation models- participating in the experiments- according to all evaluation metrics used (except for few separate cases)- including the two most important and widely used metrics in the field of medical image segmentation- namely the Intersection over Union (IoU) and Dice Similarity Coefficient (DSC). More specifically- on the BUSI dataset and dataset B- BGRD-TransUNet achieves IoU values of 76.77% and 86.61%- and DSC values of 85.08% and 92.47%- respectively- which are higher by 7.27 and 3.64- and 5.81 and 2.54 percentage points- than the corresponding values achieved by the baseline (TransUNet).
Y. Forghani- R. Timotoe- M. Figueiredo- T. Marques- E. Batista- F. Cordoso- M.J. Cardoso- J. Santinha- P. Gouveia,Breast tissue segmentation in MR images using deep-learning,Breast cancer is one of the malignancies that affects women. Breast cancer is a condition that is brought on by abnormal breast cells that multiply and form tumours. If left untreated- tumours have the capacity to grow throughout the body and become fatal. Early initiation and thorough completion of treatment is associated with better outcomes and greater patient tolerance for breast cancer patients. These days- early detection of breast cancer is quite helpful and will help the women who battle the illness. The earliest detection of breast cancer can be successfully achieved with the use of machine learning-based approaches. Breast cancer can be diagnosed with great accuracy using a number of machine learning techniques- including CNN- RF- SVM- NB- KNN- AB- and others. Thus- I am introducing a triple hybrid deep learning method for breast cancer diagnosis and prognosis. This is the CNN- GRU- and LSTM combination.
ArunaDevi Karuppasamy- Abdelhamid Abdesselam- Hamza zidoum- Rachid Hedjam- Maiya Al-Bahri,Combining a forward supervised filter learning with a sparse NMF for breast cancer histopathological image classification,Breast cancer remains a global health problem requiring effective diagnostic methods for early detection in order to achieve WHO&rsquo;s ultimate goal of breast self-examination (BSE). A literature review indicates the urgency of improving diagnostic methods and identifies thermography as a promising- cost-effective- and non-invasive and adjunctive and complementary detection method. This research explores the potential of using machine learning (ML) techniques- specifically Bayesian Networks (BN) combined with Convolutional Neural Networks (CNN) to improve breast cancer diagnosis at early stages. Explainable artificial intelligence (XAI) aims to clarify the reasoning behind any output of artificial neural networks based models. The proposed integration adds interpretability of the diagnosis- which is particularly significant for a medical diagnosis. We have constructed two diagnostic expert models. In research model A- combining thermal images after XAI process together with medical records- an accuracy of 84.07% has been achieved- while model B- that includes also CNN prediction- achieved an accuracy of 90.93%. These results demonstrate the potential of XAI to transform breast cancer diagnosis- increasing accuracy and reducing the risk of misdiagnosis.
Yuan Yao- Yang Zhao- Xu Guo- Xiangli Xu- Baiyang Fu- Hao Cui- Jian Xue- Jiawei Tian- Ke Lu- Lei Zhang,Deep Learning for Distinguishing Mucinous Breast Carcinoma From Fibroadenoma on Ultrasound,"Abstract: Breast cancer poses a significant global health threat to women, underscoring the crucial need for reliable and effective screening approaches. The utilization of computer-aided diagnostic (CAD) systems, leveraging mammograms, enables early detection, diagnosis, and treatment of breast cancer, thereby offering vital support in combating this disease. This study introduces a unique deep-learning model that uses transfer learning to identify and categorize breast cancer automatically. Several recent studies have shown that deep convolutional neural networks (DCNNs) can be used to diagnose breast cancer in mammograms with performances comparable to or even superior to those of human experts. The proposed model extracts features from the Mammographic Image Analysis Society (MIAS) dataset using pre-trained convolutional neural network (CNN) architectures such as ResNet50 and VGG-16. This revolutionary deep-learning model has the potential to improve the efficiency and accuracy of breast cancer detection and categorization."
Vedagiriswaran N- SHRIHARI KAMALAN KUMARAGURUPARAN- Kumara  Guru R,Machine Learning and Structural Informatics Approaches to Identify Mtor Inhibitors for Drug Repurposing in Triple-Negative Breast Cancer,Early detection significantly enhances patients' survival rates by identifying tumors in their initial stages through medical imaging. However- prevailing methodologies encounter challenges in extracting comprehensive information from diverse modalities- thereby exacerbating semantic disparities and overlooking critical task correlations- consequently compromising the accuracy of prognosis predictions. Moreover- clinical insights emphasize the advantageous sharing of parameters between tumor segmentation and survival prediction for enhanced prognostic accuracy. This paper proposes a novel model- BTSSPro- designed to concurrently address Breast cancer Tumor Segmentation and Survival prediction through a Prompt-guided multi-modal co-learning framework. Technologically- our approach involves the extraction of tumor-specific discriminative features utilizing shared dual attention (SDA) blocks- which amalgamate spatial and channel information from breast MR images. Subsequently- we employ a guided fusion module (GFM) to seamlessly integrate the Electronic Health Record (EHR) vector into the extracted tumor-related discriminative feature representations. This integration prompts the model's feature selection to align more closely with real-world scenarios. Finally- a feature harmonic unit (FHU) is introduced to coordinate the transformer encoder and CNN decoder- thus reducing semantic differences. Remarkably- BTSSPro achieved a C-index of 0.968 and Dice score of 0.715 on the Breast MRI-NACT-Pilot dataset and a C-index of 0.807 and Dice score of 0.791 on the ISPY1 dataset- surpassing the previous state-of-the-art methods.
Zhe Lin,Breast cancer classification based on hybrid machine learning model,Automatic breast tumor segmentation based on convolutional neural networks (CNNs) is significant for the diagnosis and monitoring of breast cancers. CNNs have become an important method for early diagnosis of breast cancer and- thus- can help decrease the mortality rate. In order to assist medical professionals in breast cancer investigation a computerized system based on two encoder-decoder architectures for breast tumor segmentation has been developed. Two pre-trained DeepLabV3+ and U-Net models are proposed. The encoder generates a high-dimensional feature vector while the decoder analyses the low-resolution feature vector provided by the encoder and generates a semantic segmentation mask. Semantic segmentation based on deep learning techniques can overcome the limitations of traditional algorithms. To assess the efficiency of breast ultrasound image segmentation- we compare the segmentation results provided by CNNs against the Local Graph Cut technique (a semi-automatic segmentation method) in the Image Segmenter application. The output segmentation results have been evaluated by using the Dice similarity coefficient that compares the ground truth images provided by the specialists against the predicted segmentation results provided by the CNNs and Local Graph Cut algorithm. The proposed approach is validated on 780 breast ultrasonographic images of the BUSI public database of which 437 are benign and 210 are malignant. The BUSI database provides classification (benign or malignant) labels for ground truth in binary mask images. The average Dice scores computed between the ground truth images against CNNs were as follows: 0.9360 (malignant) and 0.9325 (benign) for the DeepLabV3+ architecture and of 0.6251 (malignant) and 0.6252 (benign) for the U-Net- respectively. When the segmentation results provided by CNNs were compared with the Local Graph Cut segmented images- the Dice scores were 0.9377 (malignant) and 0.9204 (benign) for DeepLabV3+ architecture and 0.6115 (malignant) and 0.6119 (benign) for U-Net- respectively. The results show that the DeepLabV3+ has significantly better segmentation performance and outperforms the U-Net network.
Ziming Liu,Improving breast cancer classification using histopathology images through deep learning,The most fatal disease affecting women worldwide now is breast cancer. Early detection of breast cancer enhances the likelihood of a full recovery and lowers mortality. Based on medical imaging- researchers from all around the world are developing breast cancer screening technologies. Due to their rapid progress- deep learning algorithms have caught the interest of many in the field of medical imaging. This research proposes a novel method in mammogram image feature extraction with classification and optimization using machine learning in breast cancer detection. The input image has been processed for noise removal- smoothening- and normalization. The input image features were extracted using probabilistic principal component analysis for detecting the presence of tumors in mammogram images. The extracted tumor region is classified using the Naâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšâ‰¤ve Bayes classifier and transfer integrated convolution neural networks. The classified output has been optimized using firefly binary grey optimization and metaheuristic moth flame lion optimization. The experimental analysis has been carried out in terms of different parameters based on datasets. The proposed framework used an ensemble model for breast cancer that made use of the proposed Bayesâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢FBGO and TCNNâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢MMFLO classifier and optimizer for diverse mammography image datasets. The INbreast dataset was evaluated using the proposed Bayesâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢FBGO and TCNNâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢MMFLO classifiers- which achieved 95% and 98% accuracy- respectively.
Milan Manoj- Akshay Rajan- Gouri Santhosh- Anjali T- Panchami Sankar,An Extensive Analysis of Breast Cancer detection using Deep Learning Algorithms,AI is transforming the medical field- especially in early detection and categorization of breast cancer. Deep learning models like CNNI-BCC are displaying impressive capabilities in examining MRI images to precisely recognize different types of breast cancer. This advancement in technology has significant implications for enhancing patient outcomes. By utilizing AI- healthcare professionals can now receive more accurate and prompt diagnoses. CNNI- BCC's exceptional accuracy in analyzing MRI images allows for earlier detection of breast cancer- which is crucial for successful treatment. This technology enables doctors to identify potential abnormalities that may have been missed by traditional methods- leading to more effective interventions.
Rajon Dash- Md Saidur Rahman Kohinoor- Promise Ghosh Chowdhury,Comprehensive Analysis of Machine and Deep Learning Models for Breast Cancer Diagnosis and Risk Assessment with Diverse Datasets,Background: Accurate detection of axillary lymph node (ALN) metastases in breast cancer is crucial for clinical staging and treatment planning. This study aims to develop a deep learning model using clinical implication-applied preprocessed computed tomography (CT) images to enhance the prediction of ALN metastasis in breast cancer patients. Methods: A total of 1128 axial CT images of ALN (538 malignant and 590 benign lymph nodes) were collected from 523 breast cancer patients who underwent preoperative CT scans between January 2012 and July 2022 at Hallym University Medical Center. To develop an optimal deep learning model for distinguishing metastatic ALN from benign ALN- a CT image preprocessing protocol with clinical implications and two different cropping methods (fixed size crop [FSC] method and adjustable square crop [ASC] method) were employed. The images were analyzed using three different convolutional neural network (CNN) architectures (ResNet- DenseNet- and EfficientNet). Ensemble methods involving and combining the selection of the two best-performing CNN architectures from each cropping method were applied to generate the final result. Results: For the two different cropping methods- DenseNet consistently outperformed ResNet and EfficientNet. The area under the receiver operating characteristic curve (AUROC) for DenseNet- using the FSC and ASC methods- was 0.934 and 0.939- respectively. The ensemble model- which combines the performance of the DenseNet121 architecture for both cropping methods- delivered outstanding results with an AUROC of 0.968- an accuracy of 0.938- a sensitivity of 0.980- and a specificity of 0.903. Furthermore- distinct trends observed in gradient-weighted class activation mapping images with the two cropping methods suggest that our deep learning model not only evaluates the lymph node itself- but also distinguishes subtler changes in lymph node margin and adjacent soft tissue- which often elude human interpretation. Conclusions: This research demonstrates the promising performance of a deep learning model in accurately detecting malignant ALNs in breast cancer patients using CT images. The integration of clinical considerations into image processing and the utilization of ensemble methods further improved diagnostic precision.
A Sharma- S Mittal,Deep Learning Approachâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®Improved CNN Model for the Breast Cancer Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Flowchart of deep learning radiomic nomogram modeling for LVI prediction in patients with invasive breast cancer. BMUS- B-mode ultrasound; CDFI- color doppler flow imaging; ROI- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
RO Ogundokun- ART Abdullahi- ...,Hybrid Deep Learning for Breast Cancer Diagnosis: Evaluating CNN and ANN on BreakHis_v1_400X,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ In order to solve the above problems- we propose a deep learning method for early prediction of NAC for breast cancer based on multistage bimodal ultrasound images. This model is â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
SM Thwin- SJ Malebary- AW Abulfaraj- HS Park,Attention-Based Ensemble Network for Effective Breast Cancer Classification over Benchmarks,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ and classification of breast cancer using transfer learning. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ [19] used the DL-CNN for breast cancer classification from â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ -negative breast cancer based on images of primary breast cancer. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
PSRC Murty- C Anuradha- PA Naidu- D Mandru- ...,Integrative hybrid deep learning for enhanced breast cancer diagnosis: leveraging the Wisconsin Breast Cancer Database and the CBIS-DDSM dataset,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ of breast cancer- this investigation used a hybrid deep learning â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ The Wisconsin Breast Cancer Database is used for CNN â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ - and therapeutically applicable breast cancer detection method â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Erin J. Kim- Enoch Chung- Bernard T. Lee- Dhruv Singhal,D134. Application of Machine Learning to Predict Breast Cancer Related-lymphedema Development,Introduction: When considering cancer mortality rates in general- Breast Cancer (BC) is a major contributor among females. Patientsâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ chances of survival increase when BC is detected early and treated with the appropriate treatment at the right time. There is strong evidence that mammography- when used as a screening tool- can detect BC at an early stage. Mammography is a diagnostic tool that uses low-dose X-rays to visualise the breast and evaluate its anatomy. For screening purposes- it is currently the preferred method. The present study employs deep learning models trained using Transfer Learning (TL) techniques. Aim: To automate the process of BC diagnosis in mammograms. The main goal of this approach is to simplify the process of early detection and diagnosis of BC for healthcare practitioners. Materials and Methods: The dataset obtained from the Mammographic Image Analysis Society (MIAS) was categorised into three distinct categories: benign- malignant and normal. The initial MIAS dataset underwent several preprocessing techniques- including noise reduction- breast image contrast enhancement- non breast region deletion and malignant lesion identification- before analysis. An intricately designed fully connected classifier complements pretrained Convolutional Neural Network (CNN) architectures like ResNet50 and VGG16 in the proposed model. Results: The VGG16 model performed admirably- achieving an Area Under the Curve (AUC) of 0.950 and an accuracy rate of 96.00%. In addition- it displayed an outstanding F-score of 97%- along with high sensitivity- specificity and accuracy. These outcomes are significantly better compared to the other methods. Conclusion: The modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s enhanced capabilities for early-stage cancer detection could improve patient outcomes and reduce mortality rates. Furthermore- new tools can ease the workload for radiologists- leading to more standardised and efficient diagnostic procedures.
,Machine Learning-Based Breast Cancer Detection Using Histopathological Images,In worldwide women mortality increases extremely every year due to breast cancer and diagnosis of the issue through prediction is very much imperative for healthy lifespan. Here precision of cancer extrapolation is an essential thing for survivability of patient with appropriate treatment. Deep learning algorithms have materialised as influential tool for predicting breast cancer in medical image processing- which leverages capabilities of artificial neural networks (ANN) that are intended to mimic an architecture and functionalities of human brain. Superior features of convolutional neural network (CNN) in deep learning for handling image-based data like- exploiting spatial information- hierarchical feature learning- parameter sharing and data augmentation are important parameters in medical image processing. In this paper CNN algorithm is incorporated for predicting breast cancer in earlier and malignant stage- the results are compared with other deep learning algorithms and our proposed algorithm is expected to give better performance in parameters like accuracy testing- image classifiers- gene sequence classifiers and malignancy detection.
Sarathkumar M- Dhanalakshmi K S- Madhivadhani D- Revathi V,A Deep Learning Approach for Efficient Breast Cancer Diagnosis Using Hybrid CNN-BILSTM with Soft Attention Mechanism,Large language models (LLMs) have garnered significant attention in the AI domain owing to their exemplary context recognition and response capabilities. However- the potential of LLMs in specific clinical scenarios- particularly in breast cancer diagnosis- treatment- and care- has not been fully explored. This study aimed to compare the performances of three major LLMs in the clinical context of breast cancer. In this study- clinical scenarios designed specifically for breast cancer were segmented into five pivotal domains (nine cases): assessment and diagnosis- treatment decision-making- postoperative care- psychosocial support- and prognosis and rehabilitation. The LLMs were used to generate feedback for various queries related to these domains. For each scenario- a panel of five breast cancer specialists- each with over a decade of experience- evaluated the feedback from LLMs. They assessed feedback concerning LLMs in terms of their quality- relevance- and applicability. There was a moderate level of agreement among the raters (Fleiss' kappa=0.345- P<0.05). Comparing the performance of different models regarding response length- GPT-4.0 and GPT-3.5 provided relatively longer feedback than Claude2. Furthermore- across the nine case analyses- GPT-4.0 significantly outperformed the other two models in average quality- relevance- and applicability. Within the five clinical areas- GPT-4.0 markedly surpassed GPT-3.5 in the quality of the other four areas and scored higher than Claude2 in tasks related to psychosocial support and treatment decision-making. This study revealed that in the realm of clinical applications for breast cancer- GPT-4.0 showcases not only superiority in terms of quality and relevance but also demonstrates exceptional capability in applicability- especially when compared to GPT-3.5. Relative to Claude2- GPT-4.0 holds advantages in specific domains. With the expanding use of LLMs in the clinical field- ongoing optimization and rigorous accuracy assessments are paramount.
Sahan Yoruc Selcuk- Xilin Yang- Bijie Bai- Yijie Zhang- Yuzhu Li- Musa Aydin- Aras Firat Unal- Aditya Gomatam- Zhen Guo- Morgan A. Darrow- Goren Kolodney- Karine Atlan- Tal K. Haran- Nir Pillar- Aydogan Ozcan,Classification of HER2 score in breast cancer images using deep learning and pyramid sampling,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ slide images (WSI) and artificial intelligence (AI) featuring digital â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ - image transformers leverage self-attention mechanisms â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ CNN and transformer-based deep learning methods for the â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
N Thakur- P Kumar- A Kumar,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ semantic segmentation and attention based backpropagation convolutional neural network (ABB-CNN) for breast cancer identification and classification â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ by transformer and graph deep learning- this study proposes a novel classification method of WSI breast cancer pathological images based on BiFormer and graph attention network (â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Altulayhi- A Alhrgan,Evaluating Study Between Vision Transformers and Pre-trained CNN Learning Algorithms to Classify Breast Cancer Histopathological Images,Health-related quality of life (HRQOL) has become increasingly important for breast cancer survivors- but clinically relevant declines often persist for many years after treatment. This study aimed to investigate whether social relationships can mitigate or prevent this decline in HRQOL. Data were used from the German population-based Mamma Carcinoma Risk Factor Investigation (MARIE) cohort of 2022 breast cancer cases with follow-up information for more than 15 years after diagnosis. Correlations between social integration- social support- and global health status (GHS) as an overall measure of HRQOL were analyzed- and linear regression analysis was performed with structural equation modeling. The majority of participants reported high levels of social integration and social support and moderate levels of GHS. Social integration 5 years after diagnosis was associated with GHS 5 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 1.12; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.25-1.99)- but no longitudinal effects were found. Social support 5 years after diagnosis was associated with better GHS 5 years (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.42; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.36-0.48) and 10 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.12; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.02-0.22)- whereas social support 10 years after diagnosis was associated with GHS 10 years (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.29; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.20-0.39) and 15 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.10; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.01-0.21). These results confirm that social relationships positively influence HRQOL in long-term breast cancer survivors and that their association should receive more attention clinically and beyond routine care.
Muniraj Gupta- Nidhi Verma- Naveen Sharma- Satyendra Narayan Singh- R. K. Brojen Singh- Saurabh Kumar Sharma,Deep Transfer Learning Hybrid Techniques for Precision in Breast Cancer Tumor Histopathology Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ development of artificial intelligence- CAD systems utilizing deep learning technology have â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Compared to CNNs- the self-attention mechanism in Transformers exhibits robust global â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Juan Gutierrez-Cardenas,"Breast Cancer Classification through Transfer Learning with Vision Transformer, PCA, and Machine Learning Models",The objective of our study was to explore the feasibility of integrating artificial intelligence (AI) algorithms for breast cancer detection into a portable- point-of-care ultrasound device (POCUS). This proof-of-concept implementation is to demonstrate the platform for integrating AI algorithms into a POCUS device to achieve a performance benchmark of at least 15 frames/second. Our methodology involved the application of five AI models (FasterRCNN+MobileNetV3- FasterRCNN+ResNet50- RetinaNet+ResNet50- SSD300+VGG16- and SSDLite320+MobileNetV3)- pretrained on public datasets of natural images- fine-tuned using a dataset of gelatin-based breast phantom images with both anechoic and hyperechoic lesions- mimicking real tissue characteristics. We created various gelatin-based ultrasound phantoms containing ten simulated lesions- ranging from 4-20 mm in size. Our experimental setup used the Clarius L15 scanning probe- which was connected via Wi-Fi to both a tablet and a laptop- forming the core of our development platform. The phantom data was divided into training- validation- and held-out testing sets on a per-video basis. We executed 200 timing trials for each finetuned AI model- streaming scanning video from the ultrasound probe in real-time. SSDLite320+MobileNetV3 emerged as a standout- showing a mean frame-to-frame timing of 0.068 seconds (SD=0.005)- which is approximately 14.71 FPS- closely followed by FasterRCNN+MobileNetV3- with a mean timing of 0.123 seconds (SD=0.016)- or about 8.13 FPS. Both models show acceptable performance in lesion localization. Compared to our goal of 15 frames/second- only the SSDLite320+MobileNetV3 architecture performed with sufficient evaluation speed to be used in real-time. Our findings show the necessity of using AI architectures designed for edge devices for real-time use- as well as the potential need for hardware acceleration to encode AI models for use in POCUS.
L Panigrahi- TB Chandra- AK Srivastava- ...,: Multilevel Breast Cancer Classification Framework Using Radiomic Features,This investigation explores the potential efficacy of machine learning algorithms (MLAs)- particularly convolutional neural networks (CNNs)- in distinguishing between benign and malignant breast cancer tissue through the analysis of 1000 breast cancer images gathered from Kaggle.com- a domain of publicly accessible data. The dataset was meticulously partitioned into training- validation- and testing sets to facilitate model development and evaluation. Our results reveal promising outcomes- with the developed model achieving notable precision (92%)- recall (92%)- accuracy (92%)- sensitivity (89%)- specificity (96%)- an F1 score of 0.92- and an area under the curve (AUC) of 0.944. These metrics underscore the model's ability to accurately identify malignant breast cancer images. Because of limitationsÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ such as sample size and potential variations in image quality- further research- data collection- and integration of theoretical models in a real-world clinical settingÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ are needed to expand the reliability and generalizability of these MLAs. Nonetheless- this study serves to highlight the potential use of artificial intelligence models as supporting tools for physicians to utilize in breast cancer detection.
D Shah- MAU Khan- M Abrar- ...,Optimizing Breast Cancer Detection With an Ensemble Deep Learning Approach,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ To enhance breast cancer detection- this study adopts a multifaceted approach centered on applying CNNs- a class of deep learning algorithms renowned for their prowess in image â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Luca Urso- Luigi Manco- Corrado Cittanti- Sara Adamantiadis- Klarisa Elena Szilagyi- Giovanni Scribano- Noemi Mindicini- Aldo Carnevale- Mirco Bartolomei- Melchiore Giganti,18F-FDG PET/CT radiomic analysis and artificial intelligence to predict pathological complete response after neoadjuvant chemotherapy in breast cancer patients,Early detection of breast cancer with computer assistance has developed since two decades ago. Artificial intelligence using the convolutional neural network (CNN) method has successfully predicted mammography images with a high level of accuracy similar to human brain learning. The potential of AI models provides opportunities to spot breast cancer cases better. This research aims to develop AI models with CNN using the public DDSM dataset with a sample size of 1871- consisting of 1546 images for training and 325 images for testing. These AI models provided prediction results with different accuracy rate. Increasing the accuracy of the AI model can be done by improving the image quality before the modeling process- increasing the number of datasets- or carrying out a more profound iteration process so that the AI model with CNN can have a better level of accuracy.
Khadija Aguerchi- Y. Jabrane- Maryam Habba- Amir Hajjam El Hassani,A CNN Hyperparameters Optimization Based on Particle Swarm Optimization for Mammography Breast Cancer Classification,Objectives: To develop a model for the prediction of Breast cancer. Cancer is one of the deadliest diseases and it is regarded as the second leading cause of death in women throughout the sphere. Former detection of cancer can save the patient's life. Outliers can have an impact on the model's performance. For this reason- eliminating outliers is the first factor to be considered. Methods: In this study- the Wisconsin Diagnostic Breast Cancer dataset was used. It consists of 569 instances of which 357 instances are benign and 212 are malignant cases. It has 32 attributes including two class attribute labels (diagnosis: B= benign- M= malignant)- ID number- and 30 real value attributes. These attributes are computed from a digitized image of a Fine Needle Aspiration (FNA) procedure of a breast mass and are used to describe the characteristics of the cell nuclei present in the image. The HOTSM outlier detection approach- which handles anomalies in two stages- was proposed in the current study. First- the Inter Quartile Range (IQR) was employed to diminish the influence of outliers. After the analysis had been finished- the non-outlier data was transmitted to an isolation forest- wherein the absolute mean error was calculated. Pearson's Correlation was employed to minimize the dimensionality. Findings: For the performance evaluation- two datasets are generated; one using isolation forest and the other using HOTSM. The performance of both datasets is tested using SVM- Decision Tree- and Random Forest classifiers- highest accuracies are obtained as 97.80 %-96.80%- and 98.4% respectively. It was found that the dataset generated using the proposed method performed well. The proposed model is capable of identifying Breast cancer- more accurately. Novelty: The Interquartile Range has been utilized for altering the traditional isolation forest algorithm- enhancing performance metrics. The thorough removal of anomalies reduces the likelihood of misdiagnosis- yet they cannot exclude all outliers. Keywords: Outliers- Breast Cancer- Accuracy- Machine Learning- Hybrid
Umesh Dutta- Simran Kaushik- Srinidhi Iyer- Ina Singh,A Comparative Analysis of Machine Learning Techniques for Breast Cancer Prediction,Breast cancer is one of the most common causes of death in women. Early signs of breast cancer can be an abnormality depicted on breast images like breast ultrasonography. Unfortunately- ultrasound images contain a lot of noise- which greatly increases the difficulty for doctors to interpret them. In recent years- computer-aided diagnosis (CAD) has been widely used in medical images- reducing the workload of doctors and the probability of misdiagnosis. However- it still faces the following challenges in clinical practice: one is the lack of interpretability- and another is that the accuracy is not high enough. In this paper- we propose a classification model of breast ultrasound images that leverages tumor boundaries as prior knowledge and strengthens the model to guide classification. Furthermore- we employ the advantages of convolutional neural network (CNN) to extract local features and Transformer to extract global features to achieve information balance and complementarity between the two neural network models which increase the recognition performance of the model. Additionally- an explanation method is used to generate visual results- thereby improving the poor interpretability of deep learning models. Finally- we evaluate the model on the BUSI dataset and compare it with other CNN and Transformer models. Experimental results show that the proposed model obtains an accuracy of 0.9870 and an F1 score of 0.9872- achieving state-of-the-art performance.
Mahdi Ahmadi- N. Karimi- S. Samavi,A lightweight deep learning pipeline with DRDA-Net and MobileNet for breast cancer classification,Purposes: Breast cancer (BC) is a disease in which the breast cells multiply uncontrolled. Breast cancer is one of the most often diagnosed malignancies in women worldwide. Early identification of breast cancer is critical for limiting the impact on affected people's health conditions. The influence of technology and artificial intelligence approaches (AI) in the health industry is tremendous as technology advances. Deep learning (DL) techniques are used in this study to classify breast lumps. Materials and Methods: The study makes use of two distinct breast ultrasound images (BUSI) with binary and multiclass classification. To assist the models in understanding the data- the datasets are exposed to numerous preprocessing and hyperparameter approaches. With data imbalance being a key difficulty in health analysis- due to the likelihood of not having a condition exceeding that of having the disease- this study applies a cutoff stage to impact the decision threshold in the datasets data augmentation procedures. The capsule neural network (CapsNet)- Gabor capsule network (GCN)- and convolutional neural network (CNN) are the DL models used to train the various datasets. Results: The findings showed that the CapsNet earned the maximum accuracy value of 93.62% while training the multiclass data- while the GCN achieved the highest model accuracy of 97.08\% when training the binary data. The models were also evaluated using a variety of performance assessment parameters- which yielded consistent results across all datasets. Conclusion: The study provides a non-invasive approach to detect breast cancer; and enables stakeholders- medical practitioners- and health research enthusiasts a fresh view into the analysis of breast cancer detection with DL techniques to make educated judgements.
Chenlu Zhang- Nan Li- Pengxia Zhang- Zhimei Jiang- Yichao Cheng- Huiqing Li- Zhenfei Pang,Advancing precision and personalized breast cancer treatment through multi-omics technologies,The most prevalent cancer in women is breast cancer (BC)- and effective treatment depends on being detected early. Many people seek medical imaging techniques to help in the early detection of problems- but results often need to be corrected for increased accuracy. A new deep learning approach for medical images is applied in the detection of BC in this paper. Early detection is carried out through the proposed method using a combination of Convolutional Neural Network (CNNs) with feature selection and fusion methods. The proposed method may decrease the mortality rate due to the early-stage detection of BC with high precision. In this work- the proposed Deep Learning Framework (DLF) uses many levels of artificial neural networks to sort images of BC into categories correctly. This proposed method further increases the scalability of convolutional recurrent networks. It also achieved 94.93Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % accuracy- 93.66Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % precision- 89.21Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % recall and 98.86Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % F1-score. Through this approach- cancer tumors in a specific location can be detected more accurately. The existing methods are dependent mainly on manually selecting and extracting features. The proposed framework automatically learns and finds relevant features from images that result in outperforming existing methods.
S. S. Boudouh- M. Bouakkaz,Advancing precision in breast cancer detection: a fusion of vision transformers and CNNs for calcification mammography classification,Breast cancer is a major cause of death worldwide. The complexity of endocrine regulation in breast cancer may allow the cancer cells to escape from a particular treatment and result in resistant and aggressive disease. These breast cancers usually have fewer treatment options. Targeted therapies for cancer patients may offer fewer adverse side effects because of specificity compared to conventional chemotherapy. Signaling pathways of nuclear receptors- such as the estrogen receptor (ER)- have been intensively studied and used as therapeutic targets. Recently- the role of the androgen receptor (AR) in breast cancer is gaining greater attention as a therapeutic target and as a prognostic biomarker. The expression of constitutively active truncated AR splice variants in breast cancer is a possible mechanism contributing to treatment resistance. Therefore- targeting both the full-length AR and AR variants- either through the activation or suppression of AR function- depending on the status of the ER- progesterone receptor- or human epidermal growth factor receptor 2- may provide additional treatment options. Studies targeting AR in combination with other treatment strategies are ongoing in clinical trials. The determination of the status of nuclear receptors to classify and identify patient subgroups will facilitate optimized and targeted combination therapies.
Wei Wang- Lei Liu- Jianxiong Zhu- Youqiang Xing- Songlong Jiao- Ze Wu,AI-Enhanced Visual-Spectral Synergy for Fast and Ultrasensitive Biodetection of Breast Cancer-Related miRNAs.,Breast cancer is a dangerous disease- contributing to a high mortality rate in women. Early detection plays a pivotal role in enhancing survival rates. Breast ultrasound is considered an effective method to help diagnose breast diseases early. Breast ultrasound is inexpensive- easy to perform- non-invasive and painless- so it is often prescribed by doctors in cases where it is necessary to examine the nature of clinically palpable lesions or related symptoms in the breast. In this paper- we introduce a method based on transfer learning and deep feature fusion to classify breast cancer using ultrasound images. The results from our experiments involving 780 breast ultrasound images across three categories (benign- malignant- and normal) indicated that the model using max fusion of deep features outperformed an original CNN in terms of performance- the combination of the maximum value between deep features has a higher performance level with an accuracy of about 1% to 4% compared to the original model. The concatenation fusion of VGG19 and ViT features delivers 1% - 4% times more accuracy than the original model alone
Ling Liao- Eva M Aagaard,An open codebase for enhancing transparency in deep learning-based breast cancer diagnosis utilizing CBIS-DDSM data,In breast cancer- several gene expression assays have been developed to provide a more personalised treatment. This study focuses on the prediction of two molecular proliferation signatures: an 11-gene proliferation score and the MKI67 proliferation marker gene. The aim was to assess whether these could be predicted from digital whole slide images (WSIs) using deep learning models. WSIs and RNA-sequencing data from 819 invasive breast cancer patients were included for training- and models were evaluated on an internal test set of 172 cases as well as on 997 cases from a fully independent external test set. Two deep Convolutional Neural Network (CNN) models were optimised using WSIs and gene expression readouts from RNA-sequencing data of either the proliferation signature or the proliferation marker- and assessed using Spearman correlation (r). Prognostic performance was assessed through Cox proportional hazard modelling- estimating hazard ratios (HR). Optimised CNNs successfully predicted the proliferation score and proliferation marker on the unseen internal test set (â€šÃ¢Ã âˆšÂ¨â€šÃ Ã¶âˆšÃ±â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.691(pâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.001) with R2â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.438- and â€šÃ¢Ã âˆšÂ¨â€šÃ Ã¶âˆšÃ±â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.564 (pâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.001) with R2â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.251 respectively) and on the external test set (â€šÃ¢Ã âˆšÂ¨â€šÃ Ã¶âˆšÃ±â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.502 (pâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.001) with R2â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.319- and â€šÃ¢Ã âˆšÂ¨â€šÃ Ã¶âˆšÃ±â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.403 (pâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.001) with R2â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.222 respectively). Patients with a high proliferation score or marker were significantly associated with a higher risk of recurrence or death in the external test set (HRâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢1.65 (95% CI: 1.05-2.61) and HRâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢1.84 (95% CI: 1.17-2.89)- respectively). The results from this study suggest that gene expression levels of proliferation scores can be predicted directly from breast cancer morphology in WSIs using CNNs and that the predictions provide prognostic information that could be used in research as well as in the clinical setting.
Meena L C- Joe Prathap P M,An optimal deep learning approach for breast cancer detection and classification with pre-trained CNN-based feature learning mechanism,To explore the value of combined radiomics and deep learning models using different machine learning algorithms based on mammography (MG) and magnetic resonance imaging (MRI) for predicting axillary lymph node metastasis (ALNM) in breast cancer (BC). The objective is to provide guidance for developing scientifically individualized treatment plans- assessing prognosis- and planning preoperative interventions. A retrospective analysis was conducted on clinical and imaging data from 270 patients with BC confirmed by surgical pathology at the Third Hospital of Shanxi Medical University between November 2022 and April 2024. Multiple sequence images from MG and MRI were selected- and regions of interest in the lesions were delineated. Radiomics and deep learning (3D-Resnet18) features were extracted and fused. The samples were randomly divided into training and test sets in a 7:3 ratio. Dimensionality reduction and feature selection were performed using the least absolute shrinkage and selection operator (LASSO) regression model- and other methods. Various machine learning algorithms were used to construct radiomics- deep learning- and combined models. These models were visualized and evaluated for performance using receiver operating characteristic curves- area under the curve (AUC)- calibration curves- and decision curves. The highest AUCs in the test set were achieved using radiomics-logistic regression (AUC = 0.759)- deep learning-multilayer perceptron (MLP) (AUC = 0.712)- and combined-MLP models (AUC = 0.846). The MLP model demonstrated strong classification performance- with the combined model (AUC = 0.846) outperforming both the radiomics (AUC = 0.756) and deep learning (AUC = 0.712) models. The multimodal radiomics and deep learning models developed in this study- incorporating various machine learning algorithms- offer significant value for the preoperative prediction of ALNM in BC.
Xiangyang Zhang- Yang Chen- Changjing Cai- Yifeng Wang- Jun Tan- Zijie Fang- Le Wei- Zhuchen Shao- Liwen Wang- Tiezheng Qi- Yihan Liu- Zhaohui Jiang- Yin Li- Ying Han- Tibera Kagemulo Rugambwa- Shan Zeng- Haoqian Wang- Hong Shen- Yongbing Zhang,Artificial Intelligence Predicts Multiclass Molecular Signatures and Subtypes Directly From Breast Cancer Histology: a Multicenter Retrospective Study,The uncontrolled proliferation of breast cancer cells in a specific area of the body is the second most common cause of death among women worldwide. If the disease is detected in its early stages- it can be cured. While the use of digital image processing to detect breast cancer is not new- many new approaches are being developed to accurately predict its location. The current approach involves both visual inspection of the tumor region and determining the region in which most of the tumor is concentrated. The primary objective of this study is to determine the most efficient algorithm or combination of algorithms for the detection of breast tumors. Various algorithms have been employed in the proposed work; however- the CNN-Deep Learning model combination is the most effective for the diagnosis of breast cancer. This approach may help radiologists to evaluate screening mammography more effectively.
Aslâ€šÃ Ãœâˆšâ‰ Â¬Â¨Â¬Â±nur Albayrak- Kayhan Nuri Cengiz,Assessment of breast cancer awareness among female pharmacy students at a university in Turkey,Breast cancer remains a pressing global health concern- necessitating accurate diagnostics for effective interventions. Deep learning models (AlexNet- ResNet-50- VGG16- GoogLeNet) show remarkable microcalcification identification (>90%). However- distinct architectures and methodologies pose challenges. We propose an ensemble model- merging unique perspectives- enhancing precision- and understanding critical factors for breast cancer intervention. Evaluation favors GoogleNet and ResNet-50- driving their selection for combined functionalities- ensuring improved precision- and dependability in microcalcification detection in clinical settings. This study presents a comprehensive mammogram preprocessing framework using an optimized deep learning ensemble approach. The proposed framework begins with artifact removal using Otsu Segmentation and morphological operation. Subsequent steps include image resizing- adaptive median filtering- and deep convolutional neural network (D-CNN) development via transfer learning with ResNet-50 model. Hyperparameters are optimized- and ensemble optimization (AlexNet- GoogLeNet- VGG16- ResNet-50) are constructed to identify the localized area of microcalcification. Rigorous evaluation protocol validates the efficacy of individual models- culminating in the ensemble model demonstrating superior predictive accuracy. Based on our analysis- the proposed ensemble model exhibited exceptional performance in the classification of microcalcifications. This was evidenced by the model's average confidence score- which indicated a high degree of dependability and certainty in differentiating these critical characteristics. The proposed model demonstrated a noteworthy average confidence level of 0.9305 in the classification of microcalcification- outperforming alternative models and providing substantial insights into the dependability of the model. The average confidence of the ensemble model in classifying normal cases was 0.8859- which strengthened the model's consistent and dependable predictions. In addition- the ensemble models attained remarkably high performances in terms of accuracy- precision- recall- F1-score- and area under the curve (AUC). The proposed model's thorough dataset integration and focus on average confidence ratings within classes improve clinical diagnosis accuracy and effectiveness for breast cancer. This study introduces a novel methodology that takes advantage of an ensemble model and rigorous evaluation standards to substantially improve the accuracy and dependability of breast cancer diagnostics- specifically in the detection of microcalcifications.
Ekta- Vandana Bhatia,Auto-BCS: A Hybrid System for Real-Time Breast Cancer Screening from Pathological Images.,The rapid evolution of telehealth- or telemedicine- has spurred crucial technological advancements aimed at addressing the early stages of complex cancer conditions- where conventional diagnostic methods face challenges. This research introduces a cancer detection system that utilizes Internet of Things (IoT)-based patient records and machine learning. The primary objective is to automate real-time breast cancer monitoring and detection in residential institutions and smart hospitals- thus enhancing the delivery of quality cancer healthcare. Background: Traditional diagnostic methods- particularly physical inspection- exhibit inherent limitations in identifying breast cancer at early stages. This research responds to this challenge by leveraging innovative technologies- such as IoT and deep learning-based techniques- to overcome the constraints of conventional approaches. Objective: The primary goal of this study is to develop and implement a cancer detection system that integrates IoT-based patient records and machine learning for real-time breast cancer monitoring in residential and healthcare settings. Method: The research employs a synergistic combination of IoT technology for collecting images of residential users and Convolutional Neural Network (CNN)- a deep learning technique- for early cancer prediction. The focus lies on contributing to the overall well-being of individuals who may unknowingly be living with cancer. Result: Simulated outcomes after 25 epochs are presented- emphasizing the training accuracy of the model and its validation accuracy using the proposed VGG16 classifier. Graphical representations of the results indicate consistent performance metrics- with both validation and training accuracy exceeding 99%. Specifically- the training accuracy measures at an impressive 99.64%- while the validation accuracy stands at 99.12%. Main Findings: The study demonstrates the effectiveness of the integrated IoT and deep learning techniques in achieving high accuracy rates for early breast cancer prediction. The findings affirm the potential of this approach to assist dermatologists in identifying breast malignancies at treatable stages. Conclusion: This research establishes a foundational framework for the integration of IoT and deep learning techniques- presenting a promising avenue for advancing early cancer detection in smart healthcare systems. The proposed cancer detection system holds significant potential for improving healthcare outcomes and contributing to the overall well-being of individuals at risk of breast cancer.
Shuhan Li- Yuxuan Xiang- Hongman Li- Chunmin Yang- Wenting He- Jiahua Wu- M Tish Knobf- Zengjie Ye,Body image- self-efficacy- and sleep quality among patients with breast cancer: A latent profile and mediation analysis,Quantum machine learning holds the potential to revolutionize cancer treatment and diagnostic imaging by uncovering complex patterns beyond the reach of classical methods. This study explores the effectiveness of quantum convolutional layers in classifying ultrasound breast images for cancer detection. By encoding classical data into quantum states through angle embedding and employing a robustly entangled 9-qubit circuit design with an SU(4) gate- we developed a Quantum Convolutional Neural Network (QCNN) and compared it to a classical CNN of similar architecture. Our QCNN model- leveraging two quantum circuits as convolutional layers- achieved an impressive peak training accuracy of 76.66% and a validation accuracy of 87.17% at a learning rate of 1 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 10-2. In contrast- the classical CNN model attained a training accuracy of 77.52% and a validation accuracy of 83.33%. These compelling results highlight the potential of quantum circuits to serve as effective convolutional layers for feature extraction in image classification- especially with small datasets.
S. Kanimozhi- S. Priyadarsini,Breast Cancer Histopathological Image Classification Using CNN and VGG-19,Ferroptosis has received increasing attention as a novel nonapoptotic programmed death. Recently- iron-based nanomaterials have been extensively exploited for efficient tumor ferroptosis therapy- as they directly release high concentrations of iron and increase intracellular reactive oxygen species levels. Breast cancer is one of the commonest malignant tumors in women; inhibiting breast cancer cell proliferation through activating the ferroptosis pathway could be a potential new target for patient treatment. Here- we briefly introduce the background of ferroptosis and systematically review the current cancer therapeutic strategies based on iron-based ferroptosis inducers. Finally- we summarize the advantages of these various ferroptosis inducers and shed light on future perspectives. This review aims to provide better guidance for the development of iron-based nanomaterial ferroptosis inducers.
Elsy Cruz- Lourdes Santos- Hiram Calvo- â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšÃ±lvaro Anzueto-Râ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ os- Yenny Villuendas-Rey,Breast density classification in mammograms using VGG convolutional networks,Breast cancer is a leading cause of death among women worldwide. The emergence of Artificial Intelligence (AI) has led to significant progress in breast cancer detection research. Early detection of breast cancer is crucial for making informed decisions about treatment and eradicating the disease. Deep Learning (DL) techniques- commonly used in computer vision- have been applied to various domains- including healthcare. The Convolutional Neural Network (CNN) is a widely used model for medical image processing- but its performance may not be optimal for a specific imaging modality without empirical study. This paper introduces an enhanced CNN model called Breast Cancer Detection Network (BCDNet)- designed to be more efficient with breast mammogram images. We also propose an algorithm called Learning-Based Cancer Screening (LBCS) that leverages the BCDNet model. An empirical study using the CBID-DDSM benchmark dataset demonstrates that BCDNet outperforms many existing deep learning models- achieving the highest accuracy of 97.68%. This proposed model can be utilized for breast cancer screening in healthcare units as part of a Clinical Decision Support System (CDSS).
LaRae L Seemann- Tina Ardon- Rebecca A Bowie- Kati C Bullock- A. Clapp,Breast Pain Differential: Mondorâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s Disease of the Breast,Breast cancer continues to be a substantial worldwide health concern- affecting millions of individuals each year; this emphasizes the critical nature of early detection in order to enhance patient prognoses. The present study aims to assess the classification performance of three convolutional neural network (CNN) architectures-visual geometry group 19 (VGG19)- AlexNet- and residual network 50 (ResNet50)-with respect to breast cancer detection in medical images. Thorough assessments- encompassing metrics such as accuracy- precision- recall- and F-score- were undertaken to evaluate the diagnostic performance of the models. ResNet50 consistently outperforms other models- as evidenced by its highest accuracy and F-score. The research highlights the significant importance of carefully choosing suitable architectures for medical image analysis- with a specific focus on the detection of breast cancer. In addition- it demonstrates the capacity of deep learning models- such as ResNet50- to improve the diagnosis of breast cancer with exceptional precision and sensitivity- which is critical for reducing the occurrence of false positives and negatives in clinical environments. In addition- computational efficiency is taken into account; AlexNet is recognized as the most efficient model- which is advantageous in environments with limited resources. This study advances medical image processing by demonstrating the potential of CNNs in the detection of breast cancer. The results of this study establish a fundamental basis for sub- sequent inquiries and suggest approaches to improve timely detection and treatment- which will ultimately be advantageous for both patients and healthcare professionals.
Jessica Prunaretty- Fatima Mekki- Pierre-Ivan Laurent- Aurelie Morel- Pauline Hinault- Celine Bourgier- David Azria- Pascal Fenoglietto,Clinical feasibility of Ethos auto-segmentation for adaptive whole-breast cancer treatment,Identification of the molecular subtypes in breast cancer allows to optimize treatment strategies- but usually requires invasive needle biopsy. Recently- non-invasive imaging has emerged as promising means to classify them. Magnetic resonance imaging is often used for this purpose because it is three-dimensional and highly informative. Instead- only a few reports have documented the use of mammograms. Given that mammography is the first choice for breast cancer screening- using it to classify molecular subtypes would allow for early intervention on a much wider scale. Here- we aimed to evaluate the effectiveness of combining global and local mammographic features by using Vision Transformer (ViT) and Convolutional Neural Network (CNN) to classify molecular subtypes in breast cancer. The feature values for binary classification were calculated using the ViT and EfficientnetV2 feature extractors- followed by dimensional compression via principal component analysis. LightGBM was used to perform binary classification of each molecular subtype: triple-negative- HER2-enriched- luminal A- and luminal B. The combination of ViT and CNN achieved higher accuracy than ViT or CNN alone. The sensitivity for triple-negative subtypes was very high (0.900- with F-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.818); whereas F-value and sensitivity were 0.720 and 0.750 for HER2-enriched- 0.765 and 0.867 for luminal A- and 0.614 and 0.711 for luminal B subtypes- respectively. Features obtained from mammograms by combining ViT and CNN allow the classification of molecular subtypes with high accuracy. This approach could streamline early treatment workflows and triage- especially for poor prognosis subtypes such as triple-negative breast cancer.
Yi-Ming Wang- Chi-Yuan Wang- Kuo-Ying Liu- Yung-Hui Huang- Tai-Been Chen- Kon-Ning Chiu- Chih-Yu Liang- Nan-Han Lu,CNN-Based Cross-Modality Fusion for Enhanced Breast Cancer Detection Using Mammography and Ultrasound,Breast cancer ranks as the second most prevalent cancer globally and is the most frequently diagnosed cancer among women; therefore- early- automated- and precise detection is essential. Most AI-based techniques for breast cancer detection are complex and have high computational costs. Hence- to overcome this challenge- we have presented the innovative LightweightUNet hybrid deep learning (DL) classifier for the accurate classification of breast cancer. The proposed model boasts a low computational cost due to its smaller number of layers in its architecture- and its adaptive nature stems from its use of depth-wise separable convolution. We have employed a multimodal approach to validate the model's performance- using 13-000 images from two distinct modalities: mammogram imaging (MGI) and ultrasound imaging (USI). We collected the multimodal imaging datasets from seven different sources- including the benchmark datasets DDSM- MIAS- INbreast- BrEaST- BUSI- Thammasat- and HMSS. Since the datasets are from various sources- we have resized them to the uniform size of 256 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 256 pixels and normalized them using the Box-Cox transformation technique. Since the USI dataset is smaller- we have applied the StyleGAN3 model to generate 10-000 synthetic ultrasound images. In this work- we have performed two separate experiments: the first on a real dataset without augmentation and the second on a real + GAN-augmented dataset using our proposed method. During the experiments- we used a 5-fold cross-validation method- and our proposed model obtained good results on the real dataset (87.16% precision- 86.87% recall- 86.84% F1-score- and 86.87% accuracy) without adding any extra data. Similarly- the second experiment provides better performance on the real + GAN-augmented dataset (96.36% precision- 96.35% recall- 96.35% F1-score- and 96.35% accuracy). This multimodal approach- which utilizes LightweightUNet- enhances the performance by 9.20% in precision- 9.48% in recall- 9.51% in F1-score- and a 9.48% increase in accuracy on the combined dataset. The LightweightUNet model we proposed works very well thanks to a creative network design- adding fake images to the data- and a multimodal training method. These results show that the model has a lot of potential for use in clinical settings.
Andreas Giannakou- Canan Dagdeviren- Tolga Ozmen,Conformable Ultrasound Breast Patch - The Future of Breast Cancer Screening?,This research study initiates a multifaceted analysis of breast cancer- a pervasive malignancy originating in the mammary gland cells. Globally- breast cancer ranks as the second most commonly diagnosed cancer- surpassed only by skin cancer. While breast cancer can affect individuals of any gender- it disproportionately impacts women. In light of this significant health concern- this research study examines the notable advancements in breast cancer detection- encompassing a wide array of techniques designed to enhance early diagnosis. The success of this effort relies on old-fashioned techniques like mammograms and check-ups- which are still very important tools. Additionally- this study introduces emerging technologies- specifically AI-powered analysis of mammograms. The technologies- such as Convolutional Neural Networks (CNN) utilizing Residual Networks (ResNet)- Visual Geometry Group Networks (VGG16)- and Siamese Neural Network architectures (SNN) and Convolutional Recurrent Neural Network (CRNN) have shown promising potential to substantially enhance the diagnostic accuracy. Moreover- this study explores the application of various machine learning algorithms to collect datasets- aiming to predict the early development of breast cancer. This comprehensive approach underscores the promising future of breast cancer detection and emphasizes the importance of a multidimensional strategy in combating this global health challenge. This study utilizes the pre-existing research on Magnetic Resonance Imaging (MRI) scans of breast datasets- seeking to improve the accuracy and early detection by ultimately contributing to establish a more effective breast cancer management.
J Armstrong,Deep Learning Breast Cancer Radiology Anomaly Detection Explainability Using Statistical Fault Localization,"Brain tumours, breast cancer, and pneumonia are significant diseases causing a substantial number of deaths globally. These diseases affect a great part of the world, including India. Research on early detection strategies is critical for saving lives. This proposal describes a unique way to use deep learning approaches to detect three common diseases: breast cancer, brain tumours, and pneumonia. This approach aims to improve treatment outcomes and diagnostic accuracy by integrating a range of medical imaging modalities tailored to individual diseases. In similar challenges, DCNNs have demonstrated remarkable speed and accuracy, demonstrating their potential to enhance medical diagnosis. DCNN models can help medical professionals by providing accurate and automated illness identification, especially for areas with a shortage of radiologists."
Yaping Yang- Ying Zhong- Junwei Li- Jiahao Feng- C. Gong- Yunfang Yu- Yue Hu- R. Gu- Hongli Wang- Fengtao Liu- J. Mei- Xiaofang Jiang- Jin Wang- Qinyue Yao- Wei Wu- Qiang Liu- H. Yao,Deep learning combining mammography and ultrasound images to predict the malignancy of BI-RADS US 4A lesions in women with dense breasts: a diagnostic study,Breast cancer is the most prevalent type of disease among women. It has become one of the foremost causes of death among women globally. Early detection plays a significant role in administering personalized treatment and improving patient outcomes. Mammography procedures are often used to detect early-stage cancer cells. This traditional method of mammography while valuable has limitations of potential for false positives and negatives- patient discomfort- and radiation exposure. Therefore- there is a probe for more accurate techniques required in detecting breast cancer- leading to exploring the potential of machine learning in the classification of diagnostic images due to its efficiency and accuracy. This study conducted a comparative analysis of pre-trained CNNs (ResNet50 and VGG16) and Vision Transformers (ViT-Base and SWIN Transformer) with the inclusion of ViT-Base trained from scratch model architectures to effectively classify breast cancer mammographic images into benign and malignant cases. The Swin transformer exhibits superior performance with 99.8% accuracy and a precision of 99.8%. These findings demonstrate the efficiency of deep learning to accurately classify breast cancer mammographic images for the diagnosis of breast cancer- leading to improvement in patient outcomes.
Guangliang Yang- Haiqi Chen- Jinchao Yue,Deep learning to optimize radiotherapy decisions for elderly patients with early-stage breast cancer: a novel approach for personalized treatment,Accurately and swiftly segmenting breast tumors is significant for cancer diagnosis and treatment. Ultrasound imaging stands as one of the widely employed methods in clinical practice. However- due to challenges such as low contrast- blurred boundaries- and prevalent shadows in ultrasound images- tumor segmentation remains a daunting task. In this study- we propose BCT-Net- a network amalgamating CNN and transformer components for breast tumor segmentation. BCT-Net integrates a dual-level attention mechanism to capture more features and redefines the skip connection module. We introduce the utilization of a classification task as an auxiliary task to impart additional semantic information to the segmentation network- employing supervised contrastive learning. A hybrid objective loss function is proposed- which combines pixel-wise cross-entropy- binary cross-entropy- and supervised contrastive learning loss. Experimental results demonstrate that BCT-Net achieves high precision- with Pre and DSC indices of 86.12% and 88.70%- respectively. Experiments conducted on the BUSI dataset of breast ultrasound images manifest that this approach exhibits high accuracy in breast tumor segmentation.
Vahab Khoshdel- Nasrin Abharian- Amir Attar- Joe LoVetri,Denoising Diffusion Probabilistic Models for Generating Tissue Type Breast Image Dataset,In medical imaging- the effective detection and classification of Breast Cancer (BC) is a current research important task because of the still existing difficulty to distinguish abnormalities from normal breast tissues due to their subtle appearance and ambiguous margins and distinguish abnormalities from the normal breast. Moreover- BC detection based on an automated detection model is needed- because manual diagnosis faces problems due to cost and shortage of skilled manpower- and also takes a very long time. Using deep learning and ensemble feature selection techniques- in this paper- a novel framework is introduced for classifying BC from histopathology images. The five primary steps of the suggested framework are as follows: 1) to make the largest original dataset and then deep learning model with data augmentation to improve the learning. 2) The best features are selected by an Ensemble Filter Feature selection Method (EFFM) which combines the best feature subsets to produce the final feature subsets. 3) Then the pruned Convolution Neural Network (CNN) model is utilized to extract the optimal features. 4) Finally- the classification is done through the Triplet Attention based Efficient Network (TAENet) classifier. The suggested model produces a 98% accuracy rate after being trained and tested on two different histopathology imaging datasets including images from four different data cohorts. Subsequently- the suggested strategy outperforms the conventional ones since the ensemble filter habitually acquires the best features- and experimental results demonstrate the importance of the proposed approach
Jiahui Ren- Yili Li- Jing Zhou- Ting Yang- Jingfeng Jing- Qian Xiao- Zhongxu Duan- Ke Xiang- Yuchen Zhuang- Daxue Li- Han Gao,Developing machine learning models for personalized treatment strategies in early breast cancer patients undergoing neoadjuvant systemic therapy based on SEER database,Breast cancer is the second most common type of cancer among women. Prompt detection of breast cancer can impede its advancement to more advanced phases- thereby elevating the probability of favorable treatment consequences. Histopathological images are commonly used for breast cancer classification due to their detailed cellular information. Existing diagnostic approaches rely on Convolutional Neural Networks (CNNs) which are limited to local context resulting in a lower classification accuracy. Therefore- we present a fusion model composed of a Vision Transformer (ViT) and custom Atrous Spatial Pyramid Pooling (ASPP) network with an attention mechanism for effectively classifying breast cancer from histopathological images. ViT enables the model to attain global features- while the ASPP network accommodates multiscale features. Fusing the features derived from the models resulted in a robust breast cancer classifier. With the help of five-stage image preprocessing technique- the proposed model achieved 100% accuracy in classifying breast cancer on the BreakHis dataset at 100X and 400X magnification factors. On 40X and 200X magnifications- the model achieved 99.25% and 98.26% classification accuracy respectively. With a commendable classification efficacy on histopathological images- the model can be considered a dependable option for proficient breast cancer classification.
N. Nurbaiti- Eka Putra Syarif Hidayat- Khairil Anwar- Dudung Hermawan- Salman Izzuddin,Development of AI Models from Mammography Images with CNN for Early Detection of Breast Cancer,We present a survey of the current state-of-the-art in breast cancer detection and prognosis. We analyze the evolution of Artificial Intelligence-based approaches from using just uni-modal information to multi-modality for detection and how such paradigm shift facilitates the efficacy of detection- consistent with clinical observations. We conclude that interpretable AI-based predictions and ability to handle class imbalance should be considered priority.
Ting He- Qinan Tang- Qiaoju Ren- Yurong Liu- Gang He- Yuantao Pan- Ziguang Wang- Peng Huang- Jing Lin,Different Valence States of Copper Ion Delivery against Triple-Negative Breast Cancer.,The early detection of breast cancer is crucial for both accelerating the treatment process and preventing the spread of cancer. The accuracy of diagnosis is also significantly influenced by the experience of pathologists. Many studies have been conducted on the correct diagnosis of breast cancer to help specialists and increase the accuracy of diagnosis. This study focuses on classifying breast cancer using deep learning models- including pre-trained VGG16- MobileNet- DenseNet201- and a custom-built Convolutional Neural Network (CNN)- with the final dense layer optimized via the particle swarm optimization (PSO) algorithm. The Breast Histopathology Images Dataset was used to evaluate the performance of the model- forming two datasets: one with 157-572 images at 50 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 50 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 3 (Experimental Study 1) and another with 1116 images resized to 224 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 224 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 3 (Experimental Study 2). Both original (50 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 50 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 3) and rescaled (224 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 224 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 3) images were tested. The highest success rate was obtained using the custom-built CNN model with an accuracy rate of 93.80% for experimental study 1. The MobileNet model yielded an accuracy of 95.54% for experimental study 2. The experimental results demonstrate that the proposed model exhibits promising- and superior classification accuracy compared to state-of-the-art methods across varying image sizes and dataset volumes.
Adhari AlZaabi- Stephen Piccolo- Steven Graves- Marc Hansen,Differential Serum Peptidomics Reveal Multi-Marker Models That Predict Breast Cancer Progression,Breast cancer- as a malignant tumor disease- has maintained high incidence and mortality rates over the years. Ultrasonography is one of the primary methods for diagnosing early-stage breast cancer. However- correctly interpreting breast ultrasound images requires massive time from physicians with specialized knowledge and extensive experience. Recently- deep learning-based method have made significant advancements in breast tumor segmentation and classification due to their powerful fitting capabilities. However- most existing methods focus on performing one of these tasks separately- and often failing to effectively leverage information from specific tumor-related areas that hold considerable diagnostic value. In this study- we propose a multi-task network with local-global feature interaction and multiple tumoral region guidance for breast ultrasound-based tumor segmentation and classification. Specifically- we construct a dual-stream encoder- paralleling CNN and Transformer- to facilitate hierarchical interaction and fusion of local and global features. This architecture enables each stream to capitalize on the strengths of the other while preserving its unique characteristics. Moreover- we design a multi-tumoral region guidance module to explicitly learn long-range non-local dependencies within intra-tumoral and peri-tumoral regions from spatial domain- thus providing interpretable cues beneficial for classification. Experimental results on two breast ultrasound datasets show that our network outperforms state-of-the-art methods in tumor segmentation and classification tasks. Compared with the second-best competitive method- our network improves the diagnosis accuracy from 73.64% to 80.21% on a large external validation dataset- which demonstrates its superior generalization capability.
Neil M. Iyengar- Erica Salehi- Jessica A Lavery- Olivia Chan- Sarah Lehman- M. Michalski- Gina A Fickera- Adele M. Carlson- Jenna Harrison- Whitney P Underwood- Cara Anselmo- Su S Chun- Stephanie Cao- Catherine P. Lee- Wendy Demark-Wahnefried- C. Moskowitz- Lee W. Jones,Effects of plant-based diet (PBD) and exercise therapy (Ex) on weight and body composition in patients with primary hormone receptor (HR) positive breast cancer: A phase 2 randomized controlled trial.,Breast cancer (BC) is the leading cause of mortality among women across the world. Earlier screening of BC can significantly reduce the mortality rate and assist the diagnostic process to increase the survival rate. Researchers employ deep learning (DL) techniques to detect BC using mammogram images. However- these techniques are resource-intensive- leading to implementation complexities in real-life environments. The performance of convolutional neural network (CNN) models depends on the quality of mammogram images. Thus- this study aimed to build a model to detect BC using a DL technique. Image preprocessing techniques were used to enhance image quality. The authors developed a CNN model using the EfficientNet B7 modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s weights to extract the image features. Multi-class classification of BC images was performed using the LightGBM model. The Optuna algorithm was used to fine-tune LightGBM for image classification. In addition- a quantization-aware training (QAT) strategy was followed to implement the proposed model in a resource-constrained environment. The authors generalized the proposed model using the CBIS-DDSM and CMMD datasets. Additionally- they combined these two datasets to ensure the modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s generalizability to diverse images. The experimental findings revealed that the suggested BC detection model produced a promising result. The proposed BC detection model obtained an accuracy of 99.4%- 99.9%- and 97.0%- and Kappa (K) values of 96.9%- 96.9%- and 94.1% in the CBIS-DDSM- CMMD- and combined datasets. The recommended model streamlined the BC detection process in order to achieve an exceptional outcome. It can be deployed in a real-life environment to support physicians in making effective decisions. Graph convolutional networks can be used to improve the performance of the proposed model.
Zi-Han Yu- Yu-Ting Hong- Chen-Pin Chou,Enhancing Breast Cancer Diagnosis: A Nomogram Model Integrating AI Ultrasound and Clinical Factors,Axillary lymph node (ALN) status is a crucial prognostic indicator for breast cancer metastasis- with manual interpretation of whole slide images (WSIs) being the current standard practice. However- this method is subjective and time-consuming. Recent advancements in deep learning-based methods for medical image analysis have shown promise in improving clinical diagnosis. This study aims to leverage these technological advancements to develop a deep learning model based on features extracted from primary tumor biopsies for preoperatively identifying ALN metastasis in early-stage breast cancer patients with negative nodes. We present DLCNBC-SA- a deep learning-based network specifically tailored for core needle biopsy and clinical data feature extraction- which integrates a self-attention mechanism (CNBC-SA). The proposed model consists of a feature extractor based on convolutional neural network (CNN) and an improved self-attention mechanism module- which can preserve the independence of features in WSIs for analysis and enhancement to provide rich feature representation. To validate the performance of the proposed model- we conducted comparative experiments and ablation studies using publicly available datasets- and verification was performed through quantitative analysis. The comparative experiment illustrates the superior performance of the proposed model in the task of binary classification of ALNs- as compared to alternative methods. Our method achieved outstanding performance [area under the curve (AUC): 0.882] in this task- significantly surpassing the state-of-the-art (SOTA) method on the same dataset (AUC: 0.862). The ablation experiment reveals that incorporating RandomRotation data augmentation technology and utilizing Adadelta optimizer can effectively enhance the performance of the proposed model. The experimental results demonstrate that the model proposed in this paper outperforms the SOTA model on the same dataset- thereby establishing its reliability as an assistant for pathologists in analyzing WSIs of breast cancer. Consequently- it significantly enhances both the efficiency and accuracy of doctors during the diagnostic process.
Yasemin â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶Â¬âˆžetin-Kaya,Equilibrium Optimization-Based Ensemble CNN Framework for Breast Cancer Multiclass Classification Using Histopathological Image,This study explores the integration of Raman spectroscopy (RS) with machine learning for the early detection and subtyping of breast cancer using blood plasma samples. We performed detailed spectral analyses- identifying significant spectral patterns associated with cancer biomarkers. Our findings demonstrate the potential for classifying the four major subtypes of breast cancer at stage Ia with an average sensitivity and specificity of 90% and 95%- respectively- and a cross-validated macro-averaged area under the curve (AUC) of 0.98. This research highlights efforts to integrate vibrational spectroscopy with machine learning- enhancing cancer diagnostics through a non-invasive- personalised approach for early detection and monitoring disease progression. This study is the first of its kind to utilise RS and machine learning to classify the four major breast cancer subtypes at stage Ia.
Avisha Das- Amara Tariq- Felipe Batalini- Boddhisattwa Dhara- Imon Banerjee,Exposing Vulnerabilities in Clinical LLMs Through Data Poisoning Attacks: Case Study in Breast Cancer,Brain tumours- breast cancer- and pneumonia are significant diseases causing a substantial number of deaths globally. These diseases affect a great part of the world- including India. Research on early detection strategies is critical for saving lives. This proposal describes a unique way to use deep learning approaches to detect three common diseases: breast cancer- brain tumours- and pneumonia. This approach aims to improve treatment outcomes and diagnostic accuracy by integrating a range of medical imaging modalities tailored to individual diseases. In similar challenges- DCNNs have demonstrated remarkable speed and accuracy- demonstrating their potential to enhance medical diagnosis. DCNN models can help medical professionals by providing accurate and automated illness identification- especially for areas with a shortage of radiologists.
Basamma Patil- Vishwanath P- Mohammed Al-Farouni- B. Sathyavani- P. Pareek,Improved Butterfly Optimization Algorithm for Automated Breast Cancer Detection and Classification using Deep Learning,Breast cancer is considered one of the most-common types of cancers among females in the world- with a high mortality rate. Medical imaging is still one of the most-reliable tools to detect breast cancer. Unfortunately- manual image detection takes much time. This paper proposes a new deep learning method based on Convolutional Neural Networks (CNNs). Convolutional Neural Networks are widely used for image classification. However- the determination process for accurate hyperparameters and architectures is still a challenging task. In this work- a highly accurate CNN model to detect breast cancer by mammography was developed. The proposed method is based on the Particle Swarm Optimization (PSO) algorithm in order to look for suitable hyperparameters and the architecture for the CNN model. The CNN model using PSO achieved success rates of 98.23% and 97.98% on the DDSM and MIAS datasets- respectively. The experimental results proved that the proposed CNN model gave the best accuracy values in comparison with other studies in the field. As a result- CNN models for mammography classification can now be created automatically. The proposed method can be considered as a powerful technique for breast cancer prediction.
Lorenzo Gerratana- Andrew A Davis- Lorenzo Foffano- Carolina Reduzzi- Tania Rossi- Arielle Medford- Katherine Clifton- Ami N Shah- Leslie Bucheit- Marko Velimirovic- Sara Bandini- Charles S Dai- Firas Wehbe- William J Gradishar- Amir Behdad- Paola Ulivi- Cynthia X Ma- Fabio Puglisi- Aditya Bardia- Massimo Cristofanilli,Integrating machine learning-predicted circulating tumor cells (CTCs) and circulating tumor DNA (ctDNA) in metastatic breast cancer: A proof of principle study on endocrine resistance profiling,Early detection leading to timely treatment in the initial stages of cancer may decrease the breast cancer death rate. We propose deep learning techniques along with image processing for the detection of tumors. The availability of online datasets and advances in graphical processing units (GPU) have promoted the application of deep learning models for the detection of breast cancer. In this paper- deep learning models using convolutional neural network (CNN) have been built to automatically classify mammograms into benign and malignant. Issues like overfitting and dataset imbalance are overcome. Experimentation has been done on two publicly available datasets- namely mammographic image analysis society (MIAS) database and digital database for screening mammography (DDSM). Robustness of the models is accomplished by merging the datasets. In our experimentation- MatConvNet has achieved an accuracy of 94.2% on the merged dataset- performing the best amongst all the CNN models used individually. Hungarian optimization algorithm is employed for selection of individual CNN models to form an ensemble. Ensemble of CNN models led to an improved performance- resulting in an accuracy of 95.7%.
Hari Mohan Rai- Joon Yoo- Saurabh Agarwal- Neha Agarwal,LightweightUNet: Multimodal Deep Learning with GAN-Augmented Imaging Data for Efficient Breast Cancer Detection,Abstract Objective Breast cancer is one of the leading cancer causes among women worldwide. It can be classified as invasive ductal carcinoma (IDC) or metastatic cancer. Early detection of breast cancer is challenging due to the lack of early warning signs. Generally- a mammogram is recommended by specialists for screening. Existing approaches are not accurate enough for realâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢time diagnostic applications and thus require better and smarter cancer diagnostic approaches. This study aims to develop a customized machineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢learning framework that will give more accurate predictions for IDC and metastasis cancer classification. Methods This work proposes a convolutional neural network (CNN) model for classifying IDC and metastatic breast cancer. The study utilized a largeâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢scale dataset of microscopic histopathological images to automatically perceive a hierarchical manner of learning and understanding. Results It is evident that using machine learning techniques significantly (15%â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®25%) boost the effectiveness of determining cancer vulnerability- malignancy- and demise. The results demonstrate an excellent performance ensuring an average of 95% accuracy in classifying metastatic cells against benign ones and 89% accuracy was obtained in terms of detecting IDC. Conclusions The results suggest that the proposed model improves classification accuracy. Therefore- it could be applied effectively in classifying IDC and metastatic cancer in comparison to other stateâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ofâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢theâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢art models.
Xiao Guo- Jiaying Xing- Yuyan Cao- Wenchuang Yang- Xinlin Shi- Runhong Mu- Tao Wang,Machine learning based anoikis signature predicts personalized treatment strategy of breast cancer,The vision transformer (ViT) architecture- with its attention mechanism based on multi-head attention layers- has been widely adopted in various computer-aided diagnosis tasks due to its effectiveness in processing medical image information. ViTs are notably recognized for their complex architecture- which requires high-performance GPUs or CPUs for efficient model training and deployment in real-world medical diagnostic devices. This renders them more intricate than convolutional neural networks (CNNs). This difficulty is also challenging in the context of histopathology image analysis- where the images are both limited and complex. In response to these challenges- this study proposes a TokenMixer hybrid-architecture that combines the strengths of CNNs and ViTs. This hybrid architecture aims to enhance feature extraction and classification accuracy with shorter training time and fewer parameters by minimizing the number of input patches employed during training- while incorporating tokenization of input patches using convolutional layers and encoder transformer layers to process patches across all network layers for fast and accurate breast cancer tumor subtype classification. The TokenMixer mechanism is inspired by the ConvMixer and TokenLearner models. First- the ConvMixer model dynamically generates spatial attention maps using convolutional layers- enabling the extraction of patches from input images to minimize the number of input patches used in training. Second- the TokenLearner model extracts relevant regions from the selected input patches- tokenizes them to improve feature extraction- and trains all tokenized patches in an encoder transformer network. We evaluated the TokenMixer model on the BreakHis public dataset- comparing it with ViT-based and other state-of-the-art methods. Our approach achieved impressive results for both binary and multi-classification of breast cancer subtypes across various magnification levels (40â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 100â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 200â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 400â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢). The model demonstrated accuracies of 97.02% for binary classification and 93.29% for multi-classification- with decision times of 391.71 and 1173.56Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ s- respectively. These results highlight the potential of our hybrid deep ViT-CNN architecture for advancing tumor classification in histopathological images. The source code is accessible: https://github.com/abimouloud/TokenMixer .
Robert T Novo- Samantha M Thomas- Michel G Khouri- Fawaz Alenezi- James E Herndon- Meghan Michalski- Kereshmeh Collins- Tormod Nilsen- Elisabeth Edvardsen- Lee W Jones- Jessica M Scott,Machine Learning-Driven Phenogrouping and Cardiorespiratory Fitness Response in Metastatic Breast Cancer,"To develop and evaluate an AI algorithm that detects breast cancer in MRI scans up to one year before radiologists typically identify it- potentially enhancing early detection in high-risk women. A convolutional neural network (CNN) AI model- pre-trained on breast MRI data- was fine-tuned using a retrospective dataset of 3029 MRI scans from 910 patients. These contained 115 cancers that were diagnosed within one year of a negative MRI. The model aimed to identify these cancers- with the goal of predicting cancer development up to one year in advance. The network was fine-tuned and tested with 10-fold cross-validation. Mean age of patients was 52 years (range- 18-88 years)- with average follow-up of 4.3 years (range 1-12 years). The AI detected cancers one year earlier with an area under the ROC curve of 0.72 (0.67-0.76). Retrospective analysis by a radiologist of the top 10% highest risk MRIs as ranked by the AI could have increased early detection by up to 30%. (35/115- CI:22.2-39.7%- 30% sensitivity). A radiologist identified a visual correlate to biopsy-proven cancers in 83 of prior-year MRIs (83/115- CI: 62.1-79.4%). The AI algorithm identified the anatomic region where cancer would be detected in 66 cases (66/115- CI:47.8-66.5%); with both agreeing in 54 cases (54/115- CI:%37.5-56.4%). This novel AI-aided re-evaluation of ""benign"" breasts shows promise for improving early breast cancer detection with MRI. As datasets grow and image quality improves- this approach is expected to become even more impactful."
Daniel â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšÃ±lvarez Sâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»nchez-Bayuela- Juan Fernâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»ndez Martâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ n- Gianluigi Tiberi- Navid Ghavami- Rubâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨Â¬Â©n Giovanetti Gonzâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»lez- Lina Marcela Cruz Hernâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»nez- Paul Martâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ n Aguilar Angulo- Aarâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„Â¢n Darâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ o Martâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ nez Gâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„Â¢mez- Ana Rodrâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ guez Sâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»nchez- Alessandra Bigotti- Banafsheh Khalesi- Letizia Pontoriero- Massimo Calabrese- Alberto Stefano Tagliafico- Cristina Romero Castellano,Microwave imaging for breast cancer screening: protocol for an open- multicentric- interventional- prospective- non-randomised clinical investigation to evaluate cancer detection capabilities of MammoWave system on an asymptomatic population across multiple European countries,The rapid advancement of deep learning has generated considerable enthusiasm regarding its utilization in addressing medical imaging issues. Machine learning (ML) methods can help radiologists to diagnose breast cancer (BCs) barring invasive measures. Informative hand-crafted features are essential prerequisites for traditional machine learning classifiers to achieve accurate results- which are time-consuming to extract. In this paper- our deep learning algorithm is created to precisely identify breast cancers on screening mammograms- employing a training method that effectively utilizes training datasets with either full clinical annotation or solely the cancer status of the entire image. The proposed approach utilizes Lightweight Convolutional Neural Network (LWCNN) that allows automatic extraction features in an end-to-end manner. We have tested LWCNN model in two experiments. In the first experiment- the model was tested with two cases' original and enhancement datasets 1. It achieved 95Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- 93Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- 99Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % and 98Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % for training and testing accuracy respectively. In the second experiment- the model has been tested with two cases' original and enhancement datasets 2. It achieved 95Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- 91Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- 99Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % and 92Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % for training and testing accuracy respectively. Our proposed method- which uses various convolutional network to classify screening mammograms achieved exceptional performance when compared to other methods. The findings from these experiments clearly indicate that automatic deep learning techniques can be trained effectively to attain remarkable accuracy across a wide range of mammography datasets. This holds significant promise for improving clinical tools and reducing both false positive and false negative outcomes in screening mammography.
Xia Wu- Mengxin Chen- Kang Liu- Yixin Wu- Yun Feng- Shiting Fu- Huaimeng Xu- Yongqi Zhao- Feilong Lin- Liang Lin- Shihui Ye- Junqiang Lin- Taiping Xiao- Wenhao Li- Meng Lou- Hongyu Lv- Ye Qiu- Ruifan Yu- Wenyan Chen- Mengyuan Li- Xu Feng- Zhongbing Luo- Lu Guo- Hao Ke- Limin Zhao,Molecular classification of geriatric breast cancer displays distinct senescent subgroups of prognostic significance,Purpose To combine deep learning and biology-based modeling to predict the response of locally advanced- triple-negative breast cancer before initiating neoadjuvant chemotherapy (NAC). Materials and Methods In this retrospective study- a biology-based mathematical model of tumor response to NAC was constructed and calibrated on a patient-specific basis using imaging data from patients enrolled in the MD Anderson A Robust TNBC Evaluation FraMework to Improve Survival trial (ARTEMIS; ClinicalTrials.gov registration no. NCT02276443) between April 2018 and May 2021. To relate the calibrated parameters in the biology-based model and pretreatment MRI data- a convolutional neural network (CNN) was employed. The CNN predictions of the calibrated model parameters were used to estimate tumor response at the end of NAC. CNN performance in the estimations of total tumor volume (TTV)- total tumor cellularity (TTC)- and tumor status was evaluated. Model-predicted TTC and TTV measurements were compared with MRI-based measurements using the concordance correlation coefficient and area under the receiver operating characteristic curve (for predicting pathologic complete response at the end of NAC). Results The study included 118 female patients (median age- 51 years [range- 29-78 years]). For comparison of CNN predicted to measured change in TTC and TTV over the course of NAC- the concordance correlation coefficient values were 0.95 (95% CI: 0.90- 0.98) and 0.94 (95% CI: 0.87- 0.97)- respectively. CNN-predicted TTC and TTV had an area under the receiver operating characteristic curve of 0.72 (95% CI: 0.34- 0.94) and 0.72 (95% CI: 0.40- 0.95) for predicting tumor status at the time of surgery- respectively. Conclusion Deep learning integrated with a biology-based mathematical model showed good performance in predicting the spatial and temporal evolution of a patient's tumor during NAC using only pre-NAC MRI data. Keywords: Triple-Negative Breast Cancer- Neoadjuvant Chemotherapy- Convolutional Neural Network- Biology-based Mathematical Model Supplemental material is available for this article. Clinical trial registration no. NCT02276443 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â©RSNA- 2024 See also commentary by Mei and Huang in this issue.
Sang Won Park- Ye-Lin Park- Eun-Gyeong Lee- Heejung Chae- Phillip Park- Dong-Woo Choi- Yeon Ho Choi- Juyeon Hwang- Seohyun Ahn- Keunkyun Kim- Woo Jin Kim- Sun-Young Kong- So-Youn Jung- Hyun-Jin Kim,Mortality Prediction Modeling for Patients with Breast Cancer Based on Explainable Machine Learning,Background/Objectives: Breast cancer is a leading cause of mortality among women in Taiwan and globally. Non-invasive imaging methods- such as mammography and ultrasound- are critical for early detection- yet standalone modalities have limitations in regard to their diagnostic accuracy. This study aims to enhance breast cancer detection through a cross-modality fusion approach combining mammography and ultrasound imaging- using advanced convolutional neural network (CNN) architectures. Materials and Methods: Breast images were sourced from public datasets- including the RSNA- the PAS- and Kaggle- and categorized into malignant and benign groups. Data augmentation techniques were used to address imbalances in the ultrasound dataset. Three models were developed: (1) pre-trained CNNs integrated with machine learning classifiers- (2) transfer learning-based CNNs- and (3) a custom-designed 17-layer CNN for direct classification. The performance of the models was evaluated using metrics such as accuracy and the Kappa score. Results: The custom 17-layer CNN outperformed the other models- achieving an accuracy of 0.964 and a Kappa score of 0.927. The transfer learning model achieved moderate performance (accuracy 0.846- Kappa 0.694)- while the pre-trained CNNs with machine learning classifiers yielded the lowest results (accuracy 0.780- Kappa 0.559). Cross-modality fusion proved effective in leveraging the complementary strengths of mammography and ultrasound imaging. Conclusions: This study demonstrates the potential of cross-modality imaging and tailored CNN architectures to significantly improve diagnostic accuracy and reliability in breast cancer detection. The custom-designed model offers a practical solution for early detection- potentially reducing false positives and false negatives- and improving patient outcomes through timely and accurate diagnosis.
Qiang Li- George Teodoro- Yi Jiang- Jun Kong,NACNet: A histology context-aware transformer graph convolution network for predicting treatment response to neoadjuvant chemotherapy in Triple Negative Breast Cancer,Breast cancer is one of the most common causes of death in women in the modern world. Cancerous tissue detection in histopathological images relies on complex features related to tissue structure and staining properties. Convolutional neural network (CNN) models like ResNet50- Inception-V1- and VGG-16- while useful in many applications- cannot capture the patterns of cell layers and staining properties. Most previous approaches- such as stain normalization and instance-based vision transformers- either miss important features or do not process the whole image effectively. Therefore- a deep fusion-based vision Transformer model (DFViT) that combines CNNs and transformers for better feature extraction is proposed. DFViT captures local and global patterns more effectively by fusing RGB and stain-normalized images. Trained and tested on several datasets- such as BreakHis- breast cancer histology (BACH)- and UCSC cancer genomics (UC)- the results demonstrate outstanding accuracy- F1 score- precision- and recall- setting a new milestone in histopathological image analysis for diagnosing breast cancer.
Vijayshri Chaurasia- Mamta Patankar- Madhu Shandilya- Vivek Patel- Ebtasam Ahmad Siddiqui- Laxmi Kumre,Nucleion Segmentation for Breast Cancer Classification,Breast cancer is one of the most common cancers in the world- especially among women. Breast tumor segmentation is a key step in the identification and localization of the breast tumor region- which has important clinical significance. Inspired by the swin-transformer model with powerful global modeling ability- we propose a semantic segmentation framework named Swin-Net for breast ultrasound images- which combines Transformer and Convolutional Neural Networks (CNNs) to effectively improve the accuracy of breast ultrasound segmentation. Firstly- our model utilizes a swin-transformer encoder with stronger learning ability- which can extract features of images more precisely. In addition- two new modules are introduced in our method- including the feature refinement and enhancement module (RLM) and the hierarchical multi-scale feature fusion module (HFM)- given that the influence of ultrasonic image acquisition methods and the characteristics of tumor lesions is difficult to capture. Among them- the RLM module is used to further refine and enhance the feature map learned by the transformer encoder. The HFM module is used to process multi-scale high-level semantic features and low-level details- so as to achieve effective cross-layer feature fusion- suppress noise- and improve model segmentation performance. Experimental results show that Swin-Net performs significantly better than the most advanced methods on the two public benchmark datasets. In particular- it achieves an absolute improvement of 1.4â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®1.8% on Dice. Additionally- we provide a new dataset of breast ultrasound images on which we test the effect of our model- further demonstrating the validity of our method. In summary- the proposed Swin-Net framework makes significant advancements in breast ultrasound image segmentation- providing valuable exploration for research and applications in this domain.
Jung In Park- Steven Johnson- Lisiane Pruinelli,Optimizing pain management in breast cancer care: Utilizing 'All of Us' data and deep learning to identify patients at elevated risk for chronic pain,Segmentation is a technique for separating an image into discrete areas in order to separate objects of interest from their surroundings. In image analysis- segmentationâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶âˆšÃœwhich encompasses detection- feature extraction- classification- and treatmentâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶âˆšÃœis crucial. In order to plan treatments- segmentation aids doctors in measuring the amount of tissue in the breast. Categorizing the input data into two groups that are mutually exclusive is the aim of a binary classification problem. In this case- the training data is labeled in a binary format based on the problem being solved. Identifying breast lumps accurately in mammography pictures is essential for the purpose of prenatal testing for breast cancer. The proposed TLA (Transfer Learning Approach) based CNN (Convolution Neural Network) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®TLA based CNN aims to offer binary classification for rapid and precise breast cancer diagnosis (benign and malignant). In order to predict the sub-type of cancer- this exploration as used Deep Learning techniques on the Histogram of Oriented Gradient (HOG) - Feature extraction technique that creates a local histogram of the image to extract features from each place in the image with CNN classifier. This research work employs two well-known pre-trained models- ResNet-50 and VGG16- to extract characteristics from mammography images. The high-level features from the Mammogram dataset are extracted using a transfer learning model based on Visual Geometry Group (VGG) with 16-layer and Residual Neural Network with 50-layers deep model architecture (ResNet-50). The proposed model TLA based CNN has achieved 96.49% and 95.48% accuracy as compared to ResNet50 and VGG16 in the breast cancer classification and segmentation.
Yiannis Varnava- Kiran Jakate- Richard Garnett- Dimitrios Androutsos- Pascal N Tyrrell- April Khademi,Out-of-distribution generalization for segmentation of lymph node metastasis in breast cancer,This project- entitled â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Integrative Breast Cancer Detection: A Deep Learning Approach with Multi-Modal Data Fusion of Mammograms- Prescription- and Blood Reports-â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Å“Ã„ embodies a groundbreaking endeavor poised to revolutionize the landscape of breast cancer detection. By intricately weaving together a sophisticated deep learning framework- it aims not merely to improve but to fundamentally transform the diagnostic paradigm. At its core- this initiative seeks to synergize diverse datasets encompassing blood reports- prescription data- and mammograms- thus harnessing the collective power of multi-modal data fusion. Through the judicious integration of these disparate yet complementary sources of information- the project endeavors to transcend the limitations of conventional diagnostic approaches- heralding a new era of heightened precision and diagnostic efficacy. Employing cutting-edge methodologies such as Convolutional Neural Networks (CNNs)- it aims to unlock previously untapped potentials in breast cancer detection- pushing the boundaries of what is deemed possible. By harnessing the formidable computational prowess of CNNs- the goal is not only to enhance the accuracy of detection but also to streamline the diagnostic process- thereby empowering healthcare professionals with unprecedented insights and capabilities. However- the significance of this project extends beyond mere technological advancement; it embodies a holistic approach to healthcare that prioritizes the integration of disparate datasets- efficient resource allocation- and ultimately- the delivery of personalized and patient-centric care. By championing this holistic paradigm- the project endeavors to detect breast cancer at its earliest stages and empower patients and healthcare providers alike in the fight against this insidious disease. In essence- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Integrative Breast Cancer Detectionâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Å“Ã„ represents a bold and visionary initiative poised to redefine the standards of breast cancer diagnostics- ushering in a new era of precision medicine and personalized care.
Oluwatosin Seyi Oyebanji- Akinkunmi Rasheed APAMPA- Olugesun Afolabi- Samson Ohikhuare Eromonsei- Akeem Babalola,Performance benchmarking of convolutional neural networks and ensemble machine learning techniques for automated mammographic breast cancer detection: A comparative study,Abstract: Invasion of neighboring tissues is a cardinal feature of malignancy- notably observed in aggressive cancers like breast cancer- where it can lead to significant morbidity. To explore cancer invasion dynamics- the implementation of a three-dimensional (3D) tumor spheroid invasion assay offers a swift approach to mimicking a tumor micro-region or micro-metastasis. Differential Interference Contrast (DIC) time-lapse imaging was chosen for its fluorescence-free and non-destructive advantages in capturing live spheroid movement. However- the subsequent analysis posed challenges- including out-of-focus cells and a voluminous dataset with diverse microscope planes and time points. Our study introduces a segmentation framework featuring in-focus spatial stacking algorithm and novel training architecture that enabling in-depth automated analysis of 3D spheroid invasion behaviors within a microenvironment. Firstly- the MDA-MB-231 breast cancer spheroids were cultured in a microwell dish and then incorporated into a collagen type I matrix for the 3D spheroid invasion assay. Capturing spheroid invasion dynamics involved acquiring 15 z-plane images (spaced at 20 Â¬Â¨Â¬Â®Â¬Â¨Â¬Âµm intervals) per timepoint for each spheroid using DIC microscopy at 15-minute intervals over a 28-hour period- employing a 20X objective lens. We refined the Focus Stacking framework into Multiple Slices Blurry Stacking (MSB-Stack) by pre-filtering blurred areas before stacking images. This process produced 6390 slices consolidated into 426 labeled stacked images- highlighting Invasive area- Spheroid core- and Invasive cells post-invasion. We then enhanced Mask R-CNN (Region based-Convolutional Neural Networks) with a weak-to-strong augmentation mechanism- leveraging well-segmented samples from MSB-Stack for training on both fully stacked and blurred images. Blurry Consistency Mask R-CNN (BCMask R-CNN) demonstrates overall improvement across feature extractors- outperforming Mask R-CNN. Using Mean average precision (mAP) as the main metric for instance segmentation and detection- our proposed model achieves 73.0% and 65.2% on mAP @[0.5- 0.95]- showcasing robustness. Notably- our best results for mAP @0.5 reach 96.6% and 96.7% on both tasks- underscoring the effectiveness of consistency training in mitigating unclear boundary issues during preprocessing. In conclusion- our proposed method- MSB-Stack- effectively addresses the challenge of unclear boundaries in 3D breast cancer cell DIC microscopy datasets. The integration of weak-to-strong consistency training in our model- BCMask R-CNN- not only mitigates biases but also enhances performance across different backbones- setting the stage for future advancements in cell-tracking tasks and broader migratory analyses.
Andreas Ekholm- Yinxi Wang- Johan Vallon-Christersson- Constance Boissin- Mattias Rantalainen,Prediction of gene expression-based breast cancer proliferation scores from histopathology whole slide images using deep learning,Breast cancer is a leading cause of death among women- and early detection is crucial for improving survival rates. The manual breast cancer diagnosis utilizes more time and is subjective. Also- the previous CAD models mostly depend on manmade visual details that are complex to generalize across ultrasound images utilizing distinct techniques. Distinct imaging tools have been utilized in previous works such as mammography and MRI. However- these imaging tools are costly and less portable than ultrasound imaging. Also- ultrasound imaging is a non-invasive method commonly used for breast cancer screening. Hence- the paper presents a novel deep learning model- BCDNet- for classifying breast tumors as benign or malignant using ultrasound images. The primary aim of the study is to design an effective breast cancer diagnosis model that can accurately classify tumors in their early stages- thus reducing mortality rates. The model aims to optimize the weight and parameters using the RPAOSM-ESO algorithm to enhance accuracy and minimize false negative rates. The BCDNet model utilizes transfer learning from a pre-trained VGG16 network for feature extraction and employs an AHDNAM classification approach- which includes ASPP- DTCN- 1DCNN- and an attention mechanism. The RPAOSM-ESO algorithm is used to fine-tune the weights and parameters. The RPAOSM-ESO-BCDNet-based breast cancer diagnosis model provided 94.5 accuracy rates. This value is relatively higher than the previous models such as DTCN (88.2)- 1DCNN (89.6)- MobileNet (91.3)- and ASPP-DTC-1DCNN-AM (93.8). Hence- it is guaranteed that the designed RPAOSM-ESO-BCDNet produces relatively accurate solutions for the classification than the previous models. The BCDNet model- with its sophisticated feature extraction and classification techniques optimized by the RPAOSM-ESO algorithm- shows promise in accurately classifying breast tumors using ultrasound images. The study suggests that the model could be a valuable tool in the early detection of breast cancer- potentially saving lives and reducing the burden on healthcare systems.
Jing Wang- Baizhou Li- Meng Luo- Jia Huang- Kun Zhang- Shu Zheng- Suzhan Zhang- Jiaojiao Zhou,Progression from ductal carcinoma in situ to invasive breast cancer: molecular features and clinical significance,This study aims to assess the diagnostic value of ultrasound habitat sub-region radiomics feature parameters using a fully connected neural networks (FCNN) combination method L2-1-norm in relation to breast cancer Ki-67 status. Ultrasound images from 528 cases of female breast cancer at the Affiliated Hospital of Xiangnan University and 232 cases of female breast cancer at the Affiliated Rehabilitation Hospital of Xiangnan University were selected for this study. We utilized deep learning methods to automatically outline the gross tumor volume and perform habitat clustering. Subsequently- habitat sub-regions were extracted to identify radiomics features and underwent feature engineering using the L1-2-norm. A prediction model for the Ki-67 status of breast cancer patients was then developed using a FCNN. The model's performance was evaluated using accuracy- area under the curve (AUC)- specificity (Spe)- positive predictive value (PPV)- negative predictive value (NPV)- Recall- and F1. In addition- calibration curves and clinical decision curves were plotted for the test set to visually assess the predictive accuracy and clinical benefit of the models. Based on the feature engineering using the L1-2-norm- a total of 9 core features were identified. The predictive model- constructed by the FCNN model based on these 9 features- achieved the following scores: ACC 0.856- AUC 0.915- Spe 0.843- PPV 0.920- NPV 0.747- Recall 0.974- and F1 0.890. Furthermore- calibration curves and clinical decision curves of the validation set demonstrated a high level of confidence in the model's performance and its clinical benefit. Habitat clustering of ultrasound images of breast cancer is effectively supported by the combined implementation of the L1-2-norm and FCNN algorithms- allowing for the accurate classification of the Ki-67 status in breast cancer patients.
Debanjan Mukherjee- Sarjana Raikwar,Recent Update on Nanocarrier(s) as the Targeted Therapy for Breast Cancer,The objective is to evaluate the feasibility of utilizing ultrasound images in identifying critical prognostic biomarkers for HER2-positive breast cancer (HER2â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢BC). This study enrolled 512 female patients diagnosed with HER2-positive breast cancer through pathological validation at our institution from January 2016 to December 2021. Five distinct deep convolutional neural networks (DCNNs) and a deep ensemble (DE) approach were trained to classify axillary lymph node involvement (ALNM)- lymphovascular invasion (LVI)- and histological grade (HG). The efficacy of the models was evaluated based on accuracy- sensitivity- specificity- positive predictive value (PPV)- negative predictive value (NPV)- receiver operating characteristic (ROC) curves- areas under the ROC curve (AUCs)- and heat maps. DeLong test was applied to compare differences in AUC among different models. The deep ensemble approach- as the most effective model- demonstrated AUCs and accuracy of 0.869 (95% CI: 0.802-0.936) and 69.7% in LVI- 0.973 (95% CI: 0.949-0.998) and 73.8% in HG- thus providing superior classification performance in the context of imbalanced data (pâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.05 by the DeLong test). On ALNM- AUC and accuracy were 0.780 (95% CI: 0.688-0.873) and 77.5%- which were comparable to other single models. The pretreatment US-based DE model could hold promise as a clinical guidance for predicting pathological characteristics of patients with HER2-positive breast cancer- thereby providing benefit of facilitating timely adjustments in treatment strategies.
Xiu-Ying Tang- Yu-Xian Wei- Ling-Na Kong- Fang Lu,Relationship between social support and self-care ability among patients with breast cancer during rehabilitation: The multiple mediating roles of resilience and depression,In this research- we present a Convolutional Neural Network (CNN) model designed to improve the detection and classification of breast cancer from mammographic images. By categorizing images as normal- benign- or malignant- our simplified CNN model aims to increase the precision and speed of breast cancer screenings. The effectiveness of the model was validated using established MIAS and DDSM datasets- where it achieved impressive precision rates of 94.23% and 95.53%- respectively. Moreover- the modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s performance further improved- reaching an accuracy of 96.67%- when assessed on a combined dataset. These results demonstrate the considerable potential of leveraging CNN-based deep learning techniques to enhance early detection practices in breast cancer care- offering new prospects for clinical application and advancements in medical imaging technologies.
Rashed Al Amin- Roman Obermaisser,Resource-Efficient FPGA Implementation for Real-Time Breast Cancer Classification Using Custom CNNs,BACKGROUND This study evaluated the accuracy- clinical concordance- and readability of the chatbot interface generative pretrained transformer (ChatGPT) 3.5 as a source of breast cancer information for patients. METHODS Twenty questions that patients are likely to ask ChatGPT were identified by breast cancer advocates. These were posed to ChatGPT 3.5 in July 2023 and were repeated three times. Responses were graded in two domains: accuracy (4-point Likert scale- 4Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ worst) and clinical concordance (information is clinically similar to physician response; 5-point Likert scale- 5Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ not similar at all). The concordance of responses with repetition was estimated using intraclass correlation coefficient (ICC) of word counts. Response readability was calculated using the Flesch Kincaid readability scale. References were requested and verified. RESULTS The overall average accuracy was 1.88 (range 1.0-3.0; 95% confidence interval [CI]- 1.42-1.94)- and clinical concordance was 2.79 (range 1.0-5.0; 95% CI- 1.94-3.64). The average word count was 310 words per response (range- 146-441 words per response) with high concordance (ICC- 0.75; 95% CI- 0.59-0.91; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ <Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .001). The average readability was poor at 37.9 (range- 18.0-60.5) with high concordance (ICC- 0.73; 95% CI- 0.57-0.90; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ <Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .001). There was a weak correlation between ease of readability and better clinical concordance (-0.15; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .025). Accuracy did not correlate with readability (0.05; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .079). The average number of references was 1.97 (range- 1-4; total- 119). ChatGPT cited peer-reviewed articles only once and often referenced nonexistent websites (41%). CONCLUSIONS Because ChatGPT 3.5 responses were incorrect 24% of the time and did not provide real references 41% of the time- patients should be cautioned about using ChatGPT for medical information.
Yanfeng Li- Wengxing Long- Hongda Zhou- Tao Tan- Hui Xie,Revolutionizing breast cancer Ki-67 diagnosis: ultrasound radiomics and fully connected neural networks (FCNN) combination method,High breast density found using mammographs (MGs) reduces positivity rates and is considered a risk factor for breast cancer. Research on the relationship between Volpara density grade (VDG) and compressed breast thickness (CBT) in the Japanese population is still lacking. Moreover- little attention has been paid to pseudo-dense breasts with CBT < 30 mm among high-density breasts. We investigated VDG- CBT- and apparent high breast density in patients with breast cancer. Women who underwent MG and breast cancer surgery at our institution were included. VDG and CBT were measured. VDG was divided into a non-dense group (NDG) and a dense group (DG). This study included 419 patients. VDG was negatively correlated with CBT. The DG included younger patients with lower body mass index (BMI) and thinner CBT. In the DG- patients with CBT < 30 mm had lower BMI and higher VDG; however- no significant difference was noted in the positivity rate of the two groups. Younger women tend to have higher breast density- resulting in thinner CBT- which may pose challenges in detecting breast cancer on MGs. However- there was no significant difference in the breast cancer detection rate between CBT < 30 mm and CBT â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶Â¬Â¢â€šÃ„Ã¶âˆšÃ‘Â¬Â¢ 30 mm.
Arezou Ashari- Neda SoleimanvandiAzar- Marzieh Nojomi- Hadi Ranjbar- Kamran Mirzaei- Nahid Nafissi- Mahshid Roohravan Benis- Zahra Rampisheh,Risk perception regarding social determinants of health among women with breast cancer in Iran: a qualitative study,Early screening of breast cancer through image recognition technology can significantly increase the survival rate of patients. Therefore- breast cancer pathological image is of great significance for medical diagnosis and clinical research. In recent years- numerous deep learning models have been applied to breast cancer image classification- with deep CNN being a typical representative. Due to the use of multi-depth small convolutional kernels in mainstream CNN architectures such as VGG and Inception- the obtained image features often have high dimensionality. Although high dimensionality can bring more fine-grained features- it also increases the computational complexity of subsequent classifiers and may even lead to the curse of dimensionality and overfitting. To address these issues- a novel embedded kernel CNN principal component feature fusion (CNN-PCFF) algorithm is proposed. The constructed kernel function is embedded in the principal component analysis to form the multi-kernel principal component. Multi-kernel principal component analysis is used to fuse the high dimensional features obtained from the convolution base into some representative comprehensive variables- which are called kernel principal components- so as to achieve the purpose of dimensionality reduction. Any type of classifier can be added based on multi-kernel principal components. Through experimental analysis on two public breast cancer image datasets- the results show that the proposed algorithm can improve the performance of the current mainstream CNN architecture and subsequent classifiers. Therefore- the proposed algorithm in this paper is an effective tool for the classification of breast cancer pathological images.
Shengnan Hao- Yihan Jia- Jianuo Liu- Zhiwu Wang- Chunling Liu- Zhanlin Ji- Ivan Ganchev,ST-Double-Net: A Two-Stage Breast Tumor Classification Model Based on Swin Transformer and Weakly Supervised Target Localization,"The Deep learning (DL) models for diagnosing breast cancer from mammographic images often operate as""black boxes""- making it difficult for healthcare professionals to trust and understand their decision-making processes. The study presents an integrated framework combining Convolutional Neural Networks (CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an elaborate data preprocessing pipeline and advanced data augmentation techniques to counteract dataset limitations and transfer learning using pre-trained networks such as VGG-16- Inception-V3 and ResNet was employed. A focal point of our study is the evaluation of XAI's effectiveness in interpreting model predictions- highlighted by utilizing the Hausdorff measure to assess the alignment between AI-generated explanations and expert annotations quantitatively. This approach is critical for XAI in promoting trustworthiness and ethical fairness in AI-assisted diagnostics. The findings from our research illustrate the effective collaboration between CNNs and XAI in advancing diagnostic methods for breast cancer- thereby facilitating a more seamless integration of advanced AI technologies within clinical settings. By enhancing the interpretability of AI driven decisions- this work lays the groundwork for improved collaboration between AI systems and medical practitioners- ultimately enriching patient care. Furthermore- the implications of our research extended well beyond the current methodologies. It encourages further research into how to combine multimodal data and improve AI explanations to meet the needs of clinical practice."
Boya Manasa Sai- Yirivinti Hayagreeva Dinakar- Hitesh Kumar- Rupshee Jain- Sharyu Kesharwani- Siddharth S Kesharwani- Shyam Lal Mudavath- Ajmeer Ramkishan- Vikas Jain,Therapeutic delivery of siRNA for the management of breast cancer and triple-negative breast cancer,Breast cancer is the most prevalent cancer among women globally- making early and accurate detection essential for effective treatment and improved survival rates. This paper presents a method designed to detect and localize breast cancer using deep learning- specifically convolutional neural networks. The approach classifies histological images of breast tissue as either tumor-positive or tumor-negative. We utilize several deep learning models- including a custom-built CNN- EfficientNet- ResNet50- VGG-16- VGG-19- and MobileNet. Fine-tuning was also applied to VGG-16- VGG-19- and MobileNet to enhance performance. Additionally- we introduce a novel deep learning model called MR_Net- aimed at providing a more accurate network for breast cancer detection and localization- potentially assisting clinicians in making informed decisions. This model could also accelerate the diagnostic process- enabling early detection of the disease. Furthermore- we propose a method for explainable predictions by generating heatmaps that highlight the regions within tissue images that the model focuses on when predicting a label- revealing the detection of benign- atypical- and malignant tumors. We evaluate both the quantitative and qualitative performance of MR_Net and the other models- also presenting explainable results that allow visualization of the tissue areas identified by the model as relevant to the presence of breast cancer.
A. Tien- M. Sadar,Treatments Targeting the Androgen Receptor and Its Splice Variants in Breast Cancer,Cytological evaluation through microscopic image analysis of fine needle aspiration cytology (FNAC) is pivotal in the initial screening of breast cancer. The sensitivity of FNAC as a screening tool relies on both image quality and the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s expertise. To enhance diagnostic accuracy and alleviate the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s workload- a computer-aided diagnosis (CAD) system was developed. A comparative study was conducted- assessing twelve candidate pre-trained models. Utilizing a locally gathered FNAC image dataset- three superior models-MobileNet-V2- DenseNet-121- and Inception-V3-were selected based on their training- validation- and testing accuracies. Further- these models underwent evaluation in four transfer learning scenarios to enhance testing accuracy. While the outcomes were promising- they left room for improvement- motivating us to create a novel deep convolutional neural network (CNN). The newly proposed model exhibited robust performance with testing accuracy at 85%. Our research concludes that the most lightweight- high-accuracy model is the one we propose. Weâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ve integrated it into our user-friendly Android App- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Breast Cancer Detection System-â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Å“Ã„ in TensorFlow Lite format- with cloud database support- showcasing its effectiveness. Implementing an artificial intelligent (AI)-based diagnosis system with a user-friendly interface holds the potential to enhance early breast cancer detection using FNAC.
Ya-Yu Sun- Xiao-Tong Shi- Li-Long Xu,Ultrasound for breast cancer detection: A bibliometric analysis of global trends between 2004 and 2024,Breast cancer has been one of the main causes of death among women recently- and it has been the focus of attention of many specialists and researchers in the health field. Because of its seriousness and spread speed- breast cancer-resisting methods- early diagnosis- diagnosis- and treatment have been the points of research discussion. Many computers-aided diagnosis (CAD) systems have been proposed to reduce the load on physicians and increase the accuracy of breast tumor diagnosis. To the best of our knowledge- combining patient information- including medical history- breast density- age- and other factors- with mammogram features from both breasts in craniocaudal (CC) and mediolateral oblique (MLO) views has not been previously investigated for breast tumor classification. In this paper- we investigated the effectiveness of using those inputs by comparing two combination approaches. The soft voting approach- produced from statistical information-based models (decision tree- random forest- K-nearest neighbor- Gaussian naive Bayes- gradient boosting- and MLP) and an image-based model (CNN)- achieved 90% accuracy. Additionally- concatenating statistical and image-based features in a deep learning model achieved 93% accuracy. We found that it produced promising results that would enhance the CAD systems. As a result- this study finds that using both sides of mammograms outperformed the result of using only the infected side. In addition- integrating the mammogram features with statistical information enhanced the accuracy of the tumor classification. Our findings- based on a novel dataset- incorporate both patient information and four-view mammogram images- covering multiple classes: normal- benign- and malignant.
Di Zhang- Wang Zhou- Wenpeng Lu- Xia-Chuan Qin- Xian-Ya Zhang- Jun-Li Wang- Jun Wu- Yan-Hong Luo- Yayang Duan- Chao-Xue Zhang,Ultrasound-Based Deep Learning Radiomics Nomogram for the Assessment of Lymphovascular Invasion in Invasive Breast Cancer: A Multicenter Study.,Background: Breast cancer is one of the leading causes of death in women- making early detection through mammography crucial for improving survival rates. However- human interpretation of mammograms is often prone to diagnostic errors. This study addresses the challenge of improving the accuracy of breast cancer detection by leveraging advanced machine learning techniques. Methods: We propose an extended ensemble deep learning model that integrates three state-of-the-art convolutional neural network (CNN) architectures: VGG16- DenseNet121- and InceptionV3. The model utilizes multi-scale feature extraction to enhance the detection of both benign and malignant masses in mammograms. This ensemble approach is evaluated on two benchmark datasets: INbreast and CBIS-DDSM. Results: The proposed ensemble model achieved significant performance improvements. On the INbreast dataset- the ensemble model attained an accuracy of 90.1%- recall of 88.3%- and an F1-score of 89.1%. For the CBIS-DDSM dataset- the model reached 89.5% accuracy and 90.2% specificity. The ensemble method outperformed each individual CNN model- reducing both false positives and false negatives- thereby providing more reliable diagnostic results. Conclusions: The ensemble deep learning model demonstrated strong potential as a decision support tool for radiologists- offering more accurate and earlier detection of breast cancer. By leveraging the complementary strengths of multiple CNN architectures- this approach can improve clinical decision making and enhance the accessibility of high-quality breast cancer screening.
Alexander S Millar- John Arnn- Sam Himes- Julio C. Facelli,Uncertainty in Breast Cancer Risk Prediction: A Conformal Prediction Study of Race Stratification,Breast cancer (BC) is one of the most fatal forms of cancer- making it a significant contributor to mortality rates worldwide. Early detection and timely treatment of breast cancer are crucial in reducing its mortality rate. To ensure a healthy lifestyle- it is essential to develop systems that can accurately diagnose breast cancer. Recent advances in modern computing and information technologies have enabled significant progress in the early detection and prediction of diseases within healthcare systems. This study proposes a method for precise and automatic breast cancer prediction using deep-modified transfer learning-based Convolutional Neural Networks (CNNs). The CNN architectures employed include ResNet50- MobileNetV2- DenseNet121- and Xception- which serve as feature extractors to capture the most relevant features of breast Ultrasound images (BUSI). These extracted features are then accurately classified as benign or malignant using various high-performance classifiers- including Support Vector Machine (SVM)- K-Nearest Neighbors (KNN)- XGBoost- and Softmax. The experimental results demonstrate that the proposed deep modified DenseNet121 network with the Softmax classifier outperformed other models and existing techniques. This latter achieved remarkable performance metrics- including an accuracy of 95.34%- a precision of 90.90%- and an F1 score of 93.02%. These results highlight the effectiveness of our approach in enhancing the accuracy of breast cancer prediction. The superior performance of the proposed method provides significant improvements in decision-making speed and reduces the time- effort- and laboratory resources required for healthcare services. Consequently- this method has the potential to significantly enhance early diagnosis and enable more tailored treatment plans- ultimately contributing to better patient outcomes and reducing the overall mortality rates associated with breast cancer.
Shiping Li- Yihao Lin- Guangyu Liu- Zhimin Shao- Yinlong Yang,Unveiling the potential of breast MRI: a game changer for BI-RADS 4A microcalcifications.,Breast cancer can progress silently in its early stages and frequently without noticeable symptoms. However- it poses a serious risk to women. It is imperative to recognize this potential health concern to mitigate it early. In the last few years- Convolutional Neural Networks (CNNs) have advanced significantly in their ability to classify images of breast cancer. Their capacity to automatically extract discriminant features from images has enhanced the performances and accuracy of image classification tasks. They outperform state-of-the-art techniques in this area. Furthermore- complicated models that were first learned for certain tasks can be easily adapted to complete new tasks by using transfer-learning approaches. However- deep learning-based categorization techniques could experience overfitting issues- particularly in cases where the dataset is small. The primary goal of this work is to investigate the performances of certain deep learning models to classify breast cancer images and to study the effects of data augmentation techniques- such as image rotation or displacement when utilizing a transfer learning approach. Using certain image datasets- the ResNet18- Resnet50- and VGG16 models demonstrated accuracy improvements- according to our experimental results.
Yudong Zhang- Deguang Kong- Juanjuan Li- Tao Yang- Feng Yao- Ge Yang,Using Segment-Level Attention to Guide Breast Ultrasound Video Classification,Recent advances in artificial intelligence (AI)- notably deep learning- have sparked widespread curiosity with bioinformatics- particularly the challenges presented by medical imaging. Itâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s been really helpful in enabling the Computer Aided Diagnosis CAD system to provide precise outcomes. Nonetheless- it is still a difficult task to identify breast cancer in mammography images. The purpose of this effort is to lower False Positive Rate FPR and False Negative Rate FNR and increase Matthewsâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s correlation coefficient MCC value. Two highly tailored object detection models- YOLOv5 and Mask R-CNN- are utilized to get the job done. YOLOv5 is able to detect the mass and determine whether it is benign or malignant. However- YOLOV5â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s limited real estate necessitates certain tweaks to the original model in order to get the desired effects. Tumor borders and size are both identified by Mask RCNN as it traverses breast parenchyma in search of malignancies. Stages of cancer are based on the magnitude of the patientsâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ tumours. This model employs YOLOv5+Mask RCNN and is trained on the INbreast- CBIS-DDSM- and BNS dataset. The proposed model is compared against the baseline version of YOLOv5 to determine how well it performs. The proposed method improves performance- with an FPR of 0.049%- a FNR of 0.029%- and a high MCC value of 92.02%. Based on the results of the studies- combining YOLOv5 with Mask RCNN improves accuracy by 0.06 percentage points compared to using either method alone. Furthermore- this effort may aid in determining the patientâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s prognosis and allowing clinicians to be more accurate and predictable in the diagnosing process at an early stage.
Kate E Dibble- Shoshana M Rosenberg- Craig Snow- Gregory J Kirkner- Nabihah Tayob- Magnolia Contreras- Noel D Roma- Cecilia R DeGraffinreid- Timiya S Nolan- Dawn L Hershman- Michelle Naughton- Ann H Partridge,Young- Empowered & strong (YES): a study protocol paper for a randomized controlled trial of an mHealth symptom monitoring and self-management intervention for adolescent and young adult (AYA) breast cancer survivors,Applications of deep learning in medicine- like iden- tifying the kind of malignant cells- are common. Breast cancer is a most common type of cancer in women and it a main cause of death for women. There are three categories for the malignant cells: Normal- Mild- and Severe. Early diagnosis of the malignant cells can prevent these deaths. Numerous techniques- including MRIs- mammograms- ultrasounds- and biopsies- are used to identify cancerous cells. Hematoxylin and eosin-stained breast cancer histology photos are difficult to diagnose- labor-intensive- and frequently cause pathologists to disagree. Recent advances in deep learning have made histological image processing possible with convolutional neural networks (CNNs). Histology images of breast cancer are categorized into sub-classes based on general tissue structure and morphology- as well as the density- variabil- ity- and organize of the cells. These subclasses include benign- malignant- and normal. Using this information- extract features at the cell and tissue levels- respectively from histopathological images- in smaller and larger size patches. The dataset repository is where the input image was obtained. The image has to be pre- processed. The feature extraction must then be put into practice. The pre- processed image must then be segmented. The image must be divided. We are able to apply many neural network models- including VGG-19 and Convolutional Neural Network (CNN). The findings of the experiment indicate that the accuracy. The primary goal of our method is to identify or anticipate breast cancer based on the input image.
Khan Mohammad Emon- Golam Kibria- Md. Shakhan- Bushra Jannat- Fahim Hafiz- Riasat Azim,ENRNN-AU-Net: A Hybrid Deep Learning Model to Classify and Segment Histopathology Images of Breast Cancer,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ and early-stage breast cancer patients. Precise prediction of â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ encoder with paralleled parameter-shared attention (P 2 SA) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ and prognostic outcomes in breast cancer treatment. The â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
HM Balaha- KM Ali- D Gondim- M Ghazal- ...,Harnessing Vision Transformers for Precise and Explainable Breast Cancer Diagnosis,This study presents a novel approach to enhance the accuracy of breast cancer detection from mammogram images through a hybrid feature selection and classification framework. Leveraging the power of XGBoost- a state-of-the-art machine learning algorithm- an embedded genetic algorithm is introduced for optimal feature selection. The genetic algorithm refines the feature set by iteratively evolving towards a subset that maximizes the discriminative power for breast cancer diagnosis. Subsequently- the selected features are fed into a Recurrent Neural Network (RNN) architecture with Random Boolean Networks (RBN) for classification. The RNN-RBN model captures intricate temporal dependencies within the image data- providing a nuanced understanding of the complex patterns indicative of breast cancer. The synergistic coupling of the XGBoost-embedded genetic algorithm for feature selection and the RNN-RBN model for classification results in a robust and interpretable system for breast cancer detection. The proposed hybrid approach is evaluated on a comprehensive dataset of mammogram images- demonstrating superior performance compared to traditional methods. The combination of feature selection through XGBoost- embedded genetic algorithms and RNN-RBN classification showcases the potential for advanced- accurate- and efficient breast cancer diagnosis- holding promise for improving early detection rates and patient outcomes in clinical settings.
Andreas Giannakou- Canan Dagdeviren- Tolga Ozmen,Conformable Ultrasound Breast Patch - The Future of Breast Cancer Screening?,This research study initiates a multifaceted analysis of breast cancer- a pervasive malignancy originating in the mammary gland cells. Globally- breast cancer ranks as the second most commonly diagnosed cancer- surpassed only by skin cancer. While breast cancer can affect individuals of any gender- it disproportionately impacts women. In light of this significant health concern- this research study examines the notable advancements in breast cancer detection- encompassing a wide array of techniques designed to enhance early diagnosis. The success of this effort relies on old-fashioned techniques like mammograms and check-ups- which are still very important tools. Additionally- this study introduces emerging technologies- specifically AI-powered analysis of mammograms. The technologies- such as Convolutional Neural Networks (CNN) utilizing Residual Networks (ResNet)- Visual Geometry Group Networks (VGG16)- and Siamese Neural Network architectures (SNN) and Convolutional Recurrent Neural Network (CRNN) have shown promising potential to substantially enhance the diagnostic accuracy. Moreover- this study explores the application of various machine learning algorithms to collect datasets- aiming to predict the early development of breast cancer. This comprehensive approach underscores the promising future of breast cancer detection and emphasizes the importance of a multidimensional strategy in combating this global health challenge. This study utilizes the pre-existing research on Magnetic Resonance Imaging (MRI) scans of breast datasets- seeking to improve the accuracy and early detection by ultimately contributing to establish a more effective breast cancer management.
Beyzanur Erk- Ali Furkan Kamanli- Gamze Guney Eskiler,The therapeutic efficacy of 5-ALA based photodynamic therapy and chemotherapy combination in triple negative breast cancer cells,"Tumors are an important health concern in modern times. Breast cancer is one of the most prevalent causes of death for women. Breast cancer is rapidly becoming the leading cause of mortality among women globally. Early detection of breast cancer allows patients to obtain appropriate therapy- increasing their probability of survival. The adoption of 3-Dimensional (3D) mammography for the medical identification of abnormalities in the breast reduced the number of deaths dramatically. Classification and accurate detection of lumps in the breast in 3D mammography is especially difficult due to factors such as inadequate contrast and normal fluctuations in tissue density. Several Computer-Aided Diagnosis (CAD) solutions are under development to help radiologists accurately classify abnormalities in the breast. In this paper- a breast cancer diagnosis model is implemented to detect breast cancer in cancer patients to prevent death rates. The 3D mammogram images are gathered from the internet. Then- the gathered images are given to the preprocessing phase. The preprocessing is done using a median filter and image scaling method. The purpose of the preprocessing phase is to enhance the quality of the images and remove any noise or artifacts that may interfere with the detection of abnormalities. The median filter helps to smooth out any irregularities in the images- while the image scaling method adjusts the size and resolution of the images for better analysis. Once the preprocessing is complete- the preprocessed image is given to the segmentation phase. The segmentation phase is crucial in medical image analysis as it helps to identify and separate different structures within the image- such as organs or tumors. This process involves dividing the preprocessed image into meaningful regions or segments based on intensity- color- texture- or other features. The segmentation process is done using Adaptive Thresholding with Region Growing Fusion Model (AT-RGFM)"". This model combines the advantages of both thresholding and region-growing techniques to accurately identify and delineate specific structures within the image. By utilizing AT-RGFM- the segmentation phase can effectively differentiate between different parts of the image- allowing for more precise analysis and diagnosis. It plays a vital role in the medical image analysis process- providing crucial insights for healthcare professionals. Here- the Modified Garter Snake Optimization Algorithm (MGSOA) is used to optimize the parameters. It helps to optimize parameters for accurately identifying and delineating specific structures within medical images and also helps healthcare professionals in providing more precise analysis and diagnosis- ultimately playing a vital role in the medical image analysis process. MGSOA enhances the segmentation phase by effectively differentiating between different parts of the image- leading to more accurate results. Then- the segmented image is fed into the detection phase. The tumor detection is performed by the Vision Transformer-based Multiscale Adaptive EfficientNetB7 (ViT-MAENB7) model. This model utilizes a combination of advanced algorithms and deep learning techniques to accurately identify and locate tumors within the segmented medical image. By incorporating a multiscale adaptive approach- the ViT-MAENB7 model can analyze the image at various levels of detail- improving the overall accuracy of tumor detection. This crucial step in the medical image analysis process allows healthcare professionals to make more informed decisions regarding patient treatment and care. Here- the created MGSOA algorithm is used to optimize the parameters for enhancing the performance of the model. The suggested breast cancer diagnosis performance is compared to conventional cancer diagnosis models and it showed high accuracy. The accuracy of the developed MGSOA-ViT-MAENB7 is 96.6 %- and others model like RNN- LSTM- EffNet- and ViT-MAENet given the accuracy to be 90.31 %- 92.79 %- 94.46 % and 94.75 %. The developed model's ability to analyze images at multiple scales- combined with the optimization provided by the MGSOA algorithm- results in a highly accurate and efficient system for detecting tumors in medical images. This cutting-edge technology not only improves the accuracy of diagnosis but also helps healthcare professionals tailor treatment plans to individual patients- ultimately leading to better outcomes. By outperforming traditional cancer diagnosis models- the proposed model is revolutionizing the field of medical imaging and setting a new standard for precision and effectiveness in healthcare."
D Shah- MA Ullah Khan- M Abrar,Reliable Breast Cancer Diagnosis with Deep Learning: DCGANâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢Driven Mammogram Synthesis and Validity Assessment,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ the performance of the USDOT-Transformer model- which combines US and DOT images with tumor receptor biomarkers to predict the pCR of breast cancer patients under NAC. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Afaf Saad- Noha Ghatwary- Safa M Gasser- Mohamed S ElMahallawy,Automatic image generation and stage prediction of breast cancer immunobiological through a proposed IHC-GAN model,Breast cancer is globally known to be a major health concern that necessitates advancements in detection and classification methods. This study introduces a machine learning-based approach for breast cancer diagnosis using benign and malignant mammograms of breast cancer. A two-hidden-layer artificial neural network (ANN) model was designed to categorize breast cancer from mammographic images. Prior to analysis- the images were subjected to a sophisticated data augmentation process that leveraged data denoising- contrast enhancement- and the application of a generative adversarial network (GAN). This multi-enhancement preprocessing enriched the quality of the images and transformed them into a format more amenable to analysis by vectorizing the pixel data. The methodology involved rigorous training of the ANN on input images- resulting in a significant improvement in the modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s ability to classify breast cancer accurately. Experimental results demonstrate a notable enhancement in classification performance- with an increase in accuracy ranging from 22.5 to 42.5% compared to traditional scans. The final model achieved an impressive accuracy rate of unity- which considered all stages of image processing- including normal- contrast-enhanced- denoised- and GAN-enhanced scans. The outcomes of this research underlined the effectiveness of data augmentation and ANN in medical imaging. Future innovations in breast cancer diagnostics are elaborated by the potential to improve early detection and patient outcomes. The robust offered methodology for breast cancer detection is considered to be a significant contribution to biotechnological fields of interest.
Yi-Ming Wang- Chi-Yuan Wang- Kuo-Ying Liu- Yung-Hui Huang- Tai-Been Chen- Kon-Ning Chiu- Chih-Yu Liang- Nan-Han Lu,CNN-Based Cross-Modality Fusion for Enhanced Breast Cancer Detection Using Mammography and Ultrasound,Breast cancer ranks as the second most prevalent cancer globally and is the most frequently diagnosed cancer among women; therefore- early- automated- and precise detection is essential. Most AI-based techniques for breast cancer detection are complex and have high computational costs. Hence- to overcome this challenge- we have presented the innovative LightweightUNet hybrid deep learning (DL) classifier for the accurate classification of breast cancer. The proposed model boasts a low computational cost due to its smaller number of layers in its architecture- and its adaptive nature stems from its use of depth-wise separable convolution. We have employed a multimodal approach to validate the model's performance- using 13-000 images from two distinct modalities: mammogram imaging (MGI) and ultrasound imaging (USI). We collected the multimodal imaging datasets from seven different sources- including the benchmark datasets DDSM- MIAS- INbreast- BrEaST- BUSI- Thammasat- and HMSS. Since the datasets are from various sources- we have resized them to the uniform size of 256 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 256 pixels and normalized them using the Box-Cox transformation technique. Since the USI dataset is smaller- we have applied the StyleGAN3 model to generate 10-000 synthetic ultrasound images. In this work- we have performed two separate experiments: the first on a real dataset without augmentation and the second on a real + GAN-augmented dataset using our proposed method. During the experiments- we used a 5-fold cross-validation method- and our proposed model obtained good results on the real dataset (87.16% precision- 86.87% recall- 86.84% F1-score- and 86.87% accuracy) without adding any extra data. Similarly- the second experiment provides better performance on the real + GAN-augmented dataset (96.36% precision- 96.35% recall- 96.35% F1-score- and 96.35% accuracy). This multimodal approach- which utilizes LightweightUNet- enhances the performance by 9.20% in precision- 9.48% in recall- 9.51% in F1-score- and a 9.48% increase in accuracy on the combined dataset. The LightweightUNet model we proposed works very well thanks to a creative network design- adding fake images to the data- and a multimodal training method. These results show that the model has a lot of potential for use in clinical settings.
Chen Cheng- Yan Wang- Jine Zhao- Di Wu- Honge Li- Hongyan Zhao,Deep Learning and Radiomics in Triple-Negative Breast Cancer: Predicting Long-Term Prognosis and Clinical Outcomes,INTRODUCTION: Ultrasound in conjunction with mammography imaging- plays a vital role in the early detection and diagnosis of breast cancer. However- speckle noise affects medical ultrasound images and degrades visual radiological interpretation. Speckle carries information about the interactions of the ultrasound pulse with the tissue microstructure- which generally causes several difficulties in identifying malignant and benign regions. The application of deep learning in image denoising has gained more attention in recent years. OBJECTIVES: The main objective of this work is to reduce speckle noise while preserving features and details in breast ultrasound images using GAN models. METHODS: We proposed two GANs models (Conditional GAN and Wasserstein GAN) for speckle-denoising public breast ultrasound databases: BUSI- DATASET A- AND UDIAT (DATASET B). The Conditional GAN model was trained using the Unet architecture- and the WGAN model was trained using the Resnet architecture. The image quality results in both algorithms were measured by Peak Signal to Noise Ratio (PSNR- 35â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®40 dB) and Structural Similarity Index (SSIM- 0.90â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®0.95) standard values. RESULTS: The experimental analysis clearly shows that the Conditional GAN model achieves better breast ultrasound despeckling performance over the datasets in terms of PSNR = 38.18 dB and SSIM = 0.96 with respect to the WGAN model (PSNR = 33.0068 dB and SSIM = 0.91) on the small ultrasound training datasets. CONCLUSIONS: The observed performance differences between CGAN and WGAN will help to better implement new tasks in a computer-aided detection/diagnosis (CAD) system. In future work- these data can be used as CAD input training for image classification- reducing overfitting and improving the performance and accuracy of deep convolutional algorithms.
Shriram Ashok Rajurkar- Teerthraj Verma- Rajeev Gupta,Estimation of heart dose in left breast cancer radiotherapy: Assessment of vDIBH feasibility using the supervised machine learning algorithm,Invasive breast cancer diagnosis and treatment planning require an accurate assessment of human epidermal growth factor receptor 2 (HER2) expression levels. While immunohistochemical techniques (IHC) are the gold standard for HER2 evaluation- their implementation can be resource-intensive and costly. To reduce these obstacles and expedite the procedure- we present an efficient deep-learning model that generates high-quality IHC-stained images directly from Hematoxylin and Eosin (H&E) stained images. We propose a new IHC-GAN that enhances the Pix2PixHD model into a dual generator module- improving its performance and simplifying its structure. Furthermore- to strengthen feature extraction for HE-stained image classification- we integrate MobileNetV3 as the backbone network. The extracted features are then merged with those generated by the generator to improve overall performance. Moreover- the decoder's performance is enhanced by providing the related features from the classified labels by incorporating the adaptive instance normalization technique. The proposed IHC-GAN was trained and validated on a comprehensive dataset comprising 4-870 registered image pairs- encompassing a spectrum of HER2 expression levels. Our findings demonstrate promising results in translating H&E images to IHC-equivalent representations- offering a potential solution to reduce the costs associated with traditional HER2 assessment methods. We extensively validate our model and the current dataset. We compare it with state-of-the-art techniques- achieving high performance using different evaluation metrics- showing 0.0927 FID- 22.87 PSNR- and 0.3735 SSIM. The proposed approach exhibits significant enhancements over current GAN models- including an 88% reduction in Frechet Inception Distance (FID)- a 4% enhancement in Learned Perceptual Image Patch Similarity (LPIPS)- a 10% increase in Peak Signal-to-Noise Ratio (PSNR)- and a 45% reduction in Mean Squared Error (MSE). This advancement holds significant potential for enhancing efficiency- reducing manpower requirements- and facilitating timely treatment decisions in breast cancer care.
Hari Mohan Rai- Joon Yoo- Saurabh Agarwal- Neha Agarwal,LightweightUNet: Multimodal Deep Learning with GAN-Augmented Imaging Data for Efficient Breast Cancer Detection,Abstract Objective Breast cancer is one of the leading cancer causes among women worldwide. It can be classified as invasive ductal carcinoma (IDC) or metastatic cancer. Early detection of breast cancer is challenging due to the lack of early warning signs. Generally- a mammogram is recommended by specialists for screening. Existing approaches are not accurate enough for realâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢time diagnostic applications and thus require better and smarter cancer diagnostic approaches. This study aims to develop a customized machineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢learning framework that will give more accurate predictions for IDC and metastasis cancer classification. Methods This work proposes a convolutional neural network (CNN) model for classifying IDC and metastatic breast cancer. The study utilized a largeâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢scale dataset of microscopic histopathological images to automatically perceive a hierarchical manner of learning and understanding. Results It is evident that using machine learning techniques significantly (15%â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®25%) boost the effectiveness of determining cancer vulnerability- malignancy- and demise. The results demonstrate an excellent performance ensuring an average of 95% accuracy in classifying metastatic cells against benign ones and 89% accuracy was obtained in terms of detecting IDC. Conclusions The results suggest that the proposed model improves classification accuracy. Therefore- it could be applied effectively in classifying IDC and metastatic cancer in comparison to other stateâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ofâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢theâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢art models.
Amin Talebi- Ahmad Bitarafan-Rajabi- Azin Alizadeh-Asl- Parisa Seilani- Benyamin Khajetash- Ghasem Hajianfar- Meysam Tavakoli,Machine learning based radiomics model to predict radiotherapy induced cardiotoxicity in breast cancer,The survival rate of breast cancer for women in low- and middle-income countries is poor compared with that in high-income countries. Point-of-care ultrasound (POCUS) combined with deep learning could potentially be a suitable solution enabling early detection of breast cancer. We aim to improve a classification network dedicated to classifying POCUS images by comparing different techniques for increasing the amount of training data. Two data sets consisting of breast tissue images were collected- one captured with POCUS and another with standard ultrasound (US). The data sets were expanded by using different techniques- including augmentation- histogram matching- histogram equalization- and cycle-consistent adversarial networks (CycleGANs). A classification network was trained on different combinations of the original and expanded data sets. Different types of augmentation were investigated and two different CycleGAN approaches were implemented. Almost all methods for expanding the data sets significantly improved the classification results compared with solely using POCUS images during the training of the classification network. When training the classification network on POCUS and CycleGAN-generated POCUS images- it was possible to achieve an area under the receiver operating characteristic curve of 95.3% (95% confidence interval 93.4% to 97.0%). Applying augmentation during training showed to be important and increased the performance of the classification network. Adding more data also increased the performance- but using standard US images or CycleGAN-generated POCUS images gave similar results.
Y. Forghani- R. Timotoe- M. Figueiredo- T. Marques- E. Batista- F. Cordoso- M.J. Cardoso- J. Santinha- P. Gouveia,Breast tissue segmentation in MR images using deep-learning,Breast cancer is one of the malignancies that affects women. Breast cancer is a condition that is brought on by abnormal breast cells that multiply and form tumours. If left untreated- tumours have the capacity to grow throughout the body and become fatal. Early initiation and thorough completion of treatment is associated with better outcomes and greater patient tolerance for breast cancer patients. These days- early detection of breast cancer is quite helpful and will help the women who battle the illness. The earliest detection of breast cancer can be successfully achieved with the use of machine learning-based approaches. Breast cancer can be diagnosed with great accuracy using a number of machine learning techniques- including CNN- RF- SVM- NB- KNN- AB- and others. Thus- I am introducing a triple hybrid deep learning method for breast cancer diagnosis and prognosis. This is the CNN- GRU- and LSTM combination.
K. Logu- S. John Justin Thangaraj,Progressing Breast Cancer Assessment: Precise Tumor Categorization through DenseNet201-based Deep Learning,<title>Abstract</title> <p>Background Delays in seeking medical care may affect the survival rates of breast cancer patients. We aimed to explore potential risk factors for the delay in seeking medical care among breast cancer patients by constructing a highly effective machine learning (ML) prediction model. Methods A cross-sectional methodology was utilized- and the demographic and clinical characteristics of 540 patients with breast cancer in Sichuan Cancer Hospital from July 2022 to June 2023 were collected to develop a model. Feature selection was performed using a Lasso algorithm- and six ML algorithms- including XGB- LR- RF- CNB- SVM and KNN- were applied for model construction. The k-fold cross-validation method was used for internal verification. And ROC curves- calibration curves- DCA and external validation were used for model evaluation. The SHAP method was used to interpret the model visualization. Results A comprehensive analysis was conducted in a cohort of 540 patients diagnosed with breast cancer- of whom 212 patients (39.26%) experienced a delay. Lasso algorithm selected eight variables that were most suitable for model construction. The RF model demonstrated superior performance compared to the other five prediction models. The AUC values in the training set ROC- validation set ROC- and external verification ROC curves were 1.00- 0.86- and 0.76- respectively in RF model. The results of the calibration curves indicated that the calibration curves of the RF models closely resembled the ideal curves. The DCA curves exhibited a net clinical benefit in comparison to treatment for or treatment for none for all models- with the exception of CNB. Conclusions The machine learning algorithm utilized in this study effectively generated a prediction model for delays in seeking medical care for patients with breast cancer. The best RF model's remarkable predictive power- exhibiting a good discrimination and calibration.</p>
Tarek Khater- Abir Hussain- Riyad Bendardaf- Iman M. Talaat- Hissam Tawfik- Sam Ansari- Soliman Mahmoud,An Explainable Artificial Intelligence Model for the Classification of Breast Cancer,"<title>Abstract</title> <p><bold>Objectives</bold> To develop a machine learning technique that could enable the automatic classification of malignancies of the breast either as benign or malignant, using clinical and pathological data extracted from diagnostic images and patient records. <bold>Method</bold> It has clinical data and tumor characteristics features, such as clump thickness, uniformity of cell size, and marginal adhesion. In this work, several machine learning algorithms are going to be implemented, such as Decision Trees, Support Vector Machines, Naive Bayes, and K-Nearest Neighbors. Data preprocessing steps include handling missing values and feature standardization. The performance metric used in evaluating these models are Accuracy, Precision, Recall, the F1-score, the Receiver Operating characteristic graph, and Confusion Matrices. <bold>Findings</bold>: It has been observed in the experiment's outcomes that the accuracy rating was 97.14%, thus making the SVM model better than the Decision Trees, Naive Bayes, and KNN. The models were plus for the SVM model concerning precision, recall, and F1-score; hence, it was the most effective classifier in detecting benign and malignant tumors. <bold>Novelty</bold>: The paper has provided an overall comparison of different machine learning methods applied earlier in breast cancer classification and strongly administers the effectiveness of SVM. Having multiple algorithms at one's disposal, detailed metrics on performance add to great worth in helping health providers to make proper and informed decisions about diagnosis and management regarding breast cancer.</p>"
P Dinesh- AS Vickram- ...,Medical image prediction for diagnosis of breast cancer disease comparing the machine learning algorithms: SVM- KNN- logistic regression- random forest and â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ breast cancer that combines dynamic full-field optical coherence tomography (D-FFOCT)- a label-free optical imaging method- and deep learning â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Deep learning model was built up and â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Meiying Yan- Jincao Yao- Xiao Zhang- Dong Xu- Chen Yang,Machine learningâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢based model constructed from ultrasound radiomics and clinical features for predicting HER2 status in breast cancer patients with indeterminate (2+) immunohistochemical results,Background parenchymal enhancement (BPE) on dynamic contrast-enhanced MRI (DCE-MRI) as rated by radiologists is subject to inter- and intrareader variability. We aim to automate BPE category from DCE-MRI. This study represents a secondary analysis of the Dense Tissue and Early Breast Neoplasm Screening trial. 4553 women with extremely dense breasts who received supplemental breast MRI screening in eight hospitals were included. Minimal- mild- moderate and marked BPE rated by radiologists were used as reference. Fifteen quantitative MRI features of the fibroglandular tissue were extracted to predict BPE using Random Forest- Naâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšâ‰¤ve Bayes- and KNN classifiers. Majority voting was used to combine the predictions. Internal-external validation was used for training and validation. The inverse-variance weighted mean accuracy was used to express mean performance across the eight hospitals. Cox regression was used to verify non inferiority of the association between automated rating and breast cancer occurrence compared to the association for manual rating. The accuracy of majority voting ranged between 0.56 and 0.84 across the eight hospitals. The weighted mean prediction accuracy for the four BPE categories was 0.76. The hazard ratio (HR) of BPE for breast cancer occurrence was comparable between automated rating and manual rating (HRÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 2.12 versus HRÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 1.97- PÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.65 for mild/moderate/marked BPE relative to minimal BPE). It is feasible to rate BPE automatically in DCE-MRI of women with extremely dense breasts without compromising the underlying association between BPE and breast cancer occurrence. The accuracy for minimal BPE is superior to that for other BPE categories.
Hyuksool Kwon- SeokHwan Oh- Myeong-Gee Kim- Youngmin Kim- Gui-Jae Jung- Hyeon-Jik Lee- Sang-Yun Kim- Hyeon-Min Bae,Artificial Intelligence-Enhanced Quantitative Ultrasound for Breast Cancer: Pilot Study on Quantitative Parameters and Biopsy Outcomes,Breast cancer's global prevalence highlights the need for the development of precise and reliable diagnostic tools. The objective of this study is to contribute to the growing body of knowledge in breast cancer diagnosis- highlighting the potential of a range of classifier algorithms- soft and hard voting ensemble approaches- and neural networks as potent tools in medical applications. These models were utilized to assess the Wisconsin Breast Cancer dataset obtained from UCI Machine Learning repository- consisting of 569 samples and 30 features. Besides- we utilized Principal Component Analysis (PCA) and Variance Inflation Factors (VIF) techniques to perform feature selection and dimensionality reduction on the standardized and original features respectively. After conducting PCA analysis- a variety of classifier models- including k-nearest neighbors (KNN)- Lo-gistic Regression (LR)- Decision Tree (DT)- LightGBM (LGBM)- XGBoost (XGB)- Random Forest (RF)- and Naive Bayes (NB)- were employed. Moreover- after the VIF analysis- these classifier models and a Neural Network (NN) model were put into action. Subsequently- the best three and best five classifier algorithms were determined using accuracy metrics- then both soft and hard voting ensemble were executed on these algorithms. The neural network (NN) model underwent training for 500 epochs since beyond that point- the loss curves displayed nearly constant values. This model (NN) were compiled with â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´adamâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Å“Ã„ optimizer along with binary crossentropy as loss function. We observed our ensemble strategies demonstrated superior performance in accuracy compared to all existing methods.
Payam Jannatdoust- Parya Valizadeh- Nikoo Saeedi- Gelareh Valizadeh- Hanieh Mobarak Salari- Hamidreza Saligheh Rad- Masoumeh Gity,Computer-Aided Detection (CADe) and Segmentation Methods for Breast Cancer Using Magnetic Resonance Imaging (MRI),The study focuses on predicting breast cancer survival using naâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšâ‰¤ve bayes techniques and compares several machine learning models across large dataset of 310-000 patient records. The survival and non-survival classes were the two main categories. The objective of the study was to assess the effectiveness of the Naâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšâ‰¤ve Bayes classifier in the data mining area and to attain noteworthy outcomes for survival classification that were consistent with the body of existing literature. Naive Bayes achieved an average accuracy of 91.08%- indicating reliable performance but with some variability across folds. Logistic Regression achieved an accuracy of 94.84%- excelling in identifying instances of class 1 but struggling with class 0. Decision Tree model- with an accuracy of 93.42%- showed similar performance trends. At 95.68% accuracy- Random Forest outperformed Decision Tree. However- all models faced challenges in classifying instances of class 0 accurately. The Naive Bayes algorithm was compared with K-Nearest Neighbors (KNN) and Support Vector Machines (SVM). Future research will enhance prediction models with new methods and address the challenge of accurately identifying instances of class 0.
Usman Haider- Muhammad Hanif- Ahmer Rashid- Khursheed Aurangzeb- A. Khalil- Musaed A. Alhussein,Discriminative Dictionary Learning Using Penalized Rank-1 Approximation for Breast Cancer Classification With Imbalanced Dataset,Analysis of histopathological images (HIs) is crucial for detecting breast cancer (BR). However- because they vary- it is still very difficult to extract well-designed elements. Deep learning (DL) is a recent development that is used to extract high-level features. However- DL techniques continue to confront several difficult problems- such as the need for sufficient training data for DL models- which reduces the classification findings. In this study- an ensemble deep transfer convolutional neural network is presented to address this problem. The pre-trained models (ResNet50 and MobileNet) are employed to extract high-level features by freezing the front layer parameters while fine-tuning the last layers. In the proposed ensemble framework- KNN- SVM- logistic regression and neural networks are used as base classifiers. The majority vote and product approaches are used to integrate the predictions of each separate classifier. In the benchmark BreaKHis dataset- the suggested ensemble model is compared to some current approaches. It demonstrates that while the ensemble model obtains a considerable accuracy of 97.72% for the multiclass classification test- it achieves an accuracy of 99.2% for the binary task. The suggested ensemble modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s effectiveness in extracting useful features for BR images is demonstrated by comparison with existing cutting-edge models.
Paidipati Dinesh- A. S. Vickram- P. Kalyanasundaram,Medical image prediction for diagnosis of breast cancer disease comparing the machine learning algorithms: SVM- KNN- logistic regression- random forest and decision tree to measure accuracy,Breast cancer is the most fatal womenâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s cancer- and accurate diagnosis of this disease in the initial phase is crucial to abate death rates worldwide. The demand for computer-aided disease diagnosis technologies in healthcare is growing significantly to assist physicians in ensuring the effectual treatment of critical diseases. The vital purpose of this study is to analyze and evaluate the classification efficiency of several machine learning algorithms with hyperparameter optimization techniques using grid search and random search to reveal an efficient breast cancer diagnosis approach. Choosing the optimal combination of hyperparameters using hyperparameter optimization for machine learning models has a straight influence on the performance of models. According to the findings of several evaluation studies- the k-nearest neighbor is addressed in this study for effective diagnosis of breast cancer- which got a 100.00% recall value with hyperparameters found utilizing grid search. k-nearest neighbor- logistic regression- and multilayer perceptron obtained 99.42% accuracy after utilizing hyperparameter optimization. All machine learning models showed higher efficiency in breast cancer diagnosis with grid search-based hyperparameter optimization except for XGBoost. Therefore- the evaluation outcomes strongly validate the effectiveness and reliability of the proposed technique for breast cancer diagnosis.
Ruth Moulson- Guillaume Feugâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨âˆšÃœre- Tracy S Moreira-Lucas- Florence Dequen- Jessica Weiss- Janet Smith- Christine Brezden-Masley,Real-World Treatment Patterns and Clinical Outcomes among Patients Receiving CDK4/6 Inhibitors for Metastatic Breast Cancer in a Canadian Setting Using AI-Extracted Data,The study aimed to develop natural language processing (NLP) algorithms to automate extracting patient-centred breast cancer treatment outcomes from clinical notes in electronic health records (EHRs)- particularly for women from under-represented populations. The study used clinical notes from 2010 to 2021 from a tertiary hospital in the USA. The notes were processed through various NLP techniques- including vectorisation methods (term frequency-inverse document frequency (TF-IDF)- Word2Vec- Doc2Vec) and classification models (support vector classification- K-nearest neighbours (KNN)- random forest (RF)). Feature selection and optimisation through random search and fivefold cross-validation were also conducted. The study annotated 100 out of 1000 clinical notes- using 970 notes to build the text corpus. TF-IDF and Doc2Vec combined with RF showed the highest performance- while Word2Vec was less effective. RF classifier demonstrated the best performance- although with lower recall rates- suggesting more false negatives. KNN showed lower recall due to its sensitivity to data noise. The study highlights the significance of using NLP in analysing clinical notes to understand breast cancer treatment outcomes in under-represented populations. The TF-IDF and Doc2Vec models were more effective in capturing relevant information than Word2Vec. The study observed lower recall rates in RF models- attributed to the dataset's imbalanced nature and the complexity of clinical notes. The study developed high-performing NLP pipeline to capture treatment outcomes for breast cancer in under-represented populations- demonstrating the importance of document-level vectorisation and ensemble methods in clinical notes analysis. The findings provide insights for more equitable healthcare strategies and show the potential for broader NLP applications in clinical settings.
Michele Zeverino- Consiglia Piccolo- Maud Marguet- Wendy Jeanneret-Sozzi- Jean Bourhis- Francois Bochud- Raphaâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨Â¬â€¢l Moeckli,Sensitivity of automated and manual treatment planning approaches to contouring variation in early-breast cancer treatment,"Objective: This study aims to develop an interpretable machine learning (ML) model to accurately predict the probability of achieving total pathological complete response (tpCR) in patients with locally advanced breast cancer (LABC) following neoadjuvant chemotherapy (NAC). Methods: This multi-center retrospective study included pre-NAC clinical pathology data from 698 LABC patients. Post-operative pathological outcomes divided patients into tpCR and non-tpCR groups. Data from 586 patients at Shanghai Ruijin Hospital were randomly assigned to a training set (80%) and a test set (20%). In comparison- data from our hospital's remaining 112 patients were used for external validation. Variable selection was performed using the Least Absolute Shrinkage and Selection Operator (LASSO) regression analysis. Predictive models were constructed using six ML algorithms: decision trees- K-nearest neighbors (KNN)- support vector machine- light gradient boosting machine- and extreme gradient boosting. Model efficacy was assessed through various metrics- including receiver operating characteristic (ROC) curves- precision-recall (PR) curves- confusion matrices- calibration plots- and decision curve analysis (DCA). The best-performing model was selected by comparing the performance of different algorithms. Moreover- variable relevance was ranked using the SHapley Additive exPlanations (SHAP) technique to improve the interpretability of the model and solve the ""black box"" problem. Results: A total of 191 patients (32.59%) achieved tpCR following NAC. Through LASSO regression analysis- five variables were identified as predictive factors for model construction- including tumor size- Ki-67- molecular subtype- targeted therapy- and chemotherapy regimen. The KNN model outperformed the other five classifier algorithms- achieving area under the curve (AUC) values of 0.847 (95% CI: 0.809-0.883) in the training set- 0.763 (95% CI: 0.670-0.856) in the test set- and 0.665 (95% CI: 0.555-0.776) in the external validation set. DCA demonstrated that the KNN model yielded the highest net advantage through a wide range of threshold probabilities in both the training and test sets. Furthermore- the analysis of the KNN model utilizing SHAP technology demonstrated that targeted therapy is the most crucial factor in predicting tpCR. Conclusion: An ML prediction model using clinical and pathological data collected before NAC was developed and verified. This model accurately predicted the probability of achieving a tpCR in patients with LABC after receiving NAC. SHAP technology enhanced the interpretability of the model and assisted in clinical decision-making and therapy optimization."
Matthias Hans Belau- Lisa Jung- Tabea Maurer- Nadia Obi- Sabine Behrens- Petra Seibold- Heiko Becher- Jenny Chang-Claude,Social relationships and their impact on health-related quality of life in a long-term breast cancer survivor cohort,Machine learning classifiers are increasingly used to create predictive models for pathological complete response (pCR) in breast cancer after neoadjuvant therapy (NAT). Few studies have compared the effectiveness of different ML classifiers. This study evaluated radiomics models based on pre- and post-contrast first-phase T1 weighted images (T1WI) in predicting breast cancer pCR after NAT and compared the performance of ML classifiers. This retrospective study enrolled 281 patients undergoing NAT from the Duke-Breast-Cancer-MRI dataset. Radiomic features were extracted from pre- and post-contrast first-phase T1WI images. The Synthetic Minority Oversampling Technique (SMOTE) was applied- then the dataset was randomly divided into training and validation groups (7:3). The radiomics model was built using selected optimal features. Support vector machine (SVM)- random forest (RF)- decision tree (DT)- k-nearest neighbor (KNN)- extreme gradient boosting (XGBoost)- and light gradient boosting machine (LightGBM) were classifiers. Receiver operating characteristic curves were used to assess predictive performance. LightGBM performed best in predicting pCR [area under the curve (AUC): 0.823- 95% confidence interval (CI) [0.743-0.902]- accuracy 74.0%- sensitivity 85.0%- specificity 67.2%]. During subgroup analysis- RF was most effective in pCR prediction in luminal breast cancers (AUC: 0.914- 95% CI [0.847-0.981]- accuracy 87.0%- sensitivity 85.2%- specificity 88.1%). In triple-negative breast cancers- LightGBM performed best (AUC: 0.836- 95% CI [0.708-0.965]- accuracy 78.6%- sensitivity 68.2%- specificity 90.0%). The LightGBM-based radiomics model performed best in predicting pCR in patients with breast cancer. RF and LightGBM showed promising results for luminal and triple-negative breast cancers- respectively.
Alexander S Millar- John Arnn- Sam Himes- Julio C. Facelli,Uncertainty in Breast Cancer Risk Prediction: A Conformal Prediction Study of Race Stratification,Breast cancer (BC) is one of the most fatal forms of cancer- making it a significant contributor to mortality rates worldwide. Early detection and timely treatment of breast cancer are crucial in reducing its mortality rate. To ensure a healthy lifestyle- it is essential to develop systems that can accurately diagnose breast cancer. Recent advances in modern computing and information technologies have enabled significant progress in the early detection and prediction of diseases within healthcare systems. This study proposes a method for precise and automatic breast cancer prediction using deep-modified transfer learning-based Convolutional Neural Networks (CNNs). The CNN architectures employed include ResNet50- MobileNetV2- DenseNet121- and Xception- which serve as feature extractors to capture the most relevant features of breast Ultrasound images (BUSI). These extracted features are then accurately classified as benign or malignant using various high-performance classifiers- including Support Vector Machine (SVM)- K-Nearest Neighbors (KNN)- XGBoost- and Softmax. The experimental results demonstrate that the proposed deep modified DenseNet121 network with the Softmax classifier outperformed other models and existing techniques. This latter achieved remarkable performance metrics- including an accuracy of 95.34%- a precision of 90.90%- and an F1 score of 93.02%. These results highlight the effectiveness of our approach in enhancing the accuracy of breast cancer prediction. The superior performance of the proposed method provides significant improvements in decision-making speed and reduces the time- effort- and laboratory resources required for healthcare services. Consequently- this method has the potential to significantly enhance early diagnosis and enable more tailored treatment plans- ultimately contributing to better patient outcomes and reducing the overall mortality rates associated with breast cancer.
NA Chowdhury- L Wang- L Gu- ...,Machine Learning for Early Breast Cancer Detection,The volatility of global energy markets- particularly electricity prices- plays a crucial role in influencing international economic activities. In the era of big data- machine learning has revolutionized the field of cancer research- particularly in analyzing gene expression data. This study explores the application of machine learning models to the GSE45827 dataset- which contains breast cancer gene expression profiles. With over 54-000 genes and 151 samples categorized into six classes- the dataset presents a high-dimensional challenge that is addressed using dimensionality reduction techniques such as Principal Component Analysis (PCA) and t-distributed Stochastic Neighbor Embedding (t-SNE). The PCA method proved most effective in retaining the critical features of the data in lower dimensions- allowing for clearer visualization and enhanced model performance. The reduced dataset was then classified using the eXtreme Gradient Boosting (XGBoost) model- achieving promising multi-class classification results. The model demonstrated high precision- recall- and F1-scores across several classes- particularly exc elling in classes 1- 2- and 5. However- certain classes- such as 0 and 4- exhibited lower recall- highlighting areas for further refinement. The integration of PCA and XGBoost not only improved the interpretability and computational efficiency of the model but also contributed to the accurate identification of breast cancer subtypes- emphasizing the importance of machine learning in cancer diagnosis and treatment.
â€šÃ Ã¶âˆšÃ¡â€šÃ Ã¶âˆšâˆ«â€šÃ„Ã¶âˆšâ€ âˆšÂª â€šÃ Ã¶âˆšÂ£Â¬Â¨â€šÃ„Â¢â€šÃ„Ã¶âˆšâ€ Â¬Â¥,Prediction Model of Anti-Breast Cancer Drug Activity Based on Machine Learning,This research presents an in-depth exploration of breast cancer prediction through the application of machine learning models- specifically focusing on Logistic Regression- K-Nearest Neighbors- Support Vector Classifier- 'Decision Tree Classifier- Random Forest Classifier- Gradient Boosting Classifier- AdaBoost Classifier- and XGBoost Classifier. The study utilizes a comprehensive dataset comprising clinical features extracted from Kaggle. Various algorithms are employed- and a meticulous analysis of precision- recall- F1-score- and accuracy is conducted to assess model performance. Through advanced visualization techniques and statistical analysis- the research provides insights into the effectiveness of machine learning models in predicting breast cancer. The outcomes of this study aim to contribute valuable knowledge to the field of medical diagnostics- emphasizing the importance of machine learning methodologies in enhancing breast cancer prediction and classification.
HM Balaha- KM Ali- D Gondim- M Ghazal- ...,Harnessing Vision Transformers for Precise and Explainable Breast Cancer Diagnosis,This study presents a novel approach to enhance the accuracy of breast cancer detection from mammogram images through a hybrid feature selection and classification framework. Leveraging the power of XGBoost- a state-of-the-art machine learning algorithm- an embedded genetic algorithm is introduced for optimal feature selection. The genetic algorithm refines the feature set by iteratively evolving towards a subset that maximizes the discriminative power for breast cancer diagnosis. Subsequently- the selected features are fed into a Recurrent Neural Network (RNN) architecture with Random Boolean Networks (RBN) for classification. The RNN-RBN model captures intricate temporal dependencies within the image data- providing a nuanced understanding of the complex patterns indicative of breast cancer. The synergistic coupling of the XGBoost-embedded genetic algorithm for feature selection and the RNN-RBN model for classification results in a robust and interpretable system for breast cancer detection. The proposed hybrid approach is evaluated on a comprehensive dataset of mammogram images- demonstrating superior performance compared to traditional methods. The combination of feature selection through XGBoost- embedded genetic algorithms and RNN-RBN classification showcases the potential for advanced- accurate- and efficient breast cancer diagnosis- holding promise for improving early detection rates and patient outcomes in clinical settings.
Abdelrahman Gamal- A. Sharafeldeen- Eman Alnaghy- Reham Alghandour- Norah Saleh Alghamdi- Khadiga M. Ali- S. Shamaa- Amal AbouEleneen- Ahmed Elsaid Tolba- Samir Elmougy- M. Ghazal- S. Contractor- A. El-Baz,A Novel Machine Learning Approach for Predicting Neoadjuvant Chemotherapy Response in Breast Cancer: Integration of Multimodal Radiomics With Clinical and Molecular Subtype Markers,Breast cancer diagnosis is a crucial domain where Explainable Artificial Intelligence (XAI) integration holds immense importance. Understanding AI model decisions not only enhances trust but also aids in treatment strategies. However- the need for explainability must address privacy concerns- prompting the exploration of Federated Learning. This study explores the intersection of Explainable AI- Privacy- and Federated Learning in breast cancer diagnosis. Utilizing Wisconsin Diagnostic Breast Cancer Dataset and Wisconsin Breast Cancer Dataset- our results showcase that Federated Learning enhances user privacy while maintaining performance- achieving an accuracy of 97.59% and F1 score of 98.393% in Wisconsin Diagnostic Breast Cancer Dataset using artificial neural networks and 97.14% accuracy and 95.65% F1 score in Wisconsin Breast Cancer Dataset employing XGBoost. By computing SHAP values locally- we maintain explainability while enhancing privacy. Our findings highlight the potential of federated learning in maintaining privacy and explainability- advancing breast cancer diagnosis and treatment.
Yang Lu- Fei Yang- Yichao Tao- Pang An,An XGBoost Machine Learning Based Model for Predicting Ki-67 Value â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶Â¬Â¢â€šÃ„Ã¶âˆšÃ‘Â¬Â¢ 15% in T2NXM0 Stage Primary Breast Cancer Receiving Neoadjuvant Chemotherapy Using Clinical Data and Delta-Radiomic Features on Ultrasound Images and Overall Survival Analysis: A 5-Year Postoperative Follow-Up Study,The advancements in artificial intelligence and computational power have made deep learning an attractive tool for radiotherapy treatment planning. Deep learning has the potential to significantly simplify the trial-and-error process involved in inverse planning required by modern treatment techniques such as volumetric modulated arc therapy (VMAT). In this study- we explore the ability of deep learning to predict organ-at-risk (OAR) dose-volume histograms (DVHs) of left-sided breast cancer patients undergoing VMAT treatment based solely on their anatomical characteristics. The predicted DVHs could be used to derive patient-specific dose constraints and dose objectives- streamlining the treatment planning process- standardizing the quality of the plans- and personalizing the treatment planning. This study aimed to develop a deep learning-based framework for the prediction of organ-specific dose-volume histograms (DVH) based on structures delineated for left-sided breast cancer treatment. We used a dataset of 249 left-sided breast cancer patients treated with tangential VMAT fields. We extracted delineated structures and dose distributions for each patient and derived slice-by-slice DVHs for planning target volume (PTV) and organs-at-risk. The patients were divided into training (70%- nÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 174)- validation (10%- nÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 24)- and test (20%- nÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 51) sets. Collected data were used to train a deep learning model for the prediction of the DVHs based on the delineated structures. The developed deep learning model comprised a modified DenseNet architecture followed by a recurrent neural network. In the independent test set (nÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 51)- the point-wise differences in the slice-by-slice DVHs between the clinical and predicted DVHs were small; the mean squared errors were 3.53- 1.58- 2.28- 3.37- and 1.44 [â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢10-4] for PTV- heart- ipsilateral lung- contralateral lung- and contralateral breast- respectively. With the derived cumulative DVHs- the mean absolute differenceÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬Â±Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ standard deviation of mean doses between the clinical and the predicted DVH were 0.08Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 0.04Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Gy- 0.24Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 0.22Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Gy- 0.73Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 0.46Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Gy- 0.07Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 0.06Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Gy- and 0.14Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 0.14Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Gy for PTV- heart- ipsilateral lung- contralateral lung- and contralateral breast- respectively. The deep learning-based approach enabled automatic and reliable prediction of the DVH based on delineated structures. The predicted DVHs could potentially serve as patient-specific clinical goals used to aid treatment planning and avoid suboptimal plans or to derive optimization objectives and constraints for automated treatment planning.
S M Yu- C Y M Young- Y H Chan- Y S Chan- C Tsoi- M N Y Choi- T H Chan- J Leung- W C W Chu- E H Y Hung- H H L Chau,Artificial intelligence-based computer-aided diagnosis for breast cancer detection on digital mammography in Hong Kong,Breast cancer-related lymphedema (BCRL) is one of the common complications after breast cancer surgery. It can easily lead to limb swelling- deformation and upper limb dysfunction- which has a serious impact on the physical and mental health and quality of life of patients. Previous studies have mostly used statistical methods such as linear regression and logistic regression to analyze the influencing factors- but all of them have certain limitations. Machine learning (ML) is an important branch of artificial intelligence- which can effectively overcome the problems of multivariate interaction and collinearity. This study aimed to explore the influencing factors for the occurrence of BCRL in breast cancer patients- and construct a predictive model with ML algorithms and validate its predictive value on this basis. Clinical data of breast cancer patients admitted to Hainan Cancer Hospital from September 2018 to May 2024 were retrospectively collected. BCRL was considered as the outcome measurement- and the data were divided into training and validation sets in a ratio of 7:3. In the training set- random forest (RF)- support vector machine (SVM)- and eXtreme Gradient Boosting (XGBoost) algorithms were used to construct predictive models. The discrimination accuracy of the models was evaluated with receiver operating characteristic (ROC) curve analysis- sensitivity- specificity- and F1 score. The calibration of the models was assessed using calibration curves and the Hosmer-Lemeshow (H-L) Chi-squared test. Two hundred and forty patients who met the inclusion criteria were screened- and they were randomly divided into a training set (168 patients) and a validation set (72 patients) in a 7:3 ratio. In the training set- 44 cases developed BCRL- while 124 did not. There were statistically significant differences (P<0.05) in hypertension history- number of dissected lymph nodes- postoperative complications- postoperative functional exercises- chemotherapy- radiotherapy- tumor node metastasis (TNM) stage- and level of axillary lymph node dissection between the BCRL and non-BCRL groups. Among the four models- the XGBoost model showed the best predictive performance- with an area under the curve (AUC) of 0.99 in the training set and 0.89 in the validation set. The XGBoost model demonstrated good calibration in both the training and validation sets- showing good consistency with the ideal model. The ML-based XGBoost model for predicting BCRL exhibits excellent performance and assists healthcare professionals in rapidly and accurately assessing the risk of BCRL occurrence.
Mâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»ria Kovâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»â€šÃ Ãœâˆšâ‰ â€šÃ Ã¶âˆšÃ¼ovâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»- Viktor Hlavâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»â€šÃ Ãœâˆšâ‰ â€šÃ Ã¶âˆšÃ¼- Renata Koâ€šÃ„Ã¶âˆšÂ¢âˆšâ€ â€šÃ Ã¶Â¬âˆ‚evnikovovâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»- Karel Rauâ€šÃ„Ã¶âˆšÂ¢âˆšâ€ Â¬Â¨â€šÃ Ã»- Jiâ€šÃ„Ã¶âˆšÂ¢âˆšâ€ â€šÃ Ã¶Â¬â€¢â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€  Gatâ€šÃ Ãœâˆšâ‰ â€šÃ Ã¶Â¬Âµk- Pavel Souâ€šÃ Ãœâˆšâ‰ â€šÃ Ã¶âˆšÃ¼ek,Artificial Intelligence-Driven Prediction Revealed CFTR Associated with Therapy Outcome of Breast Cancer: A Feasibility Study,Current radiomics research primarily focuses on intratumoral regions and fixed peritumoral areas- lacking optimization for accurate Ki-67 prediction. This study aimed to develop machine learning (ML) models to analyze radiomic features from Automated Breast Volume Scanning (ABVS) images of different peritumoral region sizes to identify the optimal size for accurate preoperative Ki-67 prediction. A total of 668 breast cancer patients were enrolled and divided into training (486) and testing (182) cohorts. In the training cohort- ML models were developed for intratumoral and peritumoral regions (2- 4- 6- 8- and 10Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ mm). Relevant Ki-67 features for each ROI were identified- and different models were compared to determine the optimal one. These models were validated using a testing cohort to find the most accurate peritumoral region for Ki-67 prediction. SHAP (Shapley Additive Explanations) analysis was performed to identify key radiomic features from the optimal model. The Extreme Gradient Boosting (XGBoost) model for the intratumoral region combined with the 6Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ mm peritumoral region achieved the highest predictive accuracy- with an AUC of 0.957 in the training cohort and 0.920 in the testing cohort. Calibration curves confirmed reliability- and decision curve analysis demonstrated the highest net benefit. SHAP indicated that 6Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ mm peritumoral radiomic features are more significant than intratumoral features. The XGBoost model using ABVS-derived radiomic features from both the intratumoral and 6Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ mm peritumoral regions provides the most accurate preoperative Ki-67 prediction.
Hyuksool Kwon- SeokHwan Oh- Myeong-Gee Kim- Youngmin Kim- Gui-Jae Jung- Hyeon-Jik Lee- Sang-Yun Kim- Hyeon-Min Bae,Artificial Intelligence-Enhanced Quantitative Ultrasound for Breast Cancer: Pilot Study on Quantitative Parameters and Biopsy Outcomes,Breast cancer's global prevalence highlights the need for the development of precise and reliable diagnostic tools. The objective of this study is to contribute to the growing body of knowledge in breast cancer diagnosis- highlighting the potential of a range of classifier algorithms- soft and hard voting ensemble approaches- and neural networks as potent tools in medical applications. These models were utilized to assess the Wisconsin Breast Cancer dataset obtained from UCI Machine Learning repository- consisting of 569 samples and 30 features. Besides- we utilized Principal Component Analysis (PCA) and Variance Inflation Factors (VIF) techniques to perform feature selection and dimensionality reduction on the standardized and original features respectively. After conducting PCA analysis- a variety of classifier models- including k-nearest neighbors (KNN)- Lo-gistic Regression (LR)- Decision Tree (DT)- LightGBM (LGBM)- XGBoost (XGB)- Random Forest (RF)- and Naive Bayes (NB)- were employed. Moreover- after the VIF analysis- these classifier models and a Neural Network (NN) model were put into action. Subsequently- the best three and best five classifier algorithms were determined using accuracy metrics- then both soft and hard voting ensemble were executed on these algorithms. The neural network (NN) model underwent training for 500 epochs since beyond that point- the loss curves displayed nearly constant values. This model (NN) were compiled with â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´adamâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Å“Ã„ optimizer along with binary crossentropy as loss function. We observed our ensemble strategies demonstrated superior performance in accuracy compared to all existing methods.
Gil Shamai- Ran Schley- Alexandra Cretu- Tal Neoran- Edmond Sabo- Yoav Binenbaum- Shachar Cohen- Tal Goldman- Antâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„Â¢nio Polâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„Â¢nia- Keren Drumea- Karin Stoliar- Ron Kimmel,Clinical utility of receptor status prediction in breast cancer and misdiagnosis identification using deep learning on hematoxylin and eosin-stained slides,TiaoShenGongJian (TSGJ) decoction- a traditional Chinese medicine for breast cancer- has unknown active compounds- targets- and mechanisms. This study identifies TSGJ's key targets and compounds for breast cancer treatment through network pharmacology- machine learning- and experimental validation. Bioactive components and targets of TSGJ were identified from the TCMSP database- and breast cancer-related targets from GeneCards- PharmGkb- and RNA-seq datasets. Intersection of these targets revealed therapeutic targets of TSGJ. PPI analysis was performed via STRING- and machine learning methods (SVM- RF- GLM- XGBoost) identified key targets- validated by GSE70905- GSE70947- GSE22820- and TCGA-BRCA datasets. Pathway analyses and molecular docking were performed. TSGJ and core compounds' effectiveness was confirmed by MTT and RT-qPCR assays. 160 common targets of TSGJ were identified- with 30Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ hub targets from PPI analysis. Five predictive targets (HIF1A- CASP8- FOS- EGFR- PPARG) were screened via SVM. Their diagnostic- biomarker- immune- and clinical values were validated. Quercetin- luteolin- and baicalein were identified as core components. Molecular docking confirmed their strong affinities with predicted targets. These compounds modulated key targets and induced cytotoxicity in breast cancer cell lines in a similar way as TSGJ. This study reveals the main active components and targets of TSGJ against breast cancer- supporting its potential for breast cancer prevention and treatment.
Petru Manescu- Joseph Geradts- Delmiro Fernandez-Reyes,Computational Pathology Detection of Hypoxia-Induced Morphologic Changes in Breast Cancer,Breast cancer is a significant global health concern- and early detection is crucial for improving patient outcomes. Mammography is widely used but has limitations- particularly for younger women with denser breasts. These include reduced sensitivity- false positives- and radiation risks. This highlights the need for alternative screening methods. In this study- we assess the performance of SAFE (Scan and Find Early)- a novel microwave imaging device- in detecting breast cancer in a larger patient cohort. Unlike previous studies that predominantly relied on cross-validation- this study employs a more reliable- independent evaluation methodology to enhance generalizability. We developed an XGBoost model to classify breast cancer cases into positive (malignant) and negative (benign or healthy) groups. The model was analyzed with respect to key factors such as breast size- density- age- tumor size- and histopathological findings. This approach provides a better understanding of how these factors influence the model's performance- using an independent evaluation methodology for increased reliability. Our results demonstrate that SAFE exhibits high sensitivity- particularly in dense breasts (91%) and younger patients (83%)- suggesting its potential as a supplemental screening tool. Additionally- the system shows high detection accuracy for both small (<2 cm) and larger lesions- proving effective in early cancer detection. This study reinforces the potential of SAFE to complement existing screening methods- particularly for patients with dense breasts- where mammography's sensitivity is reduced. The promising results warrant further research to solidify SAFE's clinical application as an alternative screening tool for breast cancer detection.
M Ramkumar- R Sarath Kumar- R Padmapriya- S Balu Mahandiran,Improved DeTraC Binary Coyote Net-Based Multiple Instance Learning for Predicting Lymph Node Metastasis of Breast Cancer From Whole-Slide Pathological Images,With the tremendous leap of various adjuvant therapies- breast cancer (BC)-related deaths have decreased significantly. Increasing attention was focused on the effect of cardiac disease on BC survivors- while limited existing population-based studies lay emphasis on the young age population. Data of BC patients aged less than 50Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ years was collected from the SEER database. A competing risk model was introduced to analyze the effects of clinicopathology variables on the cardiac disease-specific death (CDSD) risks of these patients. Further- an XGBoost prediction model was constructed to predict the risk of CDSD. Prediction performance was assessed using the receiver operating characteristic (ROC) analysis- area under the POC curve (AUC) values- calibration curves- decision curves- and confusion matrix- and SHapley Additive exPlanations (SHAP) were used to interpret the models. Our competing risk analysis proved that young BC patients with older age- low household income- non-metropolitan residential environment- black race- unmarried status- HRâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢subtype- higher T stage (T2-4)- receiving chemotherapy- and non-surgery are under higher risk of CDSD. Further- five machine learning models were constructed to predict the CDSD risks of young BC patients- among which the XGBoost models showed the highest AUC value (train set: AUCâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.846; test set: AUCâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.836). The confusion matrix of the XGBoost model demonstrated that the sensitivity- specificity- and correction were 0.81- 0.94- and 0.94 for the train set- and 0.82- 0.95- and 0.96 for the test set- respectively. The SHAP graph indicated that median household income- marital status- race- and age at diagnosis were the top four strongest predictors. Independent CDSD risk factors for young BC patients were identified- and machine-learning prognostic models were constructed to predict their CDSD risks. Our validation results indicated that the predicted probability of our XGBoost model agrees well with the actual CDSD risks- and it can help recognize high-risk populations and therefore develop effective cardioprotection strategies. Hopefully- our findings can support the growth of the new field of cardio-oncology.
Fanli Qu- Guanwen Wang- Ping Wen- Xiaoyu Liu- Xiaohua Zeng,Knowledge mapping of immunotherapy for breast cancer: A bibliometric analysis from 2013 to 2022,The goal is to use three different machine learning models to predict the recurrence of breast cancer across a very heterogeneous sample of patients with varying disease kinds and stages. A heterogeneous group of patients with varying cancer kinds and stages- including both triple-negative breast cancer (TNBC) and non-triple-negative breast cancer (non-TNBC)- was examined. Three distinct models were created using the following five machine learning techniques: Adaptive Boosting (AdaBoost)- Random Under-sampling Boosting (RUSBoost)- Extreme Gradient Boosting (XGBoost)- support vector machines (SVM)- and Logistic Regression. The clinical model used both clinical and pathology data in conjunction with the machine learning algorithms. The machine learning algorithms were combined with dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) imaging characteristics in the radiomic model- and the merged model combined the two types of data. Each technique was evaluated using several criteria- including the receiver operating characteristic (ROC) curve- precision- recall- and F1 score. The results suggest that the integration of clinical and radiomic data improves the predictive accuracy in identifying instances of breast cancer recurrence. The XGBoost algorithm is widely recognized as the most effective algorithm in terms of performance. The findings presented in this study offer significant contributions to the field of breast cancer research- particularly in relation to the prediction of cancer recurrence. These insights hold great potential for informing future investigations and clinical interventions that seek to enhance the accuracy and effectiveness of recurrence prediction in breast cancer patients.
Paidipati Dinesh- A. S. Vickram- P. Kalyanasundaram,Medical image prediction for diagnosis of breast cancer disease comparing the machine learning algorithms: SVM- KNN- logistic regression- random forest and decision tree to measure accuracy,Breast cancer is the most fatal womenâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s cancer- and accurate diagnosis of this disease in the initial phase is crucial to abate death rates worldwide. The demand for computer-aided disease diagnosis technologies in healthcare is growing significantly to assist physicians in ensuring the effectual treatment of critical diseases. The vital purpose of this study is to analyze and evaluate the classification efficiency of several machine learning algorithms with hyperparameter optimization techniques using grid search and random search to reveal an efficient breast cancer diagnosis approach. Choosing the optimal combination of hyperparameters using hyperparameter optimization for machine learning models has a straight influence on the performance of models. According to the findings of several evaluation studies- the k-nearest neighbor is addressed in this study for effective diagnosis of breast cancer- which got a 100.00% recall value with hyperparameters found utilizing grid search. k-nearest neighbor- logistic regression- and multilayer perceptron obtained 99.42% accuracy after utilizing hyperparameter optimization. All machine learning models showed higher efficiency in breast cancer diagnosis with grid search-based hyperparameter optimization except for XGBoost. Therefore- the evaluation outcomes strongly validate the effectiveness and reliability of the proposed technique for breast cancer diagnosis.
JunHao Yin- Ximei Wu- Xueying Liu,Multi-Class Classification of Breast Cancer Gene Expression Using PCA and XGBoost,"This study uses three machine learning models to perform classification analysis on breast cancer data, aiming to improve diagnostic accuracy. After data preprocessing and standardization, the performance of each model was comprehensively evaluated using classification and regression metrics. The results showed that the logistic regression model performed the best, with an accuracy of 0.9825, while SVM and random forest also showed good performance. The classification effects of each model were visualized through ROC curves and confusion matrices, demonstrating that logistic regression has high application value in breast cancer diagnosis."
K H Park- S Loibl- J Sohn- Y H Park- Z Jiang- H Tadjoedin- S Nag- S Saji- M Md Yusof- E M B Villegas- E H Lim- Y-S Lu- S Ithimakin- L-M Tseng- T Dejthevaporn- T W-W Chen- S C Lee- C Galvez- S Malwinder- T Kogawa- J Bajpai- B Brahma- S Wang- G Curigliano- T Yoshino- S-B Kim- G Pentheroudakis- S-A Im- F Andre- J B Ahn- N Harbeck,Pan-Asian adapted ESMO Clinical Practice Guidelines for the diagnosis- treatment and follow-up of patients with early breast cancer,Objective: To establish a model based on clinical and delta-radiomic features within ultrasound images using XGBoost machine learning to predict proliferation-associated nuclear antigen Ki-67 valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶Â¬Â¢â€šÃ„Ã¶âˆšÃ‘Â¬Â¢â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢15% in T2NXM0 stage primary breast cancer (BC). Method: Data were collected from 228 randomly selected BC patients who received ultrasound screening and postoperative pathologic assessment from April 2015 to September 2018. The patients were classified into the study group (nâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢80) and control group (nâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢148)- and the data were apportioned into the training set and test set at a 7:3 ratio based on time intervals. In the training set- crucial factors were identified from clinical features and grayscale and delta-radiomic features within ultrasound images- by using the chi-square test- t-test- and rank-sum test. The clinical model- imaging model- and combined model were built using multivariate logistic regression- respectively. The model's predictive performance and clinical net benefit were assessed using DeLong's method and decision curve analysis. Meanwhile- an XGBoost algorithm is used to establish a prediction model to verify the above results. Results: The crucial factors affecting Ki-67 valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶Â¬Â¢â€šÃ„Ã¶âˆšÃ‘Â¬Â¢â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢15% included BMI- lymph node metastases- BC volume- CA153- pathology type- tumor boundaries- tumor morphology- elastography score- and delta-radscore. The predictive performance of the combined model [AUC 0.857- OR 0.0290- 95% CI 0.793-0.908] was considerably improved on the training set than the clinical model [AUC 0.724- OR 0.0422- 95% CI 0.648-0.792] and the imaging model [AUC 0.798- OR 0.0355- 95% CI 0.727-0.857]. The decision curve analysis also confirmed that the combined model delivered a higher clinical net benefit- and the verification on the test set yielded similar results. The nomogram and the calibration curve plotted based on the combined model achieved satisfactory clinical effects. The SHAP value of the XGBoost algorithm also confirmed that lymph node metastasis- BC volume- elastography score- and delta-radscore are the best independent factors for predicting BC Ki-67 valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶Â¬Â¢â€šÃ„Ã¶âˆšÃ‘Â¬Â¢â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢15%. Conclusion: The XGBoost machine learning-based combined model integrating clinical features and delta-radiomic features on ultrasound images was able to predict the Ki-67 valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶Â¬Â¢â€šÃ„Ã¶âˆšÃ‘Â¬Â¢â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢15% in an efficient and noninvasive manner- providing important clues for clinical decision-making and follow-up in BC.
Matthias Hans Belau- Lisa Jung- Tabea Maurer- Nadia Obi- Sabine Behrens- Petra Seibold- Heiko Becher- Jenny Chang-Claude,Social relationships and their impact on health-related quality of life in a long-term breast cancer survivor cohort,Machine learning classifiers are increasingly used to create predictive models for pathological complete response (pCR) in breast cancer after neoadjuvant therapy (NAT). Few studies have compared the effectiveness of different ML classifiers. This study evaluated radiomics models based on pre- and post-contrast first-phase T1 weighted images (T1WI) in predicting breast cancer pCR after NAT and compared the performance of ML classifiers. This retrospective study enrolled 281 patients undergoing NAT from the Duke-Breast-Cancer-MRI dataset. Radiomic features were extracted from pre- and post-contrast first-phase T1WI images. The Synthetic Minority Oversampling Technique (SMOTE) was applied- then the dataset was randomly divided into training and validation groups (7:3). The radiomics model was built using selected optimal features. Support vector machine (SVM)- random forest (RF)- decision tree (DT)- k-nearest neighbor (KNN)- extreme gradient boosting (XGBoost)- and light gradient boosting machine (LightGBM) were classifiers. Receiver operating characteristic curves were used to assess predictive performance. LightGBM performed best in predicting pCR [area under the curve (AUC): 0.823- 95% confidence interval (CI) [0.743-0.902]- accuracy 74.0%- sensitivity 85.0%- specificity 67.2%]. During subgroup analysis- RF was most effective in pCR prediction in luminal breast cancers (AUC: 0.914- 95% CI [0.847-0.981]- accuracy 87.0%- sensitivity 85.2%- specificity 88.1%). In triple-negative breast cancers- LightGBM performed best (AUC: 0.836- 95% CI [0.708-0.965]- accuracy 78.6%- sensitivity 68.2%- specificity 90.0%). The LightGBM-based radiomics model performed best in predicting pCR in patients with breast cancer. RF and LightGBM showed promising results for luminal and triple-negative breast cancers- respectively.
Alexander S Millar- John Arnn- Sam Himes- Julio C. Facelli,Uncertainty in Breast Cancer Risk Prediction: A Conformal Prediction Study of Race Stratification,Breast cancer (BC) is one of the most fatal forms of cancer- making it a significant contributor to mortality rates worldwide. Early detection and timely treatment of breast cancer are crucial in reducing its mortality rate. To ensure a healthy lifestyle- it is essential to develop systems that can accurately diagnose breast cancer. Recent advances in modern computing and information technologies have enabled significant progress in the early detection and prediction of diseases within healthcare systems. This study proposes a method for precise and automatic breast cancer prediction using deep-modified transfer learning-based Convolutional Neural Networks (CNNs). The CNN architectures employed include ResNet50- MobileNetV2- DenseNet121- and Xception- which serve as feature extractors to capture the most relevant features of breast Ultrasound images (BUSI). These extracted features are then accurately classified as benign or malignant using various high-performance classifiers- including Support Vector Machine (SVM)- K-Nearest Neighbors (KNN)- XGBoost- and Softmax. The experimental results demonstrate that the proposed deep modified DenseNet121 network with the Softmax classifier outperformed other models and existing techniques. This latter achieved remarkable performance metrics- including an accuracy of 95.34%- a precision of 90.90%- and an F1 score of 93.02%. These results highlight the effectiveness of our approach in enhancing the accuracy of breast cancer prediction. The superior performance of the proposed method provides significant improvements in decision-making speed and reduces the time- effort- and laboratory resources required for healthcare services. Consequently- this method has the potential to significantly enhance early diagnosis and enable more tailored treatment plans- ultimately contributing to better patient outcomes and reducing the overall mortality rates associated with breast cancer.
Ali Yurtseven- Aleksandar Janjic- Mehmet Cayoren- Onur Bugdayci- Mustafa Erkin Aribal- Ibrahim Akduman,XGBoost Enhances the Performance of SAFE: A Novel Microwave Imaging System for Early Detection of Malignant Breast Cancer,This present study focuses on integrating data-driven approaches into personalized medicine for better detection and treatment of Parkinson's disease and breast cancer through the US healthcare system. The deeper integration of genomics- clinical records- and patient self-reported data with machine learning algorithms will enhance early disease detection and optimization of treatment pathways. The results show that- more precisely- Random Forest and XGBoost machine learning models hold great promise for considerably improving diagnostic precision and predictive power. This realization opens a door for precision medicine-tailored health services according to the peculiarities of individual patients- which would improve treatment outcomes and encourage preventive healthcare. In addition- this approach aligns with the latest US efforts in precision medicine and contributes to evidence-based transformation in healthcare practice.
