Timea Bezdan- Ivana Strumberger- Milan Tuba,Optimizing Machine Learning for Breast Cancer Detection by Hybrid Metaheuristic Approach,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ clinical practice although recent artificial intelligence (AI) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ the transformer-based approaches to handle time attention- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ used to improve the quality of large language modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s (LLM) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
HM Balaha- KM Ali- D Gondim- M Ghazal- ...,Harnessing Vision Transformers for Precise and Explainable Breast Cancer Diagnosis,This study presents a novel approach to enhance the accuracy of breast cancer detection from mammogram images through a hybrid feature selection and classification framework. Leveraging the power of XGBoost- a state-of-the-art machine learning algorithm- an embedded genetic algorithm is introduced for optimal feature selection. The genetic algorithm refines the feature set by iteratively evolving towards a subset that maximizes the discriminative power for breast cancer diagnosis. Subsequently- the selected features are fed into a Recurrent Neural Network (RNN) architecture with Random Boolean Networks (RBN) for classification. The RNN-RBN model captures intricate temporal dependencies within the image data- providing a nuanced understanding of the complex patterns indicative of breast cancer. The synergistic coupling of the XGBoost-embedded genetic algorithm for feature selection and the RNN-RBN model for classification results in a robust and interpretable system for breast cancer detection. The proposed hybrid approach is evaluated on a comprehensive dataset of mammogram images- demonstrating superior performance compared to traditional methods. The combination of feature selection through XGBoost- embedded genetic algorithms and RNN-RBN classification showcases the potential for advanced- accurate- and efficient breast cancer diagnosis- holding promise for improving early detection rates and patient outcomes in clinical settings.
Emmanuel Ahishakiye- Fredrick Kanobe,Breast Cancer Classification Using Breast Ultrasound Images with a Hybrid of Transfer Learning and Bayesian-Optimized Fast Learning Network,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ summary based on transformer language model approaches. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ self-attention mechanism within the transformer architecture â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ the shortcomings of traditional deep learning models- such as â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Muniraj Gupta- Nidhi Verma- Naveen Sharma- Satyendra Narayan Singh- R. K. Brojen Singh- Saurabh Kumar Sharma,Deep Transfer Learning Hybrid Techniques for Precision in Breast Cancer Tumor Histopathology Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ development of artificial intelligence- CAD systems utilizing deep learning technology have â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Compared to CNNs- the self-attention mechanism in Transformers exhibits robust global â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Guangliang Yang- Haiqi Chen- Jinchao Yue,Deep learning to optimize radiotherapy decisions for elderly patients with early-stage breast cancer: a novel approach for personalized treatment,Accurately and swiftly segmenting breast tumors is significant for cancer diagnosis and treatment. Ultrasound imaging stands as one of the widely employed methods in clinical practice. However- due to challenges such as low contrast- blurred boundaries- and prevalent shadows in ultrasound images- tumor segmentation remains a daunting task. In this study- we propose BCT-Net- a network amalgamating CNN and transformer components for breast tumor segmentation. BCT-Net integrates a dual-level attention mechanism to capture more features and redefines the skip connection module. We introduce the utilization of a classification task as an auxiliary task to impart additional semantic information to the segmentation network- employing supervised contrastive learning. A hybrid objective loss function is proposed- which combines pixel-wise cross-entropy- binary cross-entropy- and supervised contrastive learning loss. Experimental results demonstrate that BCT-Net achieves high precision- with Pre and DSC indices of 86.12% and 88.70%- respectively. Experiments conducted on the BUSI dataset of breast ultrasound images manifest that this approach exhibits high accuracy in breast tumor segmentation.
Xiao Guo- Jiaying Xing- Yuyan Cao- Wenchuang Yang- Xinlin Shi- Runhong Mu- Tao Wang,Machine learning based anoikis signature predicts personalized treatment strategy of breast cancer,The vision transformer (ViT) architecture- with its attention mechanism based on multi-head attention layers- has been widely adopted in various computer-aided diagnosis tasks due to its effectiveness in processing medical image information. ViTs are notably recognized for their complex architecture- which requires high-performance GPUs or CPUs for efficient model training and deployment in real-world medical diagnostic devices. This renders them more intricate than convolutional neural networks (CNNs). This difficulty is also challenging in the context of histopathology image analysis- where the images are both limited and complex. In response to these challenges- this study proposes a TokenMixer hybrid-architecture that combines the strengths of CNNs and ViTs. This hybrid architecture aims to enhance feature extraction and classification accuracy with shorter training time and fewer parameters by minimizing the number of input patches employed during training- while incorporating tokenization of input patches using convolutional layers and encoder transformer layers to process patches across all network layers for fast and accurate breast cancer tumor subtype classification. The TokenMixer mechanism is inspired by the ConvMixer and TokenLearner models. First- the ConvMixer model dynamically generates spatial attention maps using convolutional layers- enabling the extraction of patches from input images to minimize the number of input patches used in training. Second- the TokenLearner model extracts relevant regions from the selected input patches- tokenizes them to improve feature extraction- and trains all tokenized patches in an encoder transformer network. We evaluated the TokenMixer model on the BreakHis public dataset- comparing it with ViT-based and other state-of-the-art methods. Our approach achieved impressive results for both binary and multi-classification of breast cancer subtypes across various magnification levels (40â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 100â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 200â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 400â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢). The model demonstrated accuracies of 97.02% for binary classification and 93.29% for multi-classification- with decision times of 391.71 and 1173.56Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ s- respectively. These results highlight the potential of our hybrid deep ViT-CNN architecture for advancing tumor classification in histopathological images. The source code is accessible: https://github.com/abimouloud/TokenMixer .
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
HM Balaha- KM Ali- D Gondim- M Ghazal- ...,Harnessing Vision Transformers for Precise and Explainable Breast Cancer Diagnosis,This study presents a novel approach to enhance the accuracy of breast cancer detection from mammogram images through a hybrid feature selection and classification framework. Leveraging the power of XGBoost- a state-of-the-art machine learning algorithm- an embedded genetic algorithm is introduced for optimal feature selection. The genetic algorithm refines the feature set by iteratively evolving towards a subset that maximizes the discriminative power for breast cancer diagnosis. Subsequently- the selected features are fed into a Recurrent Neural Network (RNN) architecture with Random Boolean Networks (RBN) for classification. The RNN-RBN model captures intricate temporal dependencies within the image data- providing a nuanced understanding of the complex patterns indicative of breast cancer. The synergistic coupling of the XGBoost-embedded genetic algorithm for feature selection and the RNN-RBN model for classification results in a robust and interpretable system for breast cancer detection. The proposed hybrid approach is evaluated on a comprehensive dataset of mammogram images- demonstrating superior performance compared to traditional methods. The combination of feature selection through XGBoost- embedded genetic algorithms and RNN-RBN classification showcases the potential for advanced- accurate- and efficient breast cancer diagnosis- holding promise for improving early detection rates and patient outcomes in clinical settings.
Xiao Guo- Jiaying Xing- Yuyan Cao- Wenchuang Yang- Xinlin Shi- Runhong Mu- Tao Wang,Machine learning based anoikis signature predicts personalized treatment strategy of breast cancer,The vision transformer (ViT) architecture- with its attention mechanism based on multi-head attention layers- has been widely adopted in various computer-aided diagnosis tasks due to its effectiveness in processing medical image information. ViTs are notably recognized for their complex architecture- which requires high-performance GPUs or CPUs for efficient model training and deployment in real-world medical diagnostic devices. This renders them more intricate than convolutional neural networks (CNNs). This difficulty is also challenging in the context of histopathology image analysis- where the images are both limited and complex. In response to these challenges- this study proposes a TokenMixer hybrid-architecture that combines the strengths of CNNs and ViTs. This hybrid architecture aims to enhance feature extraction and classification accuracy with shorter training time and fewer parameters by minimizing the number of input patches employed during training- while incorporating tokenization of input patches using convolutional layers and encoder transformer layers to process patches across all network layers for fast and accurate breast cancer tumor subtype classification. The TokenMixer mechanism is inspired by the ConvMixer and TokenLearner models. First- the ConvMixer model dynamically generates spatial attention maps using convolutional layers- enabling the extraction of patches from input images to minimize the number of input patches used in training. Second- the TokenLearner model extracts relevant regions from the selected input patches- tokenizes them to improve feature extraction- and trains all tokenized patches in an encoder transformer network. We evaluated the TokenMixer model on the BreakHis public dataset- comparing it with ViT-based and other state-of-the-art methods. Our approach achieved impressive results for both binary and multi-classification of breast cancer subtypes across various magnification levels (40â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 100â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 200â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 400â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢). The model demonstrated accuracies of 97.02% for binary classification and 93.29% for multi-classification- with decision times of 391.71 and 1173.56Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ s- respectively. These results highlight the potential of our hybrid deep ViT-CNN architecture for advancing tumor classification in histopathological images. The source code is accessible: https://github.com/abimouloud/TokenMixer .
Zhe Lin,Breast cancer classification based on hybrid machine learning model,Automatic breast tumor segmentation based on convolutional neural networks (CNNs) is significant for the diagnosis and monitoring of breast cancers. CNNs have become an important method for early diagnosis of breast cancer and- thus- can help decrease the mortality rate. In order to assist medical professionals in breast cancer investigation a computerized system based on two encoder-decoder architectures for breast tumor segmentation has been developed. Two pre-trained DeepLabV3+ and U-Net models are proposed. The encoder generates a high-dimensional feature vector while the decoder analyses the low-resolution feature vector provided by the encoder and generates a semantic segmentation mask. Semantic segmentation based on deep learning techniques can overcome the limitations of traditional algorithms. To assess the efficiency of breast ultrasound image segmentation- we compare the segmentation results provided by CNNs against the Local Graph Cut technique (a semi-automatic segmentation method) in the Image Segmenter application. The output segmentation results have been evaluated by using the Dice similarity coefficient that compares the ground truth images provided by the specialists against the predicted segmentation results provided by the CNNs and Local Graph Cut algorithm. The proposed approach is validated on 780 breast ultrasonographic images of the BUSI public database of which 437 are benign and 210 are malignant. The BUSI database provides classification (benign or malignant) labels for ground truth in binary mask images. The average Dice scores computed between the ground truth images against CNNs were as follows: 0.9360 (malignant) and 0.9325 (benign) for the DeepLabV3+ architecture and of 0.6251 (malignant) and 0.6252 (benign) for the U-Net- respectively. When the segmentation results provided by CNNs were compared with the Local Graph Cut segmented images- the Dice scores were 0.9377 (malignant) and 0.9204 (benign) for DeepLabV3+ architecture and 0.6115 (malignant) and 0.6119 (benign) for U-Net- respectively. The results show that the DeepLabV3+ has significantly better segmentation performance and outperforms the U-Net network.
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
Xiao Guo- Jiaying Xing- Yuyan Cao- Wenchuang Yang- Xinlin Shi- Runhong Mu- Tao Wang,Machine learning based anoikis signature predicts personalized treatment strategy of breast cancer,The vision transformer (ViT) architecture- with its attention mechanism based on multi-head attention layers- has been widely adopted in various computer-aided diagnosis tasks due to its effectiveness in processing medical image information. ViTs are notably recognized for their complex architecture- which requires high-performance GPUs or CPUs for efficient model training and deployment in real-world medical diagnostic devices. This renders them more intricate than convolutional neural networks (CNNs). This difficulty is also challenging in the context of histopathology image analysis- where the images are both limited and complex. In response to these challenges- this study proposes a TokenMixer hybrid-architecture that combines the strengths of CNNs and ViTs. This hybrid architecture aims to enhance feature extraction and classification accuracy with shorter training time and fewer parameters by minimizing the number of input patches employed during training- while incorporating tokenization of input patches using convolutional layers and encoder transformer layers to process patches across all network layers for fast and accurate breast cancer tumor subtype classification. The TokenMixer mechanism is inspired by the ConvMixer and TokenLearner models. First- the ConvMixer model dynamically generates spatial attention maps using convolutional layers- enabling the extraction of patches from input images to minimize the number of input patches used in training. Second- the TokenLearner model extracts relevant regions from the selected input patches- tokenizes them to improve feature extraction- and trains all tokenized patches in an encoder transformer network. We evaluated the TokenMixer model on the BreakHis public dataset- comparing it with ViT-based and other state-of-the-art methods. Our approach achieved impressive results for both binary and multi-classification of breast cancer subtypes across various magnification levels (40â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 100â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 200â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 400â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢). The model demonstrated accuracies of 97.02% for binary classification and 93.29% for multi-classification- with decision times of 391.71 and 1173.56Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ s- respectively. These results highlight the potential of our hybrid deep ViT-CNN architecture for advancing tumor classification in histopathological images. The source code is accessible: https://github.com/abimouloud/TokenMixer .
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
Xinru Chen- Yingying Zhao- Yaohui Wang- Yumei Ye- Shuguang Xu- Liheng Zhou- Yanping Lin- Jingsong Lu- Wenjin Yin,Fluctuations in serum lipid levels during neoadjuvant treatment as novel predictive and prognostic biomarkers for locally advanced breast cancer: a retrospective analysis based on a prospective cohort,Breast cancer ranks as the second most prevalent cancer in women- recognized as one of the most dangerous types of cancer- and is on the rise globally. Regular screenings are essential for early-stage treatment. Digital mammography (DM) is the most recognized and widely used technique for breast cancer screening. Contrast-Enhanced Spectral Mammography (CESM or CM) is used in conjunction with DM to detect and identify hidden abnormalities- particularly in dense breast tissue where DM alone might not be as effective. In this work- we explore the effectiveness of each modality (CM- DM- or both) in detecting breast cancer lesions using deep learning methods. We introduce an architecture for detecting and classifying breast cancer lesions in DM and CM images in Craniocaudal (CC) and Mediolateral Oblique (MLO) views. The proposed architecture (JointNet) consists of a convolution module for extracting local features- a transformer module for extracting long-range features- and a feature fusion layer to fuse the local features- global features- and global features weighted based on the local ones. This significantly enhances the accuracy of classifying DM and CM images into normal or abnormal categories and lesion classification into benign or malignant. Using our architecture as a backbone- three lesion classification pipelines are introduced that utilize attention mechanisms focused on lesion shape- texture- and overall breast texture- examining the critical features for effective lesion classification. The results demonstrate that our proposed methods outperform their components in classifying images as normal or abnormal and mitigate the limitations of independently using the transformer module or the convolution module. An ensemble model is also introduced to explore the effect of each modality and each view to increase our baseline architecture's accuracy. The results demonstrate superior performance compared with other similar works. The best performance on DM images was achieved with the semi-automatic AOL Lesion Classification Pipeline- yielding an accuracy of 98.85Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- AUROC of 0.9965- F1-score of 98.85Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- precision of 98.85Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- and specificity of 98.85Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %. For CM images- the highest results were obtained using the automatic AOL Lesion Classification Pipeline- with an accuracy of 97.47Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- AUROC of 0.9771- F1-score of 97.34Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- precision of 94.45Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- and specificity of 97.23Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %. The semi-automatic ensemble AOL Classification Pipeline provided the best overall performance when using both DM and CM images- with an accuracy of 94.74Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- F1-score of 97.67Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- specificity of 93.75Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- and sensitivity of 95.45Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %. Furthermore- we explore the comparative effectiveness of CM and DM images in deep learning models- indicating that while CM images offer clearer insights to the human eye- our model trained on DM images yields better results using Attention on Lesion (AOL) techniques. The research also suggests a multimodal approach using both DM and CM images and ensemble learning could provide more robust classification outcomes.
Maria Colomba Comes- Annarita Fanizzi- Samantha Bove- Luca Boldrini- Agnese Latorre- Deniz Can Guven- Serena Iacovelli- Tiziana Talienti- Alessandro Rizzo- Francesco Alfredo Zito- Raffaella Massafra,Monitoring Over Time of Pathological Complete Response to Neoadjuvant Chemotherapy in Breast Cancer Patients Through an Ensemble Vision Transformers-Based Model,"Women with breast cancer face a high degree of uncertainty. Trust between health providers and patients has been shown to improve patient quality of life and may enhance clinical outcomes. This study aimed to explore the meaning of trust along the treatment pathway. The study followed a convergent mixed-methods design. We collected qualitative data longitudinally from diagnosis to follow-up using unstructured digital diaries and 45 semi-structured interviews with twelve women with breast cancer. To measure symptom burden and trust- we collected quantitative data by means of 57 questionnaires. Data analysis was based on phenomenology according to van Manen and on descriptive statistics. Data synthesis resulted in a conceptual model of trust. The women experienced trust as a dynamic phenomenon within the biomedical cancer care ""machinery"". Their trust was strongly influenced by contextual factors- professionals' expertise- and person-centeredness. The relevance of trust differed according to treatment phases. Due to a high degree of uncertainty- trust was particularly important. Professionals positively influenced the women's trust to a certain extent through a patient-centered approach and by demonstrating expertise within the biomedical cancer care ""machinery"". The conceptual model of trust should receive attention to bring care closer to the women's lived experience so that their care experience can be improved."
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
Maria Colomba Comes- Annarita Fanizzi- Samantha Bove- Luca Boldrini- Agnese Latorre- Deniz Can Guven- Serena Iacovelli- Tiziana Talienti- Alessandro Rizzo- Francesco Alfredo Zito- Raffaella Massafra,Monitoring Over Time of Pathological Complete Response to Neoadjuvant Chemotherapy in Breast Cancer Patients Through an Ensemble Vision Transformers-Based Model,"Women with breast cancer face a high degree of uncertainty. Trust between health providers and patients has been shown to improve patient quality of life and may enhance clinical outcomes. This study aimed to explore the meaning of trust along the treatment pathway. The study followed a convergent mixed-methods design. We collected qualitative data longitudinally from diagnosis to follow-up using unstructured digital diaries and 45 semi-structured interviews with twelve women with breast cancer. To measure symptom burden and trust- we collected quantitative data by means of 57 questionnaires. Data analysis was based on phenomenology according to van Manen and on descriptive statistics. Data synthesis resulted in a conceptual model of trust. The women experienced trust as a dynamic phenomenon within the biomedical cancer care ""machinery"". Their trust was strongly influenced by contextual factors- professionals' expertise- and person-centeredness. The relevance of trust differed according to treatment phases. Due to a high degree of uncertainty- trust was particularly important. Professionals positively influenced the women's trust to a certain extent through a patient-centered approach and by demonstrating expertise within the biomedical cancer care ""machinery"". The conceptual model of trust should receive attention to bring care closer to the women's lived experience so that their care experience can be improved."
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
