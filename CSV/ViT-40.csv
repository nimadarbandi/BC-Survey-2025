Sinae Oh- Jae Yong Shim,Development and validation of a deep learningâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®based cardiovascular disease risk prediction model for long-term breast cancer survivors.,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ As machine learning and artificial intelligence algorithms â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ ogy images using large vision-language models- combining image â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ language models- such as Vision Transformers or â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
J Dong- W Huang- J Zhang,Identification of Key Features in Breast Cancer Diagnosis Using Vision Transformer,Accurate segmentation of the clinical target volume (CTV) of CBCT images can observe the changes of CTV during patients' radiotherapy- and lay a foundation for the subsequent implementation of adaptive radiotherapy (ART). However- segmentation is challenging due to the poor quality of CBCT images and difficulty in obtaining target volumes. An uncertainty estimation- and attention-based semi-supervised model called residual convolutional block attention-uncertainty aware mean teacher (RCBA-UAMT) was proposed to delineate the CTV in cone-beam computed tomography (CBCT) images of breast cancer automatically. A total of 60 patients who undergone radiotherapy after breast-conserving surgery were enrolled in this study- which involved 60 planning CTs and 380 CBCTs. RCBA-UAMT was proposed by integrating residual and attention modules in the backbone network 3D UNet. The attention module can adjust channel and spatial weights of the extracted image features. The proposed design can train the model and segment CBCT images with a small amount of labeled data (5%- 10%- and 20%) and a large amount of unlabeled data. Four types of evaluation metrics- namely- dice similarity coefficient (DSC)- Jaccard- average surface distance (ASD)- and 95% Hausdorff distance (95HD)- are used to assess the model segmentation performance quantitatively. The proposed method achieved average DSC- Jaccard- 95HD- and ASD of 82%- 70%- 8.93- and 1.49Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ mm for CTV delineation on CBCT images of breast cancer- respectively. Compared with the three classical methods of mean teacher- uncertainty-aware mean-teacher and uncertainty rectified pyramid consistency- DSC and Jaccard increased by 7.89-9.33% and 14.75-16.67%- respectively- while 95HD and ASD decreased by 33.16-67.81% and 36.05-75.57%- respectively. The comparative experiment results of the labeled data with different proportions (5%- 10% and 20%) showed significant differences in the DSC- Jaccard- and 95HD evaluation indexes in the labeled data with 5% versus 10% and 5% versus 20%. Moreover- no significant differences were observed in the labeled data with 10% versus 20% among all evaluation indexes. Therefore- we can use only 10% labeled data to achieve the experimental objective. Using the proposed RCBA-UAMT- the CTV of breast cancer CBCT images can be delineated reliably with a small amount of labeled data. These delineated images can be used to observe the changes in CTV and lay the foundation for the follow-up implementation of ART.
Premisha Premananthan- Mauran Kanagarathnam,Deep Learning-Based Mitosis Detection in Breast Cancer Histopathology Images: A Mapping Study,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Deep learning (DL) AI tools are predominantly employed for re-â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Utilizing a vision transformer style- the ConvNeXt system â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ -making in screening- special attention should be paid to â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Ashish Kumar- Shubhangi Ojha- Sejal Tyagi- Utkarsh Kumar Yadav- Satyapriya Mittal,Histopathological Breast Cancer Detection: A Vision Transformer and Attention-Based Approach,Aims: To test the efficacy of artificial intelligence (AI)â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢assisted Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 digital image analysis in invasive breast carcinoma (IBC) with quantitative assessment of AI model performance. Methods and Results: This study used 494 cases of Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 slide images of IBC core needle biopsies. The methods were divided into two steps: (i) construction of a deepâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢learning model (DL); and (ii) DL implementation for Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 analysis. First- a DL tissue classifier model (DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC) and a DL nuclear detection model (DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ND) were constructed using HALO AI DenseNet V2 algorithm with 31-924 annotations in 300 Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 digital slide images. Whether the class predicted by DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC in the test set was correct compared with the annotation of ground truth at the pixel level was evaluated. Second- DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TCâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ and DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢NDâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢assisted digital image analysis (DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA) was performed in the other 194 luminalâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢type cases and correlations with manual counting and clinical outcome were investigated to confirm the accuracy and prognostic potential of DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA. The performance of DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC was excellent and invasive carcinoma nests were well segmented from other elements (average precision: 0.851; recall: 0.878; F1â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢score: 0.858). Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 index data and the number of nuclei from DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA were positively correlated with data from manual counting ( Conclusion: The performances of DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC and DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ND were excellent. DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA demonstrated a high degree of concordance with manual counting of Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 and the results of this approach have prognostic potential.
Vaishnawi Priyadarshni- Sanjay Kumar Sharma,Machine Learning Based Classification of Histopathological Image for Breast Cancer,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ multimodal deep learning framework integrating breast â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ vision transformer (ViT) backbone: (a) ViT-base- (b) ViTlarge- and (câ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Bao- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Multi-modal artificial intelligence for the combination of â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Sabry- HM Balaha- KM Ali- ...,A vision transformer approach for breast cancer classification in histopathology,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Breast cancer is the second-leading cause of cancer-related deaths in women worldwide. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ for classifying Breast Cancer (BC) from histopathology slides using a Vision Transformer (ViT) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
ML Abimouloud- K Bensid- M Elleuch- ...,Vision transformer-convolution for breast cancer classification using mammography images: A comparative study,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Breast cancer (BC) is a widely diagnosed deadly disease â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Many deep learning-based breast cancer diagnostic methods â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ encoder-based multi-attention triple decoder convolution neural â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
D Manalâ€šÃ Ãœâˆšâ‰ Â¬Â¨Â¬Â±- H Demirel- A Eleyan,Deep Learning Based Breast Cancer Detection Using Decision Fusion,This paper introduces a self-attention Vision Transformer model specifically developed for classifying breast cancer in histology images. We examine various training strategies and configurations- including pretraining- dimension resizing- data augmentation and color normalization strategies- patch overlap- and patch size configurations- in order to evaluate their impact on the effectiveness of the histology image classification. Additionally- we provide evidence for the increase in effectiveness gathered through geometric and color data augmentation techniques. We primarily utilize the BACH dataset to train and validate our methods and models- but we also test them on two additional datasets- BRACS and AIDPATH- to verify their generalization capabilities. Our model- developed from a transformer pretrained on ImageNet- achieves an accuracy rate of 0.91 on the BACH dataset- 0.74 on the BRACS dataset- and 0.92 on the AIDPATH dataset. Using a model based on the prostate small and prostate medium HistoEncoder models- we achieve accuracy rates of 0.89 and 0.86- respectively. Our results suggest that pretraining on large-scale general datasets like ImageNet is advantageous. We also show the potential benefits of using domain-specific pretraining datasets- such as extensive histopathological image collections as in HistoEncoder- though not yet with clear advantages.
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
MR JebeliHajiAbadi,Classification of Breast Cancer Cytological Images using Vision Transformers,Although cancer therapy suppresses recurrence and prolongs life- it may be accompanied by strong side effects; thus- there is a strong demand for the development effective treatments with fewer side effects. Cancer therapy using plant-derived essential oils is attracting attention as one promising method. This study investigated the antitumor effects of essential oil volatiles on breast cancer cells and identifies four essential oils that display antitumor activity. Breast cancer cells were cultured in a 96-well plate- then one of twenty essential oils was added dropwise to the central well. The plate was incubated at 37Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšâ€ âˆšÂªC for 48Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ h and the effect of the volatile components of each essential oil on the surrounding breast cancer cell growth ability was examined using an MTT assay. Gas chromatography was used to investigate the concentration of the transpiration components that may affect cancer cells. Of the 20 essential oils- Lemongrass- Lemon myrtle- Litsea- and Melissa displayed strong anti-tumor effects. These essential oils inhibited the growth of nearby breast cancer cells- even when diluted more than 500-fold. The transpiration component of lemon Myrtle showed the strongest antitumor effect- but was the least cytotoxic to mononuclear cells in normal peripheral blood (PBMC). Each of these essential oils contained a very large amount of citral. The IC50 against breast cancer cells when citral was volatilized from each essential oil was 1.67Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬ÂµL/mL for geranial and 1.31 Â¬Â¨Â¬Â®Â¬Â¨Â¬ÂµL/mL for neral. Volatilized citral alone showed strong anti-proliferation and infiltration-inhibiting effects. The transpiration components of Lemongrass- Lemon myrtle- Litsea- and Melissa are thought to inhibit breast cancer cell proliferation due to their high levels of citral.
M Altulayhi- A Alhrgan,Evaluating Study Between Vision Transformers and Pre-trained CNN Learning Algorithms to Classify Breast Cancer Histopathological Images,Health-related quality of life (HRQOL) has become increasingly important for breast cancer survivors- but clinically relevant declines often persist for many years after treatment. This study aimed to investigate whether social relationships can mitigate or prevent this decline in HRQOL. Data were used from the German population-based Mamma Carcinoma Risk Factor Investigation (MARIE) cohort of 2022 breast cancer cases with follow-up information for more than 15 years after diagnosis. Correlations between social integration- social support- and global health status (GHS) as an overall measure of HRQOL were analyzed- and linear regression analysis was performed with structural equation modeling. The majority of participants reported high levels of social integration and social support and moderate levels of GHS. Social integration 5 years after diagnosis was associated with GHS 5 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 1.12; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.25-1.99)- but no longitudinal effects were found. Social support 5 years after diagnosis was associated with better GHS 5 years (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.42; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.36-0.48) and 10 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.12; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.02-0.22)- whereas social support 10 years after diagnosis was associated with GHS 10 years (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.29; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.20-0.39) and 15 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.10; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.01-0.21). These results confirm that social relationships positively influence HRQOL in long-term breast cancer survivors and that their association should receive more attention clinically and beyond routine care.
HM Balaha- KM Ali- D Gondim- M Ghazal- ...,Harnessing Vision Transformers for Precise and Explainable Breast Cancer Diagnosis,This study presents a novel approach to enhance the accuracy of breast cancer detection from mammogram images through a hybrid feature selection and classification framework. Leveraging the power of XGBoost- a state-of-the-art machine learning algorithm- an embedded genetic algorithm is introduced for optimal feature selection. The genetic algorithm refines the feature set by iteratively evolving towards a subset that maximizes the discriminative power for breast cancer diagnosis. Subsequently- the selected features are fed into a Recurrent Neural Network (RNN) architecture with Random Boolean Networks (RBN) for classification. The RNN-RBN model captures intricate temporal dependencies within the image data- providing a nuanced understanding of the complex patterns indicative of breast cancer. The synergistic coupling of the XGBoost-embedded genetic algorithm for feature selection and the RNN-RBN model for classification results in a robust and interpretable system for breast cancer detection. The proposed hybrid approach is evaluated on a comprehensive dataset of mammogram images- demonstrating superior performance compared to traditional methods. The combination of feature selection through XGBoost- embedded genetic algorithms and RNN-RBN classification showcases the potential for advanced- accurate- and efficient breast cancer diagnosis- holding promise for improving early detection rates and patient outcomes in clinical settings.
A Sriwastawa- JA Arul Jothi,Vision transformer and its variants for image classification in digital breast cancer histopathology: A comparative study,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Here- the space attention- channel attention- and center attention modules are combined to form the triplet attention mechanism. Finally- this study proposes EfficientNet deep learning â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
ML ABIMOULOUD- K BENSID- M Elleuch- ...,Vision transformer based convolutional neural network for breast cancer histopathological images classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ transformer techniques in breast cancer classification using histopathological images. Our method is based on attention â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ and accurate classification of breast cancer subtype cells and â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
ML Abimouloud- K Bensid- M Elleuch- O Aiadi- ...,Vision Transformer Based Tokenization for Enhanced Breast Cancer Histopathological Images Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ women diagnosed with breast cancer and 379 â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ breast cancer- was defined by linking to the Stockholm-Gotland regional cancer center breast cancer registry where breast cancer â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Juan Gutierrez-Cardenas,"Breast Cancer Classification through Transfer Learning with Vision Transformer, PCA, and Machine Learning Models",The objective of our study was to explore the feasibility of integrating artificial intelligence (AI) algorithms for breast cancer detection into a portable- point-of-care ultrasound device (POCUS). This proof-of-concept implementation is to demonstrate the platform for integrating AI algorithms into a POCUS device to achieve a performance benchmark of at least 15 frames/second. Our methodology involved the application of five AI models (FasterRCNN+MobileNetV3- FasterRCNN+ResNet50- RetinaNet+ResNet50- SSD300+VGG16- and SSDLite320+MobileNetV3)- pretrained on public datasets of natural images- fine-tuned using a dataset of gelatin-based breast phantom images with both anechoic and hyperechoic lesions- mimicking real tissue characteristics. We created various gelatin-based ultrasound phantoms containing ten simulated lesions- ranging from 4-20 mm in size. Our experimental setup used the Clarius L15 scanning probe- which was connected via Wi-Fi to both a tablet and a laptop- forming the core of our development platform. The phantom data was divided into training- validation- and held-out testing sets on a per-video basis. We executed 200 timing trials for each finetuned AI model- streaming scanning video from the ultrasound probe in real-time. SSDLite320+MobileNetV3 emerged as a standout- showing a mean frame-to-frame timing of 0.068 seconds (SD=0.005)- which is approximately 14.71 FPS- closely followed by FasterRCNN+MobileNetV3- with a mean timing of 0.123 seconds (SD=0.016)- or about 8.13 FPS. Both models show acceptable performance in lesion localization. Compared to our goal of 15 frames/second- only the SSDLite320+MobileNetV3 architecture performed with sufficient evaluation speed to be used in real-time. Our findings show the necessity of using AI architectures designed for edge devices for real-time use- as well as the potential need for hardware acceleration to encode AI models for use in POCUS.
Kishan Sharda- Mandeep Singh Ramdev- Deepak Rawat- Pawan Bishnoi,Feature Selection for Breast Cancer Detection,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ In the field of early diagnosis of breast cancer- deep learning and machine learning â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ language-image pre-training (CLIP) model- named ViT-L/14 CLIP- a large vision transformer model â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Alruily- AA Mahmoud- H Allahem- ...,Enhancing Breast Cancer Detection in Ultrasound Images: An Innovative Approach Using Progressive Fineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢Tuning of Vision Transformer Models,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ By illustrating the potential of transformer architectures for breast cancer detection- especially using ultrasound images- we contribute to the broader field of medical imaging. Our â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
F. Jacobs- S. D'Amico- E. Ferraro- E. Agostinetto- C.A. Tondini- M. Gaudio- C. Benvenuti- R. Gerosa- G. Saltalamacchia- R. De Sanctis- M.G. Della Porta- A. Santoro- M. Fornier- E. de Azambuja- A. Zambelli,70P Development and validation of a machine learning (ML) nomogram to predict RSClin results and guide adjuvant treatment of node-negative (N0) hormone receptor-positive (HR+)/human epidermal growth factor receptor-negative (HER2-) early breast cancer (eBC) in Europe,Breast cancer is a prominent contributor to mortality associated with cancer in the female population on a global scale. The timely identification and precise categorization of breast cancer are of utmost importance in enhancing patient prognosis. Nevertheless- the task of precisely categorizing breast cancer based on ultrasound imaging continues to present difficulties- primarily due to the presence of dense breast tissues and their inherent heterogeneity. This study presents a unique approach for breast cancer categorization utilizing the wavelet based vision transformer network. To enhance the neural networkâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s receptive fields- we have incorporated the discrete wavelet transform (DWT) into the network input. This technique enables the capture of significant features in the frequency domain. The proposed model exhibits the capability to effectively capture intricate characteristics of breast tissue- hence enabling correct classification of breast cancer with a notable degree of precision and efficiency. We utilized two breast tumor ultrasound datasets- including 780 cases from Baheya hospital in Egypt and 267 patients from the UDIAT Diagnostic Centre of Sabadell in Spain. The findings of our study indicate that the proposed transformer network achieves exceptional performance in breast cancerclassification. With an AUC rate of 0.984 and 0.968 on both datasets- our approach surpasses conventional deep learning techniques- establishing itself as the leading method in this domain. This study signifies a noteworthy advancement in the diagnosis and categorization of breast cancer- showcasing the potential of the proposed transformer networks to enhance the efficacy of medical imaging analysis.
Ahsan Fiaz- Basit Raza- Muhammad Faheem- Aadil Raza,A deep fusion-based vision transformer for breast cancer classification,Hormone receptor-positive (HR+)/human epidermal growth factor receptor 2-negative (HER2-) breast cancer is the most common type of breast cancer- with continuous recurrence remaining an important clinical issue. Current relapse predictive models in HR+/HER2- breast cancer patients still have limitations. The integration of multidimensional data represents a promising alternative for predicting relapse. In this study- we leverage our multi-omics cohort comprising 579 HR+/HER2- breast cancer patients (200 patients with complete data across 7 modalities) and develop a machine-learning-based model- namely CIMPTGV- which integrates clinical information- immunohistochemistry- metabolomics- pathomics- transcriptomics- genomics- and copy number variations to predict recurrence risk of HR+/HER2- breast cancer. This model achieves concordance indices (C-indices) of 0.871 and 0.869 in the train and test sets- respectively. The risk population predicted by the CIMPTGV model encompasses those identified by single-modality models. Feature analysis reveals that synergistic and complementary effects exist in different modalities. Simultaneously- we develop a simplified model with a mean area under the curve (AUC) of 0.840- presenting a useful approach for clinical applications.
Chenyang He- Yan Diao- Xingcong Ma- Shuo Yu- Xin He- Guochao Mao- Xinyu Wei- Yu Zhang- Yang Zhao,A Vision Transformer Network With Wavelet-Based Features for Breast Ultrasound Classification,
S. S. Boudouh- M. Bouakkaz,Advancing precision in breast cancer detection: a fusion of vision transformers and CNNs for calcification mammography classification,Breast cancer is a major cause of death worldwide. The complexity of endocrine regulation in breast cancer may allow the cancer cells to escape from a particular treatment and result in resistant and aggressive disease. These breast cancers usually have fewer treatment options. Targeted therapies for cancer patients may offer fewer adverse side effects because of specificity compared to conventional chemotherapy. Signaling pathways of nuclear receptors- such as the estrogen receptor (ER)- have been intensively studied and used as therapeutic targets. Recently- the role of the androgen receptor (AR) in breast cancer is gaining greater attention as a therapeutic target and as a prognostic biomarker. The expression of constitutively active truncated AR splice variants in breast cancer is a possible mechanism contributing to treatment resistance. Therefore- targeting both the full-length AR and AR variants- either through the activation or suppression of AR function- depending on the status of the ER- progesterone receptor- or human epidermal growth factor receptor 2- may provide additional treatment options. Studies targeting AR in combination with other treatment strategies are ongoing in clinical trials. The determination of the status of nuclear receptors to classify and identify patient subgroups will facilitate optimized and targeted combination therapies.
Chiharu Kai- Hideaki Tamori- Tsunehiro Ohtsuka- Miyako Nara- Akifumi Yoshida- Ikumi Sato- Hitoshi Futamura- Naoki Kodama- Satoshi Kasai,Classifying the molecular subtype of breast cancer using vision transformer and convolutional neural network features,Adversarial data can lead to malfunction of deep learning applications. It is essential to develop deep learning models that are robust to adversarial data while accurate on standard- clean data. In this study- we proposed a novel adversarially robust feature learning (ARFL) method for a real-world application of breast cancer diagnosis. ARFL facilitates adversarial training using both standard data and adversarial data- where a feature correlation measure is incorporated as an objective function to encourage learning of robust features and restrain spurious features. To show the effects of ARFL in breast cancer diagnosis- we built and evaluated diagnosis models using two independent clinically collected breast imaging datasets- comprising a total of 9-548 mammogram images. We performed extensive experiments showing that our method outperformed several state-of-the-art methods and that our method can enhance safer breast cancer diagnosis against adversarial attacks in clinical settings.
Jessica Prunaretty- Fatima Mekki- Pierre-Ivan Laurent- Aurelie Morel- Pauline Hinault- Celine Bourgier- David Azria- Pascal Fenoglietto,Clinical feasibility of Ethos auto-segmentation for adaptive whole-breast cancer treatment,Identification of the molecular subtypes in breast cancer allows to optimize treatment strategies- but usually requires invasive needle biopsy. Recently- non-invasive imaging has emerged as promising means to classify them. Magnetic resonance imaging is often used for this purpose because it is three-dimensional and highly informative. Instead- only a few reports have documented the use of mammograms. Given that mammography is the first choice for breast cancer screening- using it to classify molecular subtypes would allow for early intervention on a much wider scale. Here- we aimed to evaluate the effectiveness of combining global and local mammographic features by using Vision Transformer (ViT) and Convolutional Neural Network (CNN) to classify molecular subtypes in breast cancer. The feature values for binary classification were calculated using the ViT and EfficientnetV2 feature extractors- followed by dimensional compression via principal component analysis. LightGBM was used to perform binary classification of each molecular subtype: triple-negative- HER2-enriched- luminal A- and luminal B. The combination of ViT and CNN achieved higher accuracy than ViT or CNN alone. The sensitivity for triple-negative subtypes was very high (0.900- with F-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.818); whereas F-value and sensitivity were 0.720 and 0.750 for HER2-enriched- 0.765 and 0.867 for luminal A- and 0.614 and 0.711 for luminal B subtypes- respectively. Features obtained from mammograms by combining ViT and CNN allow the classification of molecular subtypes with high accuracy. This approach could streamline early treatment workflows and triage- especially for poor prognosis subtypes such as triple-negative breast cancer.
Yaping Yang- Ying Zhong- Junwei Li- Jiahao Feng- C. Gong- Yunfang Yu- Yue Hu- R. Gu- Hongli Wang- Fengtao Liu- J. Mei- Xiaofang Jiang- Jin Wang- Qinyue Yao- Wei Wu- Qiang Liu- H. Yao,Deep learning combining mammography and ultrasound images to predict the malignancy of BI-RADS US 4A lesions in women with dense breasts: a diagnostic study,Breast cancer is the most prevalent type of disease among women. It has become one of the foremost causes of death among women globally. Early detection plays a significant role in administering personalized treatment and improving patient outcomes. Mammography procedures are often used to detect early-stage cancer cells. This traditional method of mammography while valuable has limitations of potential for false positives and negatives- patient discomfort- and radiation exposure. Therefore- there is a probe for more accurate techniques required in detecting breast cancer- leading to exploring the potential of machine learning in the classification of diagnostic images due to its efficiency and accuracy. This study conducted a comparative analysis of pre-trained CNNs (ResNet50 and VGG16) and Vision Transformers (ViT-Base and SWIN Transformer) with the inclusion of ViT-Base trained from scratch model architectures to effectively classify breast cancer mammographic images into benign and malignant cases. The Swin transformer exhibits superior performance with 99.8% accuracy and a precision of 99.8%. These findings demonstrate the efficiency of deep learning to accurately classify breast cancer mammographic images for the diagnosis of breast cancer- leading to improvement in patient outcomes.
Idan Kassis- Dror Lederman- Gal Ben-Arie- Maia Giladi Rosenthal- Ilan Shelef- Yaniv Zigel,Detection of breast cancer in digital breast tomosynthesis with vision transformers,Breast cancer remains a major public health concern- and early detection is crucial for improving survival rates. Metabolomics offers the potential to develop non-invasive screening and diagnostic tools based on metabolic biomarkers. However- the inherent complexity of metabolomic datasets and the high dimensionality of biomarkers complicates the identification of diagnostically relevant features- with multiple studies demonstrating limited consensus on the specific metabolites involved. Unlike previous studies that rely on singular feature selection techniques such as Partial Least Square (PLS) or LASSO regression- this research combines supervised and unsupervised machine learning methods with random sampling strategies- offering a more robust and interpretable approach to feature selection. This study aimed to identify a parsimonious and robust set of biomarkers for breast cancer diagnosis using metabolomics data. Plasma samples from 185 breast cancer patients and 53 controls (from the Cooperative Human Tissue Network- USA) were analyzed. This study also overcomes the common issue of dataset imbalance by using propensity score matching (PSM)- which ensures reliable comparisons between cancer and control groups. We employed Univariate Naâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšâ‰¤ve Bayes- L2-regularized Support Vector Classifier (SVC)- Principal Component Analysis (PCA)- and feature engineering techniques to refine and select the most informative features. Our best-performing feature set comprised 11 biomarkers- including 9 metabolites (SM(OH) C22:2- SM C18:0- C0- C3OH- C14:2OH- C16:2OH- LysoPC a C18:1- PC aa C36:0 and Asparagine)- a metabolite ratio (Kynurenine-to-Tryptophan)- and 1 demographic variable (Age)- achieving an area under the ROC curve (AUC) of 98%. These results demonstrate the potential for a robust- cost-effective- and non-invasive breast cancer screening and diagnostic tool- offering significant clinical value for early detection and personalized patient management.
Jiahui Ren- Yili Li- Jing Zhou- Ting Yang- Jingfeng Jing- Qian Xiao- Zhongxu Duan- Ke Xiang- Yuchen Zhuang- Daxue Li- Han Gao,Developing machine learning models for personalized treatment strategies in early breast cancer patients undergoing neoadjuvant systemic therapy based on SEER database,Breast cancer is the second most common type of cancer among women. Prompt detection of breast cancer can impede its advancement to more advanced phases- thereby elevating the probability of favorable treatment consequences. Histopathological images are commonly used for breast cancer classification due to their detailed cellular information. Existing diagnostic approaches rely on Convolutional Neural Networks (CNNs) which are limited to local context resulting in a lower classification accuracy. Therefore- we present a fusion model composed of a Vision Transformer (ViT) and custom Atrous Spatial Pyramid Pooling (ASPP) network with an attention mechanism for effectively classifying breast cancer from histopathological images. ViT enables the model to attain global features- while the ASPP network accommodates multiscale features. Fusing the features derived from the models resulted in a robust breast cancer classifier. With the help of five-stage image preprocessing technique- the proposed model achieved 100% accuracy in classifying breast cancer on the BreakHis dataset at 100X and 400X magnification factors. On 40X and 200X magnifications- the model achieved 99.25% and 98.26% classification accuracy respectively. With a commendable classification efficacy on histopathological images- the model can be considered a dependable option for proficient breast cancer classification.
Xiao Guo- Jiaying Xing- Yuyan Cao- Wenchuang Yang- Xinlin Shi- Runhong Mu- Tao Wang,Machine learning based anoikis signature predicts personalized treatment strategy of breast cancer,The vision transformer (ViT) architecture- with its attention mechanism based on multi-head attention layers- has been widely adopted in various computer-aided diagnosis tasks due to its effectiveness in processing medical image information. ViTs are notably recognized for their complex architecture- which requires high-performance GPUs or CPUs for efficient model training and deployment in real-world medical diagnostic devices. This renders them more intricate than convolutional neural networks (CNNs). This difficulty is also challenging in the context of histopathology image analysis- where the images are both limited and complex. In response to these challenges- this study proposes a TokenMixer hybrid-architecture that combines the strengths of CNNs and ViTs. This hybrid architecture aims to enhance feature extraction and classification accuracy with shorter training time and fewer parameters by minimizing the number of input patches employed during training- while incorporating tokenization of input patches using convolutional layers and encoder transformer layers to process patches across all network layers for fast and accurate breast cancer tumor subtype classification. The TokenMixer mechanism is inspired by the ConvMixer and TokenLearner models. First- the ConvMixer model dynamically generates spatial attention maps using convolutional layers- enabling the extraction of patches from input images to minimize the number of input patches used in training. Second- the TokenLearner model extracts relevant regions from the selected input patches- tokenizes them to improve feature extraction- and trains all tokenized patches in an encoder transformer network. We evaluated the TokenMixer model on the BreakHis public dataset- comparing it with ViT-based and other state-of-the-art methods. Our approach achieved impressive results for both binary and multi-classification of breast cancer subtypes across various magnification levels (40â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 100â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 200â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 400â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢). The model demonstrated accuracies of 97.02% for binary classification and 93.29% for multi-classification- with decision times of 391.71 and 1173.56Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ s- respectively. These results highlight the potential of our hybrid deep ViT-CNN architecture for advancing tumor classification in histopathological images. The source code is accessible: https://github.com/abimouloud/TokenMixer .
Yu Du- Xuehong Diao,Machine Learning Models for Predicting Clinically and Ultrasound-Negative Axillary Lymph Node Metastasis in Early-Stage Breast Cancer,Breast cancer poses a serious threat to women's life and health. Typically- radiologists can detect early signs of breast cancer activity through breast ultrasound. However- the interpretation of breast ultrasound is time-consuming and requires physicians to possess extensive diagnostic experience. In recent years- computer aided diagnostic (CAD) technology has been introduced into breast imaging diagnosis- saving a significant amount of time for expert medical image inspection and improving diagnostic efficiency. However- current research on computer-aided diagnostic methods has mainly focused on ultrasound (US) images- with limited studies on contrast-enhanced ultrasound (CEUS) videos. To solve this challenge- we collected 332 cases of breast cancer contrast-enhanced ultrasound videos from Shengjing Hospital. We designed ResViT by combining residual neural networks with Vision Transformer to extract spatial features- and used the Temporal Segment Network (TSN) in combination with linear weights to fuse the spatio-temporal features of each frame into video-level features for classification. The experiment results show that our model achieved an accuracy of 78.79% and a sensitivity of 85% in our dataset- significantly higher than the results of current mainstream video analysis networks- proving the effectiveness of our proposed model in the task of classifying contrast-enhanced ultrasound videos.
Maria Colomba Comes- Annarita Fanizzi- Samantha Bove- Luca Boldrini- Agnese Latorre- Deniz Can Guven- Serena Iacovelli- Tiziana Talienti- Alessandro Rizzo- Francesco Alfredo Zito- Raffaella Massafra,Monitoring Over Time of Pathological Complete Response to Neoadjuvant Chemotherapy in Breast Cancer Patients Through an Ensemble Vision Transformers-Based Model,"Women with breast cancer face a high degree of uncertainty. Trust between health providers and patients has been shown to improve patient quality of life and may enhance clinical outcomes. This study aimed to explore the meaning of trust along the treatment pathway. The study followed a convergent mixed-methods design. We collected qualitative data longitudinally from diagnosis to follow-up using unstructured digital diaries and 45 semi-structured interviews with twelve women with breast cancer. To measure symptom burden and trust- we collected quantitative data by means of 57 questionnaires. Data analysis was based on phenomenology according to van Manen and on descriptive statistics. Data synthesis resulted in a conceptual model of trust. The women experienced trust as a dynamic phenomenon within the biomedical cancer care ""machinery"". Their trust was strongly influenced by contextual factors- professionals' expertise- and person-centeredness. The relevance of trust differed according to treatment phases. Due to a high degree of uncertainty- trust was particularly important. Professionals positively influenced the women's trust to a certain extent through a patient-centered approach and by demonstrating expertise within the biomedical cancer care ""machinery"". The conceptual model of trust should receive attention to bring care closer to the women's lived experience so that their care experience can be improved."
Qiang Li- George Teodoro- Yi Jiang- Jun Kong,NACNet: A histology context-aware transformer graph convolution network for predicting treatment response to neoadjuvant chemotherapy in Triple Negative Breast Cancer,Breast cancer is one of the most common causes of death in women in the modern world. Cancerous tissue detection in histopathological images relies on complex features related to tissue structure and staining properties. Convolutional neural network (CNN) models like ResNet50- Inception-V1- and VGG-16- while useful in many applications- cannot capture the patterns of cell layers and staining properties. Most previous approaches- such as stain normalization and instance-based vision transformers- either miss important features or do not process the whole image effectively. Therefore- a deep fusion-based vision Transformer model (DFViT) that combines CNNs and transformers for better feature extraction is proposed. DFViT captures local and global patterns more effectively by fusing RGB and stain-normalized images. Trained and tested on several datasets- such as BreakHis- breast cancer histology (BACH)- and UCSC cancer genomics (UC)- the results demonstrate outstanding accuracy- F1 score- precision- and recall- setting a new milestone in histopathological image analysis for diagnosing breast cancer.
Giulia Lucrezia Baroni- Laura Rasotto- Kevin Roitero- Angelica Tulisso- Carla Di Loreto- Vincenzo Della Mea,Optimizing Vision Transformers for Histopathology: Pretraining and Normalization in Breast Cancer Classification,Triple negative breast cancer (TNBC) is one of the subtypes of breast cancer characterized by a heterogeneous and aggressive nature. Photodynamic therapy (PDT) has drawn significant attention in cancer treatment. However- solubility of photosensitizer- penetration problems into a target tissue and insufficient oxygen concentration limit the effectiveness of PDT. To overcome these limitations and to reduce the side effects of chemotherapy- combination treatment modalities play an essential role in cancer treatment. In this study- we aimed to investigate the combination efficacy of cisplatin-based chemotherapy and 5-Aminolevulinic acid (5-ALA)/PDT in TNBC cells and healthy breast cellsÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ in vitro. To determine the effect of the combination effects of cisplatin and 5-ALA/PDT on TNBC cells- two treatment protocols (simultaneous and sequential combination therapy) were evaluated compared with cisplatin and 5-ALA/PDT monotherapy and WST-1- Annexin V assay- acridine orange (AO) and mitochondrial staining were performed. Our findings showed that MDA-MB-231 TNBC cell viability was significantly decreased following simultaneous combination treatment compared to cisplatin and 5-ALA/PDT monotherapy. Additionally- simultaneous combination treatment was more effective than sequential combination treatment. The simultaneous combination treatment of 2.5Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬ÂµM cisplatin and 5-ALA/PDT at 6Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2 and 9Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2 induced 46.78% and 53.6% total apoptotic death- respectively in TNBC cells compared with monotherapies (cisplatin (37.88%) and 5-ALA/PDT (6Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2: 31.48% and 9Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2: 37.78%). Additionally- cisplatin and 5-ALA/PDT combination treatment resulted in nuclear fragmentation and mitochondrial damage due to apoptosis. Our results suggest that cisplatin and 5-ALA/PDT simultaneous combination therapy could be a promising new alternative strategy for treating TNBC. However- further studies are required to assess the underlying molecular mechanisms of cisplatin and 5-ALA/PDT combination treatment at the molecular level.
Xuefeng Fu- Yang Jiao- Yao Feng- Fengwei Lin- Bing Zhang- Qing Mao- Jiahui Wang- Wen Jiang- Yanhua Mou- Han Wang- Shaojie Wang,Scaffold Hopping of Pristimerin Provides Derivatives Containing a Privileged Quinoxaline Substructure as Potent Autophagy Inducers in Breast Cancer Cells,Digital Breast Tomosynthesis (DBT) has revolutionized more traditional breast imaging through its three-dimensional (3D) visualization capability that significantly enhances lesion discernibility- reduces tissue overlap- and improves diagnostic precision as compared to conventional two-dimensional (2D) mammography. In this study- we propose an advanced Computer-Aided Detection (CAD) system that harnesses the power of vision transformers to augment DBT's diagnostic efficiency. This scheme uses a neural network to glean attributes from the 2D slices of DBT followed by post-processing that considers features from neighboring slices to categorize the entire 3D scan. By leveraging a transfer learning technique- we trained and validated our CAD framework on a unique dataset consisting of 3-831 DBT scans and subsequently tested it on 685 scans. Of the architectures tested- the Swin Transformer outperformed the ResNet101 and vanilla Vision Transformer. It achieved an impressive AUC score of 0.934 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 0.026 at a resolution of 384 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 384. Increasing the image resolution from 224 to 384 not only maintained vital image attributes but also led to a marked improvement in performance (p-value = 0.0003). The Mean Teacher algorithm- a semi-supervised method using both labeled and unlabeled DBT slices- showed no significant improvement over the supervised approach. Comprehensive analyses across different lesion types- sizes- and patient ages revealed consistent performance. The integration of attention mechanisms yielded a visual narrative of the model's decision-making process that highlighted the prioritized regions during assessments. These findings should significantly propel the methodologies employed in DBT image analysis by setting a new benchmark for breast cancer diagnostic precision.
Mohammad Shiri- Monalika Padma Reddy- Jiangwen Sun,Supervised Contrastive Vision Transformer for Breast Histopathological Image Classification,
Olya Rezaeian- Onur Asan- A. E. Bayrak,The Impact of AI Explanations on Clinicians Trust and Diagnostic Accuracy in Breast Cancer,Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer. Breast tissue histopathological examination is critical in diagnosing and classifying breast cancer. Although existing methods have shown promising results- there is still room for improvement in the classification accuracy and generalization of IDC using histopathology images. We present a novel approach- Supervised Contrastive Vision Transformer (SupCon-ViT)- for improving the classification of invasive ductal carcinoma in terms of accuracy and generalization by leveraging the inherent strengths and advantages of both transfer learning- i.e.- pre-trained vision transformer- and supervised contrastive learning. Our results on a benchmark breast cancer dataset demonstrate that SupCon-ViT achieves state-of-the-art performance in IDC classification- with an F1-score of 0.8188- precision of 0.7692- and specificity of 0.8971- outperforming existing methods. In addition- the proposed model demonstrates resilience in scenarios with minimal labeled data- making it highly efficient in real-world clinical settings where labeled data is limited. Our findings suggest that supervised contrastive learning in conjunction with pre-trained vision transformers appears to be a viable strategy for an accurate classification of IDC- thus paving the way for a more efficient and reliable diagnosis of breast cancer through histopathological image analysis.
Beyzanur Erk- Ali Furkan Kamanli- Gamze Guney Eskiler,The therapeutic efficacy of 5-ALA based photodynamic therapy and chemotherapy combination in triple negative breast cancer cells,"Tumors are an important health concern in modern times. Breast cancer is one of the most prevalent causes of death for women. Breast cancer is rapidly becoming the leading cause of mortality among women globally. Early detection of breast cancer allows patients to obtain appropriate therapy- increasing their probability of survival. The adoption of 3-Dimensional (3D) mammography for the medical identification of abnormalities in the breast reduced the number of deaths dramatically. Classification and accurate detection of lumps in the breast in 3D mammography is especially difficult due to factors such as inadequate contrast and normal fluctuations in tissue density. Several Computer-Aided Diagnosis (CAD) solutions are under development to help radiologists accurately classify abnormalities in the breast. In this paper- a breast cancer diagnosis model is implemented to detect breast cancer in cancer patients to prevent death rates. The 3D mammogram images are gathered from the internet. Then- the gathered images are given to the preprocessing phase. The preprocessing is done using a median filter and image scaling method. The purpose of the preprocessing phase is to enhance the quality of the images and remove any noise or artifacts that may interfere with the detection of abnormalities. The median filter helps to smooth out any irregularities in the images- while the image scaling method adjusts the size and resolution of the images for better analysis. Once the preprocessing is complete- the preprocessed image is given to the segmentation phase. The segmentation phase is crucial in medical image analysis as it helps to identify and separate different structures within the image- such as organs or tumors. This process involves dividing the preprocessed image into meaningful regions or segments based on intensity- color- texture- or other features. The segmentation process is done using Adaptive Thresholding with Region Growing Fusion Model (AT-RGFM)"". This model combines the advantages of both thresholding and region-growing techniques to accurately identify and delineate specific structures within the image. By utilizing AT-RGFM- the segmentation phase can effectively differentiate between different parts of the image- allowing for more precise analysis and diagnosis. It plays a vital role in the medical image analysis process- providing crucial insights for healthcare professionals. Here- the Modified Garter Snake Optimization Algorithm (MGSOA) is used to optimize the parameters. It helps to optimize parameters for accurately identifying and delineating specific structures within medical images and also helps healthcare professionals in providing more precise analysis and diagnosis- ultimately playing a vital role in the medical image analysis process. MGSOA enhances the segmentation phase by effectively differentiating between different parts of the image- leading to more accurate results. Then- the segmented image is fed into the detection phase. The tumor detection is performed by the Vision Transformer-based Multiscale Adaptive EfficientNetB7 (ViT-MAENB7) model. This model utilizes a combination of advanced algorithms and deep learning techniques to accurately identify and locate tumors within the segmented medical image. By incorporating a multiscale adaptive approach- the ViT-MAENB7 model can analyze the image at various levels of detail- improving the overall accuracy of tumor detection. This crucial step in the medical image analysis process allows healthcare professionals to make more informed decisions regarding patient treatment and care. Here- the created MGSOA algorithm is used to optimize the parameters for enhancing the performance of the model. The suggested breast cancer diagnosis performance is compared to conventional cancer diagnosis models and it showed high accuracy. The accuracy of the developed MGSOA-ViT-MAENB7 is 96.6 %- and others model like RNN- LSTM- EffNet- and ViT-MAENet given the accuracy to be 90.31 %- 92.79 %- 94.46 % and 94.75 %. The developed model's ability to analyze images at multiple scales- combined with the optimization provided by the MGSOA algorithm- results in a highly accurate and efficient system for detecting tumors in medical images. This cutting-edge technology not only improves the accuracy of diagnosis but also helps healthcare professionals tailor treatment plans to individual patients- ultimately leading to better outcomes. By outperforming traditional cancer diagnosis models- the proposed model is revolutionizing the field of medical imaging and setting a new standard for precision and effectiveness in healthcare."
Vaishnawi Priyadarshni- Sanjay Kumar Sharma,Machine Learning Based Classification of Histopathological Image for Breast Cancer,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ multimodal deep learning framework integrating breast â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ vision transformer (ViT) backbone: (a) ViT-base- (b) ViTlarge- and (câ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Bao- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Multi-modal artificial intelligence for the combination of â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Sabry- HM Balaha- KM Ali- ...,A vision transformer approach for breast cancer classification in histopathology,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Breast cancer is the second-leading cause of cancer-related deaths in women worldwide. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ for classifying Breast Cancer (BC) from histopathology slides using a Vision Transformer (ViT) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Guyomard- AD Bouhnik- L Tassy- ...,Encoding breast cancer patients' medical pathways from reimbursement data using representation learning: a benchmark for clustering tasks,Neoadjuvant chemotherapy (NAC) is a key element of treatment for locally advanced breast cancer (LABC). Predicting the response to NAC for patients with Locally Advanced Breast Cancer (LABC) before treatment initiation could be beneficial to optimize therapy- ensuring the administration of effective treatments. The objective of the work here was to develop a predictive model to predict tumor response to NAC for LABC using deep learning networks and computed tomography (CT). Several deep learning approaches were investigated including ViT transformer and VGG16- VGG19- ResNet-50- Res-Net-101- Res-Net-152- InceptionV3 and Xception transfer learning networks. These deep learning networks were applied on CT images to assess the response to NAC. Performance was evaluated based on balanced_accuracy- accuracy- sensitivity and specificity classification metrics. A ViT transformer was applied to utilize the attention mechanism in order to increase the weight of important part image which leads to better discrimination between classes. Amongst the 117 LABC patients studied- 82 (70%) had clinical-pathological response and 35 (30%) had no response to NAC. The ViT transformer obtained the best performance range (accuracy = 71 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to accuracy = 77 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- specificity = 86 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 76 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 56 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- and balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%) depending on the split ratio of train-data and test-data. Xception network obtained the second best results (accuracy = 72 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to accuracy = 65 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4- specificity = 81 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 73 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 55 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5%- and balanced_accuracy = 66 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5% to balanced_accuracy = 60 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%). The worst results were obtained using VGG-16 transfer learning network. Deep learning networks in conjunction with CT imaging are able to predict the tumor response to NAC for patients with LABC prior to start. A ViT transformer could obtain the best performance- which demonstrated the importance of attention mechanism.
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
Kishan Sharda- Mandeep Singh Ramdev- Deepak Rawat- Pawan Bishnoi,Feature Selection for Breast Cancer Detection,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ In the field of early diagnosis of breast cancer- deep learning and machine learning â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ language-image pre-training (CLIP) model- named ViT-L/14 CLIP- a large vision transformer model â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Wei Wang- Lei Liu- Jianxiong Zhu- Youqiang Xing- Songlong Jiao- Ze Wu,AI-Enhanced Visual-Spectral Synergy for Fast and Ultrasensitive Biodetection of Breast Cancer-Related miRNAs.,Breast cancer is a dangerous disease- contributing to a high mortality rate in women. Early detection plays a pivotal role in enhancing survival rates. Breast ultrasound is considered an effective method to help diagnose breast diseases early. Breast ultrasound is inexpensive- easy to perform- non-invasive and painless- so it is often prescribed by doctors in cases where it is necessary to examine the nature of clinically palpable lesions or related symptoms in the breast. In this paper- we introduce a method based on transfer learning and deep feature fusion to classify breast cancer using ultrasound images. The results from our experiments involving 780 breast ultrasound images across three categories (benign- malignant- and normal) indicated that the model using max fusion of deep features outperformed an original CNN in terms of performance- the combination of the maximum value between deep features has a higher performance level with an accuracy of about 1% to 4% compared to the original model. The concatenation fusion of VGG19 and ViT features delivers 1% - 4% times more accuracy than the original model alone
Jessica Prunaretty- Fatima Mekki- Pierre-Ivan Laurent- Aurelie Morel- Pauline Hinault- Celine Bourgier- David Azria- Pascal Fenoglietto,Clinical feasibility of Ethos auto-segmentation for adaptive whole-breast cancer treatment,Identification of the molecular subtypes in breast cancer allows to optimize treatment strategies- but usually requires invasive needle biopsy. Recently- non-invasive imaging has emerged as promising means to classify them. Magnetic resonance imaging is often used for this purpose because it is three-dimensional and highly informative. Instead- only a few reports have documented the use of mammograms. Given that mammography is the first choice for breast cancer screening- using it to classify molecular subtypes would allow for early intervention on a much wider scale. Here- we aimed to evaluate the effectiveness of combining global and local mammographic features by using Vision Transformer (ViT) and Convolutional Neural Network (CNN) to classify molecular subtypes in breast cancer. The feature values for binary classification were calculated using the ViT and EfficientnetV2 feature extractors- followed by dimensional compression via principal component analysis. LightGBM was used to perform binary classification of each molecular subtype: triple-negative- HER2-enriched- luminal A- and luminal B. The combination of ViT and CNN achieved higher accuracy than ViT or CNN alone. The sensitivity for triple-negative subtypes was very high (0.900- with F-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.818); whereas F-value and sensitivity were 0.720 and 0.750 for HER2-enriched- 0.765 and 0.867 for luminal A- and 0.614 and 0.711 for luminal B subtypes- respectively. Features obtained from mammograms by combining ViT and CNN allow the classification of molecular subtypes with high accuracy. This approach could streamline early treatment workflows and triage- especially for poor prognosis subtypes such as triple-negative breast cancer.
Yaping Yang- Ying Zhong- Junwei Li- Jiahao Feng- C. Gong- Yunfang Yu- Yue Hu- R. Gu- Hongli Wang- Fengtao Liu- J. Mei- Xiaofang Jiang- Jin Wang- Qinyue Yao- Wei Wu- Qiang Liu- H. Yao,Deep learning combining mammography and ultrasound images to predict the malignancy of BI-RADS US 4A lesions in women with dense breasts: a diagnostic study,Breast cancer is the most prevalent type of disease among women. It has become one of the foremost causes of death among women globally. Early detection plays a significant role in administering personalized treatment and improving patient outcomes. Mammography procedures are often used to detect early-stage cancer cells. This traditional method of mammography while valuable has limitations of potential for false positives and negatives- patient discomfort- and radiation exposure. Therefore- there is a probe for more accurate techniques required in detecting breast cancer- leading to exploring the potential of machine learning in the classification of diagnostic images due to its efficiency and accuracy. This study conducted a comparative analysis of pre-trained CNNs (ResNet50 and VGG16) and Vision Transformers (ViT-Base and SWIN Transformer) with the inclusion of ViT-Base trained from scratch model architectures to effectively classify breast cancer mammographic images into benign and malignant cases. The Swin transformer exhibits superior performance with 99.8% accuracy and a precision of 99.8%. These findings demonstrate the efficiency of deep learning to accurately classify breast cancer mammographic images for the diagnosis of breast cancer- leading to improvement in patient outcomes.
Jiahui Ren- Yili Li- Jing Zhou- Ting Yang- Jingfeng Jing- Qian Xiao- Zhongxu Duan- Ke Xiang- Yuchen Zhuang- Daxue Li- Han Gao,Developing machine learning models for personalized treatment strategies in early breast cancer patients undergoing neoadjuvant systemic therapy based on SEER database,Breast cancer is the second most common type of cancer among women. Prompt detection of breast cancer can impede its advancement to more advanced phases- thereby elevating the probability of favorable treatment consequences. Histopathological images are commonly used for breast cancer classification due to their detailed cellular information. Existing diagnostic approaches rely on Convolutional Neural Networks (CNNs) which are limited to local context resulting in a lower classification accuracy. Therefore- we present a fusion model composed of a Vision Transformer (ViT) and custom Atrous Spatial Pyramid Pooling (ASPP) network with an attention mechanism for effectively classifying breast cancer from histopathological images. ViT enables the model to attain global features- while the ASPP network accommodates multiscale features. Fusing the features derived from the models resulted in a robust breast cancer classifier. With the help of five-stage image preprocessing technique- the proposed model achieved 100% accuracy in classifying breast cancer on the BreakHis dataset at 100X and 400X magnification factors. On 40X and 200X magnifications- the model achieved 99.25% and 98.26% classification accuracy respectively. With a commendable classification efficacy on histopathological images- the model can be considered a dependable option for proficient breast cancer classification.
Xiao Guo- Jiaying Xing- Yuyan Cao- Wenchuang Yang- Xinlin Shi- Runhong Mu- Tao Wang,Machine learning based anoikis signature predicts personalized treatment strategy of breast cancer,The vision transformer (ViT) architecture- with its attention mechanism based on multi-head attention layers- has been widely adopted in various computer-aided diagnosis tasks due to its effectiveness in processing medical image information. ViTs are notably recognized for their complex architecture- which requires high-performance GPUs or CPUs for efficient model training and deployment in real-world medical diagnostic devices. This renders them more intricate than convolutional neural networks (CNNs). This difficulty is also challenging in the context of histopathology image analysis- where the images are both limited and complex. In response to these challenges- this study proposes a TokenMixer hybrid-architecture that combines the strengths of CNNs and ViTs. This hybrid architecture aims to enhance feature extraction and classification accuracy with shorter training time and fewer parameters by minimizing the number of input patches employed during training- while incorporating tokenization of input patches using convolutional layers and encoder transformer layers to process patches across all network layers for fast and accurate breast cancer tumor subtype classification. The TokenMixer mechanism is inspired by the ConvMixer and TokenLearner models. First- the ConvMixer model dynamically generates spatial attention maps using convolutional layers- enabling the extraction of patches from input images to minimize the number of input patches used in training. Second- the TokenLearner model extracts relevant regions from the selected input patches- tokenizes them to improve feature extraction- and trains all tokenized patches in an encoder transformer network. We evaluated the TokenMixer model on the BreakHis public dataset- comparing it with ViT-based and other state-of-the-art methods. Our approach achieved impressive results for both binary and multi-classification of breast cancer subtypes across various magnification levels (40â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 100â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 200â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 400â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢). The model demonstrated accuracies of 97.02% for binary classification and 93.29% for multi-classification- with decision times of 391.71 and 1173.56Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ s- respectively. These results highlight the potential of our hybrid deep ViT-CNN architecture for advancing tumor classification in histopathological images. The source code is accessible: https://github.com/abimouloud/TokenMixer .
Yu Du- Xuehong Diao,Machine Learning Models for Predicting Clinically and Ultrasound-Negative Axillary Lymph Node Metastasis in Early-Stage Breast Cancer,Breast cancer poses a serious threat to women's life and health. Typically- radiologists can detect early signs of breast cancer activity through breast ultrasound. However- the interpretation of breast ultrasound is time-consuming and requires physicians to possess extensive diagnostic experience. In recent years- computer aided diagnostic (CAD) technology has been introduced into breast imaging diagnosis- saving a significant amount of time for expert medical image inspection and improving diagnostic efficiency. However- current research on computer-aided diagnostic methods has mainly focused on ultrasound (US) images- with limited studies on contrast-enhanced ultrasound (CEUS) videos. To solve this challenge- we collected 332 cases of breast cancer contrast-enhanced ultrasound videos from Shengjing Hospital. We designed ResViT by combining residual neural networks with Vision Transformer to extract spatial features- and used the Temporal Segment Network (TSN) in combination with linear weights to fuse the spatio-temporal features of each frame into video-level features for classification. The experiment results show that our model achieved an accuracy of 78.79% and a sensitivity of 85% in our dataset- significantly higher than the results of current mainstream video analysis networks- proving the effectiveness of our proposed model in the task of classifying contrast-enhanced ultrasound videos.
Qiang Li- George Teodoro- Yi Jiang- Jun Kong,NACNet: A histology context-aware transformer graph convolution network for predicting treatment response to neoadjuvant chemotherapy in Triple Negative Breast Cancer,Breast cancer is one of the most common causes of death in women in the modern world. Cancerous tissue detection in histopathological images relies on complex features related to tissue structure and staining properties. Convolutional neural network (CNN) models like ResNet50- Inception-V1- and VGG-16- while useful in many applications- cannot capture the patterns of cell layers and staining properties. Most previous approaches- such as stain normalization and instance-based vision transformers- either miss important features or do not process the whole image effectively. Therefore- a deep fusion-based vision Transformer model (DFViT) that combines CNNs and transformers for better feature extraction is proposed. DFViT captures local and global patterns more effectively by fusing RGB and stain-normalized images. Trained and tested on several datasets- such as BreakHis- breast cancer histology (BACH)- and UCSC cancer genomics (UC)- the results demonstrate outstanding accuracy- F1 score- precision- and recall- setting a new milestone in histopathological image analysis for diagnosing breast cancer.
Olya Rezaeian- Onur Asan- A. E. Bayrak,The Impact of AI Explanations on Clinicians Trust and Diagnostic Accuracy in Breast Cancer,Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer. Breast tissue histopathological examination is critical in diagnosing and classifying breast cancer. Although existing methods have shown promising results- there is still room for improvement in the classification accuracy and generalization of IDC using histopathology images. We present a novel approach- Supervised Contrastive Vision Transformer (SupCon-ViT)- for improving the classification of invasive ductal carcinoma in terms of accuracy and generalization by leveraging the inherent strengths and advantages of both transfer learning- i.e.- pre-trained vision transformer- and supervised contrastive learning. Our results on a benchmark breast cancer dataset demonstrate that SupCon-ViT achieves state-of-the-art performance in IDC classification- with an F1-score of 0.8188- precision of 0.7692- and specificity of 0.8971- outperforming existing methods. In addition- the proposed model demonstrates resilience in scenarios with minimal labeled data- making it highly efficient in real-world clinical settings where labeled data is limited. Our findings suggest that supervised contrastive learning in conjunction with pre-trained vision transformers appears to be a viable strategy for an accurate classification of IDC- thus paving the way for a more efficient and reliable diagnosis of breast cancer through histopathological image analysis.
Beyzanur Erk- Ali Furkan Kamanli- Gamze Guney Eskiler,The therapeutic efficacy of 5-ALA based photodynamic therapy and chemotherapy combination in triple negative breast cancer cells,"Tumors are an important health concern in modern times. Breast cancer is one of the most prevalent causes of death for women. Breast cancer is rapidly becoming the leading cause of mortality among women globally. Early detection of breast cancer allows patients to obtain appropriate therapy- increasing their probability of survival. The adoption of 3-Dimensional (3D) mammography for the medical identification of abnormalities in the breast reduced the number of deaths dramatically. Classification and accurate detection of lumps in the breast in 3D mammography is especially difficult due to factors such as inadequate contrast and normal fluctuations in tissue density. Several Computer-Aided Diagnosis (CAD) solutions are under development to help radiologists accurately classify abnormalities in the breast. In this paper- a breast cancer diagnosis model is implemented to detect breast cancer in cancer patients to prevent death rates. The 3D mammogram images are gathered from the internet. Then- the gathered images are given to the preprocessing phase. The preprocessing is done using a median filter and image scaling method. The purpose of the preprocessing phase is to enhance the quality of the images and remove any noise or artifacts that may interfere with the detection of abnormalities. The median filter helps to smooth out any irregularities in the images- while the image scaling method adjusts the size and resolution of the images for better analysis. Once the preprocessing is complete- the preprocessed image is given to the segmentation phase. The segmentation phase is crucial in medical image analysis as it helps to identify and separate different structures within the image- such as organs or tumors. This process involves dividing the preprocessed image into meaningful regions or segments based on intensity- color- texture- or other features. The segmentation process is done using Adaptive Thresholding with Region Growing Fusion Model (AT-RGFM)"". This model combines the advantages of both thresholding and region-growing techniques to accurately identify and delineate specific structures within the image. By utilizing AT-RGFM- the segmentation phase can effectively differentiate between different parts of the image- allowing for more precise analysis and diagnosis. It plays a vital role in the medical image analysis process- providing crucial insights for healthcare professionals. Here- the Modified Garter Snake Optimization Algorithm (MGSOA) is used to optimize the parameters. It helps to optimize parameters for accurately identifying and delineating specific structures within medical images and also helps healthcare professionals in providing more precise analysis and diagnosis- ultimately playing a vital role in the medical image analysis process. MGSOA enhances the segmentation phase by effectively differentiating between different parts of the image- leading to more accurate results. Then- the segmented image is fed into the detection phase. The tumor detection is performed by the Vision Transformer-based Multiscale Adaptive EfficientNetB7 (ViT-MAENB7) model. This model utilizes a combination of advanced algorithms and deep learning techniques to accurately identify and locate tumors within the segmented medical image. By incorporating a multiscale adaptive approach- the ViT-MAENB7 model can analyze the image at various levels of detail- improving the overall accuracy of tumor detection. This crucial step in the medical image analysis process allows healthcare professionals to make more informed decisions regarding patient treatment and care. Here- the created MGSOA algorithm is used to optimize the parameters for enhancing the performance of the model. The suggested breast cancer diagnosis performance is compared to conventional cancer diagnosis models and it showed high accuracy. The accuracy of the developed MGSOA-ViT-MAENB7 is 96.6 %- and others model like RNN- LSTM- EffNet- and ViT-MAENet given the accuracy to be 90.31 %- 92.79 %- 94.46 % and 94.75 %. The developed model's ability to analyze images at multiple scales- combined with the optimization provided by the MGSOA algorithm- results in a highly accurate and efficient system for detecting tumors in medical images. This cutting-edge technology not only improves the accuracy of diagnosis but also helps healthcare professionals tailor treatment plans to individual patients- ultimately leading to better outcomes. By outperforming traditional cancer diagnosis models- the proposed model is revolutionizing the field of medical imaging and setting a new standard for precision and effectiveness in healthcare."
Thippaluru Umamaheswari- Y Murali Mohan Babu,ViT-MAENB7: An innovative breast cancer diagnosis model from 3D mammograms using advanced segmentation and classification process,Microwave imaging presents several potential advantages including its non-ionising and harmless nature. This open- multicentric- interventional- prospective- non-randomised trial aims to validate MammoWave's artificial intelligence (AI)-based classification algorithm- leveraging microwave imaging- to achieve a sensitivity exceeding 75% and a specificity exceeding 90% in breast screening. 10â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢000 volunteers undergoing regular mammographic breast cancer screening will be recruited across 9 European centres and invited to participate in the clinical study- involving MammoWave testing on both breasts. MammoWave results will be checked against the reference standard- to be intended as the output of conventional breast examination path (with histological confirmation of cancer cases) with 2 years follow-up. Anonymised clinical and MammoWave's results- including microwave images- associated features and a label provided by the AI-based classification algorithm- will be collected and stored in a dedicated electronic case report form. The prospective study will involve a comparative analysis between the output of the conventional breast examination path (control intervention) and the labels provided by MammoWave's AI system (experimental intervention). These labels will categorise breasts into two groups: breast With Suspicious Finding- indicating the presence of a suspicious lesion or No Suspicious Finding- indicating the absence of a lesion or the presence of a low-suspicion lesion. This trial aims to provide evidence regarding the novel MammoWave's AI system for detecting breast cancer in asymptomatic populations during screening. This study was approved by the Research Ethics Committee of the Liguria Region (CET)- Italy (CET-Liguria: 524/2023-DB id 13399)- the Research Ethics Committee of Complejo Hospitalario de Toledo (CEIC)- Spain (CEIC-1094)- the National Ethics Committee for Clinical Research (CEIC)- Portugal (CEIC-2311KC814)- the Bioethical Committee of Pomeranian Medical University in Szczecin- Poland (KB-006/23/2024) and the Zurich Cantonal Ethics Commission- Switzerland (BASEC 2023-D0101). The findings of this study will be disseminated through academic and scientific conferences as well as peer-reviewed journals. NCT06291896.
Nada M. Hassan- Safwat Hamad- Khaled Mahar,YOLO-based CAD framework with ViT transformer for breast mass detection and classification in CESM and FFDM images,This research explores the integration of deep learning techniques into medical imaging for early breast cancer detection. Focused on enhancing current methodologies- the study develops a specialized deep learning model using a diverse dataset of medical images. The primary objectives include evaluating the model's performance- identifying strengths and limitations- and addressing ethical considerations inherent in deploying such technology in healthcare. The findings offer significant implications for advancing early breast cancer detection- potentially revolutionizing diagnostic practices and improving patient outcomes. The study contributes to bridging existing gaps in the literature- providing novel insights into the potential of deep learning in the context of medical imaging. By examining the model's efficacy- ethical considerations- and its broader impact on healthcare- this research lays the foundation for further innovations in the critical intersection of artificial intelligence and early cancer diagnostics.
