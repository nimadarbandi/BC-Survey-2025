Sinae Oh- Jae Yong Shim,Development and validation of a deep learningâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®based cardiovascular disease risk prediction model for long-term breast cancer survivors.,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ As machine learning and artificial intelligence algorithms â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ ogy images using large vision-language models- combining image â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ language models- such as Vision Transformers or â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
J Dong- W Huang- J Zhang,Identification of Key Features in Breast Cancer Diagnosis Using Vision Transformer,Accurate segmentation of the clinical target volume (CTV) of CBCT images can observe the changes of CTV during patients' radiotherapy- and lay a foundation for the subsequent implementation of adaptive radiotherapy (ART). However- segmentation is challenging due to the poor quality of CBCT images and difficulty in obtaining target volumes. An uncertainty estimation- and attention-based semi-supervised model called residual convolutional block attention-uncertainty aware mean teacher (RCBA-UAMT) was proposed to delineate the CTV in cone-beam computed tomography (CBCT) images of breast cancer automatically. A total of 60 patients who undergone radiotherapy after breast-conserving surgery were enrolled in this study- which involved 60 planning CTs and 380 CBCTs. RCBA-UAMT was proposed by integrating residual and attention modules in the backbone network 3D UNet. The attention module can adjust channel and spatial weights of the extracted image features. The proposed design can train the model and segment CBCT images with a small amount of labeled data (5%- 10%- and 20%) and a large amount of unlabeled data. Four types of evaluation metrics- namely- dice similarity coefficient (DSC)- Jaccard- average surface distance (ASD)- and 95% Hausdorff distance (95HD)- are used to assess the model segmentation performance quantitatively. The proposed method achieved average DSC- Jaccard- 95HD- and ASD of 82%- 70%- 8.93- and 1.49Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ mm for CTV delineation on CBCT images of breast cancer- respectively. Compared with the three classical methods of mean teacher- uncertainty-aware mean-teacher and uncertainty rectified pyramid consistency- DSC and Jaccard increased by 7.89-9.33% and 14.75-16.67%- respectively- while 95HD and ASD decreased by 33.16-67.81% and 36.05-75.57%- respectively. The comparative experiment results of the labeled data with different proportions (5%- 10% and 20%) showed significant differences in the DSC- Jaccard- and 95HD evaluation indexes in the labeled data with 5% versus 10% and 5% versus 20%. Moreover- no significant differences were observed in the labeled data with 10% versus 20% among all evaluation indexes. Therefore- we can use only 10% labeled data to achieve the experimental objective. Using the proposed RCBA-UAMT- the CTV of breast cancer CBCT images can be delineated reliably with a small amount of labeled data. These delineated images can be used to observe the changes in CTV and lay the foundation for the follow-up implementation of ART.
S Zhang- B Yang- H Yang- J Zhao- Y Zhang- Y Gao- ...,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ rapid intraoperative cancer diagnosis using dynamic full-field optical coherence tomography and deep learning: A prospective cohort study in breast cancer â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ In this section- the application of Transformer models on WSI breast cancer pathology images is analyzed from a visual perspective. The analysis is conducted on two stages: instance â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Vedagiriswaran N- SHRIHARI KAMALAN KUMARAGURUPARAN- Kumara  Guru R,Machine Learning and Structural Informatics Approaches to Identify Mtor Inhibitors for Drug Repurposing in Triple-Negative Breast Cancer,Early detection significantly enhances patients' survival rates by identifying tumors in their initial stages through medical imaging. However- prevailing methodologies encounter challenges in extracting comprehensive information from diverse modalities- thereby exacerbating semantic disparities and overlooking critical task correlations- consequently compromising the accuracy of prognosis predictions. Moreover- clinical insights emphasize the advantageous sharing of parameters between tumor segmentation and survival prediction for enhanced prognostic accuracy. This paper proposes a novel model- BTSSPro- designed to concurrently address Breast cancer Tumor Segmentation and Survival prediction through a Prompt-guided multi-modal co-learning framework. Technologically- our approach involves the extraction of tumor-specific discriminative features utilizing shared dual attention (SDA) blocks- which amalgamate spatial and channel information from breast MR images. Subsequently- we employ a guided fusion module (GFM) to seamlessly integrate the Electronic Health Record (EHR) vector into the extracted tumor-related discriminative feature representations. This integration prompts the model's feature selection to align more closely with real-world scenarios. Finally- a feature harmonic unit (FHU) is introduced to coordinate the transformer encoder and CNN decoder- thus reducing semantic differences. Remarkably- BTSSPro achieved a C-index of 0.968 and Dice score of 0.715 on the Breast MRI-NACT-Pilot dataset and a C-index of 0.807 and Dice score of 0.791 on the ISPY1 dataset- surpassing the previous state-of-the-art methods.
Premisha Premananthan- Mauran Kanagarathnam,Deep Learning-Based Mitosis Detection in Breast Cancer Histopathology Images: A Mapping Study,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Deep learning (DL) AI tools are predominantly employed for re-â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Utilizing a vision transformer style- the ConvNeXt system â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ -making in screening- special attention should be paid to â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Ashish Kumar- Shubhangi Ojha- Sejal Tyagi- Utkarsh Kumar Yadav- Satyapriya Mittal,Histopathological Breast Cancer Detection: A Vision Transformer and Attention-Based Approach,Aims: To test the efficacy of artificial intelligence (AI)â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢assisted Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 digital image analysis in invasive breast carcinoma (IBC) with quantitative assessment of AI model performance. Methods and Results: This study used 494 cases of Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 slide images of IBC core needle biopsies. The methods were divided into two steps: (i) construction of a deepâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢learning model (DL); and (ii) DL implementation for Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 analysis. First- a DL tissue classifier model (DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC) and a DL nuclear detection model (DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ND) were constructed using HALO AI DenseNet V2 algorithm with 31-924 annotations in 300 Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 digital slide images. Whether the class predicted by DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC in the test set was correct compared with the annotation of ground truth at the pixel level was evaluated. Second- DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TCâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ and DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢NDâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢assisted digital image analysis (DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA) was performed in the other 194 luminalâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢type cases and correlations with manual counting and clinical outcome were investigated to confirm the accuracy and prognostic potential of DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA. The performance of DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC was excellent and invasive carcinoma nests were well segmented from other elements (average precision: 0.851; recall: 0.878; F1â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢score: 0.858). Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 index data and the number of nuclei from DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA were positively correlated with data from manual counting ( Conclusion: The performances of DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC and DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ND were excellent. DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA demonstrated a high degree of concordance with manual counting of Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 and the results of this approach have prognostic potential.
Shruthi G.K- Pushpa Ravikumar,Lymph Node Metastasis Prediction from Breast Cancer Pathological Images Using Deep Learning,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ transformer etc. In addition- we investigate the capacity of â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ application of artificial intelligence in breast cancer diagnosis- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ channels as input and generates attention masks to refine the â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Vaishnawi Priyadarshni- Sanjay Kumar Sharma,Machine Learning Based Classification of Histopathological Image for Breast Cancer,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ multimodal deep learning framework integrating breast â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ vision transformer (ViT) backbone: (a) ViT-base- (b) ViTlarge- and (câ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Bao- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Multi-modal artificial intelligence for the combination of â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Timea Bezdan- Ivana Strumberger- Milan Tuba,Optimizing Machine Learning for Breast Cancer Detection by Hybrid Metaheuristic Approach,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ clinical practice although recent artificial intelligence (AI) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ the transformer-based approaches to handle time attention- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ used to improve the quality of large language modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s (LLM) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Sabry- HM Balaha- KM Ali- ...,A vision transformer approach for breast cancer classification in histopathology,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Breast cancer is the second-leading cause of cancer-related deaths in women worldwide. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ for classifying Breast Cancer (BC) from histopathology slides using a Vision Transformer (ViT) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
K Wang- F Zheng- L Cheng- HN Dai- ...,Breast Cancer Classification from Digital Pathology Images via Connectivity-aware Graph Transformer,The manual examination of Breast Cancer (BC) images for disease detection is prone to error- is time-consuming- and has low accuracy. The Computer-Aided Detection (CAD) system â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
S Barua- MS Islam,Breast cancer image classification using external attention multilayer perceptron-based transformer,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ deep learningbased breast cancer prediction. The whole overview of relevant research in breast cancer â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ an external attention-based transformer method for breast cancer image â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Guyomard- AD Bouhnik- L Tassy- ...,Encoding breast cancer patients' medical pathways from reimbursement data using representation learning: a benchmark for clustering tasks,Neoadjuvant chemotherapy (NAC) is a key element of treatment for locally advanced breast cancer (LABC). Predicting the response to NAC for patients with Locally Advanced Breast Cancer (LABC) before treatment initiation could be beneficial to optimize therapy- ensuring the administration of effective treatments. The objective of the work here was to develop a predictive model to predict tumor response to NAC for LABC using deep learning networks and computed tomography (CT). Several deep learning approaches were investigated including ViT transformer and VGG16- VGG19- ResNet-50- Res-Net-101- Res-Net-152- InceptionV3 and Xception transfer learning networks. These deep learning networks were applied on CT images to assess the response to NAC. Performance was evaluated based on balanced_accuracy- accuracy- sensitivity and specificity classification metrics. A ViT transformer was applied to utilize the attention mechanism in order to increase the weight of important part image which leads to better discrimination between classes. Amongst the 117 LABC patients studied- 82 (70%) had clinical-pathological response and 35 (30%) had no response to NAC. The ViT transformer obtained the best performance range (accuracy = 71 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to accuracy = 77 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- specificity = 86 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 76 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 56 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- and balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%) depending on the split ratio of train-data and test-data. Xception network obtained the second best results (accuracy = 72 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to accuracy = 65 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4- specificity = 81 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 73 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 55 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5%- and balanced_accuracy = 66 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5% to balanced_accuracy = 60 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%). The worst results were obtained using VGG-16 transfer learning network. Deep learning networks in conjunction with CT imaging are able to predict the tumor response to NAC for patients with LABC prior to start. A ViT transformer could obtain the best performance- which demonstrated the importance of attention mechanism.
Yan Jiang- Yuanyuan Peng- Yingyi Wu- Qing Sun- Tebo Hua,Multimodal Machine Learning-Based Ductal Carcinoma in situ Prediction from Breast Fibromatosis,<p>The utilization of mammography images plays a vital role in the prompt detection and treatment of breast cancer. Breast imaging techniques aid medical professionals in assessing the dimensions- morphology- and spatial orientation of breast lesions- facilitating the differentiation between benign and malignant conditions. Breast tissue can vary widely in terms of density- composition- and structure- leading to complexities in distinguishing between benign and malignant conditions. The primary contribution of this paper is the proposal of a spatial attention-based neural architecture search network (SANAS-Net) technique that incorporates a spatial attention mechanism- enabling the model to learn and prioritize key regions within mammograms (MMs). Multi-head attention is employed within the transformer blocks to effectively capture a wide range of spatial relations and feature interactions. Global contextual information was integrated into the transformer blocks by means of introducing positional embeddings. Several practical studies have been undertaken to verify the effectiveness of our methodology in identifying fully attentive networks that exhibit good performance in distinguishing between malignant and benign breast cancer cases. The experimental study reached a test accuracy of 89.95%- which is way higher than previously proposed algorithms for mammography imagebased breast cancer detection.</p>
Manjula Kalita- Lipi B. Mahanta- Anup Kumar Das- Mananjay Nath,A new deep learning model with interface for fine needle aspiration cytology image-based breast cancer detection,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ We demonstrate that transformer models accurately predict â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ - 0.75)- and the language model achieved an AUPRC of 0.61 (â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Orpheus- an artificial intelligence model that accurately infers â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
ML Abimouloud- K Bensid- M Elleuch- ...,Vision transformer-convolution for breast cancer classification using mammography images: A comparative study,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Breast cancer (BC) is a widely diagnosed deadly disease â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Many deep learning-based breast cancer diagnostic methods â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ encoder-based multi-attention triple decoder convolution neural â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
D Manalâ€šÃ Ãœâˆšâ‰ Â¬Â¨Â¬Â±- H Demirel- A Eleyan,Deep Learning Based Breast Cancer Detection Using Decision Fusion,This paper introduces a self-attention Vision Transformer model specifically developed for classifying breast cancer in histology images. We examine various training strategies and configurations- including pretraining- dimension resizing- data augmentation and color normalization strategies- patch overlap- and patch size configurations- in order to evaluate their impact on the effectiveness of the histology image classification. Additionally- we provide evidence for the increase in effectiveness gathered through geometric and color data augmentation techniques. We primarily utilize the BACH dataset to train and validate our methods and models- but we also test them on two additional datasets- BRACS and AIDPATH- to verify their generalization capabilities. Our model- developed from a transformer pretrained on ImageNet- achieves an accuracy rate of 0.91 on the BACH dataset- 0.74 on the BRACS dataset- and 0.92 on the AIDPATH dataset. Using a model based on the prostate small and prostate medium HistoEncoder models- we achieve accuracy rates of 0.89 and 0.86- respectively. Our results suggest that pretraining on large-scale general datasets like ImageNet is advantageous. We also show the potential benefits of using domain-specific pretraining datasets- such as extensive histopathological image collections as in HistoEncoder- though not yet with clear advantages.
X Song- J Chu- Z Guo- Q Wei- Q Wang- W Hu- ...,Prognostic prediction of breast cancer patients using machine learning models: a retrospective analysis,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ of transformer based models for the purpose of digital breast cancer histopathology- an application field that demands high accuracy. Based on our findings- transformer based models â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
P Balaji- O Alqahtani- S Babu- ...,Integrating Transformer and Bidirectional Long Short-Term Memory for Intelligent Breast Cancer Detection from Histopathology Biopsy Images.,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ of deep learning in breast cancer diagnosis with a focus on whole-slide image analysis. Artificial intelligence â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ tools for assisting pathologists and supporting breast cancer management. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
O Shobayo,Breast Cancer Classification Using Fineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢Tuned SWIN Transformer Model on Mammographic Images,To compare the diagnostic performance of intratumoral and peritumoral features from different contrast phases of breast dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) by building radiomics models for differentiating molecular subtypes of breast cancer. This retrospective study included 377 patients with pathologically confirmed breast cancer. Patients were divided into training set (nâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢202)- validation set (nâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢87) and test set (nâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢88). The intratumoral volume of interest (VOI) and peritumoral VOI were delineated on primary breast cancers at three different DCE-MRI contrast phases: early- peak- and delayed. Radiomics features were extracted from each phase. After feature standardization- the training set was filtered by variance analysis- correlation analysis- and least absolute shrinkage and selection (LASSO). Using the extracted features- a logistic regression model based on each tumor subtype (Luminal A- Luminal B- HER2-enriched- triple-negative) was established. Ten models based on intratumoral or/plus peritumoral features from three different phases were developed for each differentiation. Radiomics features extracted from delayed phase DCE-MRI demonstrated dominant diagnostic performance over features from other phases. However- the differences were not statistically significant. In the full fusion model for differentiating different molecular subtypes- the most frequently screened features were those from the delayed phase. According to the Shapley additive explanation (SHAP) method- the most important features were also identified from the delayed phase. The intratumoral and peritumoral radiomics features from the delayed phase of DCE-MRI can provide additional information for preoperative molecular typing. The delayed phase of DCE-MRI cannot be ignored. Radiomics features extracted and radiomics models constructed from the delayed phase of DCE-MRI played a crucial role in molecular subtype classification- although no significant difference was observed in the test cohort. The molecular subtype of breast cancer provides a basis for setting treatment strategy and prognosis. The delayed-phase radiomics model outperformed that of early-/peak-phases- but no differently than other phases or combinations. Both intra- and peritumoral radiomics features offer valuable insights for molecular typing.
MR JebeliHajiAbadi,Classification of Breast Cancer Cytological Images using Vision Transformers,Although cancer therapy suppresses recurrence and prolongs life- it may be accompanied by strong side effects; thus- there is a strong demand for the development effective treatments with fewer side effects. Cancer therapy using plant-derived essential oils is attracting attention as one promising method. This study investigated the antitumor effects of essential oil volatiles on breast cancer cells and identifies four essential oils that display antitumor activity. Breast cancer cells were cultured in a 96-well plate- then one of twenty essential oils was added dropwise to the central well. The plate was incubated at 37Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšâ€ âˆšÂªC for 48Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ h and the effect of the volatile components of each essential oil on the surrounding breast cancer cell growth ability was examined using an MTT assay. Gas chromatography was used to investigate the concentration of the transpiration components that may affect cancer cells. Of the 20 essential oils- Lemongrass- Lemon myrtle- Litsea- and Melissa displayed strong anti-tumor effects. These essential oils inhibited the growth of nearby breast cancer cells- even when diluted more than 500-fold. The transpiration component of lemon Myrtle showed the strongest antitumor effect- but was the least cytotoxic to mononuclear cells in normal peripheral blood (PBMC). Each of these essential oils contained a very large amount of citral. The IC50 against breast cancer cells when citral was volatilized from each essential oil was 1.67Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬ÂµL/mL for geranial and 1.31 Â¬Â¨Â¬Â®Â¬Â¨Â¬ÂµL/mL for neral. Volatilized citral alone showed strong anti-proliferation and infiltration-inhibiting effects. The transpiration components of Lemongrass- Lemon myrtle- Litsea- and Melissa are thought to inhibit breast cancer cell proliferation due to their high levels of citral.
Sahan Yoruc Selcuk- Xilin Yang- Bijie Bai- Yijie Zhang- Yuzhu Li- Musa Aydin- Aras Firat Unal- Aditya Gomatam- Zhen Guo- Morgan A. Darrow- Goren Kolodney- Karine Atlan- Tal K. Haran- Nir Pillar- Aydogan Ozcan,Classification of HER2 score in breast cancer images using deep learning and pyramid sampling,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ slide images (WSI) and artificial intelligence (AI) featuring digital â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ - image transformers leverage self-attention mechanisms â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ CNN and transformer-based deep learning methods for the â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
N Thakur- P Kumar- A Kumar,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ semantic segmentation and attention based backpropagation convolutional neural network (ABB-CNN) for breast cancer identification and classification â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ by transformer and graph deep learning- this study proposes a novel classification method of WSI breast cancer pathological images based on BiFormer and graph attention network (â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Altulayhi- A Alhrgan,Evaluating Study Between Vision Transformers and Pre-trained CNN Learning Algorithms to Classify Breast Cancer Histopathological Images,Health-related quality of life (HRQOL) has become increasingly important for breast cancer survivors- but clinically relevant declines often persist for many years after treatment. This study aimed to investigate whether social relationships can mitigate or prevent this decline in HRQOL. Data were used from the German population-based Mamma Carcinoma Risk Factor Investigation (MARIE) cohort of 2022 breast cancer cases with follow-up information for more than 15 years after diagnosis. Correlations between social integration- social support- and global health status (GHS) as an overall measure of HRQOL were analyzed- and linear regression analysis was performed with structural equation modeling. The majority of participants reported high levels of social integration and social support and moderate levels of GHS. Social integration 5 years after diagnosis was associated with GHS 5 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 1.12; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.25-1.99)- but no longitudinal effects were found. Social support 5 years after diagnosis was associated with better GHS 5 years (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.42; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.36-0.48) and 10 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.12; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.02-0.22)- whereas social support 10 years after diagnosis was associated with GHS 10 years (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.29; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.20-0.39) and 15 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.10; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.01-0.21). These results confirm that social relationships positively influence HRQOL in long-term breast cancer survivors and that their association should receive more attention clinically and beyond routine care.
HM Balaha- KM Ali- D Gondim- M Ghazal- ...,Harnessing Vision Transformers for Precise and Explainable Breast Cancer Diagnosis,This study presents a novel approach to enhance the accuracy of breast cancer detection from mammogram images through a hybrid feature selection and classification framework. Leveraging the power of XGBoost- a state-of-the-art machine learning algorithm- an embedded genetic algorithm is introduced for optimal feature selection. The genetic algorithm refines the feature set by iteratively evolving towards a subset that maximizes the discriminative power for breast cancer diagnosis. Subsequently- the selected features are fed into a Recurrent Neural Network (RNN) architecture with Random Boolean Networks (RBN) for classification. The RNN-RBN model captures intricate temporal dependencies within the image data- providing a nuanced understanding of the complex patterns indicative of breast cancer. The synergistic coupling of the XGBoost-embedded genetic algorithm for feature selection and the RNN-RBN model for classification results in a robust and interpretable system for breast cancer detection. The proposed hybrid approach is evaluated on a comprehensive dataset of mammogram images- demonstrating superior performance compared to traditional methods. The combination of feature selection through XGBoost- embedded genetic algorithms and RNN-RBN classification showcases the potential for advanced- accurate- and efficient breast cancer diagnosis- holding promise for improving early detection rates and patient outcomes in clinical settings.
S Hussain- M Ali- U Naseem- ...,Performance Evaluation of Deep Learning and Transformer Models Using Multimodal Data for Breast Cancer Classification,Co-loading of sonosensitizers and chemotherapeutic drugs into nanocarriers can improve the biocompatibilities- stabilities- and targeting of drugs and reduce the adverse reactions of drugs- providing a robust platform to orchestrate the synergistic interplay between chemotherapy and sonodynamic therapy (SDT) in cancer treatment. In this regard- biodegradable manganese dioxide (MnO2) has attracted widespread attention because of its unique properties in the tumor microenvironment (TME). Accordingly- herein- MnO2 nanoshells with hollow mesoporous structures (H-MnO2) were etched to co-load hematoporphyrin monomethyl ether (HMME) and doxorubicin (DOX)- and DOX/HMME-HMnO2@bovine serum albumin (BSA) obtained after simple BSA modification of DOX/HMME-HMnO2 exhibited excellent hydrophilicity and dispersibility. H-MnO2 rapidly degraded in the weakly acidic TME- releasing loaded HMME and DOX- and catalysed the decomposition of H2O2 abundantly present in TME- producing oxygen (O2) in situ- significantly increasing O2 concentration and downregulating the hypoxia-inducible factor 1â€šÃ¢Ã âˆšâ‰ Â¬Â¨Â¬Â± (HIF-1â€šÃ¢Ã âˆšâ‰ Â¬Â¨Â¬Â±). After irradiation of the tumor area with low-frequency ultrasound- the drug delivery efficiency of DOX/HMME-HMnO2@BSA substantially increased- and the excited HMME generated a large amount of reactive oxygen species (ROS)- which caused irreversible damage to tumor cells. Moreover- the cell death rate exceeded 60% after synergistic SDT-chemotherapy. Therefore- the pH-responsive nanoshells designed in this study can realize drug accumulation in tumor regions by responding to TME and augment SDT-chemotherapy potency for breast cancer treatment by improving hypoxia in tumors. Thus- this study provides theoretical support for the development of multifunctional nanocarriers and scientific evidence for further exploration of safer and more efficient breast cancer treatments.
A Sriwastawa- JA Arul Jothi,Vision transformer and its variants for image classification in digital breast cancer histopathology: A comparative study,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Here- the space attention- channel attention- and center attention modules are combined to form the triplet attention mechanism. Finally- this study proposes EfficientNet deep learning â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
ML ABIMOULOUD- K BENSID- M Elleuch- ...,Vision transformer based convolutional neural network for breast cancer histopathological images classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ transformer techniques in breast cancer classification using histopathological images. Our method is based on attention â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ and accurate classification of breast cancer subtype cells and â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
ML Abimouloud- K Bensid- M Elleuch- O Aiadi- ...,Vision Transformer Based Tokenization for Enhanced Breast Cancer Histopathological Images Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ women diagnosed with breast cancer and 379 â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ breast cancer- was defined by linking to the Stockholm-Gotland regional cancer center breast cancer registry where breast cancer â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Emmanuel Ahishakiye- Fredrick Kanobe,Breast Cancer Classification Using Breast Ultrasound Images with a Hybrid of Transfer Learning and Bayesian-Optimized Fast Learning Network,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ summary based on transformer language model approaches. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ self-attention mechanism within the transformer architecture â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ the shortcomings of traditional deep learning models- such as â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Muniraj Gupta- Nidhi Verma- Naveen Sharma- Satyendra Narayan Singh- R. K. Brojen Singh- Saurabh Kumar Sharma,Deep Transfer Learning Hybrid Techniques for Precision in Breast Cancer Tumor Histopathology Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ development of artificial intelligence- CAD systems utilizing deep learning technology have â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Compared to CNNs- the self-attention mechanism in Transformers exhibits robust global â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
David Groheux- Loâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšâ‰¤c Ferrer- Jennifer Vargas- Antoine Martineau- Adrien Borgel- Luis Teixeira- Philippe Menu- Philippe Bertheau- Olivier Gallinato- Thierry Colin- Jacqueline Lehmann-Che,FDG-PET/CT and multimodal machine learning model prediction of pathological complete response to neoadjuvant chemotherapy in triple-negative breast cancer,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ of artificial intelligence (AI) and biomarkers in breast cancer â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ deep learning models on high-resolution images of breast tissue â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ as EL- TL- xDNNs- U-Net- transformer- and so on. Although â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Juan Gutierrez-Cardenas,"Breast Cancer Classification through Transfer Learning with Vision Transformer, PCA, and Machine Learning Models",The objective of our study was to explore the feasibility of integrating artificial intelligence (AI) algorithms for breast cancer detection into a portable- point-of-care ultrasound device (POCUS). This proof-of-concept implementation is to demonstrate the platform for integrating AI algorithms into a POCUS device to achieve a performance benchmark of at least 15 frames/second. Our methodology involved the application of five AI models (FasterRCNN+MobileNetV3- FasterRCNN+ResNet50- RetinaNet+ResNet50- SSD300+VGG16- and SSDLite320+MobileNetV3)- pretrained on public datasets of natural images- fine-tuned using a dataset of gelatin-based breast phantom images with both anechoic and hyperechoic lesions- mimicking real tissue characteristics. We created various gelatin-based ultrasound phantoms containing ten simulated lesions- ranging from 4-20 mm in size. Our experimental setup used the Clarius L15 scanning probe- which was connected via Wi-Fi to both a tablet and a laptop- forming the core of our development platform. The phantom data was divided into training- validation- and held-out testing sets on a per-video basis. We executed 200 timing trials for each finetuned AI model- streaming scanning video from the ultrasound probe in real-time. SSDLite320+MobileNetV3 emerged as a standout- showing a mean frame-to-frame timing of 0.068 seconds (SD=0.005)- which is approximately 14.71 FPS- closely followed by FasterRCNN+MobileNetV3- with a mean timing of 0.123 seconds (SD=0.016)- or about 8.13 FPS. Both models show acceptable performance in lesion localization. Compared to our goal of 15 frames/second- only the SSDLite320+MobileNetV3 architecture performed with sufficient evaluation speed to be used in real-time. Our findings show the necessity of using AI architectures designed for edge devices for real-time use- as well as the potential need for hardware acceleration to encode AI models for use in POCUS.
Mrs. Shivali P Shinde- Dr. Manasi R. Dixit,Deep Learning Approach for Breast Cancer Detection from Histopathology Images,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ is a challenging task in artificial intelligence- aiming to â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ language models are acknowledged as foundational models â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Contrastive Language-Image Pretraining (CLIP) transformer model â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Kishan Sharda- Mandeep Singh Ramdev- Deepak Rawat- Pawan Bishnoi,Feature Selection for Breast Cancer Detection,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ In the field of early diagnosis of breast cancer- deep learning and machine learning â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ language-image pre-training (CLIP) model- named ViT-L/14 CLIP- a large vision transformer model â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
BioMed Research International,Retracted: Deep Learning-Based Real-Time Discriminate Correlation Analysis for Breast Cancer Detection,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ -stained histopathological images and artificial intelligence(AI) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ [36] proposed a Transformer-based Multiple Instance Learning (â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ (CLAM) method- which uses attention-based â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Alruily- AA Mahmoud- H Allahem- ...,Enhancing Breast Cancer Detection in Ultrasound Images: An Innovative Approach Using Progressive Fineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢Tuning of Vision Transformer Models,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ By illustrating the potential of transformer architectures for breast cancer detection- especially using ultrasound images- we contribute to the broader field of medical imaging. Our â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
D Shah- MA Ullah Khan- M Abrar,Reliable Breast Cancer Diagnosis with Deep Learning: DCGANâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢Driven Mammogram Synthesis and Validity Assessment,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ the performance of the USDOT-Transformer model- which combines US and DOT images with tumor receptor biomarkers to predict the pCR of breast cancer patients under NAC. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
F. Jacobs- S. D'Amico- E. Ferraro- E. Agostinetto- C.A. Tondini- M. Gaudio- C. Benvenuti- R. Gerosa- G. Saltalamacchia- R. De Sanctis- M.G. Della Porta- A. Santoro- M. Fornier- E. de Azambuja- A. Zambelli,70P Development and validation of a machine learning (ML) nomogram to predict RSClin results and guide adjuvant treatment of node-negative (N0) hormone receptor-positive (HR+)/human epidermal growth factor receptor-negative (HER2-) early breast cancer (eBC) in Europe,Breast cancer is a prominent contributor to mortality associated with cancer in the female population on a global scale. The timely identification and precise categorization of breast cancer are of utmost importance in enhancing patient prognosis. Nevertheless- the task of precisely categorizing breast cancer based on ultrasound imaging continues to present difficulties- primarily due to the presence of dense breast tissues and their inherent heterogeneity. This study presents a unique approach for breast cancer categorization utilizing the wavelet based vision transformer network. To enhance the neural networkâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s receptive fields- we have incorporated the discrete wavelet transform (DWT) into the network input. This technique enables the capture of significant features in the frequency domain. The proposed model exhibits the capability to effectively capture intricate characteristics of breast tissue- hence enabling correct classification of breast cancer with a notable degree of precision and efficiency. We utilized two breast tumor ultrasound datasets- including 780 cases from Baheya hospital in Egypt and 267 patients from the UDIAT Diagnostic Centre of Sabadell in Spain. The findings of our study indicate that the proposed transformer network achieves exceptional performance in breast cancerclassification. With an AUC rate of 0.984 and 0.968 on both datasets- our approach surpasses conventional deep learning techniques- establishing itself as the leading method in this domain. This study signifies a noteworthy advancement in the diagnosis and categorization of breast cancer- showcasing the potential of the proposed transformer networks to enhance the efficacy of medical imaging analysis.
Umesh Dutta- Simran Kaushik- Srinidhi Iyer- Ina Singh,A Comparative Analysis of Machine Learning Techniques for Breast Cancer Prediction,Breast cancer is one of the most common causes of death in women. Early signs of breast cancer can be an abnormality depicted on breast images like breast ultrasonography. Unfortunately- ultrasound images contain a lot of noise- which greatly increases the difficulty for doctors to interpret them. In recent years- computer-aided diagnosis (CAD) has been widely used in medical images- reducing the workload of doctors and the probability of misdiagnosis. However- it still faces the following challenges in clinical practice: one is the lack of interpretability- and another is that the accuracy is not high enough. In this paper- we propose a classification model of breast ultrasound images that leverages tumor boundaries as prior knowledge and strengthens the model to guide classification. Furthermore- we employ the advantages of convolutional neural network (CNN) to extract local features and Transformer to extract global features to achieve information balance and complementarity between the two neural network models which increase the recognition performance of the model. Additionally- an explanation method is used to generate visual results- thereby improving the poor interpretability of deep learning models. Finally- we evaluate the model on the BUSI dataset and compare it with other CNN and Transformer models. Experimental results show that the proposed model obtains an accuracy of 0.9870 and an F1 score of 0.9872- achieving state-of-the-art performance.
Ahsan Fiaz- Basit Raza- Muhammad Faheem- Aadil Raza,A deep fusion-based vision transformer for breast cancer classification,Hormone receptor-positive (HR+)/human epidermal growth factor receptor 2-negative (HER2-) breast cancer is the most common type of breast cancer- with continuous recurrence remaining an important clinical issue. Current relapse predictive models in HR+/HER2- breast cancer patients still have limitations. The integration of multidimensional data represents a promising alternative for predicting relapse. In this study- we leverage our multi-omics cohort comprising 579 HR+/HER2- breast cancer patients (200 patients with complete data across 7 modalities) and develop a machine-learning-based model- namely CIMPTGV- which integrates clinical information- immunohistochemistry- metabolomics- pathomics- transcriptomics- genomics- and copy number variations to predict recurrence risk of HR+/HER2- breast cancer. This model achieves concordance indices (C-indices) of 0.871 and 0.869 in the train and test sets- respectively. The risk population predicted by the CIMPTGV model encompasses those identified by single-modality models. Feature analysis reveals that synergistic and complementary effects exist in different modalities. Simultaneously- we develop a simplified model with a mean area under the curve (AUC) of 0.840- presenting a useful approach for clinical applications.
Yi Zhang- Bolun Zeng- Jia Li- Yuanyi Zheng- Xiaojun Chen,A Multi-Task Transformer With Local-Global Feature Interaction and Multiple Tumoral Region Guidance for Breast Cancer Diagnosis,Breast cancer is a heterogeneous disease composed of various biologically distinct subtypes- each characterized by unique molecular features. Its formation and progression involve a complex- multistep process that includes the accumulation of numerous genetic and epigenetic alterations. Although integrating RNA-seq transcriptome data with ATAC-seq epigenetic information provides a more comprehensive understanding of gene regulation and its impact across different conditions- no classification model has yet been developed for breast cancer intrinsic subtypes based on such integrative analyses. In this study- we employed machine learning algorithms to predict intrinsic subtypes through the integrative analysis of ATAC-seq and RNA-seq data. We identified 10 signature genes (CDH3- ERBB2- TYMS- GREB1- OSR1- MYBL2- FAM83D- ESR1- FOXC1- and NAT1) using recursive feature elimination with cross-validation (RFECV) and a support vector machine (SVM) based on SHAP (SHapley Additive exPlanations) feature importance. Furthermore- we found that these genes were primarily associated with immune responses- hormone signaling- cancer progression- and cellular proliferation.
Chenyang He- Yan Diao- Xingcong Ma- Shuo Yu- Xin He- Guochao Mao- Xinyu Wei- Yu Zhang- Yang Zhao,A Vision Transformer Network With Wavelet-Based Features for Breast Ultrasound Classification,
S. S. Boudouh- M. Bouakkaz,Advancing precision in breast cancer detection: a fusion of vision transformers and CNNs for calcification mammography classification,Breast cancer is a major cause of death worldwide. The complexity of endocrine regulation in breast cancer may allow the cancer cells to escape from a particular treatment and result in resistant and aggressive disease. These breast cancers usually have fewer treatment options. Targeted therapies for cancer patients may offer fewer adverse side effects because of specificity compared to conventional chemotherapy. Signaling pathways of nuclear receptors- such as the estrogen receptor (ER)- have been intensively studied and used as therapeutic targets. Recently- the role of the androgen receptor (AR) in breast cancer is gaining greater attention as a therapeutic target and as a prognostic biomarker. The expression of constitutively active truncated AR splice variants in breast cancer is a possible mechanism contributing to treatment resistance. Therefore- targeting both the full-length AR and AR variants- either through the activation or suppression of AR function- depending on the status of the ER- progesterone receptor- or human epidermal growth factor receptor 2- may provide additional treatment options. Studies targeting AR in combination with other treatment strategies are ongoing in clinical trials. The determination of the status of nuclear receptors to classify and identify patient subgroups will facilitate optimized and targeted combination therapies.
Chiharu Kai- Hideaki Tamori- Tsunehiro Ohtsuka- Miyako Nara- Akifumi Yoshida- Ikumi Sato- Hitoshi Futamura- Naoki Kodama- Satoshi Kasai,Classifying the molecular subtype of breast cancer using vision transformer and convolutional neural network features,Adversarial data can lead to malfunction of deep learning applications. It is essential to develop deep learning models that are robust to adversarial data while accurate on standard- clean data. In this study- we proposed a novel adversarially robust feature learning (ARFL) method for a real-world application of breast cancer diagnosis. ARFL facilitates adversarial training using both standard data and adversarial data- where a feature correlation measure is incorporated as an objective function to encourage learning of robust features and restrain spurious features. To show the effects of ARFL in breast cancer diagnosis- we built and evaluated diagnosis models using two independent clinically collected breast imaging datasets- comprising a total of 9-548 mammogram images. We performed extensive experiments showing that our method outperformed several state-of-the-art methods and that our method can enhance safer breast cancer diagnosis against adversarial attacks in clinical settings.
Jessica Prunaretty- Fatima Mekki- Pierre-Ivan Laurent- Aurelie Morel- Pauline Hinault- Celine Bourgier- David Azria- Pascal Fenoglietto,Clinical feasibility of Ethos auto-segmentation for adaptive whole-breast cancer treatment,Identification of the molecular subtypes in breast cancer allows to optimize treatment strategies- but usually requires invasive needle biopsy. Recently- non-invasive imaging has emerged as promising means to classify them. Magnetic resonance imaging is often used for this purpose because it is three-dimensional and highly informative. Instead- only a few reports have documented the use of mammograms. Given that mammography is the first choice for breast cancer screening- using it to classify molecular subtypes would allow for early intervention on a much wider scale. Here- we aimed to evaluate the effectiveness of combining global and local mammographic features by using Vision Transformer (ViT) and Convolutional Neural Network (CNN) to classify molecular subtypes in breast cancer. The feature values for binary classification were calculated using the ViT and EfficientnetV2 feature extractors- followed by dimensional compression via principal component analysis. LightGBM was used to perform binary classification of each molecular subtype: triple-negative- HER2-enriched- luminal A- and luminal B. The combination of ViT and CNN achieved higher accuracy than ViT or CNN alone. The sensitivity for triple-negative subtypes was very high (0.900- with F-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.818); whereas F-value and sensitivity were 0.720 and 0.750 for HER2-enriched- 0.765 and 0.867 for luminal A- and 0.614 and 0.711 for luminal B subtypes- respectively. Features obtained from mammograms by combining ViT and CNN allow the classification of molecular subtypes with high accuracy. This approach could streamline early treatment workflows and triage- especially for poor prognosis subtypes such as triple-negative breast cancer.
Yaping Yang- Ying Zhong- Junwei Li- Jiahao Feng- C. Gong- Yunfang Yu- Yue Hu- R. Gu- Hongli Wang- Fengtao Liu- J. Mei- Xiaofang Jiang- Jin Wang- Qinyue Yao- Wei Wu- Qiang Liu- H. Yao,Deep learning combining mammography and ultrasound images to predict the malignancy of BI-RADS US 4A lesions in women with dense breasts: a diagnostic study,Breast cancer is the most prevalent type of disease among women. It has become one of the foremost causes of death among women globally. Early detection plays a significant role in administering personalized treatment and improving patient outcomes. Mammography procedures are often used to detect early-stage cancer cells. This traditional method of mammography while valuable has limitations of potential for false positives and negatives- patient discomfort- and radiation exposure. Therefore- there is a probe for more accurate techniques required in detecting breast cancer- leading to exploring the potential of machine learning in the classification of diagnostic images due to its efficiency and accuracy. This study conducted a comparative analysis of pre-trained CNNs (ResNet50 and VGG16) and Vision Transformers (ViT-Base and SWIN Transformer) with the inclusion of ViT-Base trained from scratch model architectures to effectively classify breast cancer mammographic images into benign and malignant cases. The Swin transformer exhibits superior performance with 99.8% accuracy and a precision of 99.8%. These findings demonstrate the efficiency of deep learning to accurately classify breast cancer mammographic images for the diagnosis of breast cancer- leading to improvement in patient outcomes.
Guangliang Yang- Haiqi Chen- Jinchao Yue,Deep learning to optimize radiotherapy decisions for elderly patients with early-stage breast cancer: a novel approach for personalized treatment,Accurately and swiftly segmenting breast tumors is significant for cancer diagnosis and treatment. Ultrasound imaging stands as one of the widely employed methods in clinical practice. However- due to challenges such as low contrast- blurred boundaries- and prevalent shadows in ultrasound images- tumor segmentation remains a daunting task. In this study- we propose BCT-Net- a network amalgamating CNN and transformer components for breast tumor segmentation. BCT-Net integrates a dual-level attention mechanism to capture more features and redefines the skip connection module. We introduce the utilization of a classification task as an auxiliary task to impart additional semantic information to the segmentation network- employing supervised contrastive learning. A hybrid objective loss function is proposed- which combines pixel-wise cross-entropy- binary cross-entropy- and supervised contrastive learning loss. Experimental results demonstrate that BCT-Net achieves high precision- with Pre and DSC indices of 86.12% and 88.70%- respectively. Experiments conducted on the BUSI dataset of breast ultrasound images manifest that this approach exhibits high accuracy in breast tumor segmentation.
Idan Kassis- Dror Lederman- Gal Ben-Arie- Maia Giladi Rosenthal- Ilan Shelef- Yaniv Zigel,Detection of breast cancer in digital breast tomosynthesis with vision transformers,Breast cancer remains a major public health concern- and early detection is crucial for improving survival rates. Metabolomics offers the potential to develop non-invasive screening and diagnostic tools based on metabolic biomarkers. However- the inherent complexity of metabolomic datasets and the high dimensionality of biomarkers complicates the identification of diagnostically relevant features- with multiple studies demonstrating limited consensus on the specific metabolites involved. Unlike previous studies that rely on singular feature selection techniques such as Partial Least Square (PLS) or LASSO regression- this research combines supervised and unsupervised machine learning methods with random sampling strategies- offering a more robust and interpretable approach to feature selection. This study aimed to identify a parsimonious and robust set of biomarkers for breast cancer diagnosis using metabolomics data. Plasma samples from 185 breast cancer patients and 53 controls (from the Cooperative Human Tissue Network- USA) were analyzed. This study also overcomes the common issue of dataset imbalance by using propensity score matching (PSM)- which ensures reliable comparisons between cancer and control groups. We employed Univariate Naâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšâ‰¤ve Bayes- L2-regularized Support Vector Classifier (SVC)- Principal Component Analysis (PCA)- and feature engineering techniques to refine and select the most informative features. Our best-performing feature set comprised 11 biomarkers- including 9 metabolites (SM(OH) C22:2- SM C18:0- C0- C3OH- C14:2OH- C16:2OH- LysoPC a C18:1- PC aa C36:0 and Asparagine)- a metabolite ratio (Kynurenine-to-Tryptophan)- and 1 demographic variable (Age)- achieving an area under the ROC curve (AUC) of 98%. These results demonstrate the potential for a robust- cost-effective- and non-invasive breast cancer screening and diagnostic tool- offering significant clinical value for early detection and personalized patient management.
Jiahui Ren- Yili Li- Jing Zhou- Ting Yang- Jingfeng Jing- Qian Xiao- Zhongxu Duan- Ke Xiang- Yuchen Zhuang- Daxue Li- Han Gao,Developing machine learning models for personalized treatment strategies in early breast cancer patients undergoing neoadjuvant systemic therapy based on SEER database,Breast cancer is the second most common type of cancer among women. Prompt detection of breast cancer can impede its advancement to more advanced phases- thereby elevating the probability of favorable treatment consequences. Histopathological images are commonly used for breast cancer classification due to their detailed cellular information. Existing diagnostic approaches rely on Convolutional Neural Networks (CNNs) which are limited to local context resulting in a lower classification accuracy. Therefore- we present a fusion model composed of a Vision Transformer (ViT) and custom Atrous Spatial Pyramid Pooling (ASPP) network with an attention mechanism for effectively classifying breast cancer from histopathological images. ViT enables the model to attain global features- while the ASPP network accommodates multiscale features. Fusing the features derived from the models resulted in a robust breast cancer classifier. With the help of five-stage image preprocessing technique- the proposed model achieved 100% accuracy in classifying breast cancer on the BreakHis dataset at 100X and 400X magnification factors. On 40X and 200X magnifications- the model achieved 99.25% and 98.26% classification accuracy respectively. With a commendable classification efficacy on histopathological images- the model can be considered a dependable option for proficient breast cancer classification.
Elisabetta Munzone- Antonio Marra- Federico Comotto- Lorenzo Guercio- Claudia Anna Sangalli- Martina Lo Cascio- Eleonora Pagan- Davide Sangalli- Ilaria Bigoni- Francesca Maria Porta- Marianna D'Ercole- Fabiana Ritorti- Vincenzo Bagnardi- Nicola Fusco- Giuseppe Curigliano,Development and Validation of a Natural Language Processing Algorithm for Extracting Clinical and Pathological Features of Breast Cancer From Pathology Reports,The primary goal of this study is to evaluate the capabilities of Large Language Models (LLMs) in understanding and processing complex medical documentation. We chose to focus on the identification of pathologic complete response (pCR) in narrative pathology reports. This approach aims to contribute to the advancement of comprehensive reporting- health research- and public health surveillance- thereby enhancing patient care and breast cancer management strategies. The study utilized two analytical pipelines- developed with open-source LLMs within the healthcare system's computing environment. First- we extracted embeddings from pathology reports using 15 different transformer-based models and then employed logistic regression on these embeddings to classify the presence or absence of pCR. Secondly- we fine-tuned the Generative Pre-trained Transformer-2 (GPT-2) model by attaching a simple feed-forward neural network (FFNN) layer to improve the detection performance of pCR from pathology reports. In a cohort of 351 female breast cancer patients who underwent neoadjuvant chemotherapy (NAC) and subsequent surgery between 2010 and 2017 in Calgary- the optimized method displayed a sensitivity of 95.3% (95%CI: 84.0-100.0%)- a positive predictive value of 90.9% (95%CI: 76.5-100.0%)- and an F1 score of 93.0% (95%CI: 83.7-100.0%). The results- achieved through diverse LLM integration- surpassed traditional machine learning models- underscoring the potential of LLMs in clinical pathology information extraction. The study successfully demonstrates the efficacy of LLMs in interpreting and processing digital pathology data- particularly for determining pCR in breast cancer patients post-NAC. The superior performance of LLM-based pipelines over traditional models highlights their significant potential in extracting and analyzing key clinical data from narrative reports. While promising- these findings highlight the need for future external validation to confirm the reliability and broader applicability of these methods.
Adhari AlZaabi- Stephen Piccolo- Steven Graves- Marc Hansen,Differential Serum Peptidomics Reveal Multi-Marker Models That Predict Breast Cancer Progression,Breast cancer- as a malignant tumor disease- has maintained high incidence and mortality rates over the years. Ultrasonography is one of the primary methods for diagnosing early-stage breast cancer. However- correctly interpreting breast ultrasound images requires massive time from physicians with specialized knowledge and extensive experience. Recently- deep learning-based method have made significant advancements in breast tumor segmentation and classification due to their powerful fitting capabilities. However- most existing methods focus on performing one of these tasks separately- and often failing to effectively leverage information from specific tumor-related areas that hold considerable diagnostic value. In this study- we propose a multi-task network with local-global feature interaction and multiple tumoral region guidance for breast ultrasound-based tumor segmentation and classification. Specifically- we construct a dual-stream encoder- paralleling CNN and Transformer- to facilitate hierarchical interaction and fusion of local and global features. This architecture enables each stream to capitalize on the strengths of the other while preserving its unique characteristics. Moreover- we design a multi-tumoral region guidance module to explicitly learn long-range non-local dependencies within intra-tumoral and peri-tumoral regions from spatial domain- thus providing interpretable cues beneficial for classification. Experimental results on two breast ultrasound datasets show that our network outperforms state-of-the-art methods in tumor segmentation and classification tasks. Compared with the second-best competitive method- our network improves the diagnosis accuracy from 73.64% to 80.21% on a large external validation dataset- which demonstrates its superior generalization capability.
Lei Zhu- Xin Yang- Jiying Zhang- Shuling Wang- Yulong Wang- Xing Wan- Xiang Zhu- Xiuyu Song- Zhongsheng Tong- Meng Yang- Weipeng Zhao,Evaluation of prognostic risk factors of triple-negative breast cancer with 18F-FDG PET/CT parameters- clinical pathological features and biochemical indicators,The axillary lymph node status remains an important prognostic factor in breast cancer- and nodal staging using sentinel lymph node biopsy (SLNB) is routine. Randomized clinical trials provide evidence supporting de-escalation of axillary surgery and omission of SLNB in patients at low risk. However- identifying sentinel lymph node macrometastases (macro-SLNMs) is crucial for planning treatment tailored to the individual patient. This study is the first to explore the capacity of deep learning (DL) models to identify macro-SLNMs based on preoperative clinicopathological characteristics. We trained and validated five multivariable models using a population-based cohort of 18-185 patients. DL models outperform logistic regression- with Transformer showing the strongest results- under the constraint that the sensitivity is no less than 90%- reflecting the sensitivity of SLNB. This highlights the feasibility of noninvasive macro-SLNM prediction using DL. Feature importance analysis revealed that patients with similar characteristics exhibited different nodal status predictions- indicating the need for additional predictors for further improvement.
Xinru Chen- Yingying Zhao- Yaohui Wang- Yumei Ye- Shuguang Xu- Liheng Zhou- Yanping Lin- Jingsong Lu- Wenjin Yin,Fluctuations in serum lipid levels during neoadjuvant treatment as novel predictive and prognostic biomarkers for locally advanced breast cancer: a retrospective analysis based on a prospective cohort,Breast cancer ranks as the second most prevalent cancer in women- recognized as one of the most dangerous types of cancer- and is on the rise globally. Regular screenings are essential for early-stage treatment. Digital mammography (DM) is the most recognized and widely used technique for breast cancer screening. Contrast-Enhanced Spectral Mammography (CESM or CM) is used in conjunction with DM to detect and identify hidden abnormalities- particularly in dense breast tissue where DM alone might not be as effective. In this work- we explore the effectiveness of each modality (CM- DM- or both) in detecting breast cancer lesions using deep learning methods. We introduce an architecture for detecting and classifying breast cancer lesions in DM and CM images in Craniocaudal (CC) and Mediolateral Oblique (MLO) views. The proposed architecture (JointNet) consists of a convolution module for extracting local features- a transformer module for extracting long-range features- and a feature fusion layer to fuse the local features- global features- and global features weighted based on the local ones. This significantly enhances the accuracy of classifying DM and CM images into normal or abnormal categories and lesion classification into benign or malignant. Using our architecture as a backbone- three lesion classification pipelines are introduced that utilize attention mechanisms focused on lesion shape- texture- and overall breast texture- examining the critical features for effective lesion classification. The results demonstrate that our proposed methods outperform their components in classifying images as normal or abnormal and mitigate the limitations of independently using the transformer module or the convolution module. An ensemble model is also introduced to explore the effect of each modality and each view to increase our baseline architecture's accuracy. The results demonstrate superior performance compared with other similar works. The best performance on DM images was achieved with the semi-automatic AOL Lesion Classification Pipeline- yielding an accuracy of 98.85Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- AUROC of 0.9965- F1-score of 98.85Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- precision of 98.85Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- and specificity of 98.85Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %. For CM images- the highest results were obtained using the automatic AOL Lesion Classification Pipeline- with an accuracy of 97.47Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- AUROC of 0.9771- F1-score of 97.34Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- precision of 94.45Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- and specificity of 97.23Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %. The semi-automatic ensemble AOL Classification Pipeline provided the best overall performance when using both DM and CM images- with an accuracy of 94.74Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- F1-score of 97.67Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- specificity of 93.75Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- and sensitivity of 95.45Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %. Furthermore- we explore the comparative effectiveness of CM and DM images in deep learning models- indicating that while CM images offer clearer insights to the human eye- our model trained on DM images yields better results using Attention on Lesion (AOL) techniques. The research also suggests a multimodal approach using both DM and CM images and ensemble learning could provide more robust classification outcomes.
Xiao Guo- Jiaying Xing- Yuyan Cao- Wenchuang Yang- Xinlin Shi- Runhong Mu- Tao Wang,Machine learning based anoikis signature predicts personalized treatment strategy of breast cancer,The vision transformer (ViT) architecture- with its attention mechanism based on multi-head attention layers- has been widely adopted in various computer-aided diagnosis tasks due to its effectiveness in processing medical image information. ViTs are notably recognized for their complex architecture- which requires high-performance GPUs or CPUs for efficient model training and deployment in real-world medical diagnostic devices. This renders them more intricate than convolutional neural networks (CNNs). This difficulty is also challenging in the context of histopathology image analysis- where the images are both limited and complex. In response to these challenges- this study proposes a TokenMixer hybrid-architecture that combines the strengths of CNNs and ViTs. This hybrid architecture aims to enhance feature extraction and classification accuracy with shorter training time and fewer parameters by minimizing the number of input patches employed during training- while incorporating tokenization of input patches using convolutional layers and encoder transformer layers to process patches across all network layers for fast and accurate breast cancer tumor subtype classification. The TokenMixer mechanism is inspired by the ConvMixer and TokenLearner models. First- the ConvMixer model dynamically generates spatial attention maps using convolutional layers- enabling the extraction of patches from input images to minimize the number of input patches used in training. Second- the TokenLearner model extracts relevant regions from the selected input patches- tokenizes them to improve feature extraction- and trains all tokenized patches in an encoder transformer network. We evaluated the TokenMixer model on the BreakHis public dataset- comparing it with ViT-based and other state-of-the-art methods. Our approach achieved impressive results for both binary and multi-classification of breast cancer subtypes across various magnification levels (40â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 100â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 200â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 400â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢). The model demonstrated accuracies of 97.02% for binary classification and 93.29% for multi-classification- with decision times of 391.71 and 1173.56Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ s- respectively. These results highlight the potential of our hybrid deep ViT-CNN architecture for advancing tumor classification in histopathological images. The source code is accessible: https://github.com/abimouloud/TokenMixer .
Yu Du- Xuehong Diao,Machine Learning Models for Predicting Clinically and Ultrasound-Negative Axillary Lymph Node Metastasis in Early-Stage Breast Cancer,Breast cancer poses a serious threat to women's life and health. Typically- radiologists can detect early signs of breast cancer activity through breast ultrasound. However- the interpretation of breast ultrasound is time-consuming and requires physicians to possess extensive diagnostic experience. In recent years- computer aided diagnostic (CAD) technology has been introduced into breast imaging diagnosis- saving a significant amount of time for expert medical image inspection and improving diagnostic efficiency. However- current research on computer-aided diagnostic methods has mainly focused on ultrasound (US) images- with limited studies on contrast-enhanced ultrasound (CEUS) videos. To solve this challenge- we collected 332 cases of breast cancer contrast-enhanced ultrasound videos from Shengjing Hospital. We designed ResViT by combining residual neural networks with Vision Transformer to extract spatial features- and used the Temporal Segment Network (TSN) in combination with linear weights to fuse the spatio-temporal features of each frame into video-level features for classification. The experiment results show that our model achieved an accuracy of 78.79% and a sensitivity of 85% in our dataset- significantly higher than the results of current mainstream video analysis networks- proving the effectiveness of our proposed model in the task of classifying contrast-enhanced ultrasound videos.
Maria Colomba Comes- Annarita Fanizzi- Samantha Bove- Luca Boldrini- Agnese Latorre- Deniz Can Guven- Serena Iacovelli- Tiziana Talienti- Alessandro Rizzo- Francesco Alfredo Zito- Raffaella Massafra,Monitoring Over Time of Pathological Complete Response to Neoadjuvant Chemotherapy in Breast Cancer Patients Through an Ensemble Vision Transformers-Based Model,"Women with breast cancer face a high degree of uncertainty. Trust between health providers and patients has been shown to improve patient quality of life and may enhance clinical outcomes. This study aimed to explore the meaning of trust along the treatment pathway. The study followed a convergent mixed-methods design. We collected qualitative data longitudinally from diagnosis to follow-up using unstructured digital diaries and 45 semi-structured interviews with twelve women with breast cancer. To measure symptom burden and trust- we collected quantitative data by means of 57 questionnaires. Data analysis was based on phenomenology according to van Manen and on descriptive statistics. Data synthesis resulted in a conceptual model of trust. The women experienced trust as a dynamic phenomenon within the biomedical cancer care ""machinery"". Their trust was strongly influenced by contextual factors- professionals' expertise- and person-centeredness. The relevance of trust differed according to treatment phases. Due to a high degree of uncertainty- trust was particularly important. Professionals positively influenced the women's trust to a certain extent through a patient-centered approach and by demonstrating expertise within the biomedical cancer care ""machinery"". The conceptual model of trust should receive attention to bring care closer to the women's lived experience so that their care experience can be improved."
Qiang Li- George Teodoro- Yi Jiang- Jun Kong,NACNet: A histology context-aware transformer graph convolution network for predicting treatment response to neoadjuvant chemotherapy in Triple Negative Breast Cancer,Breast cancer is one of the most common causes of death in women in the modern world. Cancerous tissue detection in histopathological images relies on complex features related to tissue structure and staining properties. Convolutional neural network (CNN) models like ResNet50- Inception-V1- and VGG-16- while useful in many applications- cannot capture the patterns of cell layers and staining properties. Most previous approaches- such as stain normalization and instance-based vision transformers- either miss important features or do not process the whole image effectively. Therefore- a deep fusion-based vision Transformer model (DFViT) that combines CNNs and transformers for better feature extraction is proposed. DFViT captures local and global patterns more effectively by fusing RGB and stain-normalized images. Trained and tested on several datasets- such as BreakHis- breast cancer histology (BACH)- and UCSC cancer genomics (UC)- the results demonstrate outstanding accuracy- F1 score- precision- and recall- setting a new milestone in histopathological image analysis for diagnosing breast cancer.
Vijayshri Chaurasia- Mamta Patankar- Madhu Shandilya- Vivek Patel- Ebtasam Ahmad Siddiqui- Laxmi Kumre,Nucleion Segmentation for Breast Cancer Classification,Breast cancer is one of the most common cancers in the world- especially among women. Breast tumor segmentation is a key step in the identification and localization of the breast tumor region- which has important clinical significance. Inspired by the swin-transformer model with powerful global modeling ability- we propose a semantic segmentation framework named Swin-Net for breast ultrasound images- which combines Transformer and Convolutional Neural Networks (CNNs) to effectively improve the accuracy of breast ultrasound segmentation. Firstly- our model utilizes a swin-transformer encoder with stronger learning ability- which can extract features of images more precisely. In addition- two new modules are introduced in our method- including the feature refinement and enhancement module (RLM) and the hierarchical multi-scale feature fusion module (HFM)- given that the influence of ultrasonic image acquisition methods and the characteristics of tumor lesions is difficult to capture. Among them- the RLM module is used to further refine and enhance the feature map learned by the transformer encoder. The HFM module is used to process multi-scale high-level semantic features and low-level details- so as to achieve effective cross-layer feature fusion- suppress noise- and improve model segmentation performance. Experimental results show that Swin-Net performs significantly better than the most advanced methods on the two public benchmark datasets. In particular- it achieves an absolute improvement of 1.4â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®1.8% on Dice. Additionally- we provide a new dataset of breast ultrasound images on which we test the effect of our model- further demonstrating the validity of our method. In summary- the proposed Swin-Net framework makes significant advancements in breast ultrasound image segmentation- providing valuable exploration for research and applications in this domain.
Giulia Lucrezia Baroni- Laura Rasotto- Kevin Roitero- Angelica Tulisso- Carla Di Loreto- Vincenzo Della Mea,Optimizing Vision Transformers for Histopathology: Pretraining and Normalization in Breast Cancer Classification,Triple negative breast cancer (TNBC) is one of the subtypes of breast cancer characterized by a heterogeneous and aggressive nature. Photodynamic therapy (PDT) has drawn significant attention in cancer treatment. However- solubility of photosensitizer- penetration problems into a target tissue and insufficient oxygen concentration limit the effectiveness of PDT. To overcome these limitations and to reduce the side effects of chemotherapy- combination treatment modalities play an essential role in cancer treatment. In this study- we aimed to investigate the combination efficacy of cisplatin-based chemotherapy and 5-Aminolevulinic acid (5-ALA)/PDT in TNBC cells and healthy breast cellsÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ in vitro. To determine the effect of the combination effects of cisplatin and 5-ALA/PDT on TNBC cells- two treatment protocols (simultaneous and sequential combination therapy) were evaluated compared with cisplatin and 5-ALA/PDT monotherapy and WST-1- Annexin V assay- acridine orange (AO) and mitochondrial staining were performed. Our findings showed that MDA-MB-231 TNBC cell viability was significantly decreased following simultaneous combination treatment compared to cisplatin and 5-ALA/PDT monotherapy. Additionally- simultaneous combination treatment was more effective than sequential combination treatment. The simultaneous combination treatment of 2.5Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬ÂµM cisplatin and 5-ALA/PDT at 6Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2 and 9Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2 induced 46.78% and 53.6% total apoptotic death- respectively in TNBC cells compared with monotherapies (cisplatin (37.88%) and 5-ALA/PDT (6Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2: 31.48% and 9Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2: 37.78%). Additionally- cisplatin and 5-ALA/PDT combination treatment resulted in nuclear fragmentation and mitochondrial damage due to apoptosis. Our results suggest that cisplatin and 5-ALA/PDT simultaneous combination therapy could be a promising new alternative strategy for treating TNBC. However- further studies are required to assess the underlying molecular mechanisms of cisplatin and 5-ALA/PDT combination treatment at the molecular level.
Chunling Zhang- Peng Zhou- Ruobing Li- Zhongyuan Li- Aimei Ouyang,Prediction of lymphovascular invasion in invasive breast cancer based on clinical-MRI radiomics features,Neoadjuvant chemotherapy (NAC) response prediction for triple negative breast cancer (TNBC) patients is a challenging task clinically as it requires understanding complex histology interactions within the tumor microenvironment (TME). Digital whole slide images (WSIs) capture detailed tissue information- but their giga-pixel size necessitates computational methods based on multiple instance learning- which typically analyze small- isolated image tiles without the spatial context of the TME. To address this limitation and incorporate TME spatial histology interactions in predicting NAC response for TNBC patients- we developed a histology context-aware transformer graph convolution network (NACNet). Our deep learning method identifies the histopathological labels on individual image tiles from WSIs- constructs a spatial TME graph- and represents each node with features derived from tissue texture and social network analysis. It predicts NAC response using a transformer graph convolution network model enhanced with graph isomorphism network layers. We evaluate our method with WSIs of a cohort of TNBC patient (N=105) and compared its performance with multiple state-of-the-art machine learning and deep learning models- including both graph and non-graph approaches. Our NACNet achieves 90.0% accuracy- 96.0% sensitivity- 88.0% specificity- and an AUC of 0.82- through eight-fold cross-validation- outperforming baseline models. These comprehensive experimental results suggest that NACNet holds strong potential for stratifying TNBC patients by NAC response- thereby helping to prevent overtreatment- improve patient quality of life- reduce treatment cost- and enhance clinical outcomes- marking an important advancement toward personalized breast cancer treatment.
Takahiro Ochiya- Kazuki Hashimoto- Akihiko Shimomura,Prospects for liquid biopsy using microRNA and extracellular vesicles in breast cancer,Breast cancer is the second deadliest cancer (after lung cancer) globally among women- with high incidence and mortality rates. Its early diagnosis is pivotal for improving the cure rate. With the continuous development and maturity of deep learning technologies- traditional classification models have been widely applied for automated classification of pathological images. However- several challenges still persist. For instance- traditional classification models typically perform well in processing images with clear distinctions between target objects and backgrounds- but struggle to accurately classify pathological images due to the lack of clear distinctions between tumor lesion areas and background areas. In the light of this- we propose a two-stage breast tumor pathological classification model based on weakly supervised target localization- named ST-Double-Net. In the proposed model- precise lesion localization and classification are achieved in two stages. In the first stage- a set of global feature maps is obtained by utilizing the Swin Transformer. These feature maps are then input into a newly designed heatmap cropping (HMC) module- which forces the model to focus on discriminative features of lesion areas through heatmap-guided cropping- without requiring bounding boxes or relevant annotation information. This gradual refinement of target localization facilitates the extraction of useful global features- from coarse to fine. The images with discriminative features generated in the first stage serve as inputs for the second stage- where another Swin Transformer extracts local features from the magnified lesion region images. Finally- the global and local features extracted in the first and second stage- respectively- are fused to emphasize subtle differences in the images- thereby enhancing the modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s classification ability. The proposed ST-Double-Net model is evaluated on the BreaKHis and BACH public datasets- demonstrating superior performance compared to state-of-the-art models.
Rashed Al Amin- Roman Obermaisser,Resource-Efficient FPGA Implementation for Real-Time Breast Cancer Classification Using Custom CNNs,BACKGROUND This study evaluated the accuracy- clinical concordance- and readability of the chatbot interface generative pretrained transformer (ChatGPT) 3.5 as a source of breast cancer information for patients. METHODS Twenty questions that patients are likely to ask ChatGPT were identified by breast cancer advocates. These were posed to ChatGPT 3.5 in July 2023 and were repeated three times. Responses were graded in two domains: accuracy (4-point Likert scale- 4Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ worst) and clinical concordance (information is clinically similar to physician response; 5-point Likert scale- 5Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ not similar at all). The concordance of responses with repetition was estimated using intraclass correlation coefficient (ICC) of word counts. Response readability was calculated using the Flesch Kincaid readability scale. References were requested and verified. RESULTS The overall average accuracy was 1.88 (range 1.0-3.0; 95% confidence interval [CI]- 1.42-1.94)- and clinical concordance was 2.79 (range 1.0-5.0; 95% CI- 1.94-3.64). The average word count was 310 words per response (range- 146-441 words per response) with high concordance (ICC- 0.75; 95% CI- 0.59-0.91; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ <Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .001). The average readability was poor at 37.9 (range- 18.0-60.5) with high concordance (ICC- 0.73; 95% CI- 0.57-0.90; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ <Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .001). There was a weak correlation between ease of readability and better clinical concordance (-0.15; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .025). Accuracy did not correlate with readability (0.05; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .079). The average number of references was 1.97 (range- 1-4; total- 119). ChatGPT cited peer-reviewed articles only once and often referenced nonexistent websites (41%). CONCLUSIONS Because ChatGPT 3.5 responses were incorrect 24% of the time and did not provide real references 41% of the time- patients should be cautioned about using ChatGPT for medical information.
Xuefeng Fu- Yang Jiao- Yao Feng- Fengwei Lin- Bing Zhang- Qing Mao- Jiahui Wang- Wen Jiang- Yanhua Mou- Han Wang- Shaojie Wang,Scaffold Hopping of Pristimerin Provides Derivatives Containing a Privileged Quinoxaline Substructure as Potent Autophagy Inducers in Breast Cancer Cells,Digital Breast Tomosynthesis (DBT) has revolutionized more traditional breast imaging through its three-dimensional (3D) visualization capability that significantly enhances lesion discernibility- reduces tissue overlap- and improves diagnostic precision as compared to conventional two-dimensional (2D) mammography. In this study- we propose an advanced Computer-Aided Detection (CAD) system that harnesses the power of vision transformers to augment DBT's diagnostic efficiency. This scheme uses a neural network to glean attributes from the 2D slices of DBT followed by post-processing that considers features from neighboring slices to categorize the entire 3D scan. By leveraging a transfer learning technique- we trained and validated our CAD framework on a unique dataset consisting of 3-831 DBT scans and subsequently tested it on 685 scans. Of the architectures tested- the Swin Transformer outperformed the ResNet101 and vanilla Vision Transformer. It achieved an impressive AUC score of 0.934 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 0.026 at a resolution of 384 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 384. Increasing the image resolution from 224 to 384 not only maintained vital image attributes but also led to a marked improvement in performance (p-value = 0.0003). The Mean Teacher algorithm- a semi-supervised method using both labeled and unlabeled DBT slices- showed no significant improvement over the supervised approach. Comprehensive analyses across different lesion types- sizes- and patient ages revealed consistent performance. The integration of attention mechanisms yielded a visual narrative of the model's decision-making process that highlighted the prioritized regions during assessments. These findings should significantly propel the methodologies employed in DBT image analysis by setting a new benchmark for breast cancer diagnostic precision.
Shengnan Hao- Yihan Jia- Jianuo Liu- Zhiwu Wang- Chunling Liu- Zhanlin Ji- Ivan Ganchev,ST-Double-Net: A Two-Stage Breast Tumor Classification Model Based on Swin Transformer and Weakly Supervised Target Localization,"The Deep learning (DL) models for diagnosing breast cancer from mammographic images often operate as""black boxes""- making it difficult for healthcare professionals to trust and understand their decision-making processes. The study presents an integrated framework combining Convolutional Neural Networks (CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an elaborate data preprocessing pipeline and advanced data augmentation techniques to counteract dataset limitations and transfer learning using pre-trained networks such as VGG-16- Inception-V3 and ResNet was employed. A focal point of our study is the evaluation of XAI's effectiveness in interpreting model predictions- highlighted by utilizing the Hausdorff measure to assess the alignment between AI-generated explanations and expert annotations quantitatively. This approach is critical for XAI in promoting trustworthiness and ethical fairness in AI-assisted diagnostics. The findings from our research illustrate the effective collaboration between CNNs and XAI in advancing diagnostic methods for breast cancer- thereby facilitating a more seamless integration of advanced AI technologies within clinical settings. By enhancing the interpretability of AI driven decisions- this work lays the groundwork for improved collaboration between AI systems and medical practitioners- ultimately enriching patient care. Furthermore- the implications of our research extended well beyond the current methodologies. It encourages further research into how to combine multimodal data and improve AI explanations to meet the needs of clinical practice."
Mohammad Shiri- Monalika Padma Reddy- Jiangwen Sun,Supervised Contrastive Vision Transformer for Breast Histopathological Image Classification,
Olya Rezaeian- Onur Asan- A. E. Bayrak,The Impact of AI Explanations on Clinicians Trust and Diagnostic Accuracy in Breast Cancer,Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer. Breast tissue histopathological examination is critical in diagnosing and classifying breast cancer. Although existing methods have shown promising results- there is still room for improvement in the classification accuracy and generalization of IDC using histopathology images. We present a novel approach- Supervised Contrastive Vision Transformer (SupCon-ViT)- for improving the classification of invasive ductal carcinoma in terms of accuracy and generalization by leveraging the inherent strengths and advantages of both transfer learning- i.e.- pre-trained vision transformer- and supervised contrastive learning. Our results on a benchmark breast cancer dataset demonstrate that SupCon-ViT achieves state-of-the-art performance in IDC classification- with an F1-score of 0.8188- precision of 0.7692- and specificity of 0.8971- outperforming existing methods. In addition- the proposed model demonstrates resilience in scenarios with minimal labeled data- making it highly efficient in real-world clinical settings where labeled data is limited. Our findings suggest that supervised contrastive learning in conjunction with pre-trained vision transformers appears to be a viable strategy for an accurate classification of IDC- thus paving the way for a more efficient and reliable diagnosis of breast cancer through histopathological image analysis.
Beyzanur Erk- Ali Furkan Kamanli- Gamze Guney Eskiler,The therapeutic efficacy of 5-ALA based photodynamic therapy and chemotherapy combination in triple negative breast cancer cells,"Tumors are an important health concern in modern times. Breast cancer is one of the most prevalent causes of death for women. Breast cancer is rapidly becoming the leading cause of mortality among women globally. Early detection of breast cancer allows patients to obtain appropriate therapy- increasing their probability of survival. The adoption of 3-Dimensional (3D) mammography for the medical identification of abnormalities in the breast reduced the number of deaths dramatically. Classification and accurate detection of lumps in the breast in 3D mammography is especially difficult due to factors such as inadequate contrast and normal fluctuations in tissue density. Several Computer-Aided Diagnosis (CAD) solutions are under development to help radiologists accurately classify abnormalities in the breast. In this paper- a breast cancer diagnosis model is implemented to detect breast cancer in cancer patients to prevent death rates. The 3D mammogram images are gathered from the internet. Then- the gathered images are given to the preprocessing phase. The preprocessing is done using a median filter and image scaling method. The purpose of the preprocessing phase is to enhance the quality of the images and remove any noise or artifacts that may interfere with the detection of abnormalities. The median filter helps to smooth out any irregularities in the images- while the image scaling method adjusts the size and resolution of the images for better analysis. Once the preprocessing is complete- the preprocessed image is given to the segmentation phase. The segmentation phase is crucial in medical image analysis as it helps to identify and separate different structures within the image- such as organs or tumors. This process involves dividing the preprocessed image into meaningful regions or segments based on intensity- color- texture- or other features. The segmentation process is done using Adaptive Thresholding with Region Growing Fusion Model (AT-RGFM)"". This model combines the advantages of both thresholding and region-growing techniques to accurately identify and delineate specific structures within the image. By utilizing AT-RGFM- the segmentation phase can effectively differentiate between different parts of the image- allowing for more precise analysis and diagnosis. It plays a vital role in the medical image analysis process- providing crucial insights for healthcare professionals. Here- the Modified Garter Snake Optimization Algorithm (MGSOA) is used to optimize the parameters. It helps to optimize parameters for accurately identifying and delineating specific structures within medical images and also helps healthcare professionals in providing more precise analysis and diagnosis- ultimately playing a vital role in the medical image analysis process. MGSOA enhances the segmentation phase by effectively differentiating between different parts of the image- leading to more accurate results. Then- the segmented image is fed into the detection phase. The tumor detection is performed by the Vision Transformer-based Multiscale Adaptive EfficientNetB7 (ViT-MAENB7) model. This model utilizes a combination of advanced algorithms and deep learning techniques to accurately identify and locate tumors within the segmented medical image. By incorporating a multiscale adaptive approach- the ViT-MAENB7 model can analyze the image at various levels of detail- improving the overall accuracy of tumor detection. This crucial step in the medical image analysis process allows healthcare professionals to make more informed decisions regarding patient treatment and care. Here- the created MGSOA algorithm is used to optimize the parameters for enhancing the performance of the model. The suggested breast cancer diagnosis performance is compared to conventional cancer diagnosis models and it showed high accuracy. The accuracy of the developed MGSOA-ViT-MAENB7 is 96.6 %- and others model like RNN- LSTM- EffNet- and ViT-MAENet given the accuracy to be 90.31 %- 92.79 %- 94.46 % and 94.75 %. The developed model's ability to analyze images at multiple scales- combined with the optimization provided by the MGSOA algorithm- results in a highly accurate and efficient system for detecting tumors in medical images. This cutting-edge technology not only improves the accuracy of diagnosis but also helps healthcare professionals tailor treatment plans to individual patients- ultimately leading to better outcomes. By outperforming traditional cancer diagnosis models- the proposed model is revolutionizing the field of medical imaging and setting a new standard for precision and effectiveness in healthcare."
Kris Lami- Han-Seung Yoon- Anil V Parwani- Hoa Hoang Ngoc Pham- Yuri Tachibana- Chaim Linhart- Maya Grinwald- Manuela Vecsler- Junya Fukuoka,Validation of prostate and breast cancer detection artificial intelligence algorithms for accurate histopathological diagnosis and grading: a retrospective study with a Japanese cohort,Metastatic breast cancer (MBC) continues to be a leading cause of cancer-related deaths among women. This work introduces an innovative non-invasive breast cancer classification model designed to improve the identification of cancer metastases. While this study marks the initial exploration into predicting MBC- additional investigations are essential to validate the occurrence of MBC. Our approach combines the strengths of large language models (LLMs)- specifically the bidirectional encoder representations from transformers (BERT) model- with the powerful capabilities of graph neural networks (GNNs) to predict MBC patients based on their histopathology reports. This paper introduces a BERT-GNN approach for metastatic breast cancer prediction (BG-MBC) that integrates graph information derived from the BERT model. In this model- nodes are constructed from patient medical records- while BERT embeddings are employed to vectorise representations of the words in histopathology reports- thereby capturing semantic information crucial for classification by employing three distinct approaches (namely univariate selection- extra trees classifier for feature importance- and Shapley values to identify the features that have the most significant impact). Identifying the most crucial 30 features out of 676 generated as embeddings during model training- our model further enhances its predictive capabilities. The BG-MBC model achieves outstanding accuracy- with a detection rate of 0.98 and an area under curve (AUC) of 0.98- in identifying MBC patients. This remarkable performance is credited to the model's utilisation of attention scores generated by the LLM from histopathology reports- effectively capturing pertinent features for classification.
Nada M. Hassan- Safwat Hamad- Khaled Mahar,YOLO-based CAD framework with ViT transformer for breast mass detection and classification in CESM and FFDM images,This research explores the integration of deep learning techniques into medical imaging for early breast cancer detection. Focused on enhancing current methodologies- the study develops a specialized deep learning model using a diverse dataset of medical images. The primary objectives include evaluating the model's performance- identifying strengths and limitations- and addressing ethical considerations inherent in deploying such technology in healthcare. The findings offer significant implications for advancing early breast cancer detection- potentially revolutionizing diagnostic practices and improving patient outcomes. The study contributes to bridging existing gaps in the literature- providing novel insights into the potential of deep learning in the context of medical imaging. By examining the model's efficacy- ethical considerations- and its broader impact on healthcare- this research lays the foundation for further innovations in the critical intersection of artificial intelligence and early cancer diagnostics.
Sinae Oh- Jae Yong Shim,Development and validation of a deep learningâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®based cardiovascular disease risk prediction model for long-term breast cancer survivors.,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ As machine learning and artificial intelligence algorithms â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ ogy images using large vision-language models- combining image â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ language models- such as Vision Transformers or â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
J Dong- W Huang- J Zhang,Identification of Key Features in Breast Cancer Diagnosis Using Vision Transformer,Accurate segmentation of the clinical target volume (CTV) of CBCT images can observe the changes of CTV during patients' radiotherapy- and lay a foundation for the subsequent implementation of adaptive radiotherapy (ART). However- segmentation is challenging due to the poor quality of CBCT images and difficulty in obtaining target volumes. An uncertainty estimation- and attention-based semi-supervised model called residual convolutional block attention-uncertainty aware mean teacher (RCBA-UAMT) was proposed to delineate the CTV in cone-beam computed tomography (CBCT) images of breast cancer automatically. A total of 60 patients who undergone radiotherapy after breast-conserving surgery were enrolled in this study- which involved 60 planning CTs and 380 CBCTs. RCBA-UAMT was proposed by integrating residual and attention modules in the backbone network 3D UNet. The attention module can adjust channel and spatial weights of the extracted image features. The proposed design can train the model and segment CBCT images with a small amount of labeled data (5%- 10%- and 20%) and a large amount of unlabeled data. Four types of evaluation metrics- namely- dice similarity coefficient (DSC)- Jaccard- average surface distance (ASD)- and 95% Hausdorff distance (95HD)- are used to assess the model segmentation performance quantitatively. The proposed method achieved average DSC- Jaccard- 95HD- and ASD of 82%- 70%- 8.93- and 1.49Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ mm for CTV delineation on CBCT images of breast cancer- respectively. Compared with the three classical methods of mean teacher- uncertainty-aware mean-teacher and uncertainty rectified pyramid consistency- DSC and Jaccard increased by 7.89-9.33% and 14.75-16.67%- respectively- while 95HD and ASD decreased by 33.16-67.81% and 36.05-75.57%- respectively. The comparative experiment results of the labeled data with different proportions (5%- 10% and 20%) showed significant differences in the DSC- Jaccard- and 95HD evaluation indexes in the labeled data with 5% versus 10% and 5% versus 20%. Moreover- no significant differences were observed in the labeled data with 10% versus 20% among all evaluation indexes. Therefore- we can use only 10% labeled data to achieve the experimental objective. Using the proposed RCBA-UAMT- the CTV of breast cancer CBCT images can be delineated reliably with a small amount of labeled data. These delineated images can be used to observe the changes in CTV and lay the foundation for the follow-up implementation of ART.
Premisha Premananthan- Mauran Kanagarathnam,Deep Learning-Based Mitosis Detection in Breast Cancer Histopathology Images: A Mapping Study,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Deep learning (DL) AI tools are predominantly employed for re-â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Utilizing a vision transformer style- the ConvNeXt system â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ -making in screening- special attention should be paid to â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Ashish Kumar- Shubhangi Ojha- Sejal Tyagi- Utkarsh Kumar Yadav- Satyapriya Mittal,Histopathological Breast Cancer Detection: A Vision Transformer and Attention-Based Approach,Aims: To test the efficacy of artificial intelligence (AI)â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢assisted Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 digital image analysis in invasive breast carcinoma (IBC) with quantitative assessment of AI model performance. Methods and Results: This study used 494 cases of Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 slide images of IBC core needle biopsies. The methods were divided into two steps: (i) construction of a deepâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢learning model (DL); and (ii) DL implementation for Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 analysis. First- a DL tissue classifier model (DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC) and a DL nuclear detection model (DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ND) were constructed using HALO AI DenseNet V2 algorithm with 31-924 annotations in 300 Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 digital slide images. Whether the class predicted by DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC in the test set was correct compared with the annotation of ground truth at the pixel level was evaluated. Second- DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TCâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ and DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢NDâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢assisted digital image analysis (DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA) was performed in the other 194 luminalâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢type cases and correlations with manual counting and clinical outcome were investigated to confirm the accuracy and prognostic potential of DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA. The performance of DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC was excellent and invasive carcinoma nests were well segmented from other elements (average precision: 0.851; recall: 0.878; F1â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢score: 0.858). Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 index data and the number of nuclei from DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA were positively correlated with data from manual counting ( Conclusion: The performances of DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢TC and DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ND were excellent. DLâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢DIA demonstrated a high degree of concordance with manual counting of Kiâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢67 and the results of this approach have prognostic potential.
Vaishnawi Priyadarshni- Sanjay Kumar Sharma,Machine Learning Based Classification of Histopathological Image for Breast Cancer,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ multimodal deep learning framework integrating breast â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ vision transformer (ViT) backbone: (a) ViT-base- (b) ViTlarge- and (câ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Bao- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Multi-modal artificial intelligence for the combination of â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Sabry- HM Balaha- KM Ali- ...,A vision transformer approach for breast cancer classification in histopathology,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Breast cancer is the second-leading cause of cancer-related deaths in women worldwide. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ for classifying Breast Cancer (BC) from histopathology slides using a Vision Transformer (ViT) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
ML Abimouloud- K Bensid- M Elleuch- ...,Vision transformer-convolution for breast cancer classification using mammography images: A comparative study,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Breast cancer (BC) is a widely diagnosed deadly disease â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Many deep learning-based breast cancer diagnostic methods â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ encoder-based multi-attention triple decoder convolution neural â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
D Manalâ€šÃ Ãœâˆšâ‰ Â¬Â¨Â¬Â±- H Demirel- A Eleyan,Deep Learning Based Breast Cancer Detection Using Decision Fusion,This paper introduces a self-attention Vision Transformer model specifically developed for classifying breast cancer in histology images. We examine various training strategies and configurations- including pretraining- dimension resizing- data augmentation and color normalization strategies- patch overlap- and patch size configurations- in order to evaluate their impact on the effectiveness of the histology image classification. Additionally- we provide evidence for the increase in effectiveness gathered through geometric and color data augmentation techniques. We primarily utilize the BACH dataset to train and validate our methods and models- but we also test them on two additional datasets- BRACS and AIDPATH- to verify their generalization capabilities. Our model- developed from a transformer pretrained on ImageNet- achieves an accuracy rate of 0.91 on the BACH dataset- 0.74 on the BRACS dataset- and 0.92 on the AIDPATH dataset. Using a model based on the prostate small and prostate medium HistoEncoder models- we achieve accuracy rates of 0.89 and 0.86- respectively. Our results suggest that pretraining on large-scale general datasets like ImageNet is advantageous. We also show the potential benefits of using domain-specific pretraining datasets- such as extensive histopathological image collections as in HistoEncoder- though not yet with clear advantages.
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
MR JebeliHajiAbadi,Classification of Breast Cancer Cytological Images using Vision Transformers,Although cancer therapy suppresses recurrence and prolongs life- it may be accompanied by strong side effects; thus- there is a strong demand for the development effective treatments with fewer side effects. Cancer therapy using plant-derived essential oils is attracting attention as one promising method. This study investigated the antitumor effects of essential oil volatiles on breast cancer cells and identifies four essential oils that display antitumor activity. Breast cancer cells were cultured in a 96-well plate- then one of twenty essential oils was added dropwise to the central well. The plate was incubated at 37Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšâ€ âˆšÂªC for 48Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ h and the effect of the volatile components of each essential oil on the surrounding breast cancer cell growth ability was examined using an MTT assay. Gas chromatography was used to investigate the concentration of the transpiration components that may affect cancer cells. Of the 20 essential oils- Lemongrass- Lemon myrtle- Litsea- and Melissa displayed strong anti-tumor effects. These essential oils inhibited the growth of nearby breast cancer cells- even when diluted more than 500-fold. The transpiration component of lemon Myrtle showed the strongest antitumor effect- but was the least cytotoxic to mononuclear cells in normal peripheral blood (PBMC). Each of these essential oils contained a very large amount of citral. The IC50 against breast cancer cells when citral was volatilized from each essential oil was 1.67Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬ÂµL/mL for geranial and 1.31 Â¬Â¨Â¬Â®Â¬Â¨Â¬ÂµL/mL for neral. Volatilized citral alone showed strong anti-proliferation and infiltration-inhibiting effects. The transpiration components of Lemongrass- Lemon myrtle- Litsea- and Melissa are thought to inhibit breast cancer cell proliferation due to their high levels of citral.
M Altulayhi- A Alhrgan,Evaluating Study Between Vision Transformers and Pre-trained CNN Learning Algorithms to Classify Breast Cancer Histopathological Images,Health-related quality of life (HRQOL) has become increasingly important for breast cancer survivors- but clinically relevant declines often persist for many years after treatment. This study aimed to investigate whether social relationships can mitigate or prevent this decline in HRQOL. Data were used from the German population-based Mamma Carcinoma Risk Factor Investigation (MARIE) cohort of 2022 breast cancer cases with follow-up information for more than 15 years after diagnosis. Correlations between social integration- social support- and global health status (GHS) as an overall measure of HRQOL were analyzed- and linear regression analysis was performed with structural equation modeling. The majority of participants reported high levels of social integration and social support and moderate levels of GHS. Social integration 5 years after diagnosis was associated with GHS 5 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 1.12; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.25-1.99)- but no longitudinal effects were found. Social support 5 years after diagnosis was associated with better GHS 5 years (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.42; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.36-0.48) and 10 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.12; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.02-0.22)- whereas social support 10 years after diagnosis was associated with GHS 10 years (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.29; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.20-0.39) and 15 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.10; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.01-0.21). These results confirm that social relationships positively influence HRQOL in long-term breast cancer survivors and that their association should receive more attention clinically and beyond routine care.
HM Balaha- KM Ali- D Gondim- M Ghazal- ...,Harnessing Vision Transformers for Precise and Explainable Breast Cancer Diagnosis,This study presents a novel approach to enhance the accuracy of breast cancer detection from mammogram images through a hybrid feature selection and classification framework. Leveraging the power of XGBoost- a state-of-the-art machine learning algorithm- an embedded genetic algorithm is introduced for optimal feature selection. The genetic algorithm refines the feature set by iteratively evolving towards a subset that maximizes the discriminative power for breast cancer diagnosis. Subsequently- the selected features are fed into a Recurrent Neural Network (RNN) architecture with Random Boolean Networks (RBN) for classification. The RNN-RBN model captures intricate temporal dependencies within the image data- providing a nuanced understanding of the complex patterns indicative of breast cancer. The synergistic coupling of the XGBoost-embedded genetic algorithm for feature selection and the RNN-RBN model for classification results in a robust and interpretable system for breast cancer detection. The proposed hybrid approach is evaluated on a comprehensive dataset of mammogram images- demonstrating superior performance compared to traditional methods. The combination of feature selection through XGBoost- embedded genetic algorithms and RNN-RBN classification showcases the potential for advanced- accurate- and efficient breast cancer diagnosis- holding promise for improving early detection rates and patient outcomes in clinical settings.
A Sriwastawa- JA Arul Jothi,Vision transformer and its variants for image classification in digital breast cancer histopathology: A comparative study,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Here- the space attention- channel attention- and center attention modules are combined to form the triplet attention mechanism. Finally- this study proposes EfficientNet deep learning â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
ML ABIMOULOUD- K BENSID- M Elleuch- ...,Vision transformer based convolutional neural network for breast cancer histopathological images classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ transformer techniques in breast cancer classification using histopathological images. Our method is based on attention â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ and accurate classification of breast cancer subtype cells and â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
ML Abimouloud- K Bensid- M Elleuch- O Aiadi- ...,Vision Transformer Based Tokenization for Enhanced Breast Cancer Histopathological Images Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ women diagnosed with breast cancer and 379 â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ breast cancer- was defined by linking to the Stockholm-Gotland regional cancer center breast cancer registry where breast cancer â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Juan Gutierrez-Cardenas,"Breast Cancer Classification through Transfer Learning with Vision Transformer, PCA, and Machine Learning Models",The objective of our study was to explore the feasibility of integrating artificial intelligence (AI) algorithms for breast cancer detection into a portable- point-of-care ultrasound device (POCUS). This proof-of-concept implementation is to demonstrate the platform for integrating AI algorithms into a POCUS device to achieve a performance benchmark of at least 15 frames/second. Our methodology involved the application of five AI models (FasterRCNN+MobileNetV3- FasterRCNN+ResNet50- RetinaNet+ResNet50- SSD300+VGG16- and SSDLite320+MobileNetV3)- pretrained on public datasets of natural images- fine-tuned using a dataset of gelatin-based breast phantom images with both anechoic and hyperechoic lesions- mimicking real tissue characteristics. We created various gelatin-based ultrasound phantoms containing ten simulated lesions- ranging from 4-20 mm in size. Our experimental setup used the Clarius L15 scanning probe- which was connected via Wi-Fi to both a tablet and a laptop- forming the core of our development platform. The phantom data was divided into training- validation- and held-out testing sets on a per-video basis. We executed 200 timing trials for each finetuned AI model- streaming scanning video from the ultrasound probe in real-time. SSDLite320+MobileNetV3 emerged as a standout- showing a mean frame-to-frame timing of 0.068 seconds (SD=0.005)- which is approximately 14.71 FPS- closely followed by FasterRCNN+MobileNetV3- with a mean timing of 0.123 seconds (SD=0.016)- or about 8.13 FPS. Both models show acceptable performance in lesion localization. Compared to our goal of 15 frames/second- only the SSDLite320+MobileNetV3 architecture performed with sufficient evaluation speed to be used in real-time. Our findings show the necessity of using AI architectures designed for edge devices for real-time use- as well as the potential need for hardware acceleration to encode AI models for use in POCUS.
Kishan Sharda- Mandeep Singh Ramdev- Deepak Rawat- Pawan Bishnoi,Feature Selection for Breast Cancer Detection,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ In the field of early diagnosis of breast cancer- deep learning and machine learning â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ language-image pre-training (CLIP) model- named ViT-L/14 CLIP- a large vision transformer model â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Alruily- AA Mahmoud- H Allahem- ...,Enhancing Breast Cancer Detection in Ultrasound Images: An Innovative Approach Using Progressive Fineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢Tuning of Vision Transformer Models,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ By illustrating the potential of transformer architectures for breast cancer detection- especially using ultrasound images- we contribute to the broader field of medical imaging. Our â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
F. Jacobs- S. D'Amico- E. Ferraro- E. Agostinetto- C.A. Tondini- M. Gaudio- C. Benvenuti- R. Gerosa- G. Saltalamacchia- R. De Sanctis- M.G. Della Porta- A. Santoro- M. Fornier- E. de Azambuja- A. Zambelli,70P Development and validation of a machine learning (ML) nomogram to predict RSClin results and guide adjuvant treatment of node-negative (N0) hormone receptor-positive (HR+)/human epidermal growth factor receptor-negative (HER2-) early breast cancer (eBC) in Europe,Breast cancer is a prominent contributor to mortality associated with cancer in the female population on a global scale. The timely identification and precise categorization of breast cancer are of utmost importance in enhancing patient prognosis. Nevertheless- the task of precisely categorizing breast cancer based on ultrasound imaging continues to present difficulties- primarily due to the presence of dense breast tissues and their inherent heterogeneity. This study presents a unique approach for breast cancer categorization utilizing the wavelet based vision transformer network. To enhance the neural networkâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s receptive fields- we have incorporated the discrete wavelet transform (DWT) into the network input. This technique enables the capture of significant features in the frequency domain. The proposed model exhibits the capability to effectively capture intricate characteristics of breast tissue- hence enabling correct classification of breast cancer with a notable degree of precision and efficiency. We utilized two breast tumor ultrasound datasets- including 780 cases from Baheya hospital in Egypt and 267 patients from the UDIAT Diagnostic Centre of Sabadell in Spain. The findings of our study indicate that the proposed transformer network achieves exceptional performance in breast cancerclassification. With an AUC rate of 0.984 and 0.968 on both datasets- our approach surpasses conventional deep learning techniques- establishing itself as the leading method in this domain. This study signifies a noteworthy advancement in the diagnosis and categorization of breast cancer- showcasing the potential of the proposed transformer networks to enhance the efficacy of medical imaging analysis.
Ahsan Fiaz- Basit Raza- Muhammad Faheem- Aadil Raza,A deep fusion-based vision transformer for breast cancer classification,Hormone receptor-positive (HR+)/human epidermal growth factor receptor 2-negative (HER2-) breast cancer is the most common type of breast cancer- with continuous recurrence remaining an important clinical issue. Current relapse predictive models in HR+/HER2- breast cancer patients still have limitations. The integration of multidimensional data represents a promising alternative for predicting relapse. In this study- we leverage our multi-omics cohort comprising 579 HR+/HER2- breast cancer patients (200 patients with complete data across 7 modalities) and develop a machine-learning-based model- namely CIMPTGV- which integrates clinical information- immunohistochemistry- metabolomics- pathomics- transcriptomics- genomics- and copy number variations to predict recurrence risk of HR+/HER2- breast cancer. This model achieves concordance indices (C-indices) of 0.871 and 0.869 in the train and test sets- respectively. The risk population predicted by the CIMPTGV model encompasses those identified by single-modality models. Feature analysis reveals that synergistic and complementary effects exist in different modalities. Simultaneously- we develop a simplified model with a mean area under the curve (AUC) of 0.840- presenting a useful approach for clinical applications.
Chenyang He- Yan Diao- Xingcong Ma- Shuo Yu- Xin He- Guochao Mao- Xinyu Wei- Yu Zhang- Yang Zhao,A Vision Transformer Network With Wavelet-Based Features for Breast Ultrasound Classification,
S. S. Boudouh- M. Bouakkaz,Advancing precision in breast cancer detection: a fusion of vision transformers and CNNs for calcification mammography classification,Breast cancer is a major cause of death worldwide. The complexity of endocrine regulation in breast cancer may allow the cancer cells to escape from a particular treatment and result in resistant and aggressive disease. These breast cancers usually have fewer treatment options. Targeted therapies for cancer patients may offer fewer adverse side effects because of specificity compared to conventional chemotherapy. Signaling pathways of nuclear receptors- such as the estrogen receptor (ER)- have been intensively studied and used as therapeutic targets. Recently- the role of the androgen receptor (AR) in breast cancer is gaining greater attention as a therapeutic target and as a prognostic biomarker. The expression of constitutively active truncated AR splice variants in breast cancer is a possible mechanism contributing to treatment resistance. Therefore- targeting both the full-length AR and AR variants- either through the activation or suppression of AR function- depending on the status of the ER- progesterone receptor- or human epidermal growth factor receptor 2- may provide additional treatment options. Studies targeting AR in combination with other treatment strategies are ongoing in clinical trials. The determination of the status of nuclear receptors to classify and identify patient subgroups will facilitate optimized and targeted combination therapies.
Chiharu Kai- Hideaki Tamori- Tsunehiro Ohtsuka- Miyako Nara- Akifumi Yoshida- Ikumi Sato- Hitoshi Futamura- Naoki Kodama- Satoshi Kasai,Classifying the molecular subtype of breast cancer using vision transformer and convolutional neural network features,Adversarial data can lead to malfunction of deep learning applications. It is essential to develop deep learning models that are robust to adversarial data while accurate on standard- clean data. In this study- we proposed a novel adversarially robust feature learning (ARFL) method for a real-world application of breast cancer diagnosis. ARFL facilitates adversarial training using both standard data and adversarial data- where a feature correlation measure is incorporated as an objective function to encourage learning of robust features and restrain spurious features. To show the effects of ARFL in breast cancer diagnosis- we built and evaluated diagnosis models using two independent clinically collected breast imaging datasets- comprising a total of 9-548 mammogram images. We performed extensive experiments showing that our method outperformed several state-of-the-art methods and that our method can enhance safer breast cancer diagnosis against adversarial attacks in clinical settings.
Jessica Prunaretty- Fatima Mekki- Pierre-Ivan Laurent- Aurelie Morel- Pauline Hinault- Celine Bourgier- David Azria- Pascal Fenoglietto,Clinical feasibility of Ethos auto-segmentation for adaptive whole-breast cancer treatment,Identification of the molecular subtypes in breast cancer allows to optimize treatment strategies- but usually requires invasive needle biopsy. Recently- non-invasive imaging has emerged as promising means to classify them. Magnetic resonance imaging is often used for this purpose because it is three-dimensional and highly informative. Instead- only a few reports have documented the use of mammograms. Given that mammography is the first choice for breast cancer screening- using it to classify molecular subtypes would allow for early intervention on a much wider scale. Here- we aimed to evaluate the effectiveness of combining global and local mammographic features by using Vision Transformer (ViT) and Convolutional Neural Network (CNN) to classify molecular subtypes in breast cancer. The feature values for binary classification were calculated using the ViT and EfficientnetV2 feature extractors- followed by dimensional compression via principal component analysis. LightGBM was used to perform binary classification of each molecular subtype: triple-negative- HER2-enriched- luminal A- and luminal B. The combination of ViT and CNN achieved higher accuracy than ViT or CNN alone. The sensitivity for triple-negative subtypes was very high (0.900- with F-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.818); whereas F-value and sensitivity were 0.720 and 0.750 for HER2-enriched- 0.765 and 0.867 for luminal A- and 0.614 and 0.711 for luminal B subtypes- respectively. Features obtained from mammograms by combining ViT and CNN allow the classification of molecular subtypes with high accuracy. This approach could streamline early treatment workflows and triage- especially for poor prognosis subtypes such as triple-negative breast cancer.
Yaping Yang- Ying Zhong- Junwei Li- Jiahao Feng- C. Gong- Yunfang Yu- Yue Hu- R. Gu- Hongli Wang- Fengtao Liu- J. Mei- Xiaofang Jiang- Jin Wang- Qinyue Yao- Wei Wu- Qiang Liu- H. Yao,Deep learning combining mammography and ultrasound images to predict the malignancy of BI-RADS US 4A lesions in women with dense breasts: a diagnostic study,Breast cancer is the most prevalent type of disease among women. It has become one of the foremost causes of death among women globally. Early detection plays a significant role in administering personalized treatment and improving patient outcomes. Mammography procedures are often used to detect early-stage cancer cells. This traditional method of mammography while valuable has limitations of potential for false positives and negatives- patient discomfort- and radiation exposure. Therefore- there is a probe for more accurate techniques required in detecting breast cancer- leading to exploring the potential of machine learning in the classification of diagnostic images due to its efficiency and accuracy. This study conducted a comparative analysis of pre-trained CNNs (ResNet50 and VGG16) and Vision Transformers (ViT-Base and SWIN Transformer) with the inclusion of ViT-Base trained from scratch model architectures to effectively classify breast cancer mammographic images into benign and malignant cases. The Swin transformer exhibits superior performance with 99.8% accuracy and a precision of 99.8%. These findings demonstrate the efficiency of deep learning to accurately classify breast cancer mammographic images for the diagnosis of breast cancer- leading to improvement in patient outcomes.
Idan Kassis- Dror Lederman- Gal Ben-Arie- Maia Giladi Rosenthal- Ilan Shelef- Yaniv Zigel,Detection of breast cancer in digital breast tomosynthesis with vision transformers,Breast cancer remains a major public health concern- and early detection is crucial for improving survival rates. Metabolomics offers the potential to develop non-invasive screening and diagnostic tools based on metabolic biomarkers. However- the inherent complexity of metabolomic datasets and the high dimensionality of biomarkers complicates the identification of diagnostically relevant features- with multiple studies demonstrating limited consensus on the specific metabolites involved. Unlike previous studies that rely on singular feature selection techniques such as Partial Least Square (PLS) or LASSO regression- this research combines supervised and unsupervised machine learning methods with random sampling strategies- offering a more robust and interpretable approach to feature selection. This study aimed to identify a parsimonious and robust set of biomarkers for breast cancer diagnosis using metabolomics data. Plasma samples from 185 breast cancer patients and 53 controls (from the Cooperative Human Tissue Network- USA) were analyzed. This study also overcomes the common issue of dataset imbalance by using propensity score matching (PSM)- which ensures reliable comparisons between cancer and control groups. We employed Univariate Naâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšâ‰¤ve Bayes- L2-regularized Support Vector Classifier (SVC)- Principal Component Analysis (PCA)- and feature engineering techniques to refine and select the most informative features. Our best-performing feature set comprised 11 biomarkers- including 9 metabolites (SM(OH) C22:2- SM C18:0- C0- C3OH- C14:2OH- C16:2OH- LysoPC a C18:1- PC aa C36:0 and Asparagine)- a metabolite ratio (Kynurenine-to-Tryptophan)- and 1 demographic variable (Age)- achieving an area under the ROC curve (AUC) of 98%. These results demonstrate the potential for a robust- cost-effective- and non-invasive breast cancer screening and diagnostic tool- offering significant clinical value for early detection and personalized patient management.
Jiahui Ren- Yili Li- Jing Zhou- Ting Yang- Jingfeng Jing- Qian Xiao- Zhongxu Duan- Ke Xiang- Yuchen Zhuang- Daxue Li- Han Gao,Developing machine learning models for personalized treatment strategies in early breast cancer patients undergoing neoadjuvant systemic therapy based on SEER database,Breast cancer is the second most common type of cancer among women. Prompt detection of breast cancer can impede its advancement to more advanced phases- thereby elevating the probability of favorable treatment consequences. Histopathological images are commonly used for breast cancer classification due to their detailed cellular information. Existing diagnostic approaches rely on Convolutional Neural Networks (CNNs) which are limited to local context resulting in a lower classification accuracy. Therefore- we present a fusion model composed of a Vision Transformer (ViT) and custom Atrous Spatial Pyramid Pooling (ASPP) network with an attention mechanism for effectively classifying breast cancer from histopathological images. ViT enables the model to attain global features- while the ASPP network accommodates multiscale features. Fusing the features derived from the models resulted in a robust breast cancer classifier. With the help of five-stage image preprocessing technique- the proposed model achieved 100% accuracy in classifying breast cancer on the BreakHis dataset at 100X and 400X magnification factors. On 40X and 200X magnifications- the model achieved 99.25% and 98.26% classification accuracy respectively. With a commendable classification efficacy on histopathological images- the model can be considered a dependable option for proficient breast cancer classification.
Xiao Guo- Jiaying Xing- Yuyan Cao- Wenchuang Yang- Xinlin Shi- Runhong Mu- Tao Wang,Machine learning based anoikis signature predicts personalized treatment strategy of breast cancer,The vision transformer (ViT) architecture- with its attention mechanism based on multi-head attention layers- has been widely adopted in various computer-aided diagnosis tasks due to its effectiveness in processing medical image information. ViTs are notably recognized for their complex architecture- which requires high-performance GPUs or CPUs for efficient model training and deployment in real-world medical diagnostic devices. This renders them more intricate than convolutional neural networks (CNNs). This difficulty is also challenging in the context of histopathology image analysis- where the images are both limited and complex. In response to these challenges- this study proposes a TokenMixer hybrid-architecture that combines the strengths of CNNs and ViTs. This hybrid architecture aims to enhance feature extraction and classification accuracy with shorter training time and fewer parameters by minimizing the number of input patches employed during training- while incorporating tokenization of input patches using convolutional layers and encoder transformer layers to process patches across all network layers for fast and accurate breast cancer tumor subtype classification. The TokenMixer mechanism is inspired by the ConvMixer and TokenLearner models. First- the ConvMixer model dynamically generates spatial attention maps using convolutional layers- enabling the extraction of patches from input images to minimize the number of input patches used in training. Second- the TokenLearner model extracts relevant regions from the selected input patches- tokenizes them to improve feature extraction- and trains all tokenized patches in an encoder transformer network. We evaluated the TokenMixer model on the BreakHis public dataset- comparing it with ViT-based and other state-of-the-art methods. Our approach achieved impressive results for both binary and multi-classification of breast cancer subtypes across various magnification levels (40â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 100â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 200â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 400â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢). The model demonstrated accuracies of 97.02% for binary classification and 93.29% for multi-classification- with decision times of 391.71 and 1173.56Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ s- respectively. These results highlight the potential of our hybrid deep ViT-CNN architecture for advancing tumor classification in histopathological images. The source code is accessible: https://github.com/abimouloud/TokenMixer .
Yu Du- Xuehong Diao,Machine Learning Models for Predicting Clinically and Ultrasound-Negative Axillary Lymph Node Metastasis in Early-Stage Breast Cancer,Breast cancer poses a serious threat to women's life and health. Typically- radiologists can detect early signs of breast cancer activity through breast ultrasound. However- the interpretation of breast ultrasound is time-consuming and requires physicians to possess extensive diagnostic experience. In recent years- computer aided diagnostic (CAD) technology has been introduced into breast imaging diagnosis- saving a significant amount of time for expert medical image inspection and improving diagnostic efficiency. However- current research on computer-aided diagnostic methods has mainly focused on ultrasound (US) images- with limited studies on contrast-enhanced ultrasound (CEUS) videos. To solve this challenge- we collected 332 cases of breast cancer contrast-enhanced ultrasound videos from Shengjing Hospital. We designed ResViT by combining residual neural networks with Vision Transformer to extract spatial features- and used the Temporal Segment Network (TSN) in combination with linear weights to fuse the spatio-temporal features of each frame into video-level features for classification. The experiment results show that our model achieved an accuracy of 78.79% and a sensitivity of 85% in our dataset- significantly higher than the results of current mainstream video analysis networks- proving the effectiveness of our proposed model in the task of classifying contrast-enhanced ultrasound videos.
Maria Colomba Comes- Annarita Fanizzi- Samantha Bove- Luca Boldrini- Agnese Latorre- Deniz Can Guven- Serena Iacovelli- Tiziana Talienti- Alessandro Rizzo- Francesco Alfredo Zito- Raffaella Massafra,Monitoring Over Time of Pathological Complete Response to Neoadjuvant Chemotherapy in Breast Cancer Patients Through an Ensemble Vision Transformers-Based Model,"Women with breast cancer face a high degree of uncertainty. Trust between health providers and patients has been shown to improve patient quality of life and may enhance clinical outcomes. This study aimed to explore the meaning of trust along the treatment pathway. The study followed a convergent mixed-methods design. We collected qualitative data longitudinally from diagnosis to follow-up using unstructured digital diaries and 45 semi-structured interviews with twelve women with breast cancer. To measure symptom burden and trust- we collected quantitative data by means of 57 questionnaires. Data analysis was based on phenomenology according to van Manen and on descriptive statistics. Data synthesis resulted in a conceptual model of trust. The women experienced trust as a dynamic phenomenon within the biomedical cancer care ""machinery"". Their trust was strongly influenced by contextual factors- professionals' expertise- and person-centeredness. The relevance of trust differed according to treatment phases. Due to a high degree of uncertainty- trust was particularly important. Professionals positively influenced the women's trust to a certain extent through a patient-centered approach and by demonstrating expertise within the biomedical cancer care ""machinery"". The conceptual model of trust should receive attention to bring care closer to the women's lived experience so that their care experience can be improved."
Qiang Li- George Teodoro- Yi Jiang- Jun Kong,NACNet: A histology context-aware transformer graph convolution network for predicting treatment response to neoadjuvant chemotherapy in Triple Negative Breast Cancer,Breast cancer is one of the most common causes of death in women in the modern world. Cancerous tissue detection in histopathological images relies on complex features related to tissue structure and staining properties. Convolutional neural network (CNN) models like ResNet50- Inception-V1- and VGG-16- while useful in many applications- cannot capture the patterns of cell layers and staining properties. Most previous approaches- such as stain normalization and instance-based vision transformers- either miss important features or do not process the whole image effectively. Therefore- a deep fusion-based vision Transformer model (DFViT) that combines CNNs and transformers for better feature extraction is proposed. DFViT captures local and global patterns more effectively by fusing RGB and stain-normalized images. Trained and tested on several datasets- such as BreakHis- breast cancer histology (BACH)- and UCSC cancer genomics (UC)- the results demonstrate outstanding accuracy- F1 score- precision- and recall- setting a new milestone in histopathological image analysis for diagnosing breast cancer.
Giulia Lucrezia Baroni- Laura Rasotto- Kevin Roitero- Angelica Tulisso- Carla Di Loreto- Vincenzo Della Mea,Optimizing Vision Transformers for Histopathology: Pretraining and Normalization in Breast Cancer Classification,Triple negative breast cancer (TNBC) is one of the subtypes of breast cancer characterized by a heterogeneous and aggressive nature. Photodynamic therapy (PDT) has drawn significant attention in cancer treatment. However- solubility of photosensitizer- penetration problems into a target tissue and insufficient oxygen concentration limit the effectiveness of PDT. To overcome these limitations and to reduce the side effects of chemotherapy- combination treatment modalities play an essential role in cancer treatment. In this study- we aimed to investigate the combination efficacy of cisplatin-based chemotherapy and 5-Aminolevulinic acid (5-ALA)/PDT in TNBC cells and healthy breast cellsÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ in vitro. To determine the effect of the combination effects of cisplatin and 5-ALA/PDT on TNBC cells- two treatment protocols (simultaneous and sequential combination therapy) were evaluated compared with cisplatin and 5-ALA/PDT monotherapy and WST-1- Annexin V assay- acridine orange (AO) and mitochondrial staining were performed. Our findings showed that MDA-MB-231 TNBC cell viability was significantly decreased following simultaneous combination treatment compared to cisplatin and 5-ALA/PDT monotherapy. Additionally- simultaneous combination treatment was more effective than sequential combination treatment. The simultaneous combination treatment of 2.5Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ Â¬Â¨Â¬Â®Â¬Â¨Â¬ÂµM cisplatin and 5-ALA/PDT at 6Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2 and 9Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2 induced 46.78% and 53.6% total apoptotic death- respectively in TNBC cells compared with monotherapies (cisplatin (37.88%) and 5-ALA/PDT (6Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2: 31.48% and 9Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ J/cm2: 37.78%). Additionally- cisplatin and 5-ALA/PDT combination treatment resulted in nuclear fragmentation and mitochondrial damage due to apoptosis. Our results suggest that cisplatin and 5-ALA/PDT simultaneous combination therapy could be a promising new alternative strategy for treating TNBC. However- further studies are required to assess the underlying molecular mechanisms of cisplatin and 5-ALA/PDT combination treatment at the molecular level.
Xuefeng Fu- Yang Jiao- Yao Feng- Fengwei Lin- Bing Zhang- Qing Mao- Jiahui Wang- Wen Jiang- Yanhua Mou- Han Wang- Shaojie Wang,Scaffold Hopping of Pristimerin Provides Derivatives Containing a Privileged Quinoxaline Substructure as Potent Autophagy Inducers in Breast Cancer Cells,Digital Breast Tomosynthesis (DBT) has revolutionized more traditional breast imaging through its three-dimensional (3D) visualization capability that significantly enhances lesion discernibility- reduces tissue overlap- and improves diagnostic precision as compared to conventional two-dimensional (2D) mammography. In this study- we propose an advanced Computer-Aided Detection (CAD) system that harnesses the power of vision transformers to augment DBT's diagnostic efficiency. This scheme uses a neural network to glean attributes from the 2D slices of DBT followed by post-processing that considers features from neighboring slices to categorize the entire 3D scan. By leveraging a transfer learning technique- we trained and validated our CAD framework on a unique dataset consisting of 3-831 DBT scans and subsequently tested it on 685 scans. Of the architectures tested- the Swin Transformer outperformed the ResNet101 and vanilla Vision Transformer. It achieved an impressive AUC score of 0.934 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 0.026 at a resolution of 384 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 384. Increasing the image resolution from 224 to 384 not only maintained vital image attributes but also led to a marked improvement in performance (p-value = 0.0003). The Mean Teacher algorithm- a semi-supervised method using both labeled and unlabeled DBT slices- showed no significant improvement over the supervised approach. Comprehensive analyses across different lesion types- sizes- and patient ages revealed consistent performance. The integration of attention mechanisms yielded a visual narrative of the model's decision-making process that highlighted the prioritized regions during assessments. These findings should significantly propel the methodologies employed in DBT image analysis by setting a new benchmark for breast cancer diagnostic precision.
Mohammad Shiri- Monalika Padma Reddy- Jiangwen Sun,Supervised Contrastive Vision Transformer for Breast Histopathological Image Classification,
Olya Rezaeian- Onur Asan- A. E. Bayrak,The Impact of AI Explanations on Clinicians Trust and Diagnostic Accuracy in Breast Cancer,Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer. Breast tissue histopathological examination is critical in diagnosing and classifying breast cancer. Although existing methods have shown promising results- there is still room for improvement in the classification accuracy and generalization of IDC using histopathology images. We present a novel approach- Supervised Contrastive Vision Transformer (SupCon-ViT)- for improving the classification of invasive ductal carcinoma in terms of accuracy and generalization by leveraging the inherent strengths and advantages of both transfer learning- i.e.- pre-trained vision transformer- and supervised contrastive learning. Our results on a benchmark breast cancer dataset demonstrate that SupCon-ViT achieves state-of-the-art performance in IDC classification- with an F1-score of 0.8188- precision of 0.7692- and specificity of 0.8971- outperforming existing methods. In addition- the proposed model demonstrates resilience in scenarios with minimal labeled data- making it highly efficient in real-world clinical settings where labeled data is limited. Our findings suggest that supervised contrastive learning in conjunction with pre-trained vision transformers appears to be a viable strategy for an accurate classification of IDC- thus paving the way for a more efficient and reliable diagnosis of breast cancer through histopathological image analysis.
Beyzanur Erk- Ali Furkan Kamanli- Gamze Guney Eskiler,The therapeutic efficacy of 5-ALA based photodynamic therapy and chemotherapy combination in triple negative breast cancer cells,"Tumors are an important health concern in modern times. Breast cancer is one of the most prevalent causes of death for women. Breast cancer is rapidly becoming the leading cause of mortality among women globally. Early detection of breast cancer allows patients to obtain appropriate therapy- increasing their probability of survival. The adoption of 3-Dimensional (3D) mammography for the medical identification of abnormalities in the breast reduced the number of deaths dramatically. Classification and accurate detection of lumps in the breast in 3D mammography is especially difficult due to factors such as inadequate contrast and normal fluctuations in tissue density. Several Computer-Aided Diagnosis (CAD) solutions are under development to help radiologists accurately classify abnormalities in the breast. In this paper- a breast cancer diagnosis model is implemented to detect breast cancer in cancer patients to prevent death rates. The 3D mammogram images are gathered from the internet. Then- the gathered images are given to the preprocessing phase. The preprocessing is done using a median filter and image scaling method. The purpose of the preprocessing phase is to enhance the quality of the images and remove any noise or artifacts that may interfere with the detection of abnormalities. The median filter helps to smooth out any irregularities in the images- while the image scaling method adjusts the size and resolution of the images for better analysis. Once the preprocessing is complete- the preprocessed image is given to the segmentation phase. The segmentation phase is crucial in medical image analysis as it helps to identify and separate different structures within the image- such as organs or tumors. This process involves dividing the preprocessed image into meaningful regions or segments based on intensity- color- texture- or other features. The segmentation process is done using Adaptive Thresholding with Region Growing Fusion Model (AT-RGFM)"". This model combines the advantages of both thresholding and region-growing techniques to accurately identify and delineate specific structures within the image. By utilizing AT-RGFM- the segmentation phase can effectively differentiate between different parts of the image- allowing for more precise analysis and diagnosis. It plays a vital role in the medical image analysis process- providing crucial insights for healthcare professionals. Here- the Modified Garter Snake Optimization Algorithm (MGSOA) is used to optimize the parameters. It helps to optimize parameters for accurately identifying and delineating specific structures within medical images and also helps healthcare professionals in providing more precise analysis and diagnosis- ultimately playing a vital role in the medical image analysis process. MGSOA enhances the segmentation phase by effectively differentiating between different parts of the image- leading to more accurate results. Then- the segmented image is fed into the detection phase. The tumor detection is performed by the Vision Transformer-based Multiscale Adaptive EfficientNetB7 (ViT-MAENB7) model. This model utilizes a combination of advanced algorithms and deep learning techniques to accurately identify and locate tumors within the segmented medical image. By incorporating a multiscale adaptive approach- the ViT-MAENB7 model can analyze the image at various levels of detail- improving the overall accuracy of tumor detection. This crucial step in the medical image analysis process allows healthcare professionals to make more informed decisions regarding patient treatment and care. Here- the created MGSOA algorithm is used to optimize the parameters for enhancing the performance of the model. The suggested breast cancer diagnosis performance is compared to conventional cancer diagnosis models and it showed high accuracy. The accuracy of the developed MGSOA-ViT-MAENB7 is 96.6 %- and others model like RNN- LSTM- EffNet- and ViT-MAENet given the accuracy to be 90.31 %- 92.79 %- 94.46 % and 94.75 %. The developed model's ability to analyze images at multiple scales- combined with the optimization provided by the MGSOA algorithm- results in a highly accurate and efficient system for detecting tumors in medical images. This cutting-edge technology not only improves the accuracy of diagnosis but also helps healthcare professionals tailor treatment plans to individual patients- ultimately leading to better outcomes. By outperforming traditional cancer diagnosis models- the proposed model is revolutionizing the field of medical imaging and setting a new standard for precision and effectiveness in healthcare."
Zhe Lin,Breast cancer classification based on hybrid machine learning model,Automatic breast tumor segmentation based on convolutional neural networks (CNNs) is significant for the diagnosis and monitoring of breast cancers. CNNs have become an important method for early diagnosis of breast cancer and- thus- can help decrease the mortality rate. In order to assist medical professionals in breast cancer investigation a computerized system based on two encoder-decoder architectures for breast tumor segmentation has been developed. Two pre-trained DeepLabV3+ and U-Net models are proposed. The encoder generates a high-dimensional feature vector while the decoder analyses the low-resolution feature vector provided by the encoder and generates a semantic segmentation mask. Semantic segmentation based on deep learning techniques can overcome the limitations of traditional algorithms. To assess the efficiency of breast ultrasound image segmentation- we compare the segmentation results provided by CNNs against the Local Graph Cut technique (a semi-automatic segmentation method) in the Image Segmenter application. The output segmentation results have been evaluated by using the Dice similarity coefficient that compares the ground truth images provided by the specialists against the predicted segmentation results provided by the CNNs and Local Graph Cut algorithm. The proposed approach is validated on 780 breast ultrasonographic images of the BUSI public database of which 437 are benign and 210 are malignant. The BUSI database provides classification (benign or malignant) labels for ground truth in binary mask images. The average Dice scores computed between the ground truth images against CNNs were as follows: 0.9360 (malignant) and 0.9325 (benign) for the DeepLabV3+ architecture and of 0.6251 (malignant) and 0.6252 (benign) for the U-Net- respectively. When the segmentation results provided by CNNs were compared with the Local Graph Cut segmented images- the Dice scores were 0.9377 (malignant) and 0.9204 (benign) for DeepLabV3+ architecture and 0.6115 (malignant) and 0.6119 (benign) for U-Net- respectively. The results show that the DeepLabV3+ has significantly better segmentation performance and outperforms the U-Net network.
Ting-Ruen Wei- Michele Hell- Aren Vierra- Ran Pang- Young Kang- Mahesh Patel- Yuling Yan,Breast Cancer Detection on Dual-View Sonography via Data-Centric Deep Learning,Traditional B-mode ultrasound has difficulties distinguishing benign from malignant breast lesions. It appears that Quantitative Ultrasound (QUS) may offer advantages. We examined the QUS imaging systemâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s potential- utilizing parameters like Attenuation Coefficient (AC)- Speed of Sound (SoS)- Effective Scatterer Diameter (ESD)- and Effective Scatterer Concentration (ESC) to enhance diagnostic accuracy. B-mode images and radiofrequency signals were gathered from breast lesions. These parameters were processed and analyzed by a QUS system trained on a simulated acoustic dataset and equipped with an encoder-decoder structure. Fifty-seven patients were enrolled over six months. Biopsies served as the diagnostic ground truth. AC- SoS- and ESD showed significant differences between benign and malignant lesions (p < 0.05)- but ESC did not. A logistic regression model was developed- demonstrating an area under the receiver operating characteristic curve of 0.90 (95% CI: 0.78- 0.96) for distinguishing between benign and malignant lesions. In conclusion- the QUS system shows promise in enhancing diagnostic accuracy by leveraging AC- SoS- and ESD. Further studies are needed to validate these findings and optimize the system for clinical use.
Vaishnawi Priyadarshni- Sanjay Kumar Sharma,Machine Learning Based Classification of Histopathological Image for Breast Cancer,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ multimodal deep learning framework integrating breast â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ vision transformer (ViT) backbone: (a) ViT-base- (b) ViTlarge- and (câ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Bao- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Multi-modal artificial intelligence for the combination of â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Sabry- HM Balaha- KM Ali- ...,A vision transformer approach for breast cancer classification in histopathology,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Breast cancer is the second-leading cause of cancer-related deaths in women worldwide. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ for classifying Breast Cancer (BC) from histopathology slides using a Vision Transformer (ViT) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Guyomard- AD Bouhnik- L Tassy- ...,Encoding breast cancer patients' medical pathways from reimbursement data using representation learning: a benchmark for clustering tasks,Neoadjuvant chemotherapy (NAC) is a key element of treatment for locally advanced breast cancer (LABC). Predicting the response to NAC for patients with Locally Advanced Breast Cancer (LABC) before treatment initiation could be beneficial to optimize therapy- ensuring the administration of effective treatments. The objective of the work here was to develop a predictive model to predict tumor response to NAC for LABC using deep learning networks and computed tomography (CT). Several deep learning approaches were investigated including ViT transformer and VGG16- VGG19- ResNet-50- Res-Net-101- Res-Net-152- InceptionV3 and Xception transfer learning networks. These deep learning networks were applied on CT images to assess the response to NAC. Performance was evaluated based on balanced_accuracy- accuracy- sensitivity and specificity classification metrics. A ViT transformer was applied to utilize the attention mechanism in order to increase the weight of important part image which leads to better discrimination between classes. Amongst the 117 LABC patients studied- 82 (70%) had clinical-pathological response and 35 (30%) had no response to NAC. The ViT transformer obtained the best performance range (accuracy = 71 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to accuracy = 77 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- specificity = 86 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 76 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 56 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%- and balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3% to balanced_accuracy=69 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%) depending on the split ratio of train-data and test-data. Xception network obtained the second best results (accuracy = 72 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to accuracy = 65 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4- specificity = 81 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 6% to specificity = 73 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 3%- sensitivity = 55 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4% to sensitivity = 52 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5%- and balanced_accuracy = 66 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 5% to balanced_accuracy = 60 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â± 4%). The worst results were obtained using VGG-16 transfer learning network. Deep learning networks in conjunction with CT imaging are able to predict the tumor response to NAC for patients with LABC prior to start. A ViT transformer could obtain the best performance- which demonstrated the importance of attention mechanism.
Houmem Slimi- Sabeur Abid,Optimized Transfer Learning Models for Breast Cancer image classification,<title>Abstract</title> <p>Human epidermal growth factor receptor 2 (HER2) is a critical gene that serves as a receptor to transmit signals for aggressive cell division in cancer cells. Hence- testing of HER2 is important in treatment to indicate candidates for HER2-targeted therapy. However- in the current gold standard- i.e.- the immunohistochemistry (IHC) test- the scoring is based on the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s analysis- which has an inter- and intra-observer variation chance due to variability in staining assessment. Automating HER2 scoring using hematoxyline eosin (HE) stained images can overcome these limitations- providing more accurate and consistent results- thereby reducing healthcare costs and enhancing patient outcomes. In this work- we have presented an automated framework for classifying HER2 scores of breast cancer using HE-stained images. The developed framework uses three fine-tuned deep learning models- namely GoogLeNet- ResNet-50- and Vision Transformer (ViT). It applies the proposed hybrid weighted individual voting ensemble (WIVE) to combine the confidence scores of all the constituent models. This approach comprises two independent techniques: the Model-Specific Weights Optimization (MSWO)- customizing weights for individual models- and the Class-Specific Weights Optimization (CSWO)- fine-tunes weights for specific classes using Probabilistic model-building genetic algorithms (PMBGAs). The proposed framework surpasses the existing methods in the literature. The CSWO approach achieves an accuracy of 99.42% and a precision of 99.54%- while the MSWO approach attains an accuracy of 99.07% and a precision of 99.21%. This study outlines an economically feasible and efficient prognostic model with the potential to provide clinically significant inputs. The use of this algorithm might offer a possibility for the replacement of IHC testing- minimizing the variability in HER2 scoring- as well as simplifying the diagnostic process.</p>
Kishan Sharda- Mandeep Singh Ramdev- Deepak Rawat- Pawan Bishnoi,Feature Selection for Breast Cancer Detection,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ In the field of early diagnosis of breast cancer- deep learning and machine learning â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ language-image pre-training (CLIP) model- named ViT-L/14 CLIP- a large vision transformer model â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Wei Wang- Lei Liu- Jianxiong Zhu- Youqiang Xing- Songlong Jiao- Ze Wu,AI-Enhanced Visual-Spectral Synergy for Fast and Ultrasensitive Biodetection of Breast Cancer-Related miRNAs.,Breast cancer is a dangerous disease- contributing to a high mortality rate in women. Early detection plays a pivotal role in enhancing survival rates. Breast ultrasound is considered an effective method to help diagnose breast diseases early. Breast ultrasound is inexpensive- easy to perform- non-invasive and painless- so it is often prescribed by doctors in cases where it is necessary to examine the nature of clinically palpable lesions or related symptoms in the breast. In this paper- we introduce a method based on transfer learning and deep feature fusion to classify breast cancer using ultrasound images. The results from our experiments involving 780 breast ultrasound images across three categories (benign- malignant- and normal) indicated that the model using max fusion of deep features outperformed an original CNN in terms of performance- the combination of the maximum value between deep features has a higher performance level with an accuracy of about 1% to 4% compared to the original model. The concatenation fusion of VGG19 and ViT features delivers 1% - 4% times more accuracy than the original model alone
Jessica Prunaretty- Fatima Mekki- Pierre-Ivan Laurent- Aurelie Morel- Pauline Hinault- Celine Bourgier- David Azria- Pascal Fenoglietto,Clinical feasibility of Ethos auto-segmentation for adaptive whole-breast cancer treatment,Identification of the molecular subtypes in breast cancer allows to optimize treatment strategies- but usually requires invasive needle biopsy. Recently- non-invasive imaging has emerged as promising means to classify them. Magnetic resonance imaging is often used for this purpose because it is three-dimensional and highly informative. Instead- only a few reports have documented the use of mammograms. Given that mammography is the first choice for breast cancer screening- using it to classify molecular subtypes would allow for early intervention on a much wider scale. Here- we aimed to evaluate the effectiveness of combining global and local mammographic features by using Vision Transformer (ViT) and Convolutional Neural Network (CNN) to classify molecular subtypes in breast cancer. The feature values for binary classification were calculated using the ViT and EfficientnetV2 feature extractors- followed by dimensional compression via principal component analysis. LightGBM was used to perform binary classification of each molecular subtype: triple-negative- HER2-enriched- luminal A- and luminal B. The combination of ViT and CNN achieved higher accuracy than ViT or CNN alone. The sensitivity for triple-negative subtypes was very high (0.900- with F-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.818); whereas F-value and sensitivity were 0.720 and 0.750 for HER2-enriched- 0.765 and 0.867 for luminal A- and 0.614 and 0.711 for luminal B subtypes- respectively. Features obtained from mammograms by combining ViT and CNN allow the classification of molecular subtypes with high accuracy. This approach could streamline early treatment workflows and triage- especially for poor prognosis subtypes such as triple-negative breast cancer.
Yaping Yang- Ying Zhong- Junwei Li- Jiahao Feng- C. Gong- Yunfang Yu- Yue Hu- R. Gu- Hongli Wang- Fengtao Liu- J. Mei- Xiaofang Jiang- Jin Wang- Qinyue Yao- Wei Wu- Qiang Liu- H. Yao,Deep learning combining mammography and ultrasound images to predict the malignancy of BI-RADS US 4A lesions in women with dense breasts: a diagnostic study,Breast cancer is the most prevalent type of disease among women. It has become one of the foremost causes of death among women globally. Early detection plays a significant role in administering personalized treatment and improving patient outcomes. Mammography procedures are often used to detect early-stage cancer cells. This traditional method of mammography while valuable has limitations of potential for false positives and negatives- patient discomfort- and radiation exposure. Therefore- there is a probe for more accurate techniques required in detecting breast cancer- leading to exploring the potential of machine learning in the classification of diagnostic images due to its efficiency and accuracy. This study conducted a comparative analysis of pre-trained CNNs (ResNet50 and VGG16) and Vision Transformers (ViT-Base and SWIN Transformer) with the inclusion of ViT-Base trained from scratch model architectures to effectively classify breast cancer mammographic images into benign and malignant cases. The Swin transformer exhibits superior performance with 99.8% accuracy and a precision of 99.8%. These findings demonstrate the efficiency of deep learning to accurately classify breast cancer mammographic images for the diagnosis of breast cancer- leading to improvement in patient outcomes.
Jiahui Ren- Yili Li- Jing Zhou- Ting Yang- Jingfeng Jing- Qian Xiao- Zhongxu Duan- Ke Xiang- Yuchen Zhuang- Daxue Li- Han Gao,Developing machine learning models for personalized treatment strategies in early breast cancer patients undergoing neoadjuvant systemic therapy based on SEER database,Breast cancer is the second most common type of cancer among women. Prompt detection of breast cancer can impede its advancement to more advanced phases- thereby elevating the probability of favorable treatment consequences. Histopathological images are commonly used for breast cancer classification due to their detailed cellular information. Existing diagnostic approaches rely on Convolutional Neural Networks (CNNs) which are limited to local context resulting in a lower classification accuracy. Therefore- we present a fusion model composed of a Vision Transformer (ViT) and custom Atrous Spatial Pyramid Pooling (ASPP) network with an attention mechanism for effectively classifying breast cancer from histopathological images. ViT enables the model to attain global features- while the ASPP network accommodates multiscale features. Fusing the features derived from the models resulted in a robust breast cancer classifier. With the help of five-stage image preprocessing technique- the proposed model achieved 100% accuracy in classifying breast cancer on the BreakHis dataset at 100X and 400X magnification factors. On 40X and 200X magnifications- the model achieved 99.25% and 98.26% classification accuracy respectively. With a commendable classification efficacy on histopathological images- the model can be considered a dependable option for proficient breast cancer classification.
Xiao Guo- Jiaying Xing- Yuyan Cao- Wenchuang Yang- Xinlin Shi- Runhong Mu- Tao Wang,Machine learning based anoikis signature predicts personalized treatment strategy of breast cancer,The vision transformer (ViT) architecture- with its attention mechanism based on multi-head attention layers- has been widely adopted in various computer-aided diagnosis tasks due to its effectiveness in processing medical image information. ViTs are notably recognized for their complex architecture- which requires high-performance GPUs or CPUs for efficient model training and deployment in real-world medical diagnostic devices. This renders them more intricate than convolutional neural networks (CNNs). This difficulty is also challenging in the context of histopathology image analysis- where the images are both limited and complex. In response to these challenges- this study proposes a TokenMixer hybrid-architecture that combines the strengths of CNNs and ViTs. This hybrid architecture aims to enhance feature extraction and classification accuracy with shorter training time and fewer parameters by minimizing the number of input patches employed during training- while incorporating tokenization of input patches using convolutional layers and encoder transformer layers to process patches across all network layers for fast and accurate breast cancer tumor subtype classification. The TokenMixer mechanism is inspired by the ConvMixer and TokenLearner models. First- the ConvMixer model dynamically generates spatial attention maps using convolutional layers- enabling the extraction of patches from input images to minimize the number of input patches used in training. Second- the TokenLearner model extracts relevant regions from the selected input patches- tokenizes them to improve feature extraction- and trains all tokenized patches in an encoder transformer network. We evaluated the TokenMixer model on the BreakHis public dataset- comparing it with ViT-based and other state-of-the-art methods. Our approach achieved impressive results for both binary and multi-classification of breast cancer subtypes across various magnification levels (40â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 100â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 200â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 400â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢). The model demonstrated accuracies of 97.02% for binary classification and 93.29% for multi-classification- with decision times of 391.71 and 1173.56Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ s- respectively. These results highlight the potential of our hybrid deep ViT-CNN architecture for advancing tumor classification in histopathological images. The source code is accessible: https://github.com/abimouloud/TokenMixer .
Yu Du- Xuehong Diao,Machine Learning Models for Predicting Clinically and Ultrasound-Negative Axillary Lymph Node Metastasis in Early-Stage Breast Cancer,Breast cancer poses a serious threat to women's life and health. Typically- radiologists can detect early signs of breast cancer activity through breast ultrasound. However- the interpretation of breast ultrasound is time-consuming and requires physicians to possess extensive diagnostic experience. In recent years- computer aided diagnostic (CAD) technology has been introduced into breast imaging diagnosis- saving a significant amount of time for expert medical image inspection and improving diagnostic efficiency. However- current research on computer-aided diagnostic methods has mainly focused on ultrasound (US) images- with limited studies on contrast-enhanced ultrasound (CEUS) videos. To solve this challenge- we collected 332 cases of breast cancer contrast-enhanced ultrasound videos from Shengjing Hospital. We designed ResViT by combining residual neural networks with Vision Transformer to extract spatial features- and used the Temporal Segment Network (TSN) in combination with linear weights to fuse the spatio-temporal features of each frame into video-level features for classification. The experiment results show that our model achieved an accuracy of 78.79% and a sensitivity of 85% in our dataset- significantly higher than the results of current mainstream video analysis networks- proving the effectiveness of our proposed model in the task of classifying contrast-enhanced ultrasound videos.
Qiang Li- George Teodoro- Yi Jiang- Jun Kong,NACNet: A histology context-aware transformer graph convolution network for predicting treatment response to neoadjuvant chemotherapy in Triple Negative Breast Cancer,Breast cancer is one of the most common causes of death in women in the modern world. Cancerous tissue detection in histopathological images relies on complex features related to tissue structure and staining properties. Convolutional neural network (CNN) models like ResNet50- Inception-V1- and VGG-16- while useful in many applications- cannot capture the patterns of cell layers and staining properties. Most previous approaches- such as stain normalization and instance-based vision transformers- either miss important features or do not process the whole image effectively. Therefore- a deep fusion-based vision Transformer model (DFViT) that combines CNNs and transformers for better feature extraction is proposed. DFViT captures local and global patterns more effectively by fusing RGB and stain-normalized images. Trained and tested on several datasets- such as BreakHis- breast cancer histology (BACH)- and UCSC cancer genomics (UC)- the results demonstrate outstanding accuracy- F1 score- precision- and recall- setting a new milestone in histopathological image analysis for diagnosing breast cancer.
Olya Rezaeian- Onur Asan- A. E. Bayrak,The Impact of AI Explanations on Clinicians Trust and Diagnostic Accuracy in Breast Cancer,Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer. Breast tissue histopathological examination is critical in diagnosing and classifying breast cancer. Although existing methods have shown promising results- there is still room for improvement in the classification accuracy and generalization of IDC using histopathology images. We present a novel approach- Supervised Contrastive Vision Transformer (SupCon-ViT)- for improving the classification of invasive ductal carcinoma in terms of accuracy and generalization by leveraging the inherent strengths and advantages of both transfer learning- i.e.- pre-trained vision transformer- and supervised contrastive learning. Our results on a benchmark breast cancer dataset demonstrate that SupCon-ViT achieves state-of-the-art performance in IDC classification- with an F1-score of 0.8188- precision of 0.7692- and specificity of 0.8971- outperforming existing methods. In addition- the proposed model demonstrates resilience in scenarios with minimal labeled data- making it highly efficient in real-world clinical settings where labeled data is limited. Our findings suggest that supervised contrastive learning in conjunction with pre-trained vision transformers appears to be a viable strategy for an accurate classification of IDC- thus paving the way for a more efficient and reliable diagnosis of breast cancer through histopathological image analysis.
Beyzanur Erk- Ali Furkan Kamanli- Gamze Guney Eskiler,The therapeutic efficacy of 5-ALA based photodynamic therapy and chemotherapy combination in triple negative breast cancer cells,"Tumors are an important health concern in modern times. Breast cancer is one of the most prevalent causes of death for women. Breast cancer is rapidly becoming the leading cause of mortality among women globally. Early detection of breast cancer allows patients to obtain appropriate therapy- increasing their probability of survival. The adoption of 3-Dimensional (3D) mammography for the medical identification of abnormalities in the breast reduced the number of deaths dramatically. Classification and accurate detection of lumps in the breast in 3D mammography is especially difficult due to factors such as inadequate contrast and normal fluctuations in tissue density. Several Computer-Aided Diagnosis (CAD) solutions are under development to help radiologists accurately classify abnormalities in the breast. In this paper- a breast cancer diagnosis model is implemented to detect breast cancer in cancer patients to prevent death rates. The 3D mammogram images are gathered from the internet. Then- the gathered images are given to the preprocessing phase. The preprocessing is done using a median filter and image scaling method. The purpose of the preprocessing phase is to enhance the quality of the images and remove any noise or artifacts that may interfere with the detection of abnormalities. The median filter helps to smooth out any irregularities in the images- while the image scaling method adjusts the size and resolution of the images for better analysis. Once the preprocessing is complete- the preprocessed image is given to the segmentation phase. The segmentation phase is crucial in medical image analysis as it helps to identify and separate different structures within the image- such as organs or tumors. This process involves dividing the preprocessed image into meaningful regions or segments based on intensity- color- texture- or other features. The segmentation process is done using Adaptive Thresholding with Region Growing Fusion Model (AT-RGFM)"". This model combines the advantages of both thresholding and region-growing techniques to accurately identify and delineate specific structures within the image. By utilizing AT-RGFM- the segmentation phase can effectively differentiate between different parts of the image- allowing for more precise analysis and diagnosis. It plays a vital role in the medical image analysis process- providing crucial insights for healthcare professionals. Here- the Modified Garter Snake Optimization Algorithm (MGSOA) is used to optimize the parameters. It helps to optimize parameters for accurately identifying and delineating specific structures within medical images and also helps healthcare professionals in providing more precise analysis and diagnosis- ultimately playing a vital role in the medical image analysis process. MGSOA enhances the segmentation phase by effectively differentiating between different parts of the image- leading to more accurate results. Then- the segmented image is fed into the detection phase. The tumor detection is performed by the Vision Transformer-based Multiscale Adaptive EfficientNetB7 (ViT-MAENB7) model. This model utilizes a combination of advanced algorithms and deep learning techniques to accurately identify and locate tumors within the segmented medical image. By incorporating a multiscale adaptive approach- the ViT-MAENB7 model can analyze the image at various levels of detail- improving the overall accuracy of tumor detection. This crucial step in the medical image analysis process allows healthcare professionals to make more informed decisions regarding patient treatment and care. Here- the created MGSOA algorithm is used to optimize the parameters for enhancing the performance of the model. The suggested breast cancer diagnosis performance is compared to conventional cancer diagnosis models and it showed high accuracy. The accuracy of the developed MGSOA-ViT-MAENB7 is 96.6 %- and others model like RNN- LSTM- EffNet- and ViT-MAENet given the accuracy to be 90.31 %- 92.79 %- 94.46 % and 94.75 %. The developed model's ability to analyze images at multiple scales- combined with the optimization provided by the MGSOA algorithm- results in a highly accurate and efficient system for detecting tumors in medical images. This cutting-edge technology not only improves the accuracy of diagnosis but also helps healthcare professionals tailor treatment plans to individual patients- ultimately leading to better outcomes. By outperforming traditional cancer diagnosis models- the proposed model is revolutionizing the field of medical imaging and setting a new standard for precision and effectiveness in healthcare."
Thippaluru Umamaheswari- Y Murali Mohan Babu,ViT-MAENB7: An innovative breast cancer diagnosis model from 3D mammograms using advanced segmentation and classification process,Microwave imaging presents several potential advantages including its non-ionising and harmless nature. This open- multicentric- interventional- prospective- non-randomised trial aims to validate MammoWave's artificial intelligence (AI)-based classification algorithm- leveraging microwave imaging- to achieve a sensitivity exceeding 75% and a specificity exceeding 90% in breast screening. 10â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢000 volunteers undergoing regular mammographic breast cancer screening will be recruited across 9 European centres and invited to participate in the clinical study- involving MammoWave testing on both breasts. MammoWave results will be checked against the reference standard- to be intended as the output of conventional breast examination path (with histological confirmation of cancer cases) with 2 years follow-up. Anonymised clinical and MammoWave's results- including microwave images- associated features and a label provided by the AI-based classification algorithm- will be collected and stored in a dedicated electronic case report form. The prospective study will involve a comparative analysis between the output of the conventional breast examination path (control intervention) and the labels provided by MammoWave's AI system (experimental intervention). These labels will categorise breasts into two groups: breast With Suspicious Finding- indicating the presence of a suspicious lesion or No Suspicious Finding- indicating the absence of a lesion or the presence of a low-suspicion lesion. This trial aims to provide evidence regarding the novel MammoWave's AI system for detecting breast cancer in asymptomatic populations during screening. This study was approved by the Research Ethics Committee of the Liguria Region (CET)- Italy (CET-Liguria: 524/2023-DB id 13399)- the Research Ethics Committee of Complejo Hospitalario de Toledo (CEIC)- Spain (CEIC-1094)- the National Ethics Committee for Clinical Research (CEIC)- Portugal (CEIC-2311KC814)- the Bioethical Committee of Pomeranian Medical University in Szczecin- Poland (KB-006/23/2024) and the Zurich Cantonal Ethics Commission- Switzerland (BASEC 2023-D0101). The findings of this study will be disseminated through academic and scientific conferences as well as peer-reviewed journals. NCT06291896.
Nada M. Hassan- Safwat Hamad- Khaled Mahar,YOLO-based CAD framework with ViT transformer for breast mass detection and classification in CESM and FFDM images,This research explores the integration of deep learning techniques into medical imaging for early breast cancer detection. Focused on enhancing current methodologies- the study develops a specialized deep learning model using a diverse dataset of medical images. The primary objectives include evaluating the model's performance- identifying strengths and limitations- and addressing ethical considerations inherent in deploying such technology in healthcare. The findings offer significant implications for advancing early breast cancer detection- potentially revolutionizing diagnostic practices and improving patient outcomes. The study contributes to bridging existing gaps in the literature- providing novel insights into the potential of deep learning in the context of medical imaging. By examining the model's efficacy- ethical considerations- and its broader impact on healthcare- this research lays the foundation for further innovations in the critical intersection of artificial intelligence and early cancer diagnostics.
