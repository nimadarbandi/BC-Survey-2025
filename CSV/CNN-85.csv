Yeojin Jeong- Jeesoo Lee- Young-jin Lee- Jiyun Hwang- Sae Byul Lee- Tae-Kyung Yoo- Myeong-Seong Kim- Jae Il Kim- John L Hopper- Tuong L Nguyen- Jong Won Lee- Joohon Sung,Artificial-Intelligence Powered Identification of High-Risk Breast Cancer Subgroups Using Mammography: A Multicenter Study Integrating Automated Brightest Density Measures with Deep Learning Metrics,Breast Cancer is a significant global health challenge- particularly affecting women with higher mortality compared with other cancer types. Timely detection of such cancer types is crucial- and recent research- employing deep learning techniques- shows promise in earlier detection. The research focuses on the early detection of such tumors using mammogram images with deep-learning models. The paper utilized four public databases where a similar amount of 986 mammograms each for three classes (normal- benign- malignant) are taken for evaluation. Herein- three deep CNN models such as VGG-11- Inception v3- and ResNet50 are employed as base classifiers. The research adopts an ensemble method where the proposed approach makes use of the modified Gompertz function for building a fuzzy ranking of the base classification models and their decision scores are integrated in an adaptive manner for constructing the final prediction of results. The classification results of the proposed fuzzy ensemble approach outperform transfer learning models and other ensemble approaches such as weighted average and Sugeno integral techniques. The proposed ResNet50 ensemble network using the modified Gompertz function-based fuzzy ranking approach provides a superior classification accuracy of 98.986%.
Koagne Longpa T. Silas,Breast Cancer Diagnosis with Machine Learning Using Feed-Forward Multilayer Perceptron Analog Artificial Neural Network,OBJECTIVES:: This study explores a deep learning (DL) approach to predicting bone metastases in breast cancer (BC) patients using clinical information- such as the fat index- and features like Computed Tomography (CT) images. METHODS:: CT imaging data and clinical information were collected from 431 BC patients who underwent radical surgical resection at Harbin Medical University Cancer Hospital. The area of muscle and adipose tissue was obtained from CT images at the level of the eleventh thoracic vertebra. The corresponding histograms of oriented gradients (HOG) and local binary pattern (LBP) features were extracted from the CT images- and the network features were derived from the LBP and HOG features as well as the CT images through deep learning (DL). The combination of network features with clinical information was utilized to predict bone metastases in BC patients using the Gradient Boosting Decision Tree (GBDT) algorithm. Regularized Cox regression models were employed to identify independent prognostic factors for bone metastasis. RESULTS:: The combination of clinical information and network features extracted from LBP features- HOG features- and CT images using a convolutional neural network (CNN) yielded the best performance- achieving an AUC of 0.922 (95% confidence interval [CI]: 0.843â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®0.964- [Formula: see text] 0.01). Regularized Cox regression results indicated that the subcutaneous fat index was an independent prognostic factor for bone metastasis in breast cancer (BC). CONCLUSION:: Subcutaneous fat index could predict bone metastasis in BC patients. Deep learning multimodal algorithm demonstrates superior performance in assessing bone metastases in BC patients.
T Liu- H Wang- F Feng- W Li- F Zheng- K Wu- ...,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ clinicopathologic information and dynamic contrast-enhanced MRI for augmented prediction of neoadjuvant chemotherapy response in breast cancer,Breast UltraSound (BUS) imaging is a commonly used diagnostic tool in the field of counter fighting breast diseases- especially for early detection and diagnosis of breast cancer. Due to the inherent characteristics of ultrasound images such as blurry boundaries and diverse tumor morphologies- it is challenging for doctors to manually segment breast tumors. In recent years- the Convolutional Neural Network (CNN) technology has been widely applied to automatically segment BUS images. However- due to the inherent limitations of CNNs in capturing global contextual information- it is difficult to capture the full context. To address this issue- the paper proposes a novel BGRD-TransUNet model for breast lesion segmentation- based on TransUNet. The proposed model- first- replaces the original ResNet50 backbone network of TransUNet with DenseNet121 for initial feature extraction. Next- newly designed Residual Multi-Scale Feature Modules (RMSFMs) are employed to extract features from various layers of DenseNet121- thus capturing richer features within specific layers. Thirdly- a Boundary Guidance (BG) network is added to enhance the contour information of BUS images. Additionally- newly designed Boundary Attentional Feature Fusion Modules (BAFFMs) are used to integrate edge information and features extracted through RMSFMs. Finally- newly designed Parallel Channel and Spatial Attention Modules (PCSAMs) are used to refine feature extraction using channel and spatial attention. An extensive experimental testing performed on two public datasets demonstrates that the proposed BGRD-TransUNet model outperforms all state-of-the-art medical image segmentation models- participating in the experiments- according to all evaluation metrics used (except for few separate cases)- including the two most important and widely used metrics in the field of medical image segmentation- namely the Intersection over Union (IoU) and Dice Similarity Coefficient (DSC). More specifically- on the BUSI dataset and dataset B- BGRD-TransUNet achieves IoU values of 76.77% and 86.61%- and DSC values of 85.08% and 92.47%- respectively- which are higher by 7.27 and 3.64- and 5.81 and 2.54 percentage points- than the corresponding values achieved by the baseline (TransUNet).
Y. Forghani- R. Timotoe- M. Figueiredo- T. Marques- E. Batista- F. Cordoso- M.J. Cardoso- J. Santinha- P. Gouveia,Breast tissue segmentation in MR images using deep-learning,Breast cancer is one of the malignancies that affects women. Breast cancer is a condition that is brought on by abnormal breast cells that multiply and form tumours. If left untreated- tumours have the capacity to grow throughout the body and become fatal. Early initiation and thorough completion of treatment is associated with better outcomes and greater patient tolerance for breast cancer patients. These days- early detection of breast cancer is quite helpful and will help the women who battle the illness. The earliest detection of breast cancer can be successfully achieved with the use of machine learning-based approaches. Breast cancer can be diagnosed with great accuracy using a number of machine learning techniques- including CNN- RF- SVM- NB- KNN- AB- and others. Thus- I am introducing a triple hybrid deep learning method for breast cancer diagnosis and prognosis. This is the CNN- GRU- and LSTM combination.
ArunaDevi Karuppasamy- Abdelhamid Abdesselam- Hamza zidoum- Rachid Hedjam- Maiya Al-Bahri,Combining a forward supervised filter learning with a sparse NMF for breast cancer histopathological image classification,Breast cancer remains a global health problem requiring effective diagnostic methods for early detection in order to achieve WHO&rsquo;s ultimate goal of breast self-examination (BSE). A literature review indicates the urgency of improving diagnostic methods and identifies thermography as a promising- cost-effective- and non-invasive and adjunctive and complementary detection method. This research explores the potential of using machine learning (ML) techniques- specifically Bayesian Networks (BN) combined with Convolutional Neural Networks (CNN) to improve breast cancer diagnosis at early stages. Explainable artificial intelligence (XAI) aims to clarify the reasoning behind any output of artificial neural networks based models. The proposed integration adds interpretability of the diagnosis- which is particularly significant for a medical diagnosis. We have constructed two diagnostic expert models. In research model A- combining thermal images after XAI process together with medical records- an accuracy of 84.07% has been achieved- while model B- that includes also CNN prediction- achieved an accuracy of 90.93%. These results demonstrate the potential of XAI to transform breast cancer diagnosis- increasing accuracy and reducing the risk of misdiagnosis.
Yuan Yao- Yang Zhao- Xu Guo- Xiangli Xu- Baiyang Fu- Hao Cui- Jian Xue- Jiawei Tian- Ke Lu- Lei Zhang,Deep Learning for Distinguishing Mucinous Breast Carcinoma From Fibroadenoma on Ultrasound,"Abstract: Breast cancer poses a significant global health threat to women, underscoring the crucial need for reliable and effective screening approaches. The utilization of computer-aided diagnostic (CAD) systems, leveraging mammograms, enables early detection, diagnosis, and treatment of breast cancer, thereby offering vital support in combating this disease. This study introduces a unique deep-learning model that uses transfer learning to identify and categorize breast cancer automatically. Several recent studies have shown that deep convolutional neural networks (DCNNs) can be used to diagnose breast cancer in mammograms with performances comparable to or even superior to those of human experts. The proposed model extracts features from the Mammographic Image Analysis Society (MIAS) dataset using pre-trained convolutional neural network (CNN) architectures such as ResNet50 and VGG-16. This revolutionary deep-learning model has the potential to improve the efficiency and accuracy of breast cancer detection and categorization."
Vedagiriswaran N- SHRIHARI KAMALAN KUMARAGURUPARAN- Kumara  Guru R,Machine Learning and Structural Informatics Approaches to Identify Mtor Inhibitors for Drug Repurposing in Triple-Negative Breast Cancer,Early detection significantly enhances patients' survival rates by identifying tumors in their initial stages through medical imaging. However- prevailing methodologies encounter challenges in extracting comprehensive information from diverse modalities- thereby exacerbating semantic disparities and overlooking critical task correlations- consequently compromising the accuracy of prognosis predictions. Moreover- clinical insights emphasize the advantageous sharing of parameters between tumor segmentation and survival prediction for enhanced prognostic accuracy. This paper proposes a novel model- BTSSPro- designed to concurrently address Breast cancer Tumor Segmentation and Survival prediction through a Prompt-guided multi-modal co-learning framework. Technologically- our approach involves the extraction of tumor-specific discriminative features utilizing shared dual attention (SDA) blocks- which amalgamate spatial and channel information from breast MR images. Subsequently- we employ a guided fusion module (GFM) to seamlessly integrate the Electronic Health Record (EHR) vector into the extracted tumor-related discriminative feature representations. This integration prompts the model's feature selection to align more closely with real-world scenarios. Finally- a feature harmonic unit (FHU) is introduced to coordinate the transformer encoder and CNN decoder- thus reducing semantic differences. Remarkably- BTSSPro achieved a C-index of 0.968 and Dice score of 0.715 on the Breast MRI-NACT-Pilot dataset and a C-index of 0.807 and Dice score of 0.791 on the ISPY1 dataset- surpassing the previous state-of-the-art methods.
Zhe Lin,Breast cancer classification based on hybrid machine learning model,Automatic breast tumor segmentation based on convolutional neural networks (CNNs) is significant for the diagnosis and monitoring of breast cancers. CNNs have become an important method for early diagnosis of breast cancer and- thus- can help decrease the mortality rate. In order to assist medical professionals in breast cancer investigation a computerized system based on two encoder-decoder architectures for breast tumor segmentation has been developed. Two pre-trained DeepLabV3+ and U-Net models are proposed. The encoder generates a high-dimensional feature vector while the decoder analyses the low-resolution feature vector provided by the encoder and generates a semantic segmentation mask. Semantic segmentation based on deep learning techniques can overcome the limitations of traditional algorithms. To assess the efficiency of breast ultrasound image segmentation- we compare the segmentation results provided by CNNs against the Local Graph Cut technique (a semi-automatic segmentation method) in the Image Segmenter application. The output segmentation results have been evaluated by using the Dice similarity coefficient that compares the ground truth images provided by the specialists against the predicted segmentation results provided by the CNNs and Local Graph Cut algorithm. The proposed approach is validated on 780 breast ultrasonographic images of the BUSI public database of which 437 are benign and 210 are malignant. The BUSI database provides classification (benign or malignant) labels for ground truth in binary mask images. The average Dice scores computed between the ground truth images against CNNs were as follows: 0.9360 (malignant) and 0.9325 (benign) for the DeepLabV3+ architecture and of 0.6251 (malignant) and 0.6252 (benign) for the U-Net- respectively. When the segmentation results provided by CNNs were compared with the Local Graph Cut segmented images- the Dice scores were 0.9377 (malignant) and 0.9204 (benign) for DeepLabV3+ architecture and 0.6115 (malignant) and 0.6119 (benign) for U-Net- respectively. The results show that the DeepLabV3+ has significantly better segmentation performance and outperforms the U-Net network.
Ziming Liu,Improving breast cancer classification using histopathology images through deep learning,The most fatal disease affecting women worldwide now is breast cancer. Early detection of breast cancer enhances the likelihood of a full recovery and lowers mortality. Based on medical imaging- researchers from all around the world are developing breast cancer screening technologies. Due to their rapid progress- deep learning algorithms have caught the interest of many in the field of medical imaging. This research proposes a novel method in mammogram image feature extraction with classification and optimization using machine learning in breast cancer detection. The input image has been processed for noise removal- smoothening- and normalization. The input image features were extracted using probabilistic principal component analysis for detecting the presence of tumors in mammogram images. The extracted tumor region is classified using the Naâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšâ‰¤ve Bayes classifier and transfer integrated convolution neural networks. The classified output has been optimized using firefly binary grey optimization and metaheuristic moth flame lion optimization. The experimental analysis has been carried out in terms of different parameters based on datasets. The proposed framework used an ensemble model for breast cancer that made use of the proposed Bayesâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢FBGO and TCNNâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢MMFLO classifier and optimizer for diverse mammography image datasets. The INbreast dataset was evaluated using the proposed Bayesâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢FBGO and TCNNâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢MMFLO classifiers- which achieved 95% and 98% accuracy- respectively.
Milan Manoj- Akshay Rajan- Gouri Santhosh- Anjali T- Panchami Sankar,An Extensive Analysis of Breast Cancer detection using Deep Learning Algorithms,AI is transforming the medical field- especially in early detection and categorization of breast cancer. Deep learning models like CNNI-BCC are displaying impressive capabilities in examining MRI images to precisely recognize different types of breast cancer. This advancement in technology has significant implications for enhancing patient outcomes. By utilizing AI- healthcare professionals can now receive more accurate and prompt diagnoses. CNNI- BCC's exceptional accuracy in analyzing MRI images allows for earlier detection of breast cancer- which is crucial for successful treatment. This technology enables doctors to identify potential abnormalities that may have been missed by traditional methods- leading to more effective interventions.
Rajon Dash- Md Saidur Rahman Kohinoor- Promise Ghosh Chowdhury,Comprehensive Analysis of Machine and Deep Learning Models for Breast Cancer Diagnosis and Risk Assessment with Diverse Datasets,Background: Accurate detection of axillary lymph node (ALN) metastases in breast cancer is crucial for clinical staging and treatment planning. This study aims to develop a deep learning model using clinical implication-applied preprocessed computed tomography (CT) images to enhance the prediction of ALN metastasis in breast cancer patients. Methods: A total of 1128 axial CT images of ALN (538 malignant and 590 benign lymph nodes) were collected from 523 breast cancer patients who underwent preoperative CT scans between January 2012 and July 2022 at Hallym University Medical Center. To develop an optimal deep learning model for distinguishing metastatic ALN from benign ALN- a CT image preprocessing protocol with clinical implications and two different cropping methods (fixed size crop [FSC] method and adjustable square crop [ASC] method) were employed. The images were analyzed using three different convolutional neural network (CNN) architectures (ResNet- DenseNet- and EfficientNet). Ensemble methods involving and combining the selection of the two best-performing CNN architectures from each cropping method were applied to generate the final result. Results: For the two different cropping methods- DenseNet consistently outperformed ResNet and EfficientNet. The area under the receiver operating characteristic curve (AUROC) for DenseNet- using the FSC and ASC methods- was 0.934 and 0.939- respectively. The ensemble model- which combines the performance of the DenseNet121 architecture for both cropping methods- delivered outstanding results with an AUROC of 0.968- an accuracy of 0.938- a sensitivity of 0.980- and a specificity of 0.903. Furthermore- distinct trends observed in gradient-weighted class activation mapping images with the two cropping methods suggest that our deep learning model not only evaluates the lymph node itself- but also distinguishes subtler changes in lymph node margin and adjacent soft tissue- which often elude human interpretation. Conclusions: This research demonstrates the promising performance of a deep learning model in accurately detecting malignant ALNs in breast cancer patients using CT images. The integration of clinical considerations into image processing and the utilization of ensemble methods further improved diagnostic precision.
A Sharma- S Mittal,Deep Learning Approachâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®Improved CNN Model for the Breast Cancer Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Flowchart of deep learning radiomic nomogram modeling for LVI prediction in patients with invasive breast cancer. BMUS- B-mode ultrasound; CDFI- color doppler flow imaging; ROI- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
RO Ogundokun- ART Abdullahi- ...,Hybrid Deep Learning for Breast Cancer Diagnosis: Evaluating CNN and ANN on BreakHis_v1_400X,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ In order to solve the above problems- we propose a deep learning method for early prediction of NAC for breast cancer based on multistage bimodal ultrasound images. This model is â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
SM Thwin- SJ Malebary- AW Abulfaraj- HS Park,Attention-Based Ensemble Network for Effective Breast Cancer Classification over Benchmarks,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ and classification of breast cancer using transfer learning. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ [19] used the DL-CNN for breast cancer classification from â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ -negative breast cancer based on images of primary breast cancer. â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
PSRC Murty- C Anuradha- PA Naidu- D Mandru- ...,Integrative hybrid deep learning for enhanced breast cancer diagnosis: leveraging the Wisconsin Breast Cancer Database and the CBIS-DDSM dataset,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ of breast cancer- this investigation used a hybrid deep learning â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ The Wisconsin Breast Cancer Database is used for CNN â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ - and therapeutically applicable breast cancer detection method â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Erin J. Kim- Enoch Chung- Bernard T. Lee- Dhruv Singhal,D134. Application of Machine Learning to Predict Breast Cancer Related-lymphedema Development,Introduction: When considering cancer mortality rates in general- Breast Cancer (BC) is a major contributor among females. Patientsâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ chances of survival increase when BC is detected early and treated with the appropriate treatment at the right time. There is strong evidence that mammography- when used as a screening tool- can detect BC at an early stage. Mammography is a diagnostic tool that uses low-dose X-rays to visualise the breast and evaluate its anatomy. For screening purposes- it is currently the preferred method. The present study employs deep learning models trained using Transfer Learning (TL) techniques. Aim: To automate the process of BC diagnosis in mammograms. The main goal of this approach is to simplify the process of early detection and diagnosis of BC for healthcare practitioners. Materials and Methods: The dataset obtained from the Mammographic Image Analysis Society (MIAS) was categorised into three distinct categories: benign- malignant and normal. The initial MIAS dataset underwent several preprocessing techniques- including noise reduction- breast image contrast enhancement- non breast region deletion and malignant lesion identification- before analysis. An intricately designed fully connected classifier complements pretrained Convolutional Neural Network (CNN) architectures like ResNet50 and VGG16 in the proposed model. Results: The VGG16 model performed admirably- achieving an Area Under the Curve (AUC) of 0.950 and an accuracy rate of 96.00%. In addition- it displayed an outstanding F-score of 97%- along with high sensitivity- specificity and accuracy. These outcomes are significantly better compared to the other methods. Conclusion: The modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s enhanced capabilities for early-stage cancer detection could improve patient outcomes and reduce mortality rates. Furthermore- new tools can ease the workload for radiologists- leading to more standardised and efficient diagnostic procedures.
,Machine Learning-Based Breast Cancer Detection Using Histopathological Images,In worldwide women mortality increases extremely every year due to breast cancer and diagnosis of the issue through prediction is very much imperative for healthy lifespan. Here precision of cancer extrapolation is an essential thing for survivability of patient with appropriate treatment. Deep learning algorithms have materialised as influential tool for predicting breast cancer in medical image processing- which leverages capabilities of artificial neural networks (ANN) that are intended to mimic an architecture and functionalities of human brain. Superior features of convolutional neural network (CNN) in deep learning for handling image-based data like- exploiting spatial information- hierarchical feature learning- parameter sharing and data augmentation are important parameters in medical image processing. In this paper CNN algorithm is incorporated for predicting breast cancer in earlier and malignant stage- the results are compared with other deep learning algorithms and our proposed algorithm is expected to give better performance in parameters like accuracy testing- image classifiers- gene sequence classifiers and malignancy detection.
Sarathkumar M- Dhanalakshmi K S- Madhivadhani D- Revathi V,A Deep Learning Approach for Efficient Breast Cancer Diagnosis Using Hybrid CNN-BILSTM with Soft Attention Mechanism,Large language models (LLMs) have garnered significant attention in the AI domain owing to their exemplary context recognition and response capabilities. However- the potential of LLMs in specific clinical scenarios- particularly in breast cancer diagnosis- treatment- and care- has not been fully explored. This study aimed to compare the performances of three major LLMs in the clinical context of breast cancer. In this study- clinical scenarios designed specifically for breast cancer were segmented into five pivotal domains (nine cases): assessment and diagnosis- treatment decision-making- postoperative care- psychosocial support- and prognosis and rehabilitation. The LLMs were used to generate feedback for various queries related to these domains. For each scenario- a panel of five breast cancer specialists- each with over a decade of experience- evaluated the feedback from LLMs. They assessed feedback concerning LLMs in terms of their quality- relevance- and applicability. There was a moderate level of agreement among the raters (Fleiss' kappa=0.345- P<0.05). Comparing the performance of different models regarding response length- GPT-4.0 and GPT-3.5 provided relatively longer feedback than Claude2. Furthermore- across the nine case analyses- GPT-4.0 significantly outperformed the other two models in average quality- relevance- and applicability. Within the five clinical areas- GPT-4.0 markedly surpassed GPT-3.5 in the quality of the other four areas and scored higher than Claude2 in tasks related to psychosocial support and treatment decision-making. This study revealed that in the realm of clinical applications for breast cancer- GPT-4.0 showcases not only superiority in terms of quality and relevance but also demonstrates exceptional capability in applicability- especially when compared to GPT-3.5. Relative to Claude2- GPT-4.0 holds advantages in specific domains. With the expanding use of LLMs in the clinical field- ongoing optimization and rigorous accuracy assessments are paramount.
Sahan Yoruc Selcuk- Xilin Yang- Bijie Bai- Yijie Zhang- Yuzhu Li- Musa Aydin- Aras Firat Unal- Aditya Gomatam- Zhen Guo- Morgan A. Darrow- Goren Kolodney- Karine Atlan- Tal K. Haran- Nir Pillar- Aydogan Ozcan,Classification of HER2 score in breast cancer images using deep learning and pyramid sampling,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ slide images (WSI) and artificial intelligence (AI) featuring digital â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ - image transformers leverage self-attention mechanisms â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ CNN and transformer-based deep learning methods for the â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
N Thakur- P Kumar- A Kumar,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ semantic segmentation and attention based backpropagation convolutional neural network (ABB-CNN) for breast cancer identification and classification â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ by transformer and graph deep learning- this study proposes a novel classification method of WSI breast cancer pathological images based on BiFormer and graph attention network (â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
M Altulayhi- A Alhrgan,Evaluating Study Between Vision Transformers and Pre-trained CNN Learning Algorithms to Classify Breast Cancer Histopathological Images,Health-related quality of life (HRQOL) has become increasingly important for breast cancer survivors- but clinically relevant declines often persist for many years after treatment. This study aimed to investigate whether social relationships can mitigate or prevent this decline in HRQOL. Data were used from the German population-based Mamma Carcinoma Risk Factor Investigation (MARIE) cohort of 2022 breast cancer cases with follow-up information for more than 15 years after diagnosis. Correlations between social integration- social support- and global health status (GHS) as an overall measure of HRQOL were analyzed- and linear regression analysis was performed with structural equation modeling. The majority of participants reported high levels of social integration and social support and moderate levels of GHS. Social integration 5 years after diagnosis was associated with GHS 5 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 1.12; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.25-1.99)- but no longitudinal effects were found. Social support 5 years after diagnosis was associated with better GHS 5 years (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.42; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.36-0.48) and 10 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.12; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.02-0.22)- whereas social support 10 years after diagnosis was associated with GHS 10 years (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.29; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.20-0.39) and 15 years after diagnosis (â€šÃ¢Ã âˆšâ‰ â€šÃ„Ã¶âˆšÂ¢Â¬ÃŸÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.10; 95% CI-Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ 0.01-0.21). These results confirm that social relationships positively influence HRQOL in long-term breast cancer survivors and that their association should receive more attention clinically and beyond routine care.
Muniraj Gupta- Nidhi Verma- Naveen Sharma- Satyendra Narayan Singh- R. K. Brojen Singh- Saurabh Kumar Sharma,Deep Transfer Learning Hybrid Techniques for Precision in Breast Cancer Tumor Histopathology Classification,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ development of artificial intelligence- CAD systems utilizing deep learning technology have â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ Compared to CNNs- the self-attention mechanism in Transformers exhibits robust global â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Juan Gutierrez-Cardenas,"Breast Cancer Classification through Transfer Learning with Vision Transformer, PCA, and Machine Learning Models",The objective of our study was to explore the feasibility of integrating artificial intelligence (AI) algorithms for breast cancer detection into a portable- point-of-care ultrasound device (POCUS). This proof-of-concept implementation is to demonstrate the platform for integrating AI algorithms into a POCUS device to achieve a performance benchmark of at least 15 frames/second. Our methodology involved the application of five AI models (FasterRCNN+MobileNetV3- FasterRCNN+ResNet50- RetinaNet+ResNet50- SSD300+VGG16- and SSDLite320+MobileNetV3)- pretrained on public datasets of natural images- fine-tuned using a dataset of gelatin-based breast phantom images with both anechoic and hyperechoic lesions- mimicking real tissue characteristics. We created various gelatin-based ultrasound phantoms containing ten simulated lesions- ranging from 4-20 mm in size. Our experimental setup used the Clarius L15 scanning probe- which was connected via Wi-Fi to both a tablet and a laptop- forming the core of our development platform. The phantom data was divided into training- validation- and held-out testing sets on a per-video basis. We executed 200 timing trials for each finetuned AI model- streaming scanning video from the ultrasound probe in real-time. SSDLite320+MobileNetV3 emerged as a standout- showing a mean frame-to-frame timing of 0.068 seconds (SD=0.005)- which is approximately 14.71 FPS- closely followed by FasterRCNN+MobileNetV3- with a mean timing of 0.123 seconds (SD=0.016)- or about 8.13 FPS. Both models show acceptable performance in lesion localization. Compared to our goal of 15 frames/second- only the SSDLite320+MobileNetV3 architecture performed with sufficient evaluation speed to be used in real-time. Our findings show the necessity of using AI architectures designed for edge devices for real-time use- as well as the potential need for hardware acceleration to encode AI models for use in POCUS.
L Panigrahi- TB Chandra- AK Srivastava- ...,: Multilevel Breast Cancer Classification Framework Using Radiomic Features,This investigation explores the potential efficacy of machine learning algorithms (MLAs)- particularly convolutional neural networks (CNNs)- in distinguishing between benign and malignant breast cancer tissue through the analysis of 1000 breast cancer images gathered from Kaggle.com- a domain of publicly accessible data. The dataset was meticulously partitioned into training- validation- and testing sets to facilitate model development and evaluation. Our results reveal promising outcomes- with the developed model achieving notable precision (92%)- recall (92%)- accuracy (92%)- sensitivity (89%)- specificity (96%)- an F1 score of 0.92- and an area under the curve (AUC) of 0.944. These metrics underscore the model's ability to accurately identify malignant breast cancer images. Because of limitationsÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ such as sample size and potential variations in image quality- further research- data collection- and integration of theoretical models in a real-world clinical settingÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ are needed to expand the reliability and generalizability of these MLAs. Nonetheless- this study serves to highlight the potential use of artificial intelligence models as supporting tools for physicians to utilize in breast cancer detection.
D Shah- MAU Khan- M Abrar- ...,Optimizing Breast Cancer Detection With an Ensemble Deep Learning Approach,â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡ To enhance breast cancer detection- this study adopts a multifaceted approach centered on applying CNNs- a class of deep learning algorithms renowned for their prowess in image â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«Â¬Â¨â€šÃ Ã‡
Luca Urso- Luigi Manco- Corrado Cittanti- Sara Adamantiadis- Klarisa Elena Szilagyi- Giovanni Scribano- Noemi Mindicini- Aldo Carnevale- Mirco Bartolomei- Melchiore Giganti,18F-FDG PET/CT radiomic analysis and artificial intelligence to predict pathological complete response after neoadjuvant chemotherapy in breast cancer patients,Early detection of breast cancer with computer assistance has developed since two decades ago. Artificial intelligence using the convolutional neural network (CNN) method has successfully predicted mammography images with a high level of accuracy similar to human brain learning. The potential of AI models provides opportunities to spot breast cancer cases better. This research aims to develop AI models with CNN using the public DDSM dataset with a sample size of 1871- consisting of 1546 images for training and 325 images for testing. These AI models provided prediction results with different accuracy rate. Increasing the accuracy of the AI model can be done by improving the image quality before the modeling process- increasing the number of datasets- or carrying out a more profound iteration process so that the AI model with CNN can have a better level of accuracy.
Khadija Aguerchi- Y. Jabrane- Maryam Habba- Amir Hajjam El Hassani,A CNN Hyperparameters Optimization Based on Particle Swarm Optimization for Mammography Breast Cancer Classification,Objectives: To develop a model for the prediction of Breast cancer. Cancer is one of the deadliest diseases and it is regarded as the second leading cause of death in women throughout the sphere. Former detection of cancer can save the patient's life. Outliers can have an impact on the model's performance. For this reason- eliminating outliers is the first factor to be considered. Methods: In this study- the Wisconsin Diagnostic Breast Cancer dataset was used. It consists of 569 instances of which 357 instances are benign and 212 are malignant cases. It has 32 attributes including two class attribute labels (diagnosis: B= benign- M= malignant)- ID number- and 30 real value attributes. These attributes are computed from a digitized image of a Fine Needle Aspiration (FNA) procedure of a breast mass and are used to describe the characteristics of the cell nuclei present in the image. The HOTSM outlier detection approach- which handles anomalies in two stages- was proposed in the current study. First- the Inter Quartile Range (IQR) was employed to diminish the influence of outliers. After the analysis had been finished- the non-outlier data was transmitted to an isolation forest- wherein the absolute mean error was calculated. Pearson's Correlation was employed to minimize the dimensionality. Findings: For the performance evaluation- two datasets are generated; one using isolation forest and the other using HOTSM. The performance of both datasets is tested using SVM- Decision Tree- and Random Forest classifiers- highest accuracies are obtained as 97.80 %-96.80%- and 98.4% respectively. It was found that the dataset generated using the proposed method performed well. The proposed model is capable of identifying Breast cancer- more accurately. Novelty: The Interquartile Range has been utilized for altering the traditional isolation forest algorithm- enhancing performance metrics. The thorough removal of anomalies reduces the likelihood of misdiagnosis- yet they cannot exclude all outliers. Keywords: Outliers- Breast Cancer- Accuracy- Machine Learning- Hybrid
Umesh Dutta- Simran Kaushik- Srinidhi Iyer- Ina Singh,A Comparative Analysis of Machine Learning Techniques for Breast Cancer Prediction,Breast cancer is one of the most common causes of death in women. Early signs of breast cancer can be an abnormality depicted on breast images like breast ultrasonography. Unfortunately- ultrasound images contain a lot of noise- which greatly increases the difficulty for doctors to interpret them. In recent years- computer-aided diagnosis (CAD) has been widely used in medical images- reducing the workload of doctors and the probability of misdiagnosis. However- it still faces the following challenges in clinical practice: one is the lack of interpretability- and another is that the accuracy is not high enough. In this paper- we propose a classification model of breast ultrasound images that leverages tumor boundaries as prior knowledge and strengthens the model to guide classification. Furthermore- we employ the advantages of convolutional neural network (CNN) to extract local features and Transformer to extract global features to achieve information balance and complementarity between the two neural network models which increase the recognition performance of the model. Additionally- an explanation method is used to generate visual results- thereby improving the poor interpretability of deep learning models. Finally- we evaluate the model on the BUSI dataset and compare it with other CNN and Transformer models. Experimental results show that the proposed model obtains an accuracy of 0.9870 and an F1 score of 0.9872- achieving state-of-the-art performance.
Mahdi Ahmadi- N. Karimi- S. Samavi,A lightweight deep learning pipeline with DRDA-Net and MobileNet for breast cancer classification,Purposes: Breast cancer (BC) is a disease in which the breast cells multiply uncontrolled. Breast cancer is one of the most often diagnosed malignancies in women worldwide. Early identification of breast cancer is critical for limiting the impact on affected people's health conditions. The influence of technology and artificial intelligence approaches (AI) in the health industry is tremendous as technology advances. Deep learning (DL) techniques are used in this study to classify breast lumps. Materials and Methods: The study makes use of two distinct breast ultrasound images (BUSI) with binary and multiclass classification. To assist the models in understanding the data- the datasets are exposed to numerous preprocessing and hyperparameter approaches. With data imbalance being a key difficulty in health analysis- due to the likelihood of not having a condition exceeding that of having the disease- this study applies a cutoff stage to impact the decision threshold in the datasets data augmentation procedures. The capsule neural network (CapsNet)- Gabor capsule network (GCN)- and convolutional neural network (CNN) are the DL models used to train the various datasets. Results: The findings showed that the CapsNet earned the maximum accuracy value of 93.62% while training the multiclass data- while the GCN achieved the highest model accuracy of 97.08\% when training the binary data. The models were also evaluated using a variety of performance assessment parameters- which yielded consistent results across all datasets. Conclusion: The study provides a non-invasive approach to detect breast cancer; and enables stakeholders- medical practitioners- and health research enthusiasts a fresh view into the analysis of breast cancer detection with DL techniques to make educated judgements.
Chenlu Zhang- Nan Li- Pengxia Zhang- Zhimei Jiang- Yichao Cheng- Huiqing Li- Zhenfei Pang,Advancing precision and personalized breast cancer treatment through multi-omics technologies,The most prevalent cancer in women is breast cancer (BC)- and effective treatment depends on being detected early. Many people seek medical imaging techniques to help in the early detection of problems- but results often need to be corrected for increased accuracy. A new deep learning approach for medical images is applied in the detection of BC in this paper. Early detection is carried out through the proposed method using a combination of Convolutional Neural Network (CNNs) with feature selection and fusion methods. The proposed method may decrease the mortality rate due to the early-stage detection of BC with high precision. In this work- the proposed Deep Learning Framework (DLF) uses many levels of artificial neural networks to sort images of BC into categories correctly. This proposed method further increases the scalability of convolutional recurrent networks. It also achieved 94.93Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % accuracy- 93.66Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % precision- 89.21Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % recall and 98.86Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % F1-score. Through this approach- cancer tumors in a specific location can be detected more accurately. The existing methods are dependent mainly on manually selecting and extracting features. The proposed framework automatically learns and finds relevant features from images that result in outperforming existing methods.
S. S. Boudouh- M. Bouakkaz,Advancing precision in breast cancer detection: a fusion of vision transformers and CNNs for calcification mammography classification,Breast cancer is a major cause of death worldwide. The complexity of endocrine regulation in breast cancer may allow the cancer cells to escape from a particular treatment and result in resistant and aggressive disease. These breast cancers usually have fewer treatment options. Targeted therapies for cancer patients may offer fewer adverse side effects because of specificity compared to conventional chemotherapy. Signaling pathways of nuclear receptors- such as the estrogen receptor (ER)- have been intensively studied and used as therapeutic targets. Recently- the role of the androgen receptor (AR) in breast cancer is gaining greater attention as a therapeutic target and as a prognostic biomarker. The expression of constitutively active truncated AR splice variants in breast cancer is a possible mechanism contributing to treatment resistance. Therefore- targeting both the full-length AR and AR variants- either through the activation or suppression of AR function- depending on the status of the ER- progesterone receptor- or human epidermal growth factor receptor 2- may provide additional treatment options. Studies targeting AR in combination with other treatment strategies are ongoing in clinical trials. The determination of the status of nuclear receptors to classify and identify patient subgroups will facilitate optimized and targeted combination therapies.
Wei Wang- Lei Liu- Jianxiong Zhu- Youqiang Xing- Songlong Jiao- Ze Wu,AI-Enhanced Visual-Spectral Synergy for Fast and Ultrasensitive Biodetection of Breast Cancer-Related miRNAs.,Breast cancer is a dangerous disease- contributing to a high mortality rate in women. Early detection plays a pivotal role in enhancing survival rates. Breast ultrasound is considered an effective method to help diagnose breast diseases early. Breast ultrasound is inexpensive- easy to perform- non-invasive and painless- so it is often prescribed by doctors in cases where it is necessary to examine the nature of clinically palpable lesions or related symptoms in the breast. In this paper- we introduce a method based on transfer learning and deep feature fusion to classify breast cancer using ultrasound images. The results from our experiments involving 780 breast ultrasound images across three categories (benign- malignant- and normal) indicated that the model using max fusion of deep features outperformed an original CNN in terms of performance- the combination of the maximum value between deep features has a higher performance level with an accuracy of about 1% to 4% compared to the original model. The concatenation fusion of VGG19 and ViT features delivers 1% - 4% times more accuracy than the original model alone
Ling Liao- Eva M Aagaard,An open codebase for enhancing transparency in deep learning-based breast cancer diagnosis utilizing CBIS-DDSM data,In breast cancer- several gene expression assays have been developed to provide a more personalised treatment. This study focuses on the prediction of two molecular proliferation signatures: an 11-gene proliferation score and the MKI67 proliferation marker gene. The aim was to assess whether these could be predicted from digital whole slide images (WSIs) using deep learning models. WSIs and RNA-sequencing data from 819 invasive breast cancer patients were included for training- and models were evaluated on an internal test set of 172 cases as well as on 997 cases from a fully independent external test set. Two deep Convolutional Neural Network (CNN) models were optimised using WSIs and gene expression readouts from RNA-sequencing data of either the proliferation signature or the proliferation marker- and assessed using Spearman correlation (r). Prognostic performance was assessed through Cox proportional hazard modelling- estimating hazard ratios (HR). Optimised CNNs successfully predicted the proliferation score and proliferation marker on the unseen internal test set (â€šÃ¢Ã âˆšÂ¨â€šÃ Ã¶âˆšÃ±â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.691(pâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.001) with R2â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.438- and â€šÃ¢Ã âˆšÂ¨â€šÃ Ã¶âˆšÃ±â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.564 (pâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.001) with R2â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.251 respectively) and on the external test set (â€šÃ¢Ã âˆšÂ¨â€šÃ Ã¶âˆšÃ±â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.502 (pâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.001) with R2â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.319- and â€šÃ¢Ã âˆšÂ¨â€šÃ Ã¶âˆšÃ±â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.403 (pâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.001) with R2â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.222 respectively). Patients with a high proliferation score or marker were significantly associated with a higher risk of recurrence or death in the external test set (HRâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢1.65 (95% CI: 1.05-2.61) and HRâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢1.84 (95% CI: 1.17-2.89)- respectively). The results from this study suggest that gene expression levels of proliferation scores can be predicted directly from breast cancer morphology in WSIs using CNNs and that the predictions provide prognostic information that could be used in research as well as in the clinical setting.
Meena L C- Joe Prathap P M,An optimal deep learning approach for breast cancer detection and classification with pre-trained CNN-based feature learning mechanism,To explore the value of combined radiomics and deep learning models using different machine learning algorithms based on mammography (MG) and magnetic resonance imaging (MRI) for predicting axillary lymph node metastasis (ALNM) in breast cancer (BC). The objective is to provide guidance for developing scientifically individualized treatment plans- assessing prognosis- and planning preoperative interventions. A retrospective analysis was conducted on clinical and imaging data from 270 patients with BC confirmed by surgical pathology at the Third Hospital of Shanxi Medical University between November 2022 and April 2024. Multiple sequence images from MG and MRI were selected- and regions of interest in the lesions were delineated. Radiomics and deep learning (3D-Resnet18) features were extracted and fused. The samples were randomly divided into training and test sets in a 7:3 ratio. Dimensionality reduction and feature selection were performed using the least absolute shrinkage and selection operator (LASSO) regression model- and other methods. Various machine learning algorithms were used to construct radiomics- deep learning- and combined models. These models were visualized and evaluated for performance using receiver operating characteristic curves- area under the curve (AUC)- calibration curves- and decision curves. The highest AUCs in the test set were achieved using radiomics-logistic regression (AUC = 0.759)- deep learning-multilayer perceptron (MLP) (AUC = 0.712)- and combined-MLP models (AUC = 0.846). The MLP model demonstrated strong classification performance- with the combined model (AUC = 0.846) outperforming both the radiomics (AUC = 0.756) and deep learning (AUC = 0.712) models. The multimodal radiomics and deep learning models developed in this study- incorporating various machine learning algorithms- offer significant value for the preoperative prediction of ALNM in BC.
Xiangyang Zhang- Yang Chen- Changjing Cai- Yifeng Wang- Jun Tan- Zijie Fang- Le Wei- Zhuchen Shao- Liwen Wang- Tiezheng Qi- Yihan Liu- Zhaohui Jiang- Yin Li- Ying Han- Tibera Kagemulo Rugambwa- Shan Zeng- Haoqian Wang- Hong Shen- Yongbing Zhang,Artificial Intelligence Predicts Multiclass Molecular Signatures and Subtypes Directly From Breast Cancer Histology: a Multicenter Retrospective Study,The uncontrolled proliferation of breast cancer cells in a specific area of the body is the second most common cause of death among women worldwide. If the disease is detected in its early stages- it can be cured. While the use of digital image processing to detect breast cancer is not new- many new approaches are being developed to accurately predict its location. The current approach involves both visual inspection of the tumor region and determining the region in which most of the tumor is concentrated. The primary objective of this study is to determine the most efficient algorithm or combination of algorithms for the detection of breast tumors. Various algorithms have been employed in the proposed work; however- the CNN-Deep Learning model combination is the most effective for the diagnosis of breast cancer. This approach may help radiologists to evaluate screening mammography more effectively.
Aslâ€šÃ Ãœâˆšâ‰ Â¬Â¨Â¬Â±nur Albayrak- Kayhan Nuri Cengiz,Assessment of breast cancer awareness among female pharmacy students at a university in Turkey,Breast cancer remains a pressing global health concern- necessitating accurate diagnostics for effective interventions. Deep learning models (AlexNet- ResNet-50- VGG16- GoogLeNet) show remarkable microcalcification identification (>90%). However- distinct architectures and methodologies pose challenges. We propose an ensemble model- merging unique perspectives- enhancing precision- and understanding critical factors for breast cancer intervention. Evaluation favors GoogleNet and ResNet-50- driving their selection for combined functionalities- ensuring improved precision- and dependability in microcalcification detection in clinical settings. This study presents a comprehensive mammogram preprocessing framework using an optimized deep learning ensemble approach. The proposed framework begins with artifact removal using Otsu Segmentation and morphological operation. Subsequent steps include image resizing- adaptive median filtering- and deep convolutional neural network (D-CNN) development via transfer learning with ResNet-50 model. Hyperparameters are optimized- and ensemble optimization (AlexNet- GoogLeNet- VGG16- ResNet-50) are constructed to identify the localized area of microcalcification. Rigorous evaluation protocol validates the efficacy of individual models- culminating in the ensemble model demonstrating superior predictive accuracy. Based on our analysis- the proposed ensemble model exhibited exceptional performance in the classification of microcalcifications. This was evidenced by the model's average confidence score- which indicated a high degree of dependability and certainty in differentiating these critical characteristics. The proposed model demonstrated a noteworthy average confidence level of 0.9305 in the classification of microcalcification- outperforming alternative models and providing substantial insights into the dependability of the model. The average confidence of the ensemble model in classifying normal cases was 0.8859- which strengthened the model's consistent and dependable predictions. In addition- the ensemble models attained remarkably high performances in terms of accuracy- precision- recall- F1-score- and area under the curve (AUC). The proposed model's thorough dataset integration and focus on average confidence ratings within classes improve clinical diagnosis accuracy and effectiveness for breast cancer. This study introduces a novel methodology that takes advantage of an ensemble model and rigorous evaluation standards to substantially improve the accuracy and dependability of breast cancer diagnostics- specifically in the detection of microcalcifications.
Ekta- Vandana Bhatia,Auto-BCS: A Hybrid System for Real-Time Breast Cancer Screening from Pathological Images.,The rapid evolution of telehealth- or telemedicine- has spurred crucial technological advancements aimed at addressing the early stages of complex cancer conditions- where conventional diagnostic methods face challenges. This research introduces a cancer detection system that utilizes Internet of Things (IoT)-based patient records and machine learning. The primary objective is to automate real-time breast cancer monitoring and detection in residential institutions and smart hospitals- thus enhancing the delivery of quality cancer healthcare. Background: Traditional diagnostic methods- particularly physical inspection- exhibit inherent limitations in identifying breast cancer at early stages. This research responds to this challenge by leveraging innovative technologies- such as IoT and deep learning-based techniques- to overcome the constraints of conventional approaches. Objective: The primary goal of this study is to develop and implement a cancer detection system that integrates IoT-based patient records and machine learning for real-time breast cancer monitoring in residential and healthcare settings. Method: The research employs a synergistic combination of IoT technology for collecting images of residential users and Convolutional Neural Network (CNN)- a deep learning technique- for early cancer prediction. The focus lies on contributing to the overall well-being of individuals who may unknowingly be living with cancer. Result: Simulated outcomes after 25 epochs are presented- emphasizing the training accuracy of the model and its validation accuracy using the proposed VGG16 classifier. Graphical representations of the results indicate consistent performance metrics- with both validation and training accuracy exceeding 99%. Specifically- the training accuracy measures at an impressive 99.64%- while the validation accuracy stands at 99.12%. Main Findings: The study demonstrates the effectiveness of the integrated IoT and deep learning techniques in achieving high accuracy rates for early breast cancer prediction. The findings affirm the potential of this approach to assist dermatologists in identifying breast malignancies at treatable stages. Conclusion: This research establishes a foundational framework for the integration of IoT and deep learning techniques- presenting a promising avenue for advancing early cancer detection in smart healthcare systems. The proposed cancer detection system holds significant potential for improving healthcare outcomes and contributing to the overall well-being of individuals at risk of breast cancer.
Shuhan Li- Yuxuan Xiang- Hongman Li- Chunmin Yang- Wenting He- Jiahua Wu- M Tish Knobf- Zengjie Ye,Body image- self-efficacy- and sleep quality among patients with breast cancer: A latent profile and mediation analysis,Quantum machine learning holds the potential to revolutionize cancer treatment and diagnostic imaging by uncovering complex patterns beyond the reach of classical methods. This study explores the effectiveness of quantum convolutional layers in classifying ultrasound breast images for cancer detection. By encoding classical data into quantum states through angle embedding and employing a robustly entangled 9-qubit circuit design with an SU(4) gate- we developed a Quantum Convolutional Neural Network (QCNN) and compared it to a classical CNN of similar architecture. Our QCNN model- leveraging two quantum circuits as convolutional layers- achieved an impressive peak training accuracy of 76.66% and a validation accuracy of 87.17% at a learning rate of 1 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 10-2. In contrast- the classical CNN model attained a training accuracy of 77.52% and a validation accuracy of 83.33%. These compelling results highlight the potential of quantum circuits to serve as effective convolutional layers for feature extraction in image classification- especially with small datasets.
S. Kanimozhi- S. Priyadarsini,Breast Cancer Histopathological Image Classification Using CNN and VGG-19,Ferroptosis has received increasing attention as a novel nonapoptotic programmed death. Recently- iron-based nanomaterials have been extensively exploited for efficient tumor ferroptosis therapy- as they directly release high concentrations of iron and increase intracellular reactive oxygen species levels. Breast cancer is one of the commonest malignant tumors in women; inhibiting breast cancer cell proliferation through activating the ferroptosis pathway could be a potential new target for patient treatment. Here- we briefly introduce the background of ferroptosis and systematically review the current cancer therapeutic strategies based on iron-based ferroptosis inducers. Finally- we summarize the advantages of these various ferroptosis inducers and shed light on future perspectives. This review aims to provide better guidance for the development of iron-based nanomaterial ferroptosis inducers.
Elsy Cruz- Lourdes Santos- Hiram Calvo- â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšÃ±lvaro Anzueto-Râ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ os- Yenny Villuendas-Rey,Breast density classification in mammograms using VGG convolutional networks,Breast cancer is a leading cause of death among women worldwide. The emergence of Artificial Intelligence (AI) has led to significant progress in breast cancer detection research. Early detection of breast cancer is crucial for making informed decisions about treatment and eradicating the disease. Deep Learning (DL) techniques- commonly used in computer vision- have been applied to various domains- including healthcare. The Convolutional Neural Network (CNN) is a widely used model for medical image processing- but its performance may not be optimal for a specific imaging modality without empirical study. This paper introduces an enhanced CNN model called Breast Cancer Detection Network (BCDNet)- designed to be more efficient with breast mammogram images. We also propose an algorithm called Learning-Based Cancer Screening (LBCS) that leverages the BCDNet model. An empirical study using the CBID-DDSM benchmark dataset demonstrates that BCDNet outperforms many existing deep learning models- achieving the highest accuracy of 97.68%. This proposed model can be utilized for breast cancer screening in healthcare units as part of a Clinical Decision Support System (CDSS).
LaRae L Seemann- Tina Ardon- Rebecca A Bowie- Kati C Bullock- A. Clapp,Breast Pain Differential: Mondorâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s Disease of the Breast,Breast cancer continues to be a substantial worldwide health concern- affecting millions of individuals each year; this emphasizes the critical nature of early detection in order to enhance patient prognoses. The present study aims to assess the classification performance of three convolutional neural network (CNN) architectures-visual geometry group 19 (VGG19)- AlexNet- and residual network 50 (ResNet50)-with respect to breast cancer detection in medical images. Thorough assessments- encompassing metrics such as accuracy- precision- recall- and F-score- were undertaken to evaluate the diagnostic performance of the models. ResNet50 consistently outperforms other models- as evidenced by its highest accuracy and F-score. The research highlights the significant importance of carefully choosing suitable architectures for medical image analysis- with a specific focus on the detection of breast cancer. In addition- it demonstrates the capacity of deep learning models- such as ResNet50- to improve the diagnosis of breast cancer with exceptional precision and sensitivity- which is critical for reducing the occurrence of false positives and negatives in clinical environments. In addition- computational efficiency is taken into account; AlexNet is recognized as the most efficient model- which is advantageous in environments with limited resources. This study advances medical image processing by demonstrating the potential of CNNs in the detection of breast cancer. The results of this study establish a fundamental basis for sub- sequent inquiries and suggest approaches to improve timely detection and treatment- which will ultimately be advantageous for both patients and healthcare professionals.
Jessica Prunaretty- Fatima Mekki- Pierre-Ivan Laurent- Aurelie Morel- Pauline Hinault- Celine Bourgier- David Azria- Pascal Fenoglietto,Clinical feasibility of Ethos auto-segmentation for adaptive whole-breast cancer treatment,Identification of the molecular subtypes in breast cancer allows to optimize treatment strategies- but usually requires invasive needle biopsy. Recently- non-invasive imaging has emerged as promising means to classify them. Magnetic resonance imaging is often used for this purpose because it is three-dimensional and highly informative. Instead- only a few reports have documented the use of mammograms. Given that mammography is the first choice for breast cancer screening- using it to classify molecular subtypes would allow for early intervention on a much wider scale. Here- we aimed to evaluate the effectiveness of combining global and local mammographic features by using Vision Transformer (ViT) and Convolutional Neural Network (CNN) to classify molecular subtypes in breast cancer. The feature values for binary classification were calculated using the ViT and EfficientnetV2 feature extractors- followed by dimensional compression via principal component analysis. LightGBM was used to perform binary classification of each molecular subtype: triple-negative- HER2-enriched- luminal A- and luminal B. The combination of ViT and CNN achieved higher accuracy than ViT or CNN alone. The sensitivity for triple-negative subtypes was very high (0.900- with F-valueâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢=â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.818); whereas F-value and sensitivity were 0.720 and 0.750 for HER2-enriched- 0.765 and 0.867 for luminal A- and 0.614 and 0.711 for luminal B subtypes- respectively. Features obtained from mammograms by combining ViT and CNN allow the classification of molecular subtypes with high accuracy. This approach could streamline early treatment workflows and triage- especially for poor prognosis subtypes such as triple-negative breast cancer.
Yi-Ming Wang- Chi-Yuan Wang- Kuo-Ying Liu- Yung-Hui Huang- Tai-Been Chen- Kon-Ning Chiu- Chih-Yu Liang- Nan-Han Lu,CNN-Based Cross-Modality Fusion for Enhanced Breast Cancer Detection Using Mammography and Ultrasound,Breast cancer ranks as the second most prevalent cancer globally and is the most frequently diagnosed cancer among women; therefore- early- automated- and precise detection is essential. Most AI-based techniques for breast cancer detection are complex and have high computational costs. Hence- to overcome this challenge- we have presented the innovative LightweightUNet hybrid deep learning (DL) classifier for the accurate classification of breast cancer. The proposed model boasts a low computational cost due to its smaller number of layers in its architecture- and its adaptive nature stems from its use of depth-wise separable convolution. We have employed a multimodal approach to validate the model's performance- using 13-000 images from two distinct modalities: mammogram imaging (MGI) and ultrasound imaging (USI). We collected the multimodal imaging datasets from seven different sources- including the benchmark datasets DDSM- MIAS- INbreast- BrEaST- BUSI- Thammasat- and HMSS. Since the datasets are from various sources- we have resized them to the uniform size of 256 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 256 pixels and normalized them using the Box-Cox transformation technique. Since the USI dataset is smaller- we have applied the StyleGAN3 model to generate 10-000 synthetic ultrasound images. In this work- we have performed two separate experiments: the first on a real dataset without augmentation and the second on a real + GAN-augmented dataset using our proposed method. During the experiments- we used a 5-fold cross-validation method- and our proposed model obtained good results on the real dataset (87.16% precision- 86.87% recall- 86.84% F1-score- and 86.87% accuracy) without adding any extra data. Similarly- the second experiment provides better performance on the real + GAN-augmented dataset (96.36% precision- 96.35% recall- 96.35% F1-score- and 96.35% accuracy). This multimodal approach- which utilizes LightweightUNet- enhances the performance by 9.20% in precision- 9.48% in recall- 9.51% in F1-score- and a 9.48% increase in accuracy on the combined dataset. The LightweightUNet model we proposed works very well thanks to a creative network design- adding fake images to the data- and a multimodal training method. These results show that the model has a lot of potential for use in clinical settings.
Andreas Giannakou- Canan Dagdeviren- Tolga Ozmen,Conformable Ultrasound Breast Patch - The Future of Breast Cancer Screening?,This research study initiates a multifaceted analysis of breast cancer- a pervasive malignancy originating in the mammary gland cells. Globally- breast cancer ranks as the second most commonly diagnosed cancer- surpassed only by skin cancer. While breast cancer can affect individuals of any gender- it disproportionately impacts women. In light of this significant health concern- this research study examines the notable advancements in breast cancer detection- encompassing a wide array of techniques designed to enhance early diagnosis. The success of this effort relies on old-fashioned techniques like mammograms and check-ups- which are still very important tools. Additionally- this study introduces emerging technologies- specifically AI-powered analysis of mammograms. The technologies- such as Convolutional Neural Networks (CNN) utilizing Residual Networks (ResNet)- Visual Geometry Group Networks (VGG16)- and Siamese Neural Network architectures (SNN) and Convolutional Recurrent Neural Network (CRNN) have shown promising potential to substantially enhance the diagnostic accuracy. Moreover- this study explores the application of various machine learning algorithms to collect datasets- aiming to predict the early development of breast cancer. This comprehensive approach underscores the promising future of breast cancer detection and emphasizes the importance of a multidimensional strategy in combating this global health challenge. This study utilizes the pre-existing research on Magnetic Resonance Imaging (MRI) scans of breast datasets- seeking to improve the accuracy and early detection by ultimately contributing to establish a more effective breast cancer management.
J Armstrong,Deep Learning Breast Cancer Radiology Anomaly Detection Explainability Using Statistical Fault Localization,"Brain tumours, breast cancer, and pneumonia are significant diseases causing a substantial number of deaths globally. These diseases affect a great part of the world, including India. Research on early detection strategies is critical for saving lives. This proposal describes a unique way to use deep learning approaches to detect three common diseases: breast cancer, brain tumours, and pneumonia. This approach aims to improve treatment outcomes and diagnostic accuracy by integrating a range of medical imaging modalities tailored to individual diseases. In similar challenges, DCNNs have demonstrated remarkable speed and accuracy, demonstrating their potential to enhance medical diagnosis. DCNN models can help medical professionals by providing accurate and automated illness identification, especially for areas with a shortage of radiologists."
Yaping Yang- Ying Zhong- Junwei Li- Jiahao Feng- C. Gong- Yunfang Yu- Yue Hu- R. Gu- Hongli Wang- Fengtao Liu- J. Mei- Xiaofang Jiang- Jin Wang- Qinyue Yao- Wei Wu- Qiang Liu- H. Yao,Deep learning combining mammography and ultrasound images to predict the malignancy of BI-RADS US 4A lesions in women with dense breasts: a diagnostic study,Breast cancer is the most prevalent type of disease among women. It has become one of the foremost causes of death among women globally. Early detection plays a significant role in administering personalized treatment and improving patient outcomes. Mammography procedures are often used to detect early-stage cancer cells. This traditional method of mammography while valuable has limitations of potential for false positives and negatives- patient discomfort- and radiation exposure. Therefore- there is a probe for more accurate techniques required in detecting breast cancer- leading to exploring the potential of machine learning in the classification of diagnostic images due to its efficiency and accuracy. This study conducted a comparative analysis of pre-trained CNNs (ResNet50 and VGG16) and Vision Transformers (ViT-Base and SWIN Transformer) with the inclusion of ViT-Base trained from scratch model architectures to effectively classify breast cancer mammographic images into benign and malignant cases. The Swin transformer exhibits superior performance with 99.8% accuracy and a precision of 99.8%. These findings demonstrate the efficiency of deep learning to accurately classify breast cancer mammographic images for the diagnosis of breast cancer- leading to improvement in patient outcomes.
Guangliang Yang- Haiqi Chen- Jinchao Yue,Deep learning to optimize radiotherapy decisions for elderly patients with early-stage breast cancer: a novel approach for personalized treatment,Accurately and swiftly segmenting breast tumors is significant for cancer diagnosis and treatment. Ultrasound imaging stands as one of the widely employed methods in clinical practice. However- due to challenges such as low contrast- blurred boundaries- and prevalent shadows in ultrasound images- tumor segmentation remains a daunting task. In this study- we propose BCT-Net- a network amalgamating CNN and transformer components for breast tumor segmentation. BCT-Net integrates a dual-level attention mechanism to capture more features and redefines the skip connection module. We introduce the utilization of a classification task as an auxiliary task to impart additional semantic information to the segmentation network- employing supervised contrastive learning. A hybrid objective loss function is proposed- which combines pixel-wise cross-entropy- binary cross-entropy- and supervised contrastive learning loss. Experimental results demonstrate that BCT-Net achieves high precision- with Pre and DSC indices of 86.12% and 88.70%- respectively. Experiments conducted on the BUSI dataset of breast ultrasound images manifest that this approach exhibits high accuracy in breast tumor segmentation.
Vahab Khoshdel- Nasrin Abharian- Amir Attar- Joe LoVetri,Denoising Diffusion Probabilistic Models for Generating Tissue Type Breast Image Dataset,In medical imaging- the effective detection and classification of Breast Cancer (BC) is a current research important task because of the still existing difficulty to distinguish abnormalities from normal breast tissues due to their subtle appearance and ambiguous margins and distinguish abnormalities from the normal breast. Moreover- BC detection based on an automated detection model is needed- because manual diagnosis faces problems due to cost and shortage of skilled manpower- and also takes a very long time. Using deep learning and ensemble feature selection techniques- in this paper- a novel framework is introduced for classifying BC from histopathology images. The five primary steps of the suggested framework are as follows: 1) to make the largest original dataset and then deep learning model with data augmentation to improve the learning. 2) The best features are selected by an Ensemble Filter Feature selection Method (EFFM) which combines the best feature subsets to produce the final feature subsets. 3) Then the pruned Convolution Neural Network (CNN) model is utilized to extract the optimal features. 4) Finally- the classification is done through the Triplet Attention based Efficient Network (TAENet) classifier. The suggested model produces a 98% accuracy rate after being trained and tested on two different histopathology imaging datasets including images from four different data cohorts. Subsequently- the suggested strategy outperforms the conventional ones since the ensemble filter habitually acquires the best features- and experimental results demonstrate the importance of the proposed approach
Jiahui Ren- Yili Li- Jing Zhou- Ting Yang- Jingfeng Jing- Qian Xiao- Zhongxu Duan- Ke Xiang- Yuchen Zhuang- Daxue Li- Han Gao,Developing machine learning models for personalized treatment strategies in early breast cancer patients undergoing neoadjuvant systemic therapy based on SEER database,Breast cancer is the second most common type of cancer among women. Prompt detection of breast cancer can impede its advancement to more advanced phases- thereby elevating the probability of favorable treatment consequences. Histopathological images are commonly used for breast cancer classification due to their detailed cellular information. Existing diagnostic approaches rely on Convolutional Neural Networks (CNNs) which are limited to local context resulting in a lower classification accuracy. Therefore- we present a fusion model composed of a Vision Transformer (ViT) and custom Atrous Spatial Pyramid Pooling (ASPP) network with an attention mechanism for effectively classifying breast cancer from histopathological images. ViT enables the model to attain global features- while the ASPP network accommodates multiscale features. Fusing the features derived from the models resulted in a robust breast cancer classifier. With the help of five-stage image preprocessing technique- the proposed model achieved 100% accuracy in classifying breast cancer on the BreakHis dataset at 100X and 400X magnification factors. On 40X and 200X magnifications- the model achieved 99.25% and 98.26% classification accuracy respectively. With a commendable classification efficacy on histopathological images- the model can be considered a dependable option for proficient breast cancer classification.
N. Nurbaiti- Eka Putra Syarif Hidayat- Khairil Anwar- Dudung Hermawan- Salman Izzuddin,Development of AI Models from Mammography Images with CNN for Early Detection of Breast Cancer,We present a survey of the current state-of-the-art in breast cancer detection and prognosis. We analyze the evolution of Artificial Intelligence-based approaches from using just uni-modal information to multi-modality for detection and how such paradigm shift facilitates the efficacy of detection- consistent with clinical observations. We conclude that interpretable AI-based predictions and ability to handle class imbalance should be considered priority.
Ting He- Qinan Tang- Qiaoju Ren- Yurong Liu- Gang He- Yuantao Pan- Ziguang Wang- Peng Huang- Jing Lin,Different Valence States of Copper Ion Delivery against Triple-Negative Breast Cancer.,The early detection of breast cancer is crucial for both accelerating the treatment process and preventing the spread of cancer. The accuracy of diagnosis is also significantly influenced by the experience of pathologists. Many studies have been conducted on the correct diagnosis of breast cancer to help specialists and increase the accuracy of diagnosis. This study focuses on classifying breast cancer using deep learning models- including pre-trained VGG16- MobileNet- DenseNet201- and a custom-built Convolutional Neural Network (CNN)- with the final dense layer optimized via the particle swarm optimization (PSO) algorithm. The Breast Histopathology Images Dataset was used to evaluate the performance of the model- forming two datasets: one with 157-572 images at 50 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 50 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 3 (Experimental Study 1) and another with 1116 images resized to 224 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 224 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 3 (Experimental Study 2). Both original (50 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 50 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 3) and rescaled (224 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 224 â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢ 3) images were tested. The highest success rate was obtained using the custom-built CNN model with an accuracy rate of 93.80% for experimental study 1. The MobileNet model yielded an accuracy of 95.54% for experimental study 2. The experimental results demonstrate that the proposed model exhibits promising- and superior classification accuracy compared to state-of-the-art methods across varying image sizes and dataset volumes.
Adhari AlZaabi- Stephen Piccolo- Steven Graves- Marc Hansen,Differential Serum Peptidomics Reveal Multi-Marker Models That Predict Breast Cancer Progression,Breast cancer- as a malignant tumor disease- has maintained high incidence and mortality rates over the years. Ultrasonography is one of the primary methods for diagnosing early-stage breast cancer. However- correctly interpreting breast ultrasound images requires massive time from physicians with specialized knowledge and extensive experience. Recently- deep learning-based method have made significant advancements in breast tumor segmentation and classification due to their powerful fitting capabilities. However- most existing methods focus on performing one of these tasks separately- and often failing to effectively leverage information from specific tumor-related areas that hold considerable diagnostic value. In this study- we propose a multi-task network with local-global feature interaction and multiple tumoral region guidance for breast ultrasound-based tumor segmentation and classification. Specifically- we construct a dual-stream encoder- paralleling CNN and Transformer- to facilitate hierarchical interaction and fusion of local and global features. This architecture enables each stream to capitalize on the strengths of the other while preserving its unique characteristics. Moreover- we design a multi-tumoral region guidance module to explicitly learn long-range non-local dependencies within intra-tumoral and peri-tumoral regions from spatial domain- thus providing interpretable cues beneficial for classification. Experimental results on two breast ultrasound datasets show that our network outperforms state-of-the-art methods in tumor segmentation and classification tasks. Compared with the second-best competitive method- our network improves the diagnosis accuracy from 73.64% to 80.21% on a large external validation dataset- which demonstrates its superior generalization capability.
Neil M. Iyengar- Erica Salehi- Jessica A Lavery- Olivia Chan- Sarah Lehman- M. Michalski- Gina A Fickera- Adele M. Carlson- Jenna Harrison- Whitney P Underwood- Cara Anselmo- Su S Chun- Stephanie Cao- Catherine P. Lee- Wendy Demark-Wahnefried- C. Moskowitz- Lee W. Jones,Effects of plant-based diet (PBD) and exercise therapy (Ex) on weight and body composition in patients with primary hormone receptor (HR) positive breast cancer: A phase 2 randomized controlled trial.,Breast cancer (BC) is the leading cause of mortality among women across the world. Earlier screening of BC can significantly reduce the mortality rate and assist the diagnostic process to increase the survival rate. Researchers employ deep learning (DL) techniques to detect BC using mammogram images. However- these techniques are resource-intensive- leading to implementation complexities in real-life environments. The performance of convolutional neural network (CNN) models depends on the quality of mammogram images. Thus- this study aimed to build a model to detect BC using a DL technique. Image preprocessing techniques were used to enhance image quality. The authors developed a CNN model using the EfficientNet B7 modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s weights to extract the image features. Multi-class classification of BC images was performed using the LightGBM model. The Optuna algorithm was used to fine-tune LightGBM for image classification. In addition- a quantization-aware training (QAT) strategy was followed to implement the proposed model in a resource-constrained environment. The authors generalized the proposed model using the CBIS-DDSM and CMMD datasets. Additionally- they combined these two datasets to ensure the modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s generalizability to diverse images. The experimental findings revealed that the suggested BC detection model produced a promising result. The proposed BC detection model obtained an accuracy of 99.4%- 99.9%- and 97.0%- and Kappa (K) values of 96.9%- 96.9%- and 94.1% in the CBIS-DDSM- CMMD- and combined datasets. The recommended model streamlined the BC detection process in order to achieve an exceptional outcome. It can be deployed in a real-life environment to support physicians in making effective decisions. Graph convolutional networks can be used to improve the performance of the proposed model.
Zi-Han Yu- Yu-Ting Hong- Chen-Pin Chou,Enhancing Breast Cancer Diagnosis: A Nomogram Model Integrating AI Ultrasound and Clinical Factors,Axillary lymph node (ALN) status is a crucial prognostic indicator for breast cancer metastasis- with manual interpretation of whole slide images (WSIs) being the current standard practice. However- this method is subjective and time-consuming. Recent advancements in deep learning-based methods for medical image analysis have shown promise in improving clinical diagnosis. This study aims to leverage these technological advancements to develop a deep learning model based on features extracted from primary tumor biopsies for preoperatively identifying ALN metastasis in early-stage breast cancer patients with negative nodes. We present DLCNBC-SA- a deep learning-based network specifically tailored for core needle biopsy and clinical data feature extraction- which integrates a self-attention mechanism (CNBC-SA). The proposed model consists of a feature extractor based on convolutional neural network (CNN) and an improved self-attention mechanism module- which can preserve the independence of features in WSIs for analysis and enhancement to provide rich feature representation. To validate the performance of the proposed model- we conducted comparative experiments and ablation studies using publicly available datasets- and verification was performed through quantitative analysis. The comparative experiment illustrates the superior performance of the proposed model in the task of binary classification of ALNs- as compared to alternative methods. Our method achieved outstanding performance [area under the curve (AUC): 0.882] in this task- significantly surpassing the state-of-the-art (SOTA) method on the same dataset (AUC: 0.862). The ablation experiment reveals that incorporating RandomRotation data augmentation technology and utilizing Adadelta optimizer can effectively enhance the performance of the proposed model. The experimental results demonstrate that the model proposed in this paper outperforms the SOTA model on the same dataset- thereby establishing its reliability as an assistant for pathologists in analyzing WSIs of breast cancer. Consequently- it significantly enhances both the efficiency and accuracy of doctors during the diagnostic process.
Yasemin â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶Â¬âˆžetin-Kaya,Equilibrium Optimization-Based Ensemble CNN Framework for Breast Cancer Multiclass Classification Using Histopathological Image,This study explores the integration of Raman spectroscopy (RS) with machine learning for the early detection and subtyping of breast cancer using blood plasma samples. We performed detailed spectral analyses- identifying significant spectral patterns associated with cancer biomarkers. Our findings demonstrate the potential for classifying the four major subtypes of breast cancer at stage Ia with an average sensitivity and specificity of 90% and 95%- respectively- and a cross-validated macro-averaged area under the curve (AUC) of 0.98. This research highlights efforts to integrate vibrational spectroscopy with machine learning- enhancing cancer diagnostics through a non-invasive- personalised approach for early detection and monitoring disease progression. This study is the first of its kind to utilise RS and machine learning to classify the four major breast cancer subtypes at stage Ia.
Avisha Das- Amara Tariq- Felipe Batalini- Boddhisattwa Dhara- Imon Banerjee,Exposing Vulnerabilities in Clinical LLMs Through Data Poisoning Attacks: Case Study in Breast Cancer,Brain tumours- breast cancer- and pneumonia are significant diseases causing a substantial number of deaths globally. These diseases affect a great part of the world- including India. Research on early detection strategies is critical for saving lives. This proposal describes a unique way to use deep learning approaches to detect three common diseases: breast cancer- brain tumours- and pneumonia. This approach aims to improve treatment outcomes and diagnostic accuracy by integrating a range of medical imaging modalities tailored to individual diseases. In similar challenges- DCNNs have demonstrated remarkable speed and accuracy- demonstrating their potential to enhance medical diagnosis. DCNN models can help medical professionals by providing accurate and automated illness identification- especially for areas with a shortage of radiologists.
Basamma Patil- Vishwanath P- Mohammed Al-Farouni- B. Sathyavani- P. Pareek,Improved Butterfly Optimization Algorithm for Automated Breast Cancer Detection and Classification using Deep Learning,Breast cancer is considered one of the most-common types of cancers among females in the world- with a high mortality rate. Medical imaging is still one of the most-reliable tools to detect breast cancer. Unfortunately- manual image detection takes much time. This paper proposes a new deep learning method based on Convolutional Neural Networks (CNNs). Convolutional Neural Networks are widely used for image classification. However- the determination process for accurate hyperparameters and architectures is still a challenging task. In this work- a highly accurate CNN model to detect breast cancer by mammography was developed. The proposed method is based on the Particle Swarm Optimization (PSO) algorithm in order to look for suitable hyperparameters and the architecture for the CNN model. The CNN model using PSO achieved success rates of 98.23% and 97.98% on the DDSM and MIAS datasets- respectively. The experimental results proved that the proposed CNN model gave the best accuracy values in comparison with other studies in the field. As a result- CNN models for mammography classification can now be created automatically. The proposed method can be considered as a powerful technique for breast cancer prediction.
Lorenzo Gerratana- Andrew A Davis- Lorenzo Foffano- Carolina Reduzzi- Tania Rossi- Arielle Medford- Katherine Clifton- Ami N Shah- Leslie Bucheit- Marko Velimirovic- Sara Bandini- Charles S Dai- Firas Wehbe- William J Gradishar- Amir Behdad- Paola Ulivi- Cynthia X Ma- Fabio Puglisi- Aditya Bardia- Massimo Cristofanilli,Integrating machine learning-predicted circulating tumor cells (CTCs) and circulating tumor DNA (ctDNA) in metastatic breast cancer: A proof of principle study on endocrine resistance profiling,Early detection leading to timely treatment in the initial stages of cancer may decrease the breast cancer death rate. We propose deep learning techniques along with image processing for the detection of tumors. The availability of online datasets and advances in graphical processing units (GPU) have promoted the application of deep learning models for the detection of breast cancer. In this paper- deep learning models using convolutional neural network (CNN) have been built to automatically classify mammograms into benign and malignant. Issues like overfitting and dataset imbalance are overcome. Experimentation has been done on two publicly available datasets- namely mammographic image analysis society (MIAS) database and digital database for screening mammography (DDSM). Robustness of the models is accomplished by merging the datasets. In our experimentation- MatConvNet has achieved an accuracy of 94.2% on the merged dataset- performing the best amongst all the CNN models used individually. Hungarian optimization algorithm is employed for selection of individual CNN models to form an ensemble. Ensemble of CNN models led to an improved performance- resulting in an accuracy of 95.7%.
Hari Mohan Rai- Joon Yoo- Saurabh Agarwal- Neha Agarwal,LightweightUNet: Multimodal Deep Learning with GAN-Augmented Imaging Data for Efficient Breast Cancer Detection,Abstract Objective Breast cancer is one of the leading cancer causes among women worldwide. It can be classified as invasive ductal carcinoma (IDC) or metastatic cancer. Early detection of breast cancer is challenging due to the lack of early warning signs. Generally- a mammogram is recommended by specialists for screening. Existing approaches are not accurate enough for realâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢time diagnostic applications and thus require better and smarter cancer diagnostic approaches. This study aims to develop a customized machineâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢learning framework that will give more accurate predictions for IDC and metastasis cancer classification. Methods This work proposes a convolutional neural network (CNN) model for classifying IDC and metastatic breast cancer. The study utilized a largeâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢scale dataset of microscopic histopathological images to automatically perceive a hierarchical manner of learning and understanding. Results It is evident that using machine learning techniques significantly (15%â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®25%) boost the effectiveness of determining cancer vulnerability- malignancy- and demise. The results demonstrate an excellent performance ensuring an average of 95% accuracy in classifying metastatic cells against benign ones and 89% accuracy was obtained in terms of detecting IDC. Conclusions The results suggest that the proposed model improves classification accuracy. Therefore- it could be applied effectively in classifying IDC and metastatic cancer in comparison to other stateâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢ofâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢theâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ‘Â¢art models.
Xiao Guo- Jiaying Xing- Yuyan Cao- Wenchuang Yang- Xinlin Shi- Runhong Mu- Tao Wang,Machine learning based anoikis signature predicts personalized treatment strategy of breast cancer,The vision transformer (ViT) architecture- with its attention mechanism based on multi-head attention layers- has been widely adopted in various computer-aided diagnosis tasks due to its effectiveness in processing medical image information. ViTs are notably recognized for their complex architecture- which requires high-performance GPUs or CPUs for efficient model training and deployment in real-world medical diagnostic devices. This renders them more intricate than convolutional neural networks (CNNs). This difficulty is also challenging in the context of histopathology image analysis- where the images are both limited and complex. In response to these challenges- this study proposes a TokenMixer hybrid-architecture that combines the strengths of CNNs and ViTs. This hybrid architecture aims to enhance feature extraction and classification accuracy with shorter training time and fewer parameters by minimizing the number of input patches employed during training- while incorporating tokenization of input patches using convolutional layers and encoder transformer layers to process patches across all network layers for fast and accurate breast cancer tumor subtype classification. The TokenMixer mechanism is inspired by the ConvMixer and TokenLearner models. First- the ConvMixer model dynamically generates spatial attention maps using convolutional layers- enabling the extraction of patches from input images to minimize the number of input patches used in training. Second- the TokenLearner model extracts relevant regions from the selected input patches- tokenizes them to improve feature extraction- and trains all tokenized patches in an encoder transformer network. We evaluated the TokenMixer model on the BreakHis public dataset- comparing it with ViT-based and other state-of-the-art methods. Our approach achieved impressive results for both binary and multi-classification of breast cancer subtypes across various magnification levels (40â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 100â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 200â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢- 400â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶â€šÃ¢â€¢). The model demonstrated accuracies of 97.02% for binary classification and 93.29% for multi-classification- with decision times of 391.71 and 1173.56Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ s- respectively. These results highlight the potential of our hybrid deep ViT-CNN architecture for advancing tumor classification in histopathological images. The source code is accessible: https://github.com/abimouloud/TokenMixer .
Robert T Novo- Samantha M Thomas- Michel G Khouri- Fawaz Alenezi- James E Herndon- Meghan Michalski- Kereshmeh Collins- Tormod Nilsen- Elisabeth Edvardsen- Lee W Jones- Jessica M Scott,Machine Learning-Driven Phenogrouping and Cardiorespiratory Fitness Response in Metastatic Breast Cancer,"To develop and evaluate an AI algorithm that detects breast cancer in MRI scans up to one year before radiologists typically identify it- potentially enhancing early detection in high-risk women. A convolutional neural network (CNN) AI model- pre-trained on breast MRI data- was fine-tuned using a retrospective dataset of 3029 MRI scans from 910 patients. These contained 115 cancers that were diagnosed within one year of a negative MRI. The model aimed to identify these cancers- with the goal of predicting cancer development up to one year in advance. The network was fine-tuned and tested with 10-fold cross-validation. Mean age of patients was 52 years (range- 18-88 years)- with average follow-up of 4.3 years (range 1-12 years). The AI detected cancers one year earlier with an area under the ROC curve of 0.72 (0.67-0.76). Retrospective analysis by a radiologist of the top 10% highest risk MRIs as ranked by the AI could have increased early detection by up to 30%. (35/115- CI:22.2-39.7%- 30% sensitivity). A radiologist identified a visual correlate to biopsy-proven cancers in 83 of prior-year MRIs (83/115- CI: 62.1-79.4%). The AI algorithm identified the anatomic region where cancer would be detected in 66 cases (66/115- CI:47.8-66.5%); with both agreeing in 54 cases (54/115- CI:%37.5-56.4%). This novel AI-aided re-evaluation of ""benign"" breasts shows promise for improving early breast cancer detection with MRI. As datasets grow and image quality improves- this approach is expected to become even more impactful."
Daniel â€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ Ã¶âˆšÃ±lvarez Sâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»nchez-Bayuela- Juan Fernâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»ndez Martâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ n- Gianluigi Tiberi- Navid Ghavami- Rubâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨Â¬Â©n Giovanetti Gonzâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»lez- Lina Marcela Cruz Hernâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»nez- Paul Martâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ n Aguilar Angulo- Aarâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„Â¢n Darâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ o Martâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ nez Gâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„Â¢mez- Ana Rodrâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚â€šÃ„Ã¶âˆšÂ¢â€šÃ„â€ guez Sâ€šÃ„Ã¶âˆšâ€ âˆšâˆ‚Â¬Â¨â€šÃ Ã»nchez- Alessandra Bigotti- Banafsheh Khalesi- Letizia Pontoriero- Massimo Calabrese- Alberto Stefano Tagliafico- Cristina Romero Castellano,Microwave imaging for breast cancer screening: protocol for an open- multicentric- interventional- prospective- non-randomised clinical investigation to evaluate cancer detection capabilities of MammoWave system on an asymptomatic population across multiple European countries,The rapid advancement of deep learning has generated considerable enthusiasm regarding its utilization in addressing medical imaging issues. Machine learning (ML) methods can help radiologists to diagnose breast cancer (BCs) barring invasive measures. Informative hand-crafted features are essential prerequisites for traditional machine learning classifiers to achieve accurate results- which are time-consuming to extract. In this paper- our deep learning algorithm is created to precisely identify breast cancers on screening mammograms- employing a training method that effectively utilizes training datasets with either full clinical annotation or solely the cancer status of the entire image. The proposed approach utilizes Lightweight Convolutional Neural Network (LWCNN) that allows automatic extraction features in an end-to-end manner. We have tested LWCNN model in two experiments. In the first experiment- the model was tested with two cases' original and enhancement datasets 1. It achieved 95Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- 93Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- 99Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % and 98Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % for training and testing accuracy respectively. In the second experiment- the model has been tested with two cases' original and enhancement datasets 2. It achieved 95Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- 91Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ %- 99Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % and 92Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ % for training and testing accuracy respectively. Our proposed method- which uses various convolutional network to classify screening mammograms achieved exceptional performance when compared to other methods. The findings from these experiments clearly indicate that automatic deep learning techniques can be trained effectively to attain remarkable accuracy across a wide range of mammography datasets. This holds significant promise for improving clinical tools and reducing both false positive and false negative outcomes in screening mammography.
Xia Wu- Mengxin Chen- Kang Liu- Yixin Wu- Yun Feng- Shiting Fu- Huaimeng Xu- Yongqi Zhao- Feilong Lin- Liang Lin- Shihui Ye- Junqiang Lin- Taiping Xiao- Wenhao Li- Meng Lou- Hongyu Lv- Ye Qiu- Ruifan Yu- Wenyan Chen- Mengyuan Li- Xu Feng- Zhongbing Luo- Lu Guo- Hao Ke- Limin Zhao,Molecular classification of geriatric breast cancer displays distinct senescent subgroups of prognostic significance,Purpose To combine deep learning and biology-based modeling to predict the response of locally advanced- triple-negative breast cancer before initiating neoadjuvant chemotherapy (NAC). Materials and Methods In this retrospective study- a biology-based mathematical model of tumor response to NAC was constructed and calibrated on a patient-specific basis using imaging data from patients enrolled in the MD Anderson A Robust TNBC Evaluation FraMework to Improve Survival trial (ARTEMIS; ClinicalTrials.gov registration no. NCT02276443) between April 2018 and May 2021. To relate the calibrated parameters in the biology-based model and pretreatment MRI data- a convolutional neural network (CNN) was employed. The CNN predictions of the calibrated model parameters were used to estimate tumor response at the end of NAC. CNN performance in the estimations of total tumor volume (TTV)- total tumor cellularity (TTC)- and tumor status was evaluated. Model-predicted TTC and TTV measurements were compared with MRI-based measurements using the concordance correlation coefficient and area under the receiver operating characteristic curve (for predicting pathologic complete response at the end of NAC). Results The study included 118 female patients (median age- 51 years [range- 29-78 years]). For comparison of CNN predicted to measured change in TTC and TTV over the course of NAC- the concordance correlation coefficient values were 0.95 (95% CI: 0.90- 0.98) and 0.94 (95% CI: 0.87- 0.97)- respectively. CNN-predicted TTC and TTV had an area under the receiver operating characteristic curve of 0.72 (95% CI: 0.34- 0.94) and 0.72 (95% CI: 0.40- 0.95) for predicting tumor status at the time of surgery- respectively. Conclusion Deep learning integrated with a biology-based mathematical model showed good performance in predicting the spatial and temporal evolution of a patient's tumor during NAC using only pre-NAC MRI data. Keywords: Triple-Negative Breast Cancer- Neoadjuvant Chemotherapy- Convolutional Neural Network- Biology-based Mathematical Model Supplemental material is available for this article. Clinical trial registration no. NCT02276443 Â¬Â¨Â¬Â®Â¬Â¨Â¬Â©RSNA- 2024 See also commentary by Mei and Huang in this issue.
Sang Won Park- Ye-Lin Park- Eun-Gyeong Lee- Heejung Chae- Phillip Park- Dong-Woo Choi- Yeon Ho Choi- Juyeon Hwang- Seohyun Ahn- Keunkyun Kim- Woo Jin Kim- Sun-Young Kong- So-Youn Jung- Hyun-Jin Kim,Mortality Prediction Modeling for Patients with Breast Cancer Based on Explainable Machine Learning,Background/Objectives: Breast cancer is a leading cause of mortality among women in Taiwan and globally. Non-invasive imaging methods- such as mammography and ultrasound- are critical for early detection- yet standalone modalities have limitations in regard to their diagnostic accuracy. This study aims to enhance breast cancer detection through a cross-modality fusion approach combining mammography and ultrasound imaging- using advanced convolutional neural network (CNN) architectures. Materials and Methods: Breast images were sourced from public datasets- including the RSNA- the PAS- and Kaggle- and categorized into malignant and benign groups. Data augmentation techniques were used to address imbalances in the ultrasound dataset. Three models were developed: (1) pre-trained CNNs integrated with machine learning classifiers- (2) transfer learning-based CNNs- and (3) a custom-designed 17-layer CNN for direct classification. The performance of the models was evaluated using metrics such as accuracy and the Kappa score. Results: The custom 17-layer CNN outperformed the other models- achieving an accuracy of 0.964 and a Kappa score of 0.927. The transfer learning model achieved moderate performance (accuracy 0.846- Kappa 0.694)- while the pre-trained CNNs with machine learning classifiers yielded the lowest results (accuracy 0.780- Kappa 0.559). Cross-modality fusion proved effective in leveraging the complementary strengths of mammography and ultrasound imaging. Conclusions: This study demonstrates the potential of cross-modality imaging and tailored CNN architectures to significantly improve diagnostic accuracy and reliability in breast cancer detection. The custom-designed model offers a practical solution for early detection- potentially reducing false positives and false negatives- and improving patient outcomes through timely and accurate diagnosis.
Qiang Li- George Teodoro- Yi Jiang- Jun Kong,NACNet: A histology context-aware transformer graph convolution network for predicting treatment response to neoadjuvant chemotherapy in Triple Negative Breast Cancer,Breast cancer is one of the most common causes of death in women in the modern world. Cancerous tissue detection in histopathological images relies on complex features related to tissue structure and staining properties. Convolutional neural network (CNN) models like ResNet50- Inception-V1- and VGG-16- while useful in many applications- cannot capture the patterns of cell layers and staining properties. Most previous approaches- such as stain normalization and instance-based vision transformers- either miss important features or do not process the whole image effectively. Therefore- a deep fusion-based vision Transformer model (DFViT) that combines CNNs and transformers for better feature extraction is proposed. DFViT captures local and global patterns more effectively by fusing RGB and stain-normalized images. Trained and tested on several datasets- such as BreakHis- breast cancer histology (BACH)- and UCSC cancer genomics (UC)- the results demonstrate outstanding accuracy- F1 score- precision- and recall- setting a new milestone in histopathological image analysis for diagnosing breast cancer.
Vijayshri Chaurasia- Mamta Patankar- Madhu Shandilya- Vivek Patel- Ebtasam Ahmad Siddiqui- Laxmi Kumre,Nucleion Segmentation for Breast Cancer Classification,Breast cancer is one of the most common cancers in the world- especially among women. Breast tumor segmentation is a key step in the identification and localization of the breast tumor region- which has important clinical significance. Inspired by the swin-transformer model with powerful global modeling ability- we propose a semantic segmentation framework named Swin-Net for breast ultrasound images- which combines Transformer and Convolutional Neural Networks (CNNs) to effectively improve the accuracy of breast ultrasound segmentation. Firstly- our model utilizes a swin-transformer encoder with stronger learning ability- which can extract features of images more precisely. In addition- two new modules are introduced in our method- including the feature refinement and enhancement module (RLM) and the hierarchical multi-scale feature fusion module (HFM)- given that the influence of ultrasonic image acquisition methods and the characteristics of tumor lesions is difficult to capture. Among them- the RLM module is used to further refine and enhance the feature map learned by the transformer encoder. The HFM module is used to process multi-scale high-level semantic features and low-level details- so as to achieve effective cross-layer feature fusion- suppress noise- and improve model segmentation performance. Experimental results show that Swin-Net performs significantly better than the most advanced methods on the two public benchmark datasets. In particular- it achieves an absolute improvement of 1.4â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®1.8% on Dice. Additionally- we provide a new dataset of breast ultrasound images on which we test the effect of our model- further demonstrating the validity of our method. In summary- the proposed Swin-Net framework makes significant advancements in breast ultrasound image segmentation- providing valuable exploration for research and applications in this domain.
Jung In Park- Steven Johnson- Lisiane Pruinelli,Optimizing pain management in breast cancer care: Utilizing 'All of Us' data and deep learning to identify patients at elevated risk for chronic pain,Segmentation is a technique for separating an image into discrete areas in order to separate objects of interest from their surroundings. In image analysis- segmentationâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶âˆšÃœwhich encompasses detection- feature extraction- classification- and treatmentâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶âˆšÃœis crucial. In order to plan treatments- segmentation aids doctors in measuring the amount of tissue in the breast. Categorizing the input data into two groups that are mutually exclusive is the aim of a binary classification problem. In this case- the training data is labeled in a binary format based on the problem being solved. Identifying breast lumps accurately in mammography pictures is essential for the purpose of prenatal testing for breast cancer. The proposed TLA (Transfer Learning Approach) based CNN (Convolution Neural Network) â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â®TLA based CNN aims to offer binary classification for rapid and precise breast cancer diagnosis (benign and malignant). In order to predict the sub-type of cancer- this exploration as used Deep Learning techniques on the Histogram of Oriented Gradient (HOG) - Feature extraction technique that creates a local histogram of the image to extract features from each place in the image with CNN classifier. This research work employs two well-known pre-trained models- ResNet-50 and VGG16- to extract characteristics from mammography images. The high-level features from the Mammogram dataset are extracted using a transfer learning model based on Visual Geometry Group (VGG) with 16-layer and Residual Neural Network with 50-layers deep model architecture (ResNet-50). The proposed model TLA based CNN has achieved 96.49% and 95.48% accuracy as compared to ResNet50 and VGG16 in the breast cancer classification and segmentation.
Yiannis Varnava- Kiran Jakate- Richard Garnett- Dimitrios Androutsos- Pascal N Tyrrell- April Khademi,Out-of-distribution generalization for segmentation of lymph node metastasis in breast cancer,This project- entitled â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Integrative Breast Cancer Detection: A Deep Learning Approach with Multi-Modal Data Fusion of Mammograms- Prescription- and Blood Reports-â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Å“Ã„ embodies a groundbreaking endeavor poised to revolutionize the landscape of breast cancer detection. By intricately weaving together a sophisticated deep learning framework- it aims not merely to improve but to fundamentally transform the diagnostic paradigm. At its core- this initiative seeks to synergize diverse datasets encompassing blood reports- prescription data- and mammograms- thus harnessing the collective power of multi-modal data fusion. Through the judicious integration of these disparate yet complementary sources of information- the project endeavors to transcend the limitations of conventional diagnostic approaches- heralding a new era of heightened precision and diagnostic efficacy. Employing cutting-edge methodologies such as Convolutional Neural Networks (CNNs)- it aims to unlock previously untapped potentials in breast cancer detection- pushing the boundaries of what is deemed possible. By harnessing the formidable computational prowess of CNNs- the goal is not only to enhance the accuracy of detection but also to streamline the diagnostic process- thereby empowering healthcare professionals with unprecedented insights and capabilities. However- the significance of this project extends beyond mere technological advancement; it embodies a holistic approach to healthcare that prioritizes the integration of disparate datasets- efficient resource allocation- and ultimately- the delivery of personalized and patient-centric care. By championing this holistic paradigm- the project endeavors to detect breast cancer at its earliest stages and empower patients and healthcare providers alike in the fight against this insidious disease. In essence- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Integrative Breast Cancer Detectionâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Å“Ã„ represents a bold and visionary initiative poised to redefine the standards of breast cancer diagnostics- ushering in a new era of precision medicine and personalized care.
Oluwatosin Seyi Oyebanji- Akinkunmi Rasheed APAMPA- Olugesun Afolabi- Samson Ohikhuare Eromonsei- Akeem Babalola,Performance benchmarking of convolutional neural networks and ensemble machine learning techniques for automated mammographic breast cancer detection: A comparative study,Abstract: Invasion of neighboring tissues is a cardinal feature of malignancy- notably observed in aggressive cancers like breast cancer- where it can lead to significant morbidity. To explore cancer invasion dynamics- the implementation of a three-dimensional (3D) tumor spheroid invasion assay offers a swift approach to mimicking a tumor micro-region or micro-metastasis. Differential Interference Contrast (DIC) time-lapse imaging was chosen for its fluorescence-free and non-destructive advantages in capturing live spheroid movement. However- the subsequent analysis posed challenges- including out-of-focus cells and a voluminous dataset with diverse microscope planes and time points. Our study introduces a segmentation framework featuring in-focus spatial stacking algorithm and novel training architecture that enabling in-depth automated analysis of 3D spheroid invasion behaviors within a microenvironment. Firstly- the MDA-MB-231 breast cancer spheroids were cultured in a microwell dish and then incorporated into a collagen type I matrix for the 3D spheroid invasion assay. Capturing spheroid invasion dynamics involved acquiring 15 z-plane images (spaced at 20 Â¬Â¨Â¬Â®Â¬Â¨Â¬Âµm intervals) per timepoint for each spheroid using DIC microscopy at 15-minute intervals over a 28-hour period- employing a 20X objective lens. We refined the Focus Stacking framework into Multiple Slices Blurry Stacking (MSB-Stack) by pre-filtering blurred areas before stacking images. This process produced 6390 slices consolidated into 426 labeled stacked images- highlighting Invasive area- Spheroid core- and Invasive cells post-invasion. We then enhanced Mask R-CNN (Region based-Convolutional Neural Networks) with a weak-to-strong augmentation mechanism- leveraging well-segmented samples from MSB-Stack for training on both fully stacked and blurred images. Blurry Consistency Mask R-CNN (BCMask R-CNN) demonstrates overall improvement across feature extractors- outperforming Mask R-CNN. Using Mean average precision (mAP) as the main metric for instance segmentation and detection- our proposed model achieves 73.0% and 65.2% on mAP @[0.5- 0.95]- showcasing robustness. Notably- our best results for mAP @0.5 reach 96.6% and 96.7% on both tasks- underscoring the effectiveness of consistency training in mitigating unclear boundary issues during preprocessing. In conclusion- our proposed method- MSB-Stack- effectively addresses the challenge of unclear boundaries in 3D breast cancer cell DIC microscopy datasets. The integration of weak-to-strong consistency training in our model- BCMask R-CNN- not only mitigates biases but also enhances performance across different backbones- setting the stage for future advancements in cell-tracking tasks and broader migratory analyses.
Andreas Ekholm- Yinxi Wang- Johan Vallon-Christersson- Constance Boissin- Mattias Rantalainen,Prediction of gene expression-based breast cancer proliferation scores from histopathology whole slide images using deep learning,Breast cancer is a leading cause of death among women- and early detection is crucial for improving survival rates. The manual breast cancer diagnosis utilizes more time and is subjective. Also- the previous CAD models mostly depend on manmade visual details that are complex to generalize across ultrasound images utilizing distinct techniques. Distinct imaging tools have been utilized in previous works such as mammography and MRI. However- these imaging tools are costly and less portable than ultrasound imaging. Also- ultrasound imaging is a non-invasive method commonly used for breast cancer screening. Hence- the paper presents a novel deep learning model- BCDNet- for classifying breast tumors as benign or malignant using ultrasound images. The primary aim of the study is to design an effective breast cancer diagnosis model that can accurately classify tumors in their early stages- thus reducing mortality rates. The model aims to optimize the weight and parameters using the RPAOSM-ESO algorithm to enhance accuracy and minimize false negative rates. The BCDNet model utilizes transfer learning from a pre-trained VGG16 network for feature extraction and employs an AHDNAM classification approach- which includes ASPP- DTCN- 1DCNN- and an attention mechanism. The RPAOSM-ESO algorithm is used to fine-tune the weights and parameters. The RPAOSM-ESO-BCDNet-based breast cancer diagnosis model provided 94.5 accuracy rates. This value is relatively higher than the previous models such as DTCN (88.2)- 1DCNN (89.6)- MobileNet (91.3)- and ASPP-DTC-1DCNN-AM (93.8). Hence- it is guaranteed that the designed RPAOSM-ESO-BCDNet produces relatively accurate solutions for the classification than the previous models. The BCDNet model- with its sophisticated feature extraction and classification techniques optimized by the RPAOSM-ESO algorithm- shows promise in accurately classifying breast tumors using ultrasound images. The study suggests that the model could be a valuable tool in the early detection of breast cancer- potentially saving lives and reducing the burden on healthcare systems.
Jing Wang- Baizhou Li- Meng Luo- Jia Huang- Kun Zhang- Shu Zheng- Suzhan Zhang- Jiaojiao Zhou,Progression from ductal carcinoma in situ to invasive breast cancer: molecular features and clinical significance,This study aims to assess the diagnostic value of ultrasound habitat sub-region radiomics feature parameters using a fully connected neural networks (FCNN) combination method L2-1-norm in relation to breast cancer Ki-67 status. Ultrasound images from 528 cases of female breast cancer at the Affiliated Hospital of Xiangnan University and 232 cases of female breast cancer at the Affiliated Rehabilitation Hospital of Xiangnan University were selected for this study. We utilized deep learning methods to automatically outline the gross tumor volume and perform habitat clustering. Subsequently- habitat sub-regions were extracted to identify radiomics features and underwent feature engineering using the L1-2-norm. A prediction model for the Ki-67 status of breast cancer patients was then developed using a FCNN. The model's performance was evaluated using accuracy- area under the curve (AUC)- specificity (Spe)- positive predictive value (PPV)- negative predictive value (NPV)- Recall- and F1. In addition- calibration curves and clinical decision curves were plotted for the test set to visually assess the predictive accuracy and clinical benefit of the models. Based on the feature engineering using the L1-2-norm- a total of 9 core features were identified. The predictive model- constructed by the FCNN model based on these 9 features- achieved the following scores: ACC 0.856- AUC 0.915- Spe 0.843- PPV 0.920- NPV 0.747- Recall 0.974- and F1 0.890. Furthermore- calibration curves and clinical decision curves of the validation set demonstrated a high level of confidence in the model's performance and its clinical benefit. Habitat clustering of ultrasound images of breast cancer is effectively supported by the combined implementation of the L1-2-norm and FCNN algorithms- allowing for the accurate classification of the Ki-67 status in breast cancer patients.
Debanjan Mukherjee- Sarjana Raikwar,Recent Update on Nanocarrier(s) as the Targeted Therapy for Breast Cancer,The objective is to evaluate the feasibility of utilizing ultrasound images in identifying critical prognostic biomarkers for HER2-positive breast cancer (HER2â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢+â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢BC). This study enrolled 512 female patients diagnosed with HER2-positive breast cancer through pathological validation at our institution from January 2016 to December 2021. Five distinct deep convolutional neural networks (DCNNs) and a deep ensemble (DE) approach were trained to classify axillary lymph node involvement (ALNM)- lymphovascular invasion (LVI)- and histological grade (HG). The efficacy of the models was evaluated based on accuracy- sensitivity- specificity- positive predictive value (PPV)- negative predictive value (NPV)- receiver operating characteristic (ROC) curves- areas under the ROC curve (AUCs)- and heat maps. DeLong test was applied to compare differences in AUC among different models. The deep ensemble approach- as the most effective model- demonstrated AUCs and accuracy of 0.869 (95% CI: 0.802-0.936) and 69.7% in LVI- 0.973 (95% CI: 0.949-0.998) and 73.8% in HG- thus providing superior classification performance in the context of imbalanced data (pâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢<â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬Â¢0.05 by the DeLong test). On ALNM- AUC and accuracy were 0.780 (95% CI: 0.688-0.873) and 77.5%- which were comparable to other single models. The pretreatment US-based DE model could hold promise as a clinical guidance for predicting pathological characteristics of patients with HER2-positive breast cancer- thereby providing benefit of facilitating timely adjustments in treatment strategies.
Xiu-Ying Tang- Yu-Xian Wei- Ling-Na Kong- Fang Lu,Relationship between social support and self-care ability among patients with breast cancer during rehabilitation: The multiple mediating roles of resilience and depression,In this research- we present a Convolutional Neural Network (CNN) model designed to improve the detection and classification of breast cancer from mammographic images. By categorizing images as normal- benign- or malignant- our simplified CNN model aims to increase the precision and speed of breast cancer screenings. The effectiveness of the model was validated using established MIAS and DDSM datasets- where it achieved impressive precision rates of 94.23% and 95.53%- respectively. Moreover- the modelâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s performance further improved- reaching an accuracy of 96.67%- when assessed on a combined dataset. These results demonstrate the considerable potential of leveraging CNN-based deep learning techniques to enhance early detection practices in breast cancer care- offering new prospects for clinical application and advancements in medical imaging technologies.
Rashed Al Amin- Roman Obermaisser,Resource-Efficient FPGA Implementation for Real-Time Breast Cancer Classification Using Custom CNNs,BACKGROUND This study evaluated the accuracy- clinical concordance- and readability of the chatbot interface generative pretrained transformer (ChatGPT) 3.5 as a source of breast cancer information for patients. METHODS Twenty questions that patients are likely to ask ChatGPT were identified by breast cancer advocates. These were posed to ChatGPT 3.5 in July 2023 and were repeated three times. Responses were graded in two domains: accuracy (4-point Likert scale- 4Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ worst) and clinical concordance (information is clinically similar to physician response; 5-point Likert scale- 5Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ not similar at all). The concordance of responses with repetition was estimated using intraclass correlation coefficient (ICC) of word counts. Response readability was calculated using the Flesch Kincaid readability scale. References were requested and verified. RESULTS The overall average accuracy was 1.88 (range 1.0-3.0; 95% confidence interval [CI]- 1.42-1.94)- and clinical concordance was 2.79 (range 1.0-5.0; 95% CI- 1.94-3.64). The average word count was 310 words per response (range- 146-441 words per response) with high concordance (ICC- 0.75; 95% CI- 0.59-0.91; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ <Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .001). The average readability was poor at 37.9 (range- 18.0-60.5) with high concordance (ICC- 0.73; 95% CI- 0.57-0.90; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ <Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .001). There was a weak correlation between ease of readability and better clinical concordance (-0.15; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .025). Accuracy did not correlate with readability (0.05; pÂ¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ =Â¬Â¨Â¬Â®â€šÃ„Ã¶âˆšÃ‘â€šÃ„â€ .079). The average number of references was 1.97 (range- 1-4; total- 119). ChatGPT cited peer-reviewed articles only once and often referenced nonexistent websites (41%). CONCLUSIONS Because ChatGPT 3.5 responses were incorrect 24% of the time and did not provide real references 41% of the time- patients should be cautioned about using ChatGPT for medical information.
Yanfeng Li- Wengxing Long- Hongda Zhou- Tao Tan- Hui Xie,Revolutionizing breast cancer Ki-67 diagnosis: ultrasound radiomics and fully connected neural networks (FCNN) combination method,High breast density found using mammographs (MGs) reduces positivity rates and is considered a risk factor for breast cancer. Research on the relationship between Volpara density grade (VDG) and compressed breast thickness (CBT) in the Japanese population is still lacking. Moreover- little attention has been paid to pseudo-dense breasts with CBT < 30 mm among high-density breasts. We investigated VDG- CBT- and apparent high breast density in patients with breast cancer. Women who underwent MG and breast cancer surgery at our institution were included. VDG and CBT were measured. VDG was divided into a non-dense group (NDG) and a dense group (DG). This study included 419 patients. VDG was negatively correlated with CBT. The DG included younger patients with lower body mass index (BMI) and thinner CBT. In the DG- patients with CBT < 30 mm had lower BMI and higher VDG; however- no significant difference was noted in the positivity rate of the two groups. Younger women tend to have higher breast density- resulting in thinner CBT- which may pose challenges in detecting breast cancer on MGs. However- there was no significant difference in the breast cancer detection rate between CBT < 30 mm and CBT â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶Â¬Â¢â€šÃ„Ã¶âˆšÃ‘Â¬Â¢ 30 mm.
Arezou Ashari- Neda SoleimanvandiAzar- Marzieh Nojomi- Hadi Ranjbar- Kamran Mirzaei- Nahid Nafissi- Mahshid Roohravan Benis- Zahra Rampisheh,Risk perception regarding social determinants of health among women with breast cancer in Iran: a qualitative study,Early screening of breast cancer through image recognition technology can significantly increase the survival rate of patients. Therefore- breast cancer pathological image is of great significance for medical diagnosis and clinical research. In recent years- numerous deep learning models have been applied to breast cancer image classification- with deep CNN being a typical representative. Due to the use of multi-depth small convolutional kernels in mainstream CNN architectures such as VGG and Inception- the obtained image features often have high dimensionality. Although high dimensionality can bring more fine-grained features- it also increases the computational complexity of subsequent classifiers and may even lead to the curse of dimensionality and overfitting. To address these issues- a novel embedded kernel CNN principal component feature fusion (CNN-PCFF) algorithm is proposed. The constructed kernel function is embedded in the principal component analysis to form the multi-kernel principal component. Multi-kernel principal component analysis is used to fuse the high dimensional features obtained from the convolution base into some representative comprehensive variables- which are called kernel principal components- so as to achieve the purpose of dimensionality reduction. Any type of classifier can be added based on multi-kernel principal components. Through experimental analysis on two public breast cancer image datasets- the results show that the proposed algorithm can improve the performance of the current mainstream CNN architecture and subsequent classifiers. Therefore- the proposed algorithm in this paper is an effective tool for the classification of breast cancer pathological images.
Shengnan Hao- Yihan Jia- Jianuo Liu- Zhiwu Wang- Chunling Liu- Zhanlin Ji- Ivan Ganchev,ST-Double-Net: A Two-Stage Breast Tumor Classification Model Based on Swin Transformer and Weakly Supervised Target Localization,"The Deep learning (DL) models for diagnosing breast cancer from mammographic images often operate as""black boxes""- making it difficult for healthcare professionals to trust and understand their decision-making processes. The study presents an integrated framework combining Convolutional Neural Networks (CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an elaborate data preprocessing pipeline and advanced data augmentation techniques to counteract dataset limitations and transfer learning using pre-trained networks such as VGG-16- Inception-V3 and ResNet was employed. A focal point of our study is the evaluation of XAI's effectiveness in interpreting model predictions- highlighted by utilizing the Hausdorff measure to assess the alignment between AI-generated explanations and expert annotations quantitatively. This approach is critical for XAI in promoting trustworthiness and ethical fairness in AI-assisted diagnostics. The findings from our research illustrate the effective collaboration between CNNs and XAI in advancing diagnostic methods for breast cancer- thereby facilitating a more seamless integration of advanced AI technologies within clinical settings. By enhancing the interpretability of AI driven decisions- this work lays the groundwork for improved collaboration between AI systems and medical practitioners- ultimately enriching patient care. Furthermore- the implications of our research extended well beyond the current methodologies. It encourages further research into how to combine multimodal data and improve AI explanations to meet the needs of clinical practice."
Boya Manasa Sai- Yirivinti Hayagreeva Dinakar- Hitesh Kumar- Rupshee Jain- Sharyu Kesharwani- Siddharth S Kesharwani- Shyam Lal Mudavath- Ajmeer Ramkishan- Vikas Jain,Therapeutic delivery of siRNA for the management of breast cancer and triple-negative breast cancer,Breast cancer is the most prevalent cancer among women globally- making early and accurate detection essential for effective treatment and improved survival rates. This paper presents a method designed to detect and localize breast cancer using deep learning- specifically convolutional neural networks. The approach classifies histological images of breast tissue as either tumor-positive or tumor-negative. We utilize several deep learning models- including a custom-built CNN- EfficientNet- ResNet50- VGG-16- VGG-19- and MobileNet. Fine-tuning was also applied to VGG-16- VGG-19- and MobileNet to enhance performance. Additionally- we introduce a novel deep learning model called MR_Net- aimed at providing a more accurate network for breast cancer detection and localization- potentially assisting clinicians in making informed decisions. This model could also accelerate the diagnostic process- enabling early detection of the disease. Furthermore- we propose a method for explainable predictions by generating heatmaps that highlight the regions within tissue images that the model focuses on when predicting a label- revealing the detection of benign- atypical- and malignant tumors. We evaluate both the quantitative and qualitative performance of MR_Net and the other models- also presenting explainable results that allow visualization of the tissue areas identified by the model as relevant to the presence of breast cancer.
A. Tien- M. Sadar,Treatments Targeting the Androgen Receptor and Its Splice Variants in Breast Cancer,Cytological evaluation through microscopic image analysis of fine needle aspiration cytology (FNAC) is pivotal in the initial screening of breast cancer. The sensitivity of FNAC as a screening tool relies on both image quality and the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s expertise. To enhance diagnostic accuracy and alleviate the pathologistâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s workload- a computer-aided diagnosis (CAD) system was developed. A comparative study was conducted- assessing twelve candidate pre-trained models. Utilizing a locally gathered FNAC image dataset- three superior models-MobileNet-V2- DenseNet-121- and Inception-V3-were selected based on their training- validation- and testing accuracies. Further- these models underwent evaluation in four transfer learning scenarios to enhance testing accuracy. While the outcomes were promising- they left room for improvement- motivating us to create a novel deep convolutional neural network (CNN). The newly proposed model exhibited robust performance with testing accuracy at 85%. Our research concludes that the most lightweight- high-accuracy model is the one we propose. Weâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ve integrated it into our user-friendly Android App- â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶â€šÃ Â´Breast Cancer Detection System-â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Å“Ã„ in TensorFlow Lite format- with cloud database support- showcasing its effectiveness. Implementing an artificial intelligent (AI)-based diagnosis system with a user-friendly interface holds the potential to enhance early breast cancer detection using FNAC.
Ya-Yu Sun- Xiao-Tong Shi- Li-Long Xu,Ultrasound for breast cancer detection: A bibliometric analysis of global trends between 2004 and 2024,Breast cancer has been one of the main causes of death among women recently- and it has been the focus of attention of many specialists and researchers in the health field. Because of its seriousness and spread speed- breast cancer-resisting methods- early diagnosis- diagnosis- and treatment have been the points of research discussion. Many computers-aided diagnosis (CAD) systems have been proposed to reduce the load on physicians and increase the accuracy of breast tumor diagnosis. To the best of our knowledge- combining patient information- including medical history- breast density- age- and other factors- with mammogram features from both breasts in craniocaudal (CC) and mediolateral oblique (MLO) views has not been previously investigated for breast tumor classification. In this paper- we investigated the effectiveness of using those inputs by comparing two combination approaches. The soft voting approach- produced from statistical information-based models (decision tree- random forest- K-nearest neighbor- Gaussian naive Bayes- gradient boosting- and MLP) and an image-based model (CNN)- achieved 90% accuracy. Additionally- concatenating statistical and image-based features in a deep learning model achieved 93% accuracy. We found that it produced promising results that would enhance the CAD systems. As a result- this study finds that using both sides of mammograms outperformed the result of using only the infected side. In addition- integrating the mammogram features with statistical information enhanced the accuracy of the tumor classification. Our findings- based on a novel dataset- incorporate both patient information and four-view mammogram images- covering multiple classes: normal- benign- and malignant.
Di Zhang- Wang Zhou- Wenpeng Lu- Xia-Chuan Qin- Xian-Ya Zhang- Jun-Li Wang- Jun Wu- Yan-Hong Luo- Yayang Duan- Chao-Xue Zhang,Ultrasound-Based Deep Learning Radiomics Nomogram for the Assessment of Lymphovascular Invasion in Invasive Breast Cancer: A Multicenter Study.,Background: Breast cancer is one of the leading causes of death in women- making early detection through mammography crucial for improving survival rates. However- human interpretation of mammograms is often prone to diagnostic errors. This study addresses the challenge of improving the accuracy of breast cancer detection by leveraging advanced machine learning techniques. Methods: We propose an extended ensemble deep learning model that integrates three state-of-the-art convolutional neural network (CNN) architectures: VGG16- DenseNet121- and InceptionV3. The model utilizes multi-scale feature extraction to enhance the detection of both benign and malignant masses in mammograms. This ensemble approach is evaluated on two benchmark datasets: INbreast and CBIS-DDSM. Results: The proposed ensemble model achieved significant performance improvements. On the INbreast dataset- the ensemble model attained an accuracy of 90.1%- recall of 88.3%- and an F1-score of 89.1%. For the CBIS-DDSM dataset- the model reached 89.5% accuracy and 90.2% specificity. The ensemble method outperformed each individual CNN model- reducing both false positives and false negatives- thereby providing more reliable diagnostic results. Conclusions: The ensemble deep learning model demonstrated strong potential as a decision support tool for radiologists- offering more accurate and earlier detection of breast cancer. By leveraging the complementary strengths of multiple CNN architectures- this approach can improve clinical decision making and enhance the accessibility of high-quality breast cancer screening.
Alexander S Millar- John Arnn- Sam Himes- Julio C. Facelli,Uncertainty in Breast Cancer Risk Prediction: A Conformal Prediction Study of Race Stratification,Breast cancer (BC) is one of the most fatal forms of cancer- making it a significant contributor to mortality rates worldwide. Early detection and timely treatment of breast cancer are crucial in reducing its mortality rate. To ensure a healthy lifestyle- it is essential to develop systems that can accurately diagnose breast cancer. Recent advances in modern computing and information technologies have enabled significant progress in the early detection and prediction of diseases within healthcare systems. This study proposes a method for precise and automatic breast cancer prediction using deep-modified transfer learning-based Convolutional Neural Networks (CNNs). The CNN architectures employed include ResNet50- MobileNetV2- DenseNet121- and Xception- which serve as feature extractors to capture the most relevant features of breast Ultrasound images (BUSI). These extracted features are then accurately classified as benign or malignant using various high-performance classifiers- including Support Vector Machine (SVM)- K-Nearest Neighbors (KNN)- XGBoost- and Softmax. The experimental results demonstrate that the proposed deep modified DenseNet121 network with the Softmax classifier outperformed other models and existing techniques. This latter achieved remarkable performance metrics- including an accuracy of 95.34%- a precision of 90.90%- and an F1 score of 93.02%. These results highlight the effectiveness of our approach in enhancing the accuracy of breast cancer prediction. The superior performance of the proposed method provides significant improvements in decision-making speed and reduces the time- effort- and laboratory resources required for healthcare services. Consequently- this method has the potential to significantly enhance early diagnosis and enable more tailored treatment plans- ultimately contributing to better patient outcomes and reducing the overall mortality rates associated with breast cancer.
Shiping Li- Yihao Lin- Guangyu Liu- Zhimin Shao- Yinlong Yang,Unveiling the potential of breast MRI: a game changer for BI-RADS 4A microcalcifications.,Breast cancer can progress silently in its early stages and frequently without noticeable symptoms. However- it poses a serious risk to women. It is imperative to recognize this potential health concern to mitigate it early. In the last few years- Convolutional Neural Networks (CNNs) have advanced significantly in their ability to classify images of breast cancer. Their capacity to automatically extract discriminant features from images has enhanced the performances and accuracy of image classification tasks. They outperform state-of-the-art techniques in this area. Furthermore- complicated models that were first learned for certain tasks can be easily adapted to complete new tasks by using transfer-learning approaches. However- deep learning-based categorization techniques could experience overfitting issues- particularly in cases where the dataset is small. The primary goal of this work is to investigate the performances of certain deep learning models to classify breast cancer images and to study the effects of data augmentation techniques- such as image rotation or displacement when utilizing a transfer learning approach. Using certain image datasets- the ResNet18- Resnet50- and VGG16 models demonstrated accuracy improvements- according to our experimental results.
Yudong Zhang- Deguang Kong- Juanjuan Li- Tao Yang- Feng Yao- Ge Yang,Using Segment-Level Attention to Guide Breast Ultrasound Video Classification,Recent advances in artificial intelligence (AI)- notably deep learning- have sparked widespread curiosity with bioinformatics- particularly the challenges presented by medical imaging. Itâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s been really helpful in enabling the Computer Aided Diagnosis CAD system to provide precise outcomes. Nonetheless- it is still a difficult task to identify breast cancer in mammography images. The purpose of this effort is to lower False Positive Rate FPR and False Negative Rate FNR and increase Matthewsâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s correlation coefficient MCC value. Two highly tailored object detection models- YOLOv5 and Mask R-CNN- are utilized to get the job done. YOLOv5 is able to detect the mass and determine whether it is benign or malignant. However- YOLOV5â€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s limited real estate necessitates certain tweaks to the original model in order to get the desired effects. Tumor borders and size are both identified by Mask RCNN as it traverses breast parenchyma in search of malignancies. Stages of cancer are based on the magnitude of the patientsâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢ tumours. This model employs YOLOv5+Mask RCNN and is trained on the INbreast- CBIS-DDSM- and BNS dataset. The proposed model is compared against the baseline version of YOLOv5 to determine how well it performs. The proposed method improves performance- with an FPR of 0.049%- a FNR of 0.029%- and a high MCC value of 92.02%. Based on the results of the studies- combining YOLOv5 with Mask RCNN improves accuracy by 0.06 percentage points compared to using either method alone. Furthermore- this effort may aid in determining the patientâ€šÃ„Ã¶âˆšÃ‘âˆšâˆ‚â€šÃ Ã¶âˆšÃ«â€šÃ Ã¶Â¬â€¢s prognosis and allowing clinicians to be more accurate and predictable in the diagnosing process at an early stage.
Kate E Dibble- Shoshana M Rosenberg- Craig Snow- Gregory J Kirkner- Nabihah Tayob- Magnolia Contreras- Noel D Roma- Cecilia R DeGraffinreid- Timiya S Nolan- Dawn L Hershman- Michelle Naughton- Ann H Partridge,Young- Empowered & strong (YES): a study protocol paper for a randomized controlled trial of an mHealth symptom monitoring and self-management intervention for adolescent and young adult (AYA) breast cancer survivors,Applications of deep learning in medicine- like iden- tifying the kind of malignant cells- are common. Breast cancer is a most common type of cancer in women and it a main cause of death for women. There are three categories for the malignant cells: Normal- Mild- and Severe. Early diagnosis of the malignant cells can prevent these deaths. Numerous techniques- including MRIs- mammograms- ultrasounds- and biopsies- are used to identify cancerous cells. Hematoxylin and eosin-stained breast cancer histology photos are difficult to diagnose- labor-intensive- and frequently cause pathologists to disagree. Recent advances in deep learning have made histological image processing possible with convolutional neural networks (CNNs). Histology images of breast cancer are categorized into sub-classes based on general tissue structure and morphology- as well as the density- variabil- ity- and organize of the cells. These subclasses include benign- malignant- and normal. Using this information- extract features at the cell and tissue levels- respectively from histopathological images- in smaller and larger size patches. The dataset repository is where the input image was obtained. The image has to be pre- processed. The feature extraction must then be put into practice. The pre- processed image must then be segmented. The image must be divided. We are able to apply many neural network models- including VGG-19 and Convolutional Neural Network (CNN). The findings of the experiment indicate that the accuracy. The primary goal of our method is to identify or anticipate breast cancer based on the input image.
